Week 6
	-	Re-read N-squared paper
	-	Implemented N-squared classifier for determining similarity between questions and different sections of the textbook, used these similarity values to identify the knowledge dimension
	-	Implemented SVM for labelling questions along the cognitive dimension
	-	Implemented doc2vec to convert documents and questions to vector representation, and used these values to get cosine similarity between centroids of different cognitive levels and questions 
	-	Combined the 2 probability distributions to get a heatmap which was plotted and displayed on a GUI
	-	Brainstormed to find improvements to the existing system (@Mohit: write something about this... )

Week 7
	-	Read the SEMILAR paper
	-	Downloaded and experimented with SEMILAR code. Explored the various features available in the API
		-	Lexical similarity
		-	LSA
		-	LDA (seems to be the best method to use)
	-	Worked on improving the cognitive dimension classifier. Implemented document clustering code. Yet to do: look at recursive clustering (not able to find any information on the internet)
	-	Brainstormed on the best SEMILAR technique to use and how to incorporate it into our existing python code. Hence, downlaoded and expored jython (embedding Java in python)


