Brute Force and Exhaustive Search
Science is as far removed from brute force as this sword from a crowbar.
              --Edward Lytton (1803­1873), Leila, Book II, Chapter I
   Doing a thing well is often a waste of time.
           --Robert Byrne, a master pool and billiards player and a writer
   After introducing the framework and methods for algorithm analysis in the
   preceding chapter, we are ready to embark on a discussion of algorithm
   design strategies. Each of the next eight chapters is devoted to a particular design
   strategy. The subject of this chapter is brute force and its important special case,
   exhaustive search. Brute force can be described as follows:
   Brute force is a straightforward approach to solving a problem, usually
   directly based on the problem statement and definitions of the concepts
   involved.
   The "force" implied by the strategy's definition is that of a computer and
   not that of one's intellect. "Just do it!" would be another way to describe the
   prescription of the brute-force approach. And often, the brute-force strategy is
   indeed the one that is easiest to apply.
   As  an  example,  consider     the  exponentiation  problem:  compute     an  for     a
   nonzero number a and a nonnegative integer n. Although this problem might
   seem trivial, it provides a useful vehicle for illustrating several algorithm design
   strategies, including the brute force. (Also note that computing an mod m for some
   large integers is a principal component of a leading encryption algorithm.) By the
   definition of exponentiation,
                                  an = a  . . .  a .
                                             n times
                                                                                         97
         This suggests simply computing an by multiplying 1 by a n times.
         We have already encountered at least two brute-force algorithms in the book:
         the consecutive integer checking algorithm for computing gcd(m, n) in Section 1.1
         and the definition-based algorithm for matrix multiplication in Section 2.3. Many
         other examples are given later in this chapter. (Can you identify a few algorithms
         you already know as being based on the brute-force approach?)
         Though rarely a source of clever or efficient algorithms, the brute-force ap-
         proach should not be overlooked as an important algorithm design strategy. First,
         unlike some of the other strategies, brute force is applicable to a very wide va-
         riety of problems. In fact, it seems to be the only general approach for which it
         is more difficult to point out problems it cannot tackle. Second, for some impor-
         tant problems--e.g., sorting, searching, matrix multiplication, string matching--
         the brute-force approach yields reasonable algorithms of at least some practi-
         cal value with no limitation on instance size. Third, the expense of designing a
         more efficient algorithm may be unjustifiable if only a few instances of a prob-
         lem need to be solved and a brute-force algorithm can solve those instances with
         acceptable speed. Fourth, even if too inefficient in general, a brute-force algo-
         rithm can still be useful for solving small-size instances of a problem. Finally,
         a brute-force algorithm can serve an important theoretical or educational pur-
         pose as a yardstick with which to judge more efficient alternatives for solving a
         problem.
    3.1  Selection Sort and Bubble Sort
         In this section, we consider the application of the brute-force approach to the
         problem of sorting: given a list of n orderable items (e.g., numbers, characters
         from some alphabet, character strings), rearrange them in nondecreasing order.
         As we mentioned in Section 1.3, dozens of algorithms have been developed for
         solving this very important problem. You might have learned several of them in
         the past. If you have, try to forget them for the time being and look at the problem
         afresh.
         Now, after your mind is unburdened of previous knowledge of sorting algo-
         rithms, ask yourself a question: "What would be the most straightforward method
         for solving the sorting problem?" Reasonable people may disagree on the answer
         to this question. The two algorithms discussed here--selection sort and bubble
         sort--seem to be the two prime candidates.
         Selection Sort
         We start selection sort by scanning the entire given list to find its smallest element
         and exchange it with the first element, putting the smallest element in its final
         position in the sorted list. Then we scan the list, starting with the second element,
         to find the smallest among the last n - 1 elements and exchange it with the second
         element, putting the second smallest element in its final position. Generally, on the
ith pass through the list, which we number from 0 to n - 2, the algorithm searches
for the smallest item among the last n - i elements and swaps it with Ai:
                    A0  A1  . . .  Ai­1  Ai, . . . , Amin, . . . , An­1
                    in their final positions             the last n ­ i elements
After n - 1 passes, the list is sorted.
Here is pseudocode of this algorithm, which, for simplicity, assumes that the
list is implemented as an array:
ALGORITHM       SelectionSort(A[0..n - 1])
//Sorts a given array by selection sort
//Input: An array A[0..n - 1] of orderable elements
//Output: Array A[0..n - 1] sorted in nondecreasing order
for i  0 to n - 2 do
        min  i
        for j  i + 1 to n - 1 do
             if A[j ] < A[min]        min  j
        swap A[i] and A[min]
As an example, the action of the algorithm on the list 89, 45, 68, 90, 29, 34, 17
is illustrated in Figure 3.1.
The analysis of selection sort is straightforward. The input size is given by the
number of elements n; the basic operation is the key comparison A[j ] < A[min].
The number of times it is executed depends only on the array size and is given by
the following sum:
                n-2  n-1              n-2                                     n-2
        C(n) =                 1=          [(n - 1) - (i + 1) + 1] =               (n - 1 - i).
                i=0 j =i+1            i=0                                     i=0
                      | 89            45      68     90     29     34     17
                               17  |  45      68     90     29     34     89
                               17     29   |  68     90     45     34     89
                               17     29      34  |  90     45     68     89
                               17     29      34     45  |  90     68     89
                               17     29      34     45     68  |  90     89
                               17     29      34     45     68     89  |  90
FIGURE  3.1  Example of sorting with selection sort. Each line corresponds to one
             iteration of the algorithm, i.e., a pass through the list's tail to the right
             of the vertical bar; an element in bold indicates the smallest element
             found. Elements to the left of the vertical bar are in their final positions and
             are not considered in this and subsequent iterations.
     Since we have already encountered the last sum in analyzing the algorithm of
     Example 2 in Section 2.3, you should be able to compute it now on your own.
     Whether you compute this sum by distributing the summation symbol or by
     immediately getting the sum of decreasing integers, the answer, of course, must
     be the same:
                                n-2  n-1            n-2                      (n  -  1)n .
                   C(n) =                     1  =       (n  -  1  -  i)  =      2
                                  i=0 j =i+1        i=0
     Thus, selection sort is a     (n2) algorithm on all inputs. Note, however, that the
     number of key swaps is only     (n), or, more precisely, n - 1 (one for each repetition
     of the i loop). This property distinguishes selection sort positively from many other
     sorting algorithms.
     Bubble Sort
     Another brute-force application to the sorting problem is to compare adjacent
     elements of the list and exchange them if they are out of order. By doing it
     repeatedly, we end up "bubbling up" the largest element to the last position on
     the list. The next pass bubbles up the second largest element, and so on, until
     after n - 1 passes the list is sorted. Pass i (0  i  n - 2) of bubble sort can be
     represented by the following diagram:
                   A0, . . . , Aj ? Aj+1, . . . , An-i-1 | An-i  . . .  An-1
                                                                   in their final positions
     Here is pseudocode of this algorithm.
     ALGORITHM     BubbleSort(A[0..n - 1])
     //Sorts a given array by bubble sort
     //Input: An array A[0..n - 1] of orderable elements
     //Output: Array A[0..n - 1] sorted in nondecreasing order
     for i  0 to n - 2 do
     for j  0 to n - 2 - i do
                   if A[j + 1] < A[j ] swap A[j ] and A[j + 1]
     The action of the algorithm on the list 89, 45, 68, 90, 29, 34, 17 is illustrated
     as an example in Figure 3.2.
     The number of key comparisons for the bubble-sort version given above is
     the same for all arrays of size n; it is obtained by a sum that is almost identical to
     the sum for selection sort:
             89  ?           45           68          90           29          34        17
             45              89  ?        68          90           29          34        17
             45              68           89      ?   90    ?      29          34        17
             45              68           89          29           90      ?   34        17
             45              68           89          29           34          90     ?  17
             45              68           89          29           34          17     |  90
             45  ?           68  ?        89      ?   29              34       17     |  90
             45              68           29          89    ?         34       17     |  90
             45              68           29          34              89   ?   17     |  90
             45              68           29          34              17    |  89        90
                                                     etc.
FIGURE  3.2  First two passes of bubble sort on the list 89, 45, 68, 90, 29, 34, 17. A new
             line is shown after a swap of two elements is done. The elements to the
             right of the vertical bar are in their final positions and are not considered in
             subsequent iterations of the algorithm.
                                 n-2 n-2-i            n-2
                 C(n) =                           1=        [(n - 2 - i) - 0 + 1]
                                 i=0     j =0         i=0
                                 n-2                        (n  -     1)n
                             =        (n  -    1  -  i)  =         2           (n2).
                                 i=0
The number of key swaps, however, depends on the input. In the                               worst  case  of
decreasing arrays, it is the same as the number of key comparisons:
                             Sworst (n)   =   C(n)    =   (n  - 1)n            (n2).
                                                                2
As is often the case with an application of the brute-force strategy, the first
version of an algorithm obtained can often be improved upon with a modest
amount of effort. Specifically, we can improve the crude version of bubble sort
given above by exploiting the following observation: if a pass through the list
makes no exchanges, the list has been sorted and we can stop the algorithm
(Problem 12a in this section's exercises). Though the new version runs faster on
some inputs, it is still in      (n2) in the worst and average cases. In fact, even among
elementary sorting methods, bubble sort is an inferior choice, and if it were not for
its catchy name, you would probably have never heard of it. However, the general
lesson you just learned is important and worth repeating:
A first application of the brute-force approach often results in an algorithm
that can be improved with a modest amount of effort.
     Exercises 3.1
     1.  a.  Give an example of an algorithm that should not be considered an appli-
             cation of the brute-force approach.
         b.  Give an example of a problem that cannot be solved by a brute-force
             algorithm.
     2.  a.  What is the time efficiency of the brute-force algorithm for computing
             an as a function of n? As a function of the number of bits in the binary
             representation of n?
         b.  If you are to compute an mod m where a > 1 and n is a large positive integer,
             how would you circumvent the problem of a very large magnitude of an?
     3.  For each of the algorithms in Problems 4, 5, and 6 of Exercises 2.3, tell whether
         or not the algorithm is based on the brute-force approach.
     4.  a.  Design a brute-force algorithm for computing the value of a polynomial
                            p(x) = anxn + an-1xn-1 + . . . + a1x + a0
             at a given point x0 and determine its worst-case efficiency class.
                                                  (n2), design a linear algorithm for this
         b.  If the algorithm you designed is in
             problem.
         c.  Is it possible to design an algorithm with a better-than-linear efficiency for
             this problem?
     5.  A network topology specifies how computers, printers, and other devices
         are connected over a network. The figure below illustrates three common
         topologies of networks: the ring, the star, and the fully connected mesh.
             ring                                 star  fully connected mesh
         You are given a boolean matrix A[0..n - 1, 0..n - 1], where n > 3, which is
         supposed to be the adjacency matrix of a graph modeling a network with one
         of these topologies. Your task is to determine which of these three topologies,
         if any, the matrix represents. Design a brute-force algorithm for this task and
         indicate its time efficiency class.
     6.  Tetromino tilings  Tetrominoes are tiles made of four 1 × 1 squares. There
         are five types of tetrominoes shown below:
straight tetromino     square tetromino  L-tetromino       T-tetromino  Z-tetromino
     Is it possible to tile--i.e., cover exactly without overlaps--an 8 × 8 chessboard
     with
           a. straight tetrominoes?      b. square tetrominoes?
           c. L-tetrominoes?             d. T-tetrominoes?
           e. Z-tetrominoes?
7.   A stack of fake coins     There are n stacks of n identical-looking coins. All of
     the coins in one of these stacks are counterfeit, while all the coins in the other
     stacks are genuine. Every genuine coin weighs 10 grams; every fake weighs
     11 grams. You have an analytical scale that can determine the exact weight of
     any number of coins.
     a.  Devise a brute-force algorithm to identify the stack with the fake coins and
         determine its worst-case efficiency class.
     b. What is the minimum number of weighings needed to identify the stack
         with the fake coins?
8. Sort the list E, X, A, M, P , L, E in alphabetical order by selection sort.
9.   Is selection sort stable? (The definition of a stable sorting algorithm was given
     in Section 1.3.)
10.  Is it possible to implement selection sort for linked lists with the same       (n2)
     efficiency as the array version?
11. Sort the list E, X, A, M, P , L, E in alphabetical order by bubble sort.
12.  a.  Prove that if bubble sort makes no exchanges on its pass through a list, the
         list is sorted and the algorithm can be stopped.
     b.  Write pseudocode of the method that incorporates this improvement.
     c.  Prove that the worst-case efficiency of the improved version is quadratic.
13. Is bubble sort stable?
14.  Alternating disks  You have a row of 2n disks of two colors, n dark and n light.
     They alternate: dark, light, dark, light, and so on. You want to get all the dark
     disks to the right-hand end, and all the light disks to the left-hand end. The
     only moves you are allowed to make are those that interchange the positions
     of two neighboring disks.
     Design an algorithm for solving this puzzle and determine the number of
     moves it takes. [Gar99]
     3.2  Sequential Search and Brute-Force String Matching
          We saw in the previous section two applications of the brute-force approach to the
          sorting porblem. Here we discuss two applications of this strategy to the problem
          of searching. The first deals with the canonical problem of searching for an item
          of a given value in a given list. The second is different in that it deals with the
          string-matching problem.
          Sequential Search
          We have already encountered a brute-force algorithm for the general searching
          problem: it is called sequential search (see Section 2.1). To repeat, the algorithm
          simply compares successive elements of a given list with a given search key until
          either a match is encountered (successful search) or the list is exhausted without
          finding a match (unsuccessful search). A simple extra trick is often employed
          in implementing sequential search: if we append the search key to the end of
          the list, the search for the key will have to be successful, and therefore we can
          eliminate the end of list check altogether. Here is pseudocode of this enhanced
          version.
          ALGORITHM  SequentialSearch2(A[0..n], K)
          //Implements sequential search with a search key as a sentinel
          //Input: An array A of n elements and a search key K
          //Output: The index of the first element in A[0..n - 1] whose value is
          //        equal to K or -1 if no such element is found
          A[n]  K
          i0
          while A[i] = K do
                    ii+1
          if i < n return i
          else return -1
          Another straightforward improvement can be incorporated in sequential
          search if a given list is known to be sorted: searching in such a list can be stopped
          as soon as an element greater than or equal to the search key is encountered.
          Sequential search provides an excellent illustration of the brute-force ap-
          proach, with its characteristic strength (simplicity) and weakness (inferior effi-
          ciency). The efficiency results obtained in Section 2.1 for the standard version of
          sequential search change for the enhanced version only very slightly, so that the
          algorithm remains linear in both the worst and average cases. We discuss later in
          the book several searching algorithms with a better time efficiency.
Brute-Force String Matching
Recall the string-matching problem introduced in Section 1.3: given a string of n
characters called the text and a string of m characters (m  n) called the pattern,
find a substring of the text that matches the pattern. To put it more precisely, we
want to find i--the index of the leftmost character of the first matching substring
in the text--such that ti = p0, . . . , ti+j = pj , . . . , ti+m-1 = pm-1:
t0      ...  ti  ...       ti+j  ...  ti+m-1    ...              tn-1       text T
             p0  ...       pj    ...  pm-1      pattern P
If matches other than the first one need to be found, a string-matching algorithm
can simply continue working until the entire text is exhausted.
A brute-force algorithm for the string-matching problem is quite obvious:
align the pattern against the first m characters of the text and start matching the
corresponding pairs of characters from left to right until either all the m pairs
of the characters match (then the algorithm can stop) or a mismatching pair is
encountered. In the latter case, shift the pattern one position to the right and
resume the character comparisons, starting again with the first character of the
pattern and its counterpart in the text. Note that the last position in the text that
can still be a beginning of a matching substring is n - m (provided the text positions
are indexed from 0 to n - 1). Beyond that position, there are not enough characters
to match the entire pattern; hence, the algorithm need not make any comparisons
there.
ALGORITHM    BruteForceStringMatch(T [0..n - 1], P [0..m - 1])
//Implements brute-force string matching
//Input: An array T [0..n - 1] of n characters representing a text and
//           an array P [0..m - 1] of m characters representing a pattern
//Output: The index of the first character in the text that starts a
//           matching substring or -1 if the search is unsuccessful
for i  0 to n - m do
        j 0
        while j < m and P [j ] = T [i + j ] do
             j j +1
        if j = m return i
return -1
An operation of the algorithm is illustrated in Figure 3.3. Note that for this
example, the algorithm shifts the pattern almost always after a single character
comparison. The worst case is much worse: the algorithm may have to make
all m comparisons before shifting the pattern, and this can happen for each of
the n - m + 1 tries. (Problem 6 in this section's exercises asks you to give a
specific example of such a situation.) Thus, in the worst case, the algorithm makes
                N   O  B    O       D  Y   _    N  O      T   I  C       E    D  _  H  I  M
                N   O  T
                    N  O    T
                       N    O       T
                            N       O  T
                                    N  O   T
                                       N   O    T
                                           N    O  T
                                                N  O      T
     FIGURE 3.3     Example of brute-force string matching. The       pattern's characters   that  are
                    compared with their text counterparts are in      bold type.
     m(n - m + 1) character comparisons, which puts it in the O(nm) class. For a typical
     word search in a natural language text, however, we should expect that most shifts
     would happen after very few comparisons (check the example again). Therefore,
     the average-case efficiency should be considerably better than the worst-case
     efficiency. Indeed it is: for searching in random texts, it has been shown to be linear,
     i.e.,      (n). There are several more sophisticated and more efficient algorithms for
     string searching. The most widely known of them--by R. Boyer and J. Moore--is
     outlined in Section 7.2 along with its simplification suggested by R. Horspool.
     Exercises 3.2
     1.     Find the number of comparisons made by the sentinel version of sequential
            search
            a.  in the worst case.
            b. in the average case if the probability of a successful search is p (0  p  1).
     2.     As shown in Section 2.1, the average number of key comparisons made by
            sequential search (without a sentinel, under standard assumptions about its
            inputs) is given by the formula
                                       Cavg(n)  =  p(n +  1)  +  n(1  -  p),
                                                   2
            where p is the probability of a successful search. Determine, for a fixed n, the
            values of p (0  p  1) for which this formula yields the maximum value of
            Cavg(n) and the minimum value of Cavg(n).
     3.     Gadget testing  A firm wants to determine the highest floor of its n-story
            headquarters from which a gadget can fall without breaking. The firm has two
            identical gadgets to experiment with. If one of them gets broken, it cannot be
            repaired, and the experiment will have to be completed with the remaining
            gadget. Design an algorithm in the best efficiency class you can to solve this
            problem.
4.   Determine the number of character comparisons made by the brute-force
     algorithm in searching for the pattern GANDHI in the text
              THERE_IS_MORE_TO_LIFE_THAN_INCREASING_ITS_SPEED
     Assume that the length of the text--it is 47 characters long--is known before
     the search starts.
5.   How many comparisons (both successful and unsuccessful) will be made by
     the brute-force algorithm in searching for each of the following patterns in
     the binary text of one thousand zeros?
         a. 00001        b. 10000      c. 01010
6.   Give an example of a text of length n and a pattern of length m that constitutes
     a worst-case input for the brute-force string-matching algorithm. Exactly how
     many character comparisons will be made for such input?
7.   In solving the string-matching problem, would there be any advantage in
     comparing pattern and text characters right-to-left instead of left-to-right?
8.   Consider the problem of counting, in a given text, the number of substrings
     that start with an A and end with a B. For example, there are four such
     substrings in CABAAXBYA.
     a.  Design a brute-force  algorithm  for    this problem and determine its     effi-
         ciency class.
     b. Design a more efficient algorithm for this problem. [Gin04]
9.   Write a visualization program for the brute-force string-matching algorithm.
10.  Word Find     A popular diversion in the United States, "word find" (or "word
     search") puzzles ask the player to find each of a given set of words in a square
     table filled with single letters. A word can read horizontally (left or right),
     vertically (up or down), or along a 45 degree diagonal (in any of the four
     directions) formed by consecutively adjacent cells of the table; it may wrap
     around the table's boundaries, but it must read in the same direction with no
     zigzagging. The same cell of the table may be used in different words, but, in a
     given word, the same cell may be used no more than once. Write a computer
     program for solving this puzzle.
11.  Battleship game     Write a program based on a version of brute-force pattern
     matching for playing the game Battleship on the computer. The rules of the
     game are as follows. There are two opponents in the game (in this case,
     a human player and the computer). The game is played on two identical
     boards (10 × 10 tables of squares) on which each opponent places his or her
     ships, not seen by the opponent. Each player has five ships, each of which
     occupies a certain number of squares on the board: a destroyer (two squares),
     a submarine (three squares), a cruiser (three squares), a battleship (four
     squares), and an aircraft carrier (five squares). Each ship is placed either
     horizontally or vertically, with no two ships touching each other. The game
     is played by the opponents taking turns "shooting" at each other's ships. The
          result of every shot is displayed as either a hit or a miss. In case of a hit, the
          player gets to go again and keeps playing until missing. The goal is to sink all
          the opponent's ships before the opponent succeeds in doing it first. To sink a
          ship, all squares occupied by the ship must be hit.
     3.3  Closest-Pair and Convex-Hull Problems
          by Brute Force
          In this section, we consider a straightforward approach to two well-known prob-
          lems dealing with a finite set of points in the plane. These problems, aside from
          their theoretical interest, arise in two important applied areas: computational ge-
          ometry and operations research.
          Closest-Pair Problem
          The closest-pair problem calls for finding the two closest points in a set of n
          points. It is the simplest of a variety of problems in computational geometry that
          deals with proximity of points in the plane or higher-dimensional spaces. Points
          in question can represent such physical objects as airplanes or post offices as well
          as database records, statistical samples, DNA sequences, and so on. An air-traffic
          controller might be interested in two closest planes as the most probable collision
          candidates. A regional postal service manager might need a solution to the closest-
          pair problem to find candidate post-office locations to be closed.
          One of the important applications of the closest-pair problem is cluster analy-
          sis in statistics. Based on n data points, hierarchical cluster analysis seeks to orga-
          nize them in a hierarchy of clusters based on some similarity metric. For numerical
          data, this metric is usually the Euclidean distance; for text and other nonnumerical
          data, metrics such as the Hamming distance (see Problem 5 in this section's ex-
          ercises) are used. A bottom-up algorithm begins with each element as a separate
          cluster and merges them into successively larger clusters by combining the closest
          pair of clusters.
          For simplicity, we consider the two-dimensional case of the closest-pair prob-
          lem. We assume that the points in question are specified in a standard fashion by
          their (x, y) Cartesian coordinates and that the distance between two points pi(xi,
          yi) and pj (xj , yj ) is the standard Euclidean distance
                             d(pi, pj ) =    (xi - xj )2 + (yi - yj )2.
          The brute-force approach to solving this problem leads to the following ob-
          vious algorithm: compute the distance between each pair of distinct points and
          find a pair with the smallest distance. Of course, we do not want to compute the
          distance between the same pair of points twice. To avoid doing so, we consider
          only the pairs of points (pi, pj ) for which i < j .
Pseudocode below computes the distance between the two closest points;
getting the closest points themselves requires just a trivial modification.
ALGORITHM  BruteForceClosestPair(P )
//Finds distance between two closest points in the plane by brute force
//Input: A list P of n (n  2) points p1(x1, y1), . . . , pn(xn, yn)
//Output: The distance between the closest pair of points
d 
for i  1 to n - 1 do
for j  i + 1 to n do
          d  min(d, sqrt((xi - xj )2 + (yi - yj )2)) //sqrt is square root
return d
The basic operation of the algorithm is computing the square root. In the age
of electronic calculators with a square-root button, one might be led to believe
that computing the square root is as simple an operation as, say, addition or
multiplication. Of course, it is not. For starters, even for most integers, square roots
are irrational numbers that therefore can be found only approximately. Moreover,
computing such approximations is not a trivial matter. But, in fact, computing
square roots in the loop can be avoided! (Can you think how?) The trick is to
realize that we can simply ignore the square-root function and compare the values
(xi - xj )2 + (yi - yj )2 themselves. We can do this because the smaller a number of
which we take the square root, the smaller its square root, or, as mathematicians
say, the square-root function is strictly increasing.
Then the basic operation of the algorithm will be squaring a number. The
number of times it will be executed can be computed as follows:
                  n-1  n           n-1
          C(n) =              2=2       (n - i)
                  i=1 j =i+1       i=1
           = 2[(n - 1) + (n - 2) + . . . + 1] = (n - 1)n             (n2).
Of course, speeding up the innermost loop of the algorithm could only de-
crease the algorithm's running time by a constant factor (see Problem 1 in this
section's exercises), but it cannot improve its asymptotic efficiency class. In Chap-
ter 5, we discuss a linearithmic algorithm for this problem, which is based on a
more sophisticated design technique.
Convex-Hull Problem
On to the other problem--that of computing the convex hull. Finding the convex
hull for a given set of points in the plane or a higher dimensional space is one of
the most important--some people believe the most important--problems in com-
putational geometry. This prominence is due to a variety of applications in which
         this problem needs to be solved, either by itself or as a part of a larger task. Sev-
         eral such applications are based on the fact that convex hulls provide convenient
         approximations of object shapes and data sets given. For example, in computer an-
         imation, replacing objects by their convex hulls speeds up collision detection; the
         same idea is used in path planning for Mars mission rovers. Convex hulls are used
         in computing accessibility maps produced from satellite images by Geographic
         Information Systems. They are also used for detecting outliers by some statisti-
         cal techniques. An efficient algorithm for computing a diameter of a set of points,
         which is the largest distance between two of the points, needs the set's convex hull
         to find the largest distance between two of its extreme points (see below). Finally,
         convex hulls are important for solving many optimization problems, because their
         extreme points provide a limited set of solution candidates.
         We start with a definition of a convex set.
         DEFINITION  A set of points (finite or infinite) in the plane is called convex if
         for any two points p and q in the set, the entire line segment with the endpoints
         at p and q belongs to the set.
         All the sets depicted in Figure 3.4a are convex, and so are a straight line,
         a triangle, a rectangle, and, more generally, any convex polygon,1 a circle, and
         the entire plane. On the other hand, the sets depicted in Figure 3.4b, any finite
         set of two or more distinct points, the boundary of any convex polygon, and a
         circumference are examples of sets that are not convex.
         Now we are ready for the notion of the convex hull. Intuitively, the convex
         hull of a set of n points in the plane is the smallest convex polygon that contains
         all of them either inside or on its boundary. If this formulation does not fire up
         your enthusiasm, consider the problem as one of barricading n sleeping tigers by
         a fence of the shortest length. This interpretation is due to D. Harel [Har92]; it is
         somewhat lively, however, because the fenceposts have to be erected right at the
         spots where some of the tigers sleep! There is another, much tamer interpretation
         of this notion. Imagine that the points in question are represented by nails driven
         into a large sheet of plywood representing the plane. Take a rubber band and
         stretch it to include all the nails, then let it snap into place. The convex hull is the
         area bounded by the snapped rubber band (Figure 3.5).
         A formal definition of the convex hull that is applicable to arbitrary sets,
         including sets of points that happen to lie on the same line, follows.
         DEFINITION  The convex hull of a set S of points is the smallest convex set
         containing S. (The "smallest" requirement means that the convex hull of S must
         be a subset of any convex set containing S.)
         If S is convex, its convex hull is obviously S itself. If S is a set of two points,
         its convex hull is the line segment connecting these points. If S is a set of three
     1.  By "a triangle, a rectangle, and, more generally, any convex polygon," we mean here a region, i.e., the
         set of points both inside and on the boundary of the shape in question.
                         (a)                                      (b)
FIGURE 3.4  (a)  Convex  sets.  (b)  Sets that are  not  convex.
FIGURE 3.5 Rubber-band interpretation of the convex hull.
points not on the same line, its convex hull is the triangle with the vertices at the
three points given; if the three points do lie on the same line, the convex hull is
the line segment with its endpoints at the two points that are farthest apart. For
an example of the convex hull for a larger set, see Figure 3.6.
A study of the examples makes the following theorem an expected result.
THEOREM     The convex hull of any set S of n > 2 points not all on the same line
is a convex polygon with the vertices at some of the points of S. (If all the points
do lie on the same line, the polygon degenerates to a line segment but still with
the endpoints at two points of S.)
                                                            p6
                       p7
                           p8                           p2
                   p3                   p4                                   p5
                                                        p1
     FIGURE   3.6  The convex hull for this set of eight    points  is  the  convex  polygon  with
                   vertices at p1, p5, p6, p7, and p3.
     The convex-hull problem is the problem of constructing the convex hull for
     a given set S of n points. To solve it, we need to find the points that will serve as
     the vertices of the polygon in question. Mathematicians call the vertices of such
     a polygon "extreme points." By definition, an extreme point of a convex set is a
     point of this set that is not a middle point of any line segment with endpoints in
     the set. For example, the extreme points of a triangle are its three vertices, the
     extreme points of a circle are all the points of its circumference, and the extreme
     points of the convex hull of the set of eight points in Figure 3.6 are p1, p5, p6, p7,
     and p3.
     Extreme points have several special properties other points of a convex set
     do not have. One of them is exploited by the simplex method, a very important
     algorithm discussed in Section 10.1. This algorithm solves linear programming
     problems, which are problems of finding a minimum or a maximum of a linear
     function of n variables subject to linear constraints (see Problem 12 in this section's
     exercises for an example and Sections 6.6 and 10.1 for a general discussion). Here,
     however, we are interested in extreme points because their identification solves
     the convex-hull problem. Actually, to solve this problem completely, we need to
     know a bit more than just which of n points of a given set are extreme points of the
     set's convex hull: we need to know which pairs of points need to be connected to
     form the boundary of the convex hull. Note that this issue can also be addressed
     by listing the extreme points in a clockwise or a counterclockwise order.
     So how can we solve the convex-hull problem in a brute-force manner? If you
     do not see an immediate plan for a frontal attack, do not be dismayed: the convex-
     hull problem is one with no obvious algorithmic solution. Nevertheless, there is a
     simple but inefficient algorithm that is based on the following observation about
     line segments making up the boundary of a convex hull: a line segment connecting
     two points pi and pj of a set of n points is a part of the convex hull's boundary if and
    only if all the other points of the set lie on the same side of the straight line through
    these two points.2 (Verify this property for the set in Figure 3.6.) Repeating this
    test for every pair of points yields a list of line segments that make up the convex
    hull's boundary.
        A few elementary facts from analytical geometry are needed to implement
    this algorithm. First, the straight line through two points (x1, y1), (x2, y2) in the
    coordinate plane can be defined by the equation
                        ax + by = c,
    where a = y2 - y1, b = x1 - x2, c = x1y2 - y1x2.
        Second, such a line divides the plane into two half-planes: for all the points
    in one of them, ax + by > c, while for all the points in the other, ax + by < c.
    (For the points on the line itself, of course, ax + by = c.) Thus, to check whether
    certain points lie on the same side of the line, we can simply check whether the
    expression ax + by - c has the same sign for each of these points. We leave the
    implementation details as an exercise.
        What is the time efficiency of this algorithm? It is in O(n3): for each of
    n(n - 1)/2 pairs of distinct points, we may need to find the sign of ax + by - c
    for each of the other n - 2 points. There are much more efficient algorithms for
    this important problem, and we discuss one of them later in the book.
    Exercises 3.3
    1.  Assuming that sqrt takes about 10 times longer than each of the other oper-
        ations in the innermost loop of BruteForceClosestPoints, which are assumed
        to take the same amount of time, estimate how much faster the algorithm will
        run after the improvement discussed in Section 3.3.
    2.  Can you design a more efficient algorithm than the one based on the brute-
        force strategy to solve the closest-pair problem for n points x1, x2, . . . , xn on
        the real line?
    3.  Let x1 < x2 < . . . < xn be real numbers representing coordinates of n villages
        located along a straight road. A post office needs to be built in one of these
        villages.
        a.  Design an efficient algorithm to find the post-office location minimizing
            the average distance between the villages and the post office.
        b. Design an efficient algorithm to find the post-office location minimizing
            the maximum distance from a village to the post office.
2.  For the sake of simplicity, we assume here that no three points of a given set lie on the same line. A
    modification needed for the general case is left for the exercises.
     4.  a.  There are several alternative ways to define a distance between two points
             p1(x1, y1) and p2(x2, y2) in the Cartesian plane. In particular, the Manhat-
             tan distance is defined as
                                    dM(p1, p2) = |x1 - x2| + |y1 - y2|.
             Prove that dM satisfies the following axioms, which every distance function
             must satisfy:
             i.    dM(p1, p2)  0 for any two points p1 and p2, and dM(p1, p2) = 0 if and
                   only if p1 = p2
             ii.   dM(p1, p2) = dM(p2, p1)
             iii.  dM(p1, p2)  dM(p1, p3) + dM(p3, p2) for any p1, p2, and p3
         b.  Sketch all the points in the Cartesian plane whose Manhattan distance to
             the origin (0, 0) is equal to 1. Do the same for the Euclidean distance.
         c.  True or false: A solution to the closest-pair problem does not depend on
             which of the two metrics--dE (Euclidean) or dM (Manhattan)--is used?
     5.  The Hamming distance between two strings of equal length is defined as the
         number of positions at which the corresponding symbols are different. It is
         named after Richard Hamming (1915­1998), a prominent American scientist
         and engineer, who introduced it in his seminal paper on error-detecting and
         error-correcting codes.
         a.  Does the Hamming distance satisfy the three axioms of a distance metric
             listed in Problem 4?
         b.  What is the time efficiency class of the brute-force algorithm for the closest-
             pair problem if the points in question are strings of m symbols long and the
             distance between two of them is measured by the Hamming distance?
     6.  Odd pie fight      There are n  3 people positioned on a field (Euclidean plane)
         so that each has a unique nearest neighbor. Each person has a cream pie. At a
         signal, everybody hurls his or her pie at the nearest neighbor. Assuming that
         n is odd and that nobody can miss his or her target, true or false: There always
         remains at least one person not hit by a pie. [Car79]
     7.  The closest-pair problem can be posed in the k-dimensional space, in which
         the Euclidean distance between two points p (x1, . . . , xk) and p (x1 , . . . , xk )
         is defined as
                                    d(p , p ) =  k       -      )2.
                                                 s=1(xs     xs
         What is the time-efficiency class of the brute-force algorithm for the k-
         dimensional closest-pair problem?
     8.  Find the convex hulls of the following sets and identify their extreme points
         (if they have any):
         a.  a line segment
          b. a square
          c.  the boundary of a square
          d. a straight line
     9.   Design a linear-time algorithm to determine two extreme points of the convex
          hull of a given set of n > 1 points in the plane.
     10.  What modification needs to be made in the brute-force algorithm for the
          convex-hull problem to handle more than two points on the same straight
          line?
     11.  Write a program implementing the brute-force algorithm for the convex-hull
          problem.
     12.  Consider the following small instance of the linear programming problem:
                                maximize    3x + 5y
                                subject to           x+      y4
                                                     x + 3y  6
                                                     x  0, y  0.
          a.  Sketch, in the Cartesian plane, the problem's feasible region, defined as
              the set of points satisfying all the problem's constraints.
          b.  Identify the region's extreme points.
          c.  Solve this optimization problem by using the following theorem: A linear
              programming problem with a nonempty bounded feasible region always
              has a solution, which can be found at one of the extreme points of its
              feasible region.
3.4  Exhaustive Search
     Many important problems require finding an element with a special property in a
     domain that grows exponentially (or faster) with an instance size. Typically, such
     problems arise in situations that involve--explicitly or implicitly--combinatorial
     objects such as permutations, combinations, and subsets of a given set. Many such
     problems are optimization problems: they ask to find an element that maximizes
     or minimizes some desired characteristic such as a path length or an assignment
     cost.
          Exhaustive search is simply a brute-force approach to combinatorial prob-
     lems. It suggests generating each and every element of the problem domain, se-
     lecting those of them that satisfy all the constraints, and then finding a desired
     element (e.g., the one that optimizes some objective function). Note that although
     the idea of exhaustive search is quite straightforward, its implementation typically
     requires an algorithm for generating certain combinatorial objects. We delay a dis-
     cussion of such algorithms until the next chapter and assume here that they exist.
     We illustrate exhaustive search by applying it to three important problems: the
     traveling salesman problem, the knapsack problem, and the assignment problem.
     Traveling Salesman Problem
     The traveling salesman problem (TSP) has been intriguing researchers for the
     last 150 years by its seemingly simple formulation, important applications, and
     interesting connections to other combinatorial problems. In layman's terms, the
     problem asks to find the shortest tour through a given set of n cities that visits each
     city exactly once before returning to the city where it started. The problem can be
     conveniently modeled by a weighted graph, with the graph's vertices representing
     the cities and the edge weights specifying the distances. Then the problem can be
     stated as the problem of finding the shortest Hamiltonian circuit of the graph. (A
     Hamiltonian circuit is defined as a cycle that passes through all the vertices of the
     graph exactly once. It is named after the Irish mathematician Sir William Rowan
     Hamilton (1805­1865), who became interested in such cycles as an application of
     his algebraic discoveries.)
          It is easy to see that a Hamiltonian circuit can also be defined as a sequence of
     n + 1 adjacent vertices vi0, vi1, . . . , vin-1, vi0, where the first vertex of the sequence
     is the same as the last one and all the other n - 1 vertices are distinct. Further,
     we can assume, with no loss of generality, that all circuits start and end at one
     particular vertex (they are cycles after all, are they not?). Thus, we can get all
     the tours by generating all the permutations of n - 1 intermediate cities, compute
     the tour lengths, and find the shortest among them. Figure 3.7 presents a small
     instance of the problem and its solution by this method.
          An inspection of Figure 3.7 reveals three pairs of tours that differ only by
     their direction. Hence, we could cut the number of vertex permutations by half.
     We could, for example, choose any two intermediate vertices, say, b and c, and then
     consider only permutations in which b precedes c. (This trick implicitly defines a
     tour's direction.)
          This improvement cannot brighten the efficiency picture much, however.
     The  total  number  of  permutations  needed  is  still  1  (n  -  1)!,  which  makes         the
                                                              2
     exhaustive-search approach impractical for all but very small values of n. On the
     other hand, if you always see your glass as half-full, you can claim that cutting
     the work by half is nothing to sneeze at, even if you solve a small instance of the
     problem, especially by hand. Also note that had we not limited our investigation
     to the circuits starting at the same vertex, the number of permutations would have
     been even larger, by a factor of n.
     Knapsack Problem
     Here is another well-known problem in algorithmics. Given n items of known
     weights w1, w2, . . . , wn and values v1, v2, . . . , vn and a knapsack of capacity W ,
     find the most valuable subset of the items that fit into the knapsack. If you do not
     like the idea of putting yourself in the shoes of a thief who wants to steal the most
                              a                2            b
                              5                                3
                                      8               7
                              c                             d
                                               1
                    --To--ur                                      L--e--ng--th
        a  --->  b  ---> c ---> d     --->  a            I  = 2 + 8 + 1 + 7 = 18
        a  --->  b  ---> d    ---> c  --->  a            I  = 2 + 3 + 1 + 5 = 11  optimal
        a  --->  c  --->  b   ---> d  --->  a            I  = 5 + 8 + 3 + 7 = 23
        a  --->  c  --->  d   ---> b  --->  a            I  = 5 + 1 + 3 + 2 = 11  optimal
        a  --->  d  --->  b   ---> c  --->  a            I  = 7 + 3 + 8 + 5 = 23
        a  --->  d  --->  c   ---> b  --->  a            I  = 7 + 1 + 8 + 2 = 18
FIGURE  3.7 Solution to a small instance          of  the   traveling salesman problem by exhaustive
           search.
valuable loot that fits into his knapsack, think about a transport plane that has to
deliver the most valuable set of items to a remote location without exceeding the
plane's capacity. Figure 3.8a presents a small instance of the knapsack problem.
The exhaustive-search approach to this problem leads to generating all the
subsets of the set of n items given, computing the total weight of each subset in
order to identify feasible subsets (i.e., the ones with the total weight not exceeding
the knapsack capacity), and finding a subset of the largest value among them. As
an example, the solution to the instance of Figure 3.8a is given in Figure 3.8b. Since
the number of subsets of an n-element set is 2n, the exhaustive search leads to a
(2n) algorithm, no matter how efficiently individual subsets are generated.
Thus, for both the traveling salesman and knapsack problems considered
above, exhaustive search leads to algorithms that are extremely inefficient on
every input. In fact, these two problems are the best-known examples of so-
called NP-hard problems. No polynomial-time algorithm is known for any NP-
hard problem. Moreover, most computer scientists believe that such algorithms
do not exist, although this very important conjecture has never been proven.
More-sophisticated approaches--backtracking and branch-and-bound (see Sec-
tions 12.1 and 12.2)--enable us to solve some but not all instances of these and
     10
                       w1 = 7               w2 = 3    w3 = 4                 w4 = 5
                       v1 = $42         v2 = $12      v3 = $40               v4 = $25
             knapsack  item 1               item 2    item 3                 item 4
                                        (a)
                       Subset           Total weight  Total value
                                        0             $0
                       {1}              7             $42
                       {2}              3             $12
                       {3}              4             $40
                       {4}              5             $25
                       {1, 2}           10            $54
                       {1, 3}           11            not feasible
                       {1, 4}           12            not feasible
                       {2, 3}           7             $52
                       {2, 4}           8             $37
                       3, 4             9             $65
                       {1, 2, 3}        14            not feasible
                       {1, 2, 4}        15            not feasible
                       {1, 3, 4}        16            not feasible
                       {2, 3, 4}        12            not feasible
                       {1, 2, 3, 4}     19            not feasible
                                        (b)
     FIGURE  3.8  (a) Instance of the knapsack problem. (b) Its solution by  exhaustive search.
                  The information about the optimal selection is in bold.
similar problems in less than exponential time. Alternatively, we can use one of
many approximation algorithms, such as those described in Section 12.3.
Assignment Problem
In our third example of a problem that can be solved by exhaustive search, there
are n people who need to be assigned to execute n jobs, one person per job. (That
is, each person is assigned to exactly one job and each job is assigned to exactly
one person.) The cost that would accrue if the ith person is assigned to the j th job
is a known quantity C[i, j ] for each pair i, j = 1, 2, . . . , n. The problem is to find
an assignment with the minimum total cost.
A small instance of this problem follows, with the table entries representing
the assignment costs C[i, j ]:
                                Job 1    Job 2   Job 3       Job 4
                Person 1            9         2           7      8
                Person 2            6         4           3      7
                Person 3            5         8           1      8
                Person 4            7         6           9      4
It is easy to see that an instance of the assignment problem is completely
specified by its cost matrix C. In terms of this matrix, the problem is to select one
element in each row of the matrix so that all selected elements are in different
columns and the total sum of the selected elements is the smallest possible. Note
that no obvious strategy for finding a solution works here. For example, we cannot
select the smallest element in each row, because the smallest elements may happen
to be in the same column. In fact, the smallest element in the entire matrix need
not be a component of an optimal solution. Thus, opting for the exhaustive search
may appear as an unavoidable evil.
We can describe feasible solutions to the assignment problem as n-tuples
j1, . . . , jn  in which the ith component, i = 1, . . . , n, indicates the column of the
element selected in the ith row (i.e., the job number assigned to the ith person).
For example, for the cost matrix above,       2, 3, 4, 1  indicates the assignment of
Person 1 to Job 2, Person 2 to Job 3, Person 3 to Job 4, and Person 4 to Job 1.
The requirements of the assignment problem imply that there is a one-to-one
correspondence between feasible assignments and permutations of the first n
integers. Therefore, the exhaustive-search approach to the assignment problem
would require generating all the permutations of integers 1, 2, . . . , n, computing
the total cost of each assignment by summing up the corresponding elements of
the cost matrix, and finally selecting the one with the smallest sum. A few first
iterations of applying this algorithm to the instance given above are shown in
Figure 3.9; you are asked to complete it in the exercises.
                                 <1, 2, 3, 4>        cost = 9 + 4    +   1 + 4 = 18
                  9  2  7     8  <1, 2, 4, 3>        cost = 9 + 4    +   8 + 9 = 30
         C=       6  4  3     7  <1, 3, 2, 4>        cost = 9 + 3    +   8 + 4 = 24
                  5  8  1     8  <1, 3, 4, 2>        cost = 9 + 3    +   8 + 6 = 26  etc.
                  7  6  9     4  <1, 4, 2, 3>        cost = 9 + 7    +   8 + 9 = 33
                                 <1, 4, 3, 2>        cost = 9 + 7    +   1 + 6 = 23
     FIGURE 3.9   First few iterations of solving a  small instance  of  the assignment problem
                  by exhaustive search.
         Since the number of permutations to be considered for the general case of the
     assignment problem is n!, exhaustive search is impractical for all but very small
     instances of the problem. Fortunately, there is a much more efficient algorithm for
     this problem called the Hungarian method after the Hungarian mathematicians
     Ko¨ nig and Egerva´ ry, whose work underlies the method (see, e.g., [Kol95]).
         This is good news: the fact that a problem domain grows exponentially or
     faster does not necessarily imply that there can be no efficient algorithm for solving
     it. In fact, we present several other examples of such problems later in the book.
     However, such examples are more of an exception to the rule. More often than
     not, there are no known polynomial-time algorithms for problems whose domain
     grows exponentially with instance size, provided we want to solve them exactly.
     And, as we mentioned above, such algorithms quite possibly do not exist.
     Exercises 3.4
     1.  a.  Assuming that each tour can be generated in constant time, what will be
             the efficiency class of the exhaustive-search algorithm outlined in the text
             for the traveling salesman problem?
         b.  If this algorithm is programmed on a computer that makes ten billion
             additions per second, estimate the maximum number of cities for which
             the problem can be solved in
                  i. 1 hour.     ii. 24 hours.       iii. 1 year.    iv. 1 century.
     2.  Outline an exhaustive-search algorithm for the Hamiltonian circuit problem.
     3.  Outline an algorithm to determine whether a connected graph represented
         by its adjacency matrix has an Eulerian circuit. What is the efficiency class of
         your algorithm?
     4.  Complete the application of exhaustive search to the instance of the assign-
         ment problem started in the text.
     5.  Give an example of the assignment problem whose optimal solution does not
         include the smallest element of its cost matrix.
6.   Consider the partition problem: given n positive integers, partition them into
     two disjoint subsets with the same sum of their elements. (Of course, the prob-
     lem does not always have a solution.) Design an exhaustive-search algorithm
     for this problem. Try to minimize the number of subsets the algorithm needs
     to generate.
7.   Consider the clique problem: given a graph G and a positive integer k, deter-
     mine whether the graph contains a clique of size k, i.e., a complete subgraph
     of k vertices. Design an exhaustive-search algorithm for this problem.
8.   Explain how exhaustive search can be applied to the sorting problem and
     determine the efficiency class of such an algorithm.
9.   Eight-queens problem       Consider the classic puzzle of placing eight queens on
     an 8 × 8 chessboard so that no two queens are in the same row or in the same
     column or on the same diagonal. How many different positions are there so
     that
     a.  no two queens are on the same square?
     b. no two queens are in the same row?
     c.  no two queens are in the same row or in the same column?
     Also estimate how long it would take to find all the solutions to the problem by
     exhaustive search based on each of these approaches on a computer capable
     of checking 10 billion positions per second.
10.  Magic squares  A magic square of order n is an arrangement of the integers
     from 1 to n2 in an n × n matrix, with each number occurring exactly once, so
     that each row, each column, and each main diagonal has the same sum.
     a.  Prove that if a magic square of order n exists, the sum in question must be
         equal to n(n2 + 1)/2.
     b. Design an exhaustive-search algorithm for generating all magic squares of
         order n.
     c.  Go to the Internet or your library and find a better algorithm for generating
         magic squares.
     d. Implement the two algorithms--the exhaustive search and the one you
         have found--and run an experiment to determine the largest value of n
         for which each of the algorithms is able to find a magic square of order n
         in less than 1 minute on your computer.
11.  Famous alphametic     A puzzle in which the digits in a correct mathematical
     expression, such as a sum, are replaced by letters is called cryptarithm; if, in
     addition, the puzzle's words make sense, it is said to be an alphametic. The
     most well-known alphametic was published by the renowned British puzzlist
     Henry E. Dudeney (1857­1930):
                                             S  END
                                             + MORE
                                             MONEY
          Two conditions are assumed: first, the correspondence between letters and
          decimal digits is one-to-one, i.e., each letter represents one digit only and dif-
          ferent letters represent different digits. Second, the digit zero does not appear
          as the left-most digit in any of the numbers. To solve an alphametic means
          to find which digit each letter represents. Note that a solution's uniqueness
          cannot be assumed and has to be verified by the solver.
          a.  Write a program for solving cryptarithms by exhaustive search. Assume
              that a given cryptarithm is a sum of two words.
          b. Solve Dudeney's puzzle the way it was expected to be solved when it was
              first published in 1924.
     3.5  Depth-First Search and Breadth-First Search
          The term "exhaustive search" can also be applied to two very important algorithms
          that systematically process all vertices and edges of a graph. These two traversal
          algorithms are depth-first search (DFS) and breadth-first search (BFS). These
          algorithms have proved to be very useful for many applications involving graphs in
          artificial intelligence and operations research. In addition, they are indispensable
          for efficient investigation of fundamental properties of graphs such as connectivity
          and cycle presence.
          Depth-First Search
          Depth-first search starts a graph's traversal at an arbitrary vertex by marking it
          as visited. On each iteration, the algorithm proceeds to an unvisited vertex that
          is adjacent to the one it is currently in. (If there are several such vertices, a tie
          can be resolved arbitrarily. As a practical matter, which of the adjacent unvisited
          candidates is chosen is dictated by the data structure representing the graph. In
          our examples, we always break ties by the alphabetical order of the vertices.) This
          process continues until a dead end--a vertex with no adjacent unvisited vertices--
          is encountered. At a dead end, the algorithm backs up one edge to the vertex
          it came from and tries to continue visiting unvisited vertices from there. The
          algorithm eventually halts after backing up to the starting vertex, with the latter
          being a dead end. By then, all the vertices in the same connected component as the
          starting vertex have been visited. If unvisited vertices still remain, the depth-first
          search must be restarted at any one of them.
          It is convenient to use a stack to trace the operation of depth-first search. We
          push a vertex onto the stack when the vertex is reached for the first time (i.e., the
                                                                  a                      g
g                             h
                                                 e 6, 2           c                      h
   a                    e                        b 5, 3  j10,7
       c             f                    d3, 1  f4, 4   i 9, 8   d  f                   i
                                          c2, 5          h8, 9
   d                    b                 a1, 6          g7,10                           j
                                                                     b
j                             i
                                                                     e
             (a)                                 (b)                 (c)
FIGURE 3.10  Example of a DFS traversal. (a) Graph. (b) Traversal's stack (the first
             subscript number indicates the order in which a vertex is visited, i.e.,
             pushed onto the stack; the second one indicates the order in which it
             becomes a dead-end, i.e., popped off the stack). (c) DFS forest with the
             tree and back edges shown with solid and dashed lines, respectively.
visit of the vertex starts), and we pop a vertex off the stack when it becomes a
dead end (i.e., the visit of the vertex ends).
   It is also very useful to accompany a depth-first search traversal by construct-
ing the so-called depth-first search forest. The starting vertex of the traversal
serves as the root of the first tree in such a forest. Whenever a new unvisited vertex
is reached for the first time, it is attached as a child to the vertex from which it is
being reached. Such an edge is called a tree edge because the set of all such edges
forms a forest. The algorithm may also encounter an edge leading to a previously
visited vertex other than its immediate predecessor (i.e., its parent in the tree).
Such an edge is called a back edge because it connects a vertex to its ancestor,
other than the parent, in the depth-first search forest. Figure 3.10 provides an ex-
ample of a depth-first search traversal, with the traversal stack and corresponding
depth-first search forest shown as well.
   Here is pseudocode of the depth-first search.
ALGORITHM    DFS(G)
   //Implements a depth-first search traversal of a given graph
   //Input: Graph G =   V, E
   //Output: Graph G with its vertices marked with consecutive integers
   //        in the order they are first encountered by the DFS traversal
   mark each vertex in V with 0 as a mark of being "unvisited"
   count  0
   for each vertex v in V do
       if v is marked with 0
             dfs(v)
         dfs(v)
         //visits recursively all the unvisited vertices connected to vertex v
         //by a path and numbers them in the order they are encountered
         //via global variable count
         count  count + 1;         mark v with count
         for each vertex w in V adjacent to v do
         if w is marked with 0
                          dfs(w)
         The brevity of the DFS pseudocode and the ease with which it can be per-
         formed by hand may create a wrong impression about the level of sophistication
         of this algorithm. To appreciate its true power and depth, you should trace the
         algorithm's action by looking not at a graph's diagram but at its adjacency matrix
         or adjacency lists. (Try it for the graph in Figure 3.10 or a smaller example.)
         How efficient is depth-first search? It is not difficult to see that this algorithm
         is, in fact, quite efficient since it takes just the time proportional to the size of the
         data structure used for representing the graph in question. Thus, for the adjacency
         matrix representation, the traversal time is in     (|V |2), and for the adjacency list
         representation, it is in  (|V | + |E|) where |V | and |E| are the number of the
         graph's vertices and edges, respectively.
         A DFS forest, which is obtained as a by-product of a DFS traversal, deserves a
         few comments, too. To begin with, it is not actually a forest. Rather, we can look at
         it as the given graph with its edges classified by the DFS traversal into two disjoint
         classes: tree edges and back edges. (No other types are possible for a DFS forest
         of an undirected graph.) Again, tree edges are edges used by the DFS traversal to
         reach previously unvisited vertices. If we consider only the edges in this class, we
         will indeed get a forest. Back edges connect vertices to previously visited vertices
         other than their immediate predecessors in the traversal. They connect vertices to
         their ancestors in the forest other than their parents.
         A DFS traversal itself and the forest-like representation of the graph it pro-
         vides have proved to be extremely helpful for the development of efficient al-
         gorithms for checking many important properties of graphs.3 Note that the DFS
         yields two orderings of vertices: the order in which the vertices are reached for the
         first time (pushed onto the stack) and the order in which the vertices become dead
         ends (popped off the stack). These orders are qualitatively different, and various
         applications can take advantage of either of them.
         Important elementary applications of DFS include checking connectivity and
         checking acyclicity of a graph. Since dfs halts after visiting all the vertices con-
     3.  The discovery of several such applications was an important breakthrough achieved by the two
         American computer scientists John Hopcroft and Robert Tarjan in the 1970s. For this and other
         contributions, they were given the Turing Award--the most prestigious prize in the computing field
         [Hop87, Tar87].
nected by a path to the starting vertex, checking a graph's connectivity can be
done as follows. Start a DFS traversal at an arbitrary vertex and check, after
the algorithm halts, whether all the vertices of the graph will have been vis-
ited. If they have, the graph is connected; otherwise, it is not connected. More
generally, we can use DFS for identifying connected components of a graph
(how?).
As for checking for a cycle presence in a graph, we can take advantage of the
graph's representation in the form of a DFS forest. If the latter does not have back
edges, the graph is clearly acyclic. If there is a back edge from some vertex u to its
ancestor v (e.g., the back edge from d to a in Figure 3.10c), the graph has a cycle
that comprises the path from v to u via a sequence of tree edges in the DFS forest
followed by the back edge from u to v.
You will find a few other applications of DFS later in the book, although
more sophisticated applications, such as finding articulation points of a graph,
are not included. (A vertex of a connected graph is said to be its articulation
point if its removal with all edges incident to it breaks the graph into disjoint
pieces.)
Breadth-First Search
If depth-first search is a traversal for the brave (the algorithm goes as far from
"home" as it can), breadth-first search is a traversal for the cautious. It proceeds in
a concentric manner by visiting first all the vertices that are adjacent to a starting
vertex, then all unvisited vertices two edges apart from it, and so on, until all
the vertices in the same connected component as the starting vertex are visited.
If there still remain unvisited vertices, the algorithm has to be restarted at an
arbitrary vertex of another connected component of the graph.
It is convenient to use a queue (note the difference from depth-first search!)
to trace the operation of breadth-first search. The queue is initialized with the
traversal's starting vertex, which is marked as visited. On each iteration, the
algorithm identifies all unvisited vertices that are adjacent to the front vertex,
marks them as visited, and adds them to the queue; after that, the front vertex is
removed from the queue.
Similarly to a DFS traversal, it is useful to accompany a BFS traversal by con-
structing the so-called breadth-first search forest. The traversal's starting vertex
serves as the root of the first tree in such a forest. Whenever a new unvisited vertex
is reached for the first time, the vertex is attached as a child to the vertex it is being
reached from with an edge called a tree edge. If an edge leading to a previously
visited vertex other than its immediate predecessor (i.e., its parent in the tree)
is encountered, the edge is noted as a cross edge. Figure 3.11 provides an exam-
ple of a breadth-first search traversal, with the traversal queue and corresponding
breadth-first search forest shown.
     g                                  h
                                                                     a                g
        a                     e
                c          f               a1 c2 d3 e4 f5 b6  c      d     e       h            j
                                           g7 h8 j9 i10
        d                     b
                                                              f            b       i
     j                                  i
                   (a)                     (b)                                (c)
     FIGURE  3.11  Example of a BFS traversal. (a) Graph. (b) Traversal queue, with the
                   numbers indicating the order in which the vertices are visited, i.e., added
                   to (and removed from) the queue. (c) BFS forest with the tree and cross
                   edges shown with solid and dotted lines, respectively.
        Here is pseudocode of the breadth-first search.
     ALGORITHM     BFS(G)
        //Implements a breadth-first search traversal of a given graph
        //Input: Graph G =    V, E
        //Output: Graph G with its vertices marked with consecutive integers
        //         in the order they are visited by the BFS traversal
        mark each vertex in V with 0 as a mark of being "unvisited"
        count  0
        for each vertex v in V do
             if v is marked with 0
                   bfs(v)
        bfs(v)
        //visits all the unvisited vertices connected to vertex v
        //by a path and numbers them in the order they are visited
        //via global variable count
        count  count + 1;     mark v with count and initialize a queue with v
        while the queue is not empty do
             for each vertex w in V adjacent to the front vertex do
                   if w is marked with 0
                   count  count + 1;       mark w with count
                   add w to the queue
             remove the front vertex from the queue
                                                                        a
a            b             c  d
                                                                b          e
e            f             g  h                       c            f
                                 d                           g
                  (a)                                              (b)
FIGURE 3.12  Illustration of the BFS-based algorithm for finding a minimum-edge path.
             (a) Graph. (b) Part of its BFS tree that identifies the minimum-edge path
             from a to g.
Breadth-first search has the same efficiency as depth-first search: it is in
(|V |2) for the adjacency matrix representation and in       (|V | + |E|) for the adja-
cency list representation. Unlike depth-first search, it yields a single ordering of
vertices because the queue is a FIFO (first-in first-out) structure and hence the
order in which vertices are added to the queue is the same order in which they
are removed from it. As to the structure of a BFS forest of an undirected graph,
it can also have two kinds of edges: tree edges and cross edges. Tree edges are the
ones used to reach previously unvisited vertices. Cross edges connect vertices to
those visited before, but, unlike back edges in a DFS tree, they connect vertices
either on the same or adjacent levels of a BFS tree.
BFS can be used to check connectivity and acyclicity of a graph, essentially
in the same manner as DFS can. It is not applicable, however, for several less
straightforward applications such as finding articulation points. On the other hand,
it can be helpful in some situations where DFS cannot. For example, BFS can
be used for finding a path with the fewest number of edges between two given
vertices. To do this, we start a BFS traversal at one of the two vertices and stop
it as soon as the other vertex is reached. The simple path from the root of the
BFS tree to the second vertex is the path sought. For example, path a - b - c - g
in the graph in Figure 3.12 has the fewest number of edges among all the paths
between vertices a and g. Although the correctness of this application appears to
stem immediately from the way BFS operates, a mathematical proof of its validity
is not quite elementary (see, e.g., [Cor09, Section 22.2]).
Table 3.1 summarizes the main facts about depth-first search and breadth-first
search.
         TABLE 3.1 Main facts about depth-first search (DFS)
             and breadth-first search (BFS)
                                                DFS                  BFS
         Data structure                         a stack              a queue
         Number of vertex orderings             two orderings        one ordering
         Edge types (undirected graphs)         tree and back edges  tree and cross edges
         Applications                           connectivity,        connectivity,
                                                acyclicity,          acyclicity,
                                                articulation points  minimum-edge paths
         Efficiency for adjacency matrix        (|V 2|)              (|V 2|)
         Efficiency for adjacency lists         (|V | + |E|)         (|V | + |E|)
     Exercises 3.5
     1. Consider the following graph.
                                          f     b        c        g
                                             d       a         e
         a.  Write down the adjacency matrix and adjacency lists specifying this graph.
             (Assume that the matrix rows and columns and vertices in the adjacency
             lists follow in the alphabetical order of the vertex labels.)
         b.  Starting at vertex a and resolving ties by the vertex alphabetical order,
             traverse the graph by depth-first search and construct the corresponding
             depth-first search tree. Give the order in which the vertices were reached
             for the first time (pushed onto the traversal stack) and the order in which
             the vertices became dead ends (popped off the stack).
     2.  If we define sparse graphs as graphs for which |E|  O(|V |), which implemen-
         tation of DFS will have a better time efficiency for such graphs, the one that
         uses the adjacency matrix or the one that uses the adjacency lists?
     3.  Let G be a graph with n vertices and m edges.
         a.  True or false: All its DFS forests (for traversals starting at different ver-
             tices) will have the same number of trees?
         b. True or false: All its DFS forests will have the same number of tree edges
             and the same number of back edges?
     4.  Traverse the graph of Problem 1 by breadth-first search and construct the
         corresponding breadth-first search tree. Start the traversal at vertex a and
         resolve ties by the vertex alphabetical order.
5.   Prove that a cross edge in a BFS tree of an undirected graph can connect
     vertices only on either the same level or on two adjacent levels of a BFS tree.
6.   a.  Explain how one can check a graph's acyclicity by using breadth-first
         search.
     b.  Does either of the two traversals--DFS or BFS--always find a cycle faster
         than the other? If you answer yes, indicate which of them is better and
         explain why it is the case; if you answer no, give two examples supporting
         your answer.
7.   Explain how one can identify connected components of a graph by using
     a.  a depth-first search.
     b. a breadth-first search.
8.   A graph is said to be bipartite if all its vertices can be partitioned into two
     disjoint subsets X and Y so that every edge connects a vertex in X with a vertex
     in Y . (One can also say that a graph is bipartite if its vertices can be colored in
     two colors so that every edge has its vertices colored in different colors; such
     graphs are also called 2-colorable.) For example, graph (i) is bipartite while
     graph (ii) is not.
                         x1      y1   x3                  a        b
                         y2      x2   y3                  c        d
                                 (i)                         (ii)
     a.  Design a DFS-based algorithm for checking whether a graph is bipartite.
     b. Design a BFS-based algorithm for checking whether a graph is bipartite.
9.   Write a program that, for a given graph, outputs:
     a.  vertices of each connected component
     b. its cycle or a message that the graph is acyclic
10.  One can model a maze by having a vertex for a starting point, a finishing point,
     dead ends, and all the points in the maze where more than one path can be
     taken, and then connecting the vertices according to the paths in the maze.
     a.  Construct such a graph for the following maze.
          b. Which traversal--DFS or BFS--would you use if you found yourself in a
             maze and why?
     11.  Three Jugs   Sime´ on Denis Poisson (1781­1840), a famous French mathemati-
          cian and physicist, is said to have become interested in mathematics after
          encountering some version of the following old puzzle. Given an 8-pint jug
          full of water and two empty jugs of 5- and 3-pint capacity, get exactly 4 pints
          of water in one of the jugs by completely filling up and/or emptying jugs into
          others. Solve this puzzle by using breadth-first search.
     SUMMARY
          Brute force is a straightforward approach to solving a problem, usually directly
          based on the problem statement and definitions of the concepts involved.
          The principal strengths of the brute-force approach are wide applicability and
          simplicity; its principal weakness is the subpar efficiency of most brute-force
          algorithms.
          A first application of the brute-force approach often results in an algorithm
          that can be improved with a modest amount of effort.
          The following noted algorithms can be considered as examples of the brute-
          force approach:
          .  definition-based algorithm for matrix multiplication
          .  selection sort
          .  sequential search
          .  straightforward string-matching algorithm
          Exhaustive search is a brute-force approach to combinatorial problems. It
          suggests generating each and every combinatorial object of the problem,
          selecting those of them that satisfy all the constraints, and then finding a
          desired object.
          The traveling salesman problem, the knapsack problem, and the assignment
          problem are typical examples of problems that can be solved, at least
          theoretically, by exhaustive-search algorithms.
          Exhaustive search is impractical for all but very small instances of problems
          it can be applied to.
          Depth-first search (DFS) and breadth-first search (BFS) are two principal
          graph-traversal algorithms. By representing a graph in a form of a depth-first
          or breadth-first search forest, they help in the investigation of many important
          properties of the graph. Both algorithms have the same time efficiency:
             (|V |2) for the adjacency matrix representation and    (|V | + |E|) for the
          adjacency list representation.
