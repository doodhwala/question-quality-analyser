 an operating system is a program that manages the computer hardware. it also provides a basis for application programs and acts as an intermediary between the computer user and the computer hardware. an amazing aspect of operating systems is how varied they are in accomplishing these tasks. mainframe operating systems are designed primarily to optimize utilization of hardware. personal computer pc operating systems support complex games business applications and everything in between. operating systems for handheld computers are designed to provide an environment in which a user can easily interface with the computer to execute programs. thus some operatingsystems aredesigned tobeconvenient others tobeefficient andothers some combination of the two. before we can explore the details of computer system operation we need to know something about system structure. we begin by discussing the basic functions of system startup i o and storage. we also describe the basic computer architecture that makes it possible to write a functional operating system. because an operating system is large and complex it must be created piece by piece. each of these pieces should be a well delineated portion of the system with carefully defined inputs outputs and functions. in this chapter we provide a general overview of the major components of an operating system. objectives to provide a grand tour of the major operating systems components. to provide coverage of basic computer system organization
 we begin our discussion by looking at the operating system's role in the overall computer system. a computer system can be divided roughly into four components the hardware the operating system the application programs and the users figure . . chapter introduction i user user user i i i compiler assembler text editor database system system and application programs operating system computer hardware figure . abstract view of the components of a computer system. the hardware the central processing unit cpu the memory and the input output i o devices provides the basic computing resources for the system. the application programs such as word processors spreadsheets compilers and web browsers define the ways in which these resources are used to solve users' computing problems. the operating system controls and coordinates the use of the hardware among the various application programs for the various users. we can also view a computer system as consisting of hardware software and data. the operating system provides the means for proper use of these resources in the operation of the computer system. an operating system is similar to a government. like a government it performs no useful function by itself. it simply provides an environment within which other programs can do useful work. to understand more fully the operating system's role we next explore operating systems from two viewpoints that of the user and that of the system. . . user view the user's view of the computer varies according to the interface being used. most computer users sit in front of a pc consisting of a monitor keyboard mouse and system unit. such a system is designed for one user to monopolize its resources. the goal is to maximize the work or play that the user is performing. in this case the operating system is designed mostly for ease of use with some attention paid to performance and none paid to resource utilization how various hardware and software resources are shared. performance is of course important to the user but rather than resource utilization such systems are optimized for the single user experience. . what operating systems do in other cases a user sits at a terminal connected to a mainframe or minicomputer. other users are accessing the same computer through other terminals. these users share resources and may exchange information. the operating system in such cases is designed to maximize resource utilization to assure that all available cpu time memory and i o are used efficiently and that no individual user takes more than her fair share. in still other cases users sit at workstations connected to networks of other workstations and servers. these users have dedicated resources at their disposal but they also share resources such as networking and servers file compute and print servers. therefore their operating system is designed to compromise between individual usability and resource utilization. recently many varieties of handheld computers have come into fashion. most of these devices are standalone units for individual users. some are connected to networks either directly by wire or more often through wireless modems and networking. because of power speed and interface limitations they perform relatively few remote operations. their operating systems are designed mostly for individual usability but performance per amount of battery life is important as well. some computers have little or no user view. for example embedded computers in home devices and automobiles may have numeric keypads and may turn indicator lights on or off to show status but they and their operating systems are designed primarily to run without user intervention. . . system view from the computer's point of view the operating system is the program most intimately involved with the hardware. in this context we can view an operating system as a resource allocator. a computer system has many resources that may be required to solve a problem cpu time memory space file storage space i o devices and so on. the operating system acts as the manager of these resources. facing numerous and possibly conflicting requests for resources the operating system must decide how to allocate them to specific programs and users so that it can operate the computer system efficiently and fairly. as we have seen resource allocation is especially important where many users access the same mainframe or minicomputer. a slightly different view of an operating system emphasizes the need to control the various i o devices and user programs. an operating system is a control program. a control program manages the execution of user programs to prevent errors and improper use of the computer. it is especially concerned with the operation and control of i o devices. . . defining operating systems we have looked at the operating system's role from the views of the user and of the system. how though can we define what an operating system is? in general we have no completely adequate definition of an operating system. operating systems exist because they offer a reasonable way to solve the problem of creating a usable computing system. the fundamental goal of computer systems is to execute user programs and to make solving user problems easier. toward this goal computer hardware is constructed. since bare hardware alone is not particularly easy to use application programs are chapter introduction developed. these programs require certain common operations such as those controlling the i o devices. the common functions of controlling and allocating resources are then brought together into one piece of software the operating system. in addition we have no universally accepted definition of what is part of the operating system. a simple viewpoint is that it includes everything a vendor ships when you order the operating system. the features included however vary greatly across systems. some systems take up less than megabyte of space and lack even a full screen editor whereas others require gigabytes of space and are entirely based on graphical windowing systems. a kilobyte or kb is bytes a megabyte or mb is l bytes and a gigabyte or gb is l bytes. computer manufacturers often round off these numbers and say that a megabyte is million bytes and a gigabyte is billion bytes. a more common definition is that the operating system is the one program running at all times on the computer usually called the kernel with all else being systems programs and application programs. this last definition is the one that we generally follow. the matter of what constitutes an operating system has become increasingly important. in the united states department of justice filed suit against microsoft in essence claiming that microsoft included too much functionality in its operating systems and thus prevented application vendors from competing. for example a web browser was an integral part of the operating system. as a result microsoft was found guilty of using its operating system monopoly to limit competition
 before we can explore the details of how computer systems operate we need a general knowledge of the structure of a computer system. in this section we look at several parts of this structure to round out our background knowledge. the section is mostly concerned with computer system organization so you can skim or skip it if you already understand the concepts. . . computer system operation a modern general purpose computer system consists of one or more cpus and a number of device controllers connected through a common bus that provides access to shared memory figure . . each device controller is in charge of a specific type of device for example disk drives audio devices and video displays . the cpu and the device controllers can execute concurrently competing for memory cycles. to ensure orderly access to the shared memory a memory controller is provided whose function is to synchronize access to the memory. for a computer to start running for instance when it is powered up or rebooted it needs to have an initial program to run. this initial program or bootstrap program tends to be simple. typically it is stored in read only memory rom or electrically erasable programmable read only memory eeprom known by the general term firmware within the computer hardware. it initializes all aspects of the system from cpu registers to device . computer system organization mouse keyboard printer monitor disks cpu ! disk usb cqhtrolfer controller adapter memory figure . a modern computer system. controllers to memory contents. the bootstrap program must know how to load the operating system and to start executing that system. to accomplish this goal the bootstrap program must locate and load into memory the operatingsystem kernel. the operating system then starts executing the first process such as init and waits for some event to occur. the occurrence of an event is usually signaled by an interrupt from either the hardware or the software. hardware may trigger an interrupt at any time by sending a signal to the cpu usually by way of the system bus. software may trigger an interrupt by executing a special operation called a system call also called a monitor call . when the cpu is interrupted it stops what it is doing and immediately transfers execution to a fixed location. the fixed location usually contains the starting address where the service routine for the interrupt is located. the interrupt service routine executes on completion the cpu resumes the interrupted computation. a time line of this operation is shown in figure . . interrupts are an important part of a computer architecture. each computer design has its own interrupt mechanism but several functions are common. the interrupt must transfer control to the appropriate interrupt service routine. cpu user process u i o interrupt u processing o idle device transferring i o transfer i o transfer request done request done figure . interrupt time line for a single process doing output. chapter introduction the straightforward method for handling this transfer would be to invoke a generic routine to examine the interrupt information the routine in turn would call the interrupt specific handler. however interrupts must be handled quickly. since only a predefined number of interrupts is possible a table of pointers to interrupt routines can be used instead to provide the necessary speed. the interrupt routine is called indirectly through the table with no intermediate routine needed. generally the table of pointers is stored in low memory the first or so locations . these locations hold the addresses of the interrupt service routines for the various devices. this array or interrupt vector of addresses is then indexed by a unique device number given with the interrupt request to provide the address of the interrupt service routine for the interrupting device. operating systems as different as windows and unix dispatch interrupts in this manner. the interrupt architecture must also save the address of the interrupted instruction. many old designs simply stored the interrupt address in a fixed location or in a location indexed by the device number. more recent architectures store the return address on the system stack. if the interrupt routine needs to modify the processor state for instance by modifying register values it must explicitly save the current state and then restore that state before returning. after the interrupt is serviced the saved return address is loaded into the program counter and the interrupted computation resumes as though the interrupt had not occurred. . . storage structure computer programs must be in main memory also called random access memory or ram to be executed. main memory is the only large storage area millions to billions of bytes that the processor can access directly. it commonly is implemented in a semiconductor technology called dynamic random access memory dram which forms an array of memory words. each word has its own address. interaction is achieved through a sequence of load or store instructions to specific memory addresses. the load instruction moves a word from main memory to an internal register within the cpu whereas the s t o r e instruction moves the content of a register to main memory. aside from explicit loads and stores the cpu automatically loads instructions from main memory for execution. a typical instruction execution cycle as executed on a system with a von neumann architecture first fetches an instruction from memory and stores that instruction in the instruction register. the instruction is then decoded and may cause operands to be fetched from memory and stored in some internal register. after the instruction on the operands has been executed the result may be stored back in memory. notice that the memory unit sees only a stream of memory addresses it does not know how they are generated by the instruction counter indexing indirection literal addresses or some other means or what they are for instructions or data . accordingly we can ignore hoio a memory address is generated by a program. we are interested only in the sequence of memory addresses generated by the running program. ideally we want the programs and data to reside in main memory permanently. this arrangement usually is not possible for the following two reasons . computer system organization . main memory is usually too small to store all needed programs and data permanently. . main memory is a volatile storage device that loses its contents when power is turned off or otherwise lost. thus most computer systems provide secondary storage as an extension of main memory. the main requirement for secondary storage is that it be able to hold large quantities of data permanently. the most common secondary storage device is a magnetic disk which provides storage for both programs and data. most programs web browsers compilers word processors spreadsheets and so on are stored on a disk until they are loaded into memory. many programs then use the disk as both a source and a destination of the information for their processing. hence the proper management of disk storage is of central importance to a computer system as we discuss in chapter . in a larger sense however the storage structure that we have described consisting of registers main memory and magnetic disks is only one of many possible storage systems. others include cache memory cd rom magnetic tapes and so on. each storage system provides the basic functions of storing a datum and of holding that datum until it is retrieved at a later time. the main differences among the various storage systems lie in speed cost size and volatility. the wide variety of storage systems in a computer system can be organized in a hierarchy figure . according to speed and cost. the higher levels are expensive but they are fast. as we move down the hierarchy the cost per bit leqislorr cache t mam niomory electronic disk magnetic disk oplic.il dink magnetic tapes figure . storage device hierarchy. chapter introduction generally decreases whereas the access time generally increases. this trade off is reasonable if a given storage system were both faster and less expensive than another other properties being the same then there would be no reason to use the slower more expensive memory. in fact many early storage devices including paper tape and core memories are relegated to museums now that magnetic tape and semiconductor memory have become faster and cheaper. the top four levels of memory in figure . may be constructed using semiconductor memory. in addition to differing in speed and cost the various storage systems are either volatile or nonvolatile. as mentioned earlier volatile storage loses its contents when the power to the device is removed. in the absence of expensive battery and generator backup systems data must be written to nonvolatile storage for safekeeping. in the hierarchy shown in figure . the storage systems above the electronic disk are volatile whereas those below are nonvolatile. an electronic disk can be designed to be either volatile or nonvolatile. during normal operation the electronic disk stores data in a large dram array which is volatile. but many electronic disk devices contain a hidden magnetic hard disk and a battery for backup power. if external power is interrupted the electronic disk controller copies the data from ram to the magnetic disk. when external power is restored the controller copies the data back into the ram. another form of electronic disk is flash memory which is popular in cameras and personal digital assistants pdas in robots and increasingly as removable storage on general purpose computers. flash memory is slower than dram but needs no power to retain its contents. another form of nonvolatile storage is nvram which is dram with battery backup power. this memory can be as fast as dram but has a limited duration in which it is nonvolatile. the design of a complete memory system must balance all the factors just discussed it must use only as much expensive memory as necessary while providing as much inexpensive nonvolatile memory as possible. caches can be installed to improve performance where a large access time or transfer rate disparity exists between two components. . . i o structure storage is only one of many types of i o devices within a computer. a large portion of operating system code is dedicated to managing i o both because of its importance to the reliability and performance of a system and because of the varying nature of the devices. therefore we now provide an overview of i o. a general purpose computer system consists of cpus and multiple device controllers that are connected through a common bus. each device controller is in charge of a specific type of device. depending on the controller there may be more than one attached device. for instance seven or more devices can be attached to the small computer systems interface scsi controller. a device controller maintains some local buffer storage and a set of special purpose registers. the device controller is responsible for moving the data between the peripheral devices that it controls and its local buffer storage. typically operating systems have a device driver for each device controller. this device . computer system organization instruction execution cycle instructions thread of execution data movement and ca data cpu n dma memory figure . how a modern computer system works. driver understands the device controller and presents a uniform interface to the device to the rest of the operating system. to start an i o operation the device driver loads the appropriate registers within the device controller. the device controller in turn examines the contents of these registers to determine what action to take such as read a character from the keyboard the controller starts the transfer of data from the device to its local buffer. once the transfer of data is complete the device controller informs the device driver via an interrupt that it has finished its operation. the device driver then returns control to the operating system possibly returning the data or a pointer to the data if the operation was a read. for other operations the device driver returns status information. this form of interrupt driven i o is fine for moving small amounts of data but can produce high overhead when used for bulk data movement such as disk i o. to solve this problem direct memory access dma is used. after setting up buffers pointers and counters for the i o device the device controller transfers an entire block of data directly to or from its own buffer storage to memory with no intervention by the cpu. only one interrupt is generated per block to tell the device driver that the operation has completed rather than the one interrupt per byte generated for low speed devices. while the device controller is performing these operations the cpu is available to accomplish other work. some high end systems use switch rather than bus architecture. on these systems multiple components can talk to other components concurrently rather than competing for cycles on a shared bus. in this case dma is even more effective. figure . shows the interplay of all components of a computer system. chapter introduction
 in section . we introduced the general structure of a typical computer system. a computer system may be organized in a number of different ways which we can categorize roughly according to the number of general purpose processors used. . . single processor systems most systems vise a single processor. the variety of single processor systems may be surprising however since these systems range from pdas through mainframes. on a single processor system there is one main cpu capable of executing a general purpose instruction set including instructions from user processes. almost all systems have other special purpose processors as well. they may come in the form of device specific processors such as disk keyboard and graphics controllers or on mainframes they may come in the form of more general purpose processors such as i o processors that move data rapidly among the components of the system. all of these special purpose processors run a limited instruction set and do not run user processes. sometimes they are managed by the operating system in that the operating system sends them information about their next task and monitors their status. for example a disk controller microprocessor receives a sequence of requests from the main cpu and implements its own disk queue and scheduling algorithm. this arrangement relieves the main cpu of the overhead of disk scheduling. pcs contain a microprocessor in the keyboard to convert the keystrokes into codes to be sent to the cpu. in other systems or circumstances special purpose processors are low level components built into the hardware. the operating system cannot communicate with these processors they do their jobs autonomously. the use of special purpose microprocessors is common and does not turn a single processor system into a multiprocessor. if there is only one general purpose cpu then the system is a single processor system. . . multiprocessor systems although single processor systems are most common multiprocessor systems also known as parallel systems or tightly coupled systems are growing in importance. such systems have two or more processors in close communication sharing the computer bus and sometimes the clock memory and peripheral devices. multiprocessor systems have three main advantages . increased throughput. by increasing the number of processors we expect to get more work done in less time. the speed up ratio with n processors is not n however rather it is less than n. when multiple processors cooperate on a task a certain amount of overhead is incurred in keeping all the parts working correctly. this overhead plus contention for shared resources lowers the expected gain from additional processors. similarly n programmers working closely together do not produce n times the amount of work a single programmer would produce. . computer system architecture . economy of scale. multiprocessor systems can cost less than equivalent multiple single processor systems because they can share peripherals mass storage and power supplies. if several programs operate on the same set of data it is cheaper to store those data on one disk and to have all the processors share them than to have many computers with local disks and many copies of the data. . increased reliability. if functions can be distributed properly among several processors then the failure of one processor will not halt the system only slow it down. if we have ten processors and one fails then each of the remaining nine processors can pick up a share of the work of the failed processor. thus the entire system runs only percent slower rather than failing altogether. increased reliability of a computer system is crucial in many applications. the ability to continue providing service proportional to the level of surviving hardware is called graceful degradation. some systems go beyond graceful degradation and are called fault tolerant because they can suffer a failure of any single component and still continue operation. note that fault tolerance requires a mechanism to allow the failure to be detected diagnosed and if possible corrected. the hp nonstop system formerly tandem system uses both hardware and software duplication to ensure continued operation despite faults. the system consists of multiple pairs of cpus working in lockstep. both processors in the pair execute each instruction and compare the results. if the results differ then one cpu of the pair is at fault and both are halted. the process that was being executed is then moved to another pair of cpus and the instruction that failed is restarted. this solution is expensive since it involves special hardware and considerable hardware duplication. the multiple processor systems in use today are of two types. some systems use asymmetric multiprocessing in which each processor is assigned a specific task. a master processor controls the system the other processors either look to the master for instruction or have predefined tasks. this scheme defines a master slave relationship. the master processor schedules and allocates work to the slave processors. the most common systems use symmetric multiprocessing smp in which each processor performs all tasks within the operating system. smp means that all processors are peers no master slave relationship exists between processors. figure . illustrates a typical smp architecture. an example of the smp system is solaris a commercial version of unix designed by sun microsystems. a solaris system can be configured to employ dozens of processors all running solaris. the benefit of this model is that many processes gpu gpu cpu memory figure . symmetric multiprocessing architecture. chapter introduction can run simultaneously n processes can run if there are n cpus without causing a significant deterioration of performance. however we must carefully control i o to ensure that the data reach the appropriate processor. also since the cpus are separate one may be sitting idle while another is overloaded resulting in inefficiencies. these inefficiencies can be avoided if the processors share certain data structures. a multiprocessor system of this form will allow processes and resources such as memory to be shared dynamically among the various processors and can lower the variance among the processors. such a system must be written carefully as we shall see in chapter . virtually all modern operating systems including windows windows xp mac os x and linux now provide support for smp. the difference between symmetric and asymmetric multiprocessing may result from either hardware or software. special hardware can differentiate the multiple processors or the software can be written to allow only one master and multiple slaves. for instance sun's operating system sunos version provided asymmetric multiprocessing whereas version solaris is symmetric on the same hardware. a recent trend in cpu design is to include multiple compute cores on a single chip. in essence these are multiprocessor chips. two way chips are becoming mainstream while n way chips are going to be common in high end systems. aside from architectural considerations such as cache memory and bus contention these multi core cpus look to the operating system just as n standard processors. lastly blade servers are a recent development in which multiple processor boards i o boards and networking boards are placed in the same chassis. the difference between these and traditional multiprocessor systems is that each blade processor board boots independently and runs its own operating system. some blade server boards are multiprocessor as well which blurs the lines between types of computers. in essence those servers consist of multiple independent multiprocessor systems. . . clustered systems another type of multiple cpu system is the clustered system. like multiprocessor systems clustered systems gather together multiple cpus to accomplish computational work. clustered systems differ from multiprocessor systems however in that they are composed of two or more individual systems coupled together. the definition of the term clustered is not concrete many commercial packages wrestle with what a clustered system is and why one form is better than another. the generally accepted definition is that clustered computers share storage and are closely linked via a local area network lan as described in section . or a faster interconnect such as infiniband. clustering is usually used to provide high availability service that is service will continue even if one or more systems in the cluster fail. high availability is generally obtained by adding a level of redundancy in the system. a layer of cluster software runs on the cluster nodes. each node can monitor one or more of the others over the lan . if the monitored machine fails the monitoring machine can take ownership of its storage and restart the applications that were running on the failed machine. the users and clients of the applications see only a brief interruption of service
 clustering can be structured asymmetrically or symmetrically. in asymmetric clustering one machine is in hot standby mode while the other is running the applications. the hot standby host machine does nothing but monitor the active server. if that server fails the hot standby host becomes the active server. in symmetric mode two or more hosts are running applications and are monitoring each other. this mode is obviously more efficient as it uses all of the available hardware. it does require that more than one application be available to run. other forms of clusters include parallel clusters and clustering over a wide area network wan as described in section . . parallel clusters allow multiple hosts to access the same data on the shared storage. because most operating systems lack support for simultaneous data access by multiple hosts parallel clusters are usually accomplished by use of special versions of software and special releases of applications. for example oracle parallel server is a version of oracle's database that has been designed to run on a parallel cluster. each machine runs oracle and a layer of software tracks access to the shared disk. each machine has full access to all data in the database. to provide this shared access to data the system must also supply access control and locking to ensure that no conflicting operations occur. this function commonly known as a distributed lock manager dlm is included in some cluster technology. cluster technology is changing rapidly. some cluster products support dozens of systems in a cluster as well as clustered nodes that are separated by miles. many of these improvements are made possible by storage area networks sans as described in section . . which allow many systems to attach to a pool of storage. if the applications and their data are stored on the san then the cluster software can assign the application to run on any host that is attached to the san. if the host fails then any other host can take over. in a database cluster dozens of hosts can share the same database greatlyincreasing performance and reliability. . operating system structure now that we have discussed basic information about computer system organization and architecture we are ready to talk about operating systems. an operating system provides the environment within which programs are executed. internally operating systems vary greatly in their makeup since they are organized along many different lines. there are however many commonalities which we consider in this section. one of the most important aspects of operating systems is the ability to multiprogram. a single user cannot in general keep either the cpu or the i o devices busy at all times. multiprogramming increases cpu utilization by organizing jobs code and data so that the cpu always has one to execute. the idea is as follows the operating system keeps several jobs in memory simultaneously figure . . this set of jobs can be a subset of the jobs kept in the job pool which contains all jobs that enter the system since the number of jobs that can be kept simultaneously in memory is usually smaller than the number of jobs that can be kept in the job pool. the operating system picks and begins to execute one of the jobs in memory. eventually the job may have to wait for some task such as an i o operation to complete. in a chapter introduction operating system job job job job m figure . memory layout for a multiprogramming system. non multiprogrammed system the cpu would sit idle. in a multiprogrammed system the operating system simply switches to and executes another job. when that job needs to wait the cpu is switched to another job and so on. eventually the first job finishes waiting and gets the cpu back. as long as at least one job needs to execute the cpu is never idle. this idea is common in other life situations. a lawyer does not work for only one client at a time for example. while one case is waiting to go to trial or have papers typed the lawyer can work on another case. if he has enough clients the lawyer will never be idle for lack of work. idle lawyers tend to become politicians so there is a certain social value in keeping lawyers busy. multiprogrammed systems provide an environment in which the various system resources for example cpu memory and peripheral devices are utilized effectively but they do not provide for user interaction with the computer system. time sharing or multitasking is a logical extension of multiprogramming. in time sharing systems the cpu executes multiple jobs by switching among them but the switches occur so frequently that the users can interact with each program while it is running. time sharing requires an interactive or hands on computer system which provides direct communication between the user and the system. the user gives instructions to the operating system or to a program directly using a input device such as a keyboard or a mouse and waits for immediate results on an output device. accordingly the response time should be short typically less than one second. a time shared operating system allows many users to share the computer simultaneously. since each action or command in a time shared system tends to be short only a little cpu time is needed for each user. as the system switches rapidly from one user to the next each user is given the impression that the entire computer system is dedicated to his use even though it is being shared among many users. a time shared operating system uses cpu scheduling and multiprogramming to provide each user with a small portion of a time shared computer. each user has at least one separate program in memory. a program loaded into
 memory and executing is called a process. when a process executes it typically executes for only a short time before it either finishes or needs to perform i o. i o may be interactive that is output goes to a display for the user and input comes from a user keyboard mouse or other device. since interactive i o typically runs at people speeds it may take a long time to complete. input for example may be bounded by the user's typing speed seven characters per second is fast for people but incredibly slow for computers. rather than let the cpu sit idle as this interactive input takes place the operating system will rapidly switch the cpu to the program of some other user. time sharing and multiprogramming require several jobs to be kept simultaneously in memory. since in general main memory is too small to accommodate all jobs the jobs are kept initially on the disk in the job pool. this pool consists of all processes residing on disk awaiting allocation of main memory. if several jobs are ready to be brought into memory and if there is not enough room for all of them then the system must choose among them. making this decision is job scheduling which is discussed in chapter . when the operating system selects a job from the job pool it loads that job into memory for execution. having several programs in memory at the same time requires some form of memory management which is covered in chapters and . in addition if several jobs are ready to run at the same time the system must choose among them. making this decision is cpu scheduling which is discussed in chapter . finally running multiple jobs concurrently requires that their ability to affect one another be limited in all phases of the operating system including process scheduling disk storage and memory management. these considerations are discussed throughout the text. in a time sharing system the operating system must ensure reasonable response time which is sometimes accomplished through swapping where processes are swapped in and out of main memory to the disk. a more common method for achieving this goal is virtual memory a technique that allows the execution of a process that is not completely in memory chapter . the main advantage of the virtual memory scheme is that it enables users to run programs that are larger than actual physical memory. further it abstracts main memory into a large uniform array of storage separating logical memory as viewed by the user from physical memory. this arrangement frees programmers from concern over memory storage limitations. time sharing systems must also provide a file system chapters and . the file system resides on a collection of disks hence disk management must be provided chapter . also time sharing systems provide a mechanism for protecting resources from inappropriate use chapter . to ensure orderly execution the system must provide mechanisms for job synchronization and communication chapter and it may ensure that jobs do not get stuck in a deadlock forever waiting for one another chapter . . operating system operations as mentioned earlier modern operating systems are interrupt driven. if there are no processes to execute no i o devices to service and no users to whom to respond an operating system will sit quietly waiting for something to happen. events are almost always signaled by the occurrence of an interrupt chapter introduction or a trap. a trap or an exception is a software generated interrupt caused either by an error for example division by zero or invalid memory access or by a specific request from a user program that an operating system service be performed. the interrupt driven nature of an operating system defines that system's general structure. for each type of interrupt separate segments of code in the operating system determine what action should be taken. an interrupt service routine is provided that is responsible for dealing with the interrupt. since the operating system and the users share the hardware and software resources of the computer system we need to make sure that an error in a user program could cause problems only for the one program that was running. with sharing many processes could be adversely affected by a bug in one program. for example if a process gets stuck in an infinite loop this loop could prevent the correct operation of many other processes. more subtle errors can occur in a multiprogramming system where one erroneous program might modify another program the data of another program or even the operating system itself. without protection against these sorts of errors either the computer must execute only one process at a time or all output must be suspect. a properly designed operating system must ensure that an incorrect or malicious program cannot cause other programs to execute incorrectly. . . dual mode operation in order to ensure the proper execution of the operating system we must be able to distinguish between the execution of operating system code and userdefined code. the approach taken by most computer systems is to provide hardware support that allows us to differentiate among various modes of execution. at the very least we need two separate modes of operation user mode and kernel mode also called supervisor mode system mode or privileged mode . a bit called the mode bit is added to the hardware of the computer to indicate the current mode kernel or user . with the mode bit we are able to distinguish between a task that is executed on behalf of the operating system and one that is executed on behalf of the user. when the computer system is executing on behalf of a user application the system is in user mode. however when a user application requests a service from the operating system via a system call it must transition from user to kernel mode to fulfill the request. this is shown in figure . . as we shall see this architectural enhancement is useful for many other aspects of system operation as well. at system boot time the hardware starts in kernel mode. the operating system is then loaded and starts user applications in user mode. whenever a trap or interrupt occurs the hardware switches from user mode to kernel mode that is changes the state of the mode bit to . thus whenever the operating system gains control of the computer it is in kernel mode. the system always switches to user mode by setting the mode bit to before passing control to a user program. the dual mode of operation provides us with the means for protecting the operating system from errant users and errant users from one another. we accomplish this protection by designating some of the machine instructions that . operating system operations user mode user process executing calls system call return from system call mode bit kemel mode bit mode bit kernel mode execute system call i mode bit figure . transition from user to kernel mode. may cause harm as privileged instructions. the hardware allows privileged instructions to be executed only in kernel mode. if an attempt is made to execute a privileged instruction in user mode the hardware does not execute the instruction but rather treats it as illegal and traps it to the operating system. the instruction to switch to user mode is an example of a privileged instruction. some other examples include i o control timer management and interrupt management. as we shall see throughout the text there are many additional privileged instructions. we can now see the life cycle of instruction execution in a computer system. initial control is within the operating system where instructions are executed in kernel mode. when control is given to a user application the mode is set to user mode. eventually control is switched back to the operating system via an interrupt a trap or a system call. system calls provide the means for a user program to ask the operating system to perform tasks reserved for the operating system on the user program's behalf. a system call is invoked in a variety of ways depending on the functionality provided by the underlying processor. in all forms it is the method used by a process to request action by the operating system. a system call usually takes the form of a trap to a specific location in the interrupt vector. this trap can be executed by a generic t r a p instruction although some systems such as the mips r family have a specific s y s c a l l instruction. when a system call is executed it is treated by the hardware as a software interrupt. control passes through the interrupt vector to a service routine in the operating system and the mode bit is set to kernel mode. the systemcall service routine is a part of the operating system. the kernel examines the interrupting instruction to determine what system call has occurred a parameter indicates what type of service the user program is requesting. additional information needed for the request may be passed in registers on the stack or in memory with pointers to the memory locations passed in registers . the kernel verifies that the parameters are correct and legal executes the request and returns control to the instruction following the system call. we describe system calls more fully in section . . the lack of a hardware supported dual mode can cause serious shortcomings in an operating system. for instance ms dos was written for the intel architecture which has no mode bit and therefore no dual mode. a user program running awry can wipe out the operating system by writing over it with data and multiple programs are able to write to a device at the same time chapter introduction with possibly disastrous results. recent versions of the intel cpu such is the pentium do provide dual mode operation. accordingly most contemporary operating systems such as microsoft windows and windows xp and linux and solaris for x systems take advantage of this feature and provide greater protection for the operating system. once hardware protection is in place errors violating modes are detected by the hardware. these errors are normally handled by the operating system. if a user program fails in some way such as by making an attempt either to execute an illegal instruction or to access memory that is not in the user's address space then the hardware will trap to the operating system. the trap transfers control through the interrupt vector to the operating system just as an interrupt does. when a program error occurs the operating system must terminate the program abnormally. this situation is handled by the same code as is a user requested abnormal termination. an appropriate error message is given and the memory of the program may be dumped. the memory dump is usually written to a file so that the user or programmer can examine it and perhaps correct it and restart the program. . . timer we must ensure that the operating system maintains control over the cpu. we must prevent a user program from getting stuck in an infinite loop or not calling system services and never returning control to the operating system. to accomplish this goal we can use a timer. a timer can be set to interrupt the computer after a specified period. the period may be fixed for example second or variable for example from millisecond to second . a variable timer is generally implemented by a fixed rate clock and a counter. the operating system sets the counter. every time the clock ticks the counter is decremented. when the counter reaches an interrupt occurs. for instance a bit counter with a millisecond clock allows interrupts at intervals from millisecond to milliseconds in steps of millisecond. before turning over control to the user the operating system ensures that the timer is set to interrupt. if the timer interrupts control transfers automatically to the operating system which may treat the interrupt as a fatal error or may give the program more time. clearly instructions that modify the content of the timer are privileged. thus we can use the timer to prevent a user program from running too long. a simple technique is to initialize a counter with the amount of time that a program is allowed to run. a program with a minute time limit for example would have its counter initialized to . every second the timer interrupts and the counter is decremented by . as long as the counter is positive control is returned to the user program. when the counter becomes negative the operating system terminates the program for exceeding the assigned time limit
 a program does nothing unless its instructions are executed by a cpu. a program in execution as mentioned is a process. a time shared user program such as a compiler is a process. a word processing program being run by an
 individual user on a pc is a process. a system task such as sending utput to a printer can also be a process or at least part of one . for now you can consider a process to be a job or a time shared program but later you will learn that the concept is more general. as we shall see in chapter it is possible to provide system calls that allow processes to create subprocesses to execute concurrently. a process needs certain resources including cpu time memory files and i o devices to accomplish its task. these resources are either given to the process when it is created or allocated to it while it is running. in addition to the various physical and logical resources that a process obtains when it is created various initialization data input may be passed along. for example consider a process whose function is to display the status of a file on the screen of a terminal. the process will be given as an input the name of the file and will execute the appropriate instructions and system calls to obtain and display on the terminal the desired information. when the process terminates the operating system will reclaim any reusable resources. we emphasize that a program by itself is not a process a program is a passive entity such as the contents of a file stored on disk whereas a process is an active entity. a single threaded process has one program counter specifying the next instruction to execute. threads will be covered in chapter . the execution of such a process must be sequential. the cpu executes one instruction of the process after another until the process completes. further at any time one instruction at most is executed on behalf of the process. thus although two processes may be associated with the same program they are nevertheless considered two separate execution sequences. a multithreaded process has multiple program counters each pointing to the next instruction to execute for a given thread. a process is the unit of work in a system. such a system consists of a collection of processes some of which are operating system processes those that execute system code and the rest of which are user processes those that execute user code . all these processes can potentially execute concurrently by multiplexing the cpu among them on a single cpu for example. the operating system is responsible for the following activities in connection with process management creating and deleting both user and system processes suspending and resuming processes providing mechanisms for process synchronization providing mechanisms for process communication providing mechanisms for deadlock handling we discuss process management techniques in chapters through . . memory management as we discussed in section . . the main memory is central to the operation of a modern computer system. main memory is a large array of words or bytes chapter introduction ranging in size from hundreds of thousands to billions. each word or byte has its own address. main memory is a repository of quickly accessible data shared by the cpu and i o devices. the central processor reads instructions from main memory during the instruction fetch cycle and both reads and writes data from main memory during the data fetch cycle on a von neumann architecture . the main memory is generally the only large storage device that the cpu is able to address and access directly. for example for the cpu to process data from disk those data must first be transferred to main memory by cpu generated i o calls. in the same way instructions must be in memory for the cpu to execute them. for a program to be executed it must be mapped to absolute addresses and loaded into memory. as the program executes it accesses program instructions and data from memory by generating these absolute addresses. eventually the program terminates its memory space is declared available and the next program can be loaded and executed. to improve both the utilization of the cpu and the speed of the computer's response to its users general purpose computers must keep several programs in memory creating a need for memory management. many different memorymanagement schemes are used. these schemes reflect various approaches and the effectiveness of any given algorithm depends on the situation. in selecting a memory management scheme for a specific system we must take into account many factors especially on the hardware design of the system. each algorithm requires its own hardware support. the operating system is responsible for the following activities in connection with memory management keeping track of which parts of memory are currently being used and by whom deciding which processes or parts thereof and data to move into and out of memory allocating and deallocating memory space as needed memory management techniques will be discussed in chapters and
 to make the computer system convenient for users the operating system provides a uniform logical view of information storage. the operating system abstracts from the physical properties of its storage devices to define a logical storage unit the file. the operating system maps files onto physical media and accesses these files via the storage devices. . . file system management file management is one of the most visible components of an operating system. computers can store information on several different types of physical media. magnetic disk optical disk and magnetic tape are the most common. each of these media has its own characteristics and physical organization. each medium is controlled by a device such as a disk drive or tape drive that . storage management also has its own unique characteristics. these properties include accessspeed capacity' data transfer rate and access method sequential or random . a file is a collection of related information defined by its creator. commonly files represent programs both source and object forms and data. data files may be numeric alphabetic alphanumeric or binary. files may be free form for example text files or they may be formatted rigidly for example fixed fields . clearly the concept of a file is an extremely general one. the operating system implements the abstract concept of a file by managing mass storage media such as tapes and disks and the devices that control them. also files are normally organized into directories to make them easier to usefinally when multiple users have access to files it may be desirable to control by whom and in what ways for example read write append files may be accessed. the operating system is responsible for the following activities in connection with file management creating and deleting files creating and deleting directories to organize files supporting primitives for manipulating files and directories mapping files onto secondary storage backing up files on stable nonvolatile storage media file management techniques will be discussed in chapters and . . . mass storage management as we have already seen because main memory is too small to accommodate all data and programs and because the data that it holds are lost when power is lost the computer system must provide secondary storage to back up main memory. most modern computer systems use disks as the principal on line storage medium for both programs and data. most programs including compilers assemblers word processors editors and formatters are stored on a disk until loaded into memory and then use the disk as both the source and destination of their processing. hence the proper management of disk storage is of central importance to a computer system. the operating system is responsible for the following activities in connection with disk management free space management storage allocation disk scheduling because secondary storage is used frequently it must be used efficiently. the entire speed of operation of a computer may hinge on the speeds of the disk subsystem and of the algorithms that manipulate that subsystem. there are however many uses for storage that is slower and lower in cost and sometimes of higher capacity than secondary storage. backups of disk data seldom used data and long term archival storage are some examples. chapter introduction magnetic tape drives and their tapes and cd and dvd drives and platters are typical tertiary storage devices. the media tapes and optical platters vary between worm write once read many times and rw read write formats. tertiary storage is not crucial to system performance but it still must be managed. some operating systems take on this task while others leave tertiary storage management to application programs. some of the functions that operating systems can provide include mounting and unmounting media in devices allocating and freeing the devices for exclusive use by processes and migrating data from secondary to tertiary storage. techniques for secondary and tertiary storage management will be discussed in chapter . . . caching caching is an important principle of computer systems. information is normally kept in some storage system such as main memory . as it is used it is copied into a faster storage system the cache on a temporary basis. when we need a particular piece of information we first check whether it is in the cache. if it is we use the information directly from the cache if it is not we use the information from the source putting a copy in the cache under the assumption that we will need it again soon. in addition internal programmable registers such as index registers provide a high speed cache for main memory. the programmer or compiler implements the register allocation and register replacement algorithms to decide which information to keep in registers and which to keep in main memory. there are also caches that are implemented totally in hardware. for instance most systems have an instruction cache to hold the next instructions expected to be executed. without this cache the cpu would have to wait several cycles while an instruction was fetched from main memory. for similar reasons most systems have one or more high speed data caches in the memory hierarchy. we are not concerned with these hardware only caches in this text since they are outside the control of the operating system. because caches have limited size cache management is an important design problem. careful selection of the cache size and of a replacement policy can result in greatly increased performance. see figure . for a storage performance comparison in large workstations and small servers that shows the need for caching. various replacement algorithms for software controlled caches are discussed in chapter . main memory can be viewed as a fast cache for secondary storage since data in secondary storage must be copied into main memory for use and data must be in main memory before being moved to secondary storage for safekeeping. the file system data which resides permanently on secondary storage may appear on several levels in the storage hierarchy. at the highest level the operating system may maintain a cache of file system data in main memory also electronic ram disks also known as solid state disks may be used for high speed storage that is accessed through the file system interface. the bulk of secondary storage is on magnetic disks. the magnetic disk storage in turn is often backed up onto magnetic tapes or removable disks to protect against data loss in case of a hard disk failure. some systems automatically . storage management level i z ' ' ' isgistprs. . . eacn. um u j raajft njenwjy j cfisk sti fgge i i ! r f 'll ifflfflif s. gl. ' mul ll pm ttfejis riaihltiebsi cqess time insji j s s s . q i ! m sk m lanaielf i cfoffipifer iriafpari f i i otjemini sysfew opep!ti sii?si etti saekeiflisy sflher i ' ' ' rilaiji memory disl ! dpi fia e j f figure . performance of various levels of storage. archive old file data from secondary storage to tertiary storage such as tape jukeboxes to lower the storage cost see chapter . the movement of information between levels of a storage hierarchy may be either explicit or implicit depending on the hardware design and the controlling operating system software. for instance data transfer from cache to cpu and registers is usually a hardware function with no operating system intervention. in contrast transfer of data from disk to memory is usually controlled by the operating system. in a hierarchical storage structure the same data may appear in different levels of the storage system. for example suppose that an integer a that is to be incremented by is located in file b and file b resides on magnetic disk. the increment operation proceeds by first issuing an i o operation to copy the disk block on which a resides to main memory. this operation is followed by copying a to the cache and to an internal register. thus the copy of a appears in several places on the magnetic disk in main memory in the cache and in an internal register see figure . . once the increment takes place in the internal register the value of a differs in the various storage systems. the value of a becomes the same only after the new value of a is written from the internal register back to the magnetic disk. in a computing environment where only one process executes at a time this arrangement poses no difficulties since an access to integer a will always be to the copy at the highest level of the hierarchy. however in a multitasking environment where the cpu is switched back and forth among various processes extreme care must be taken to ensure that if several processes wish to access a then each of these processes will obtain the most recently updated value of a. magnetic main hardware disk memory register figure . migration of integer a from disk to register. chapter introduction the situation becomes more complicated in a multiprocessor environment where in addition to maintaining internal registers each of the cpus also contains a local cache. in such an environment a copy of a may exist simultaneously in several caches. since the various cpus can all execute concurrently we must make sure that an update to the value of a in one cache is immediately reflected in all other caches where a resides. this situation is called cache coherency and it is usually a hardware problem handled below the operating system level . in a distributed environment the situation becomes even more complex. in this environment several copies or replicas of the same file can be kept on different computers that are distributed in space. since the various replicas may be accessed and updated concurrently some distributed systems ensure that when a replica is updated in one place all other replicas are brought up to date as soon as possible. there are various ways to achieve this guarantee as we discuss in chapter . . . i o systems one of the purposes of an operating system is to hide the peculiarities of specific hardware devices from the user. for example in unix the peculiarities of i o devices are hidden from the bulk of the operating system itself by the i o subsystem. the i o subsystem consists of several components a memory management component that includes buffering caching and spooling a general device driver interface drivers for specific hardware devices only the device driver knows the peculiarities of the specific device to which it is assigned. we discussed in section . . how interrupt handlers and device drivers are used in the construction of efficient i o subsystems. in chapter we discuss how the i o subsystem interfaces to the other system components manages devices transfers data and detects i o completion
 if a computer system has multiple users and allows the concurrent execution of multiple processes then access to data must be regulated. for that purpose mechanisms ensure that files memory segments cpu and other resources can be operated on by only those processes that have gained proper authorization from the operating system. for example memory addressing hardware ensures that a process can execute only within its own address space. the timer ensures that no process can gain control of the cpu without eventually relinquishing control. device control registers are not accessible to users so the integrity of the various peripheral devices is protected. protection then is any mechanism for controlling the access of processes or users to the resources defined by a computer system. this mechanism must . protection and security provide means for specification of the controls to be imposed and means for enforcement. protection can improve reliability by detecting latent errors at the interfaces between component subsystems. early detection of interface errors can often prevent contamination of a healthy subsystem by another subsystem that is malfunctioning. an unprotected resource cannot defend against use or misuse by an unauthorized or incompetent user. a protection oriented system provides a means to distinguish between authorized and unauthorized usage as we discuss in chapter . a system can have adequate protection but still be prone to failure and allow inappropriate access. consider a user whose authentication information her means of identifying herself to the system is stolen. her data could be copied or deleted even though file and memory protection are working. it is the job of security to defend a system from external and internal attacks. such attacks spread across a huge range and include viruses and worms denial ofservice attacks which use all of a system's resources and so keep legitimate users out of the system identity theft and theft of service unauthorized use of a system . prevention of some of these attacks is consider an operatingsystem function on some systems while others leave the prevention to policy or additional software. due to the alarming rise in security incidents operatingsystem security features represent a fast growing area of research and of implementation. security is discussed in chapter . protection and security require the system to be able to distinguish among all its users. most operating systems maintain a list of user names and associated user identifiers user ids . in windows nt parlance this is a security id sid . these numerical ids are unique one per user. when a user logs in to the system the authentication stage determines the appropriate user id for the user. that user id is associated with all of the user's processes and threads. when an id needs to be user readable it is translated back to the user name via the user name list. in some circumstances we wish to distinguish among sets of users rather than individual users. for example the owner of a file on a unix system may be allowed to issue all operations on that file whereas a selected set of users may only be allowed to read the file. to accomplish this we need to define a group name and the set of users belonging to that group. group functionality can be implemented as a system wide list of group names and group identifiers. a user can be in one or more groups depending on operating system design decisions. the user's group ids are also included in every associated process and thread. in the course of normal use of a system the user id and group id for a user are sufficient. however a user sometimes needs to escalate privileges to gain extra permissions for an activity. the user may need access to a device that is restricted for example. operating systems provide various methods to allow privilege escalation. on unix for example the setuid attribute on a program causes that program to run with the user id of the owner of the file rather than the current user's id. the process runs with this effective uid until it turns off the extra privileges or terminates. consider an example of how this is done in solaris . user pbg has user id and group id which are assigned via etc passwd pbg x export home pbg usr bin bash chapter introduction
 a distributed system is a collection of physically separate possibly heterogeneous computer systems that are networked to provide the users with access to the various resources that the system maintains. access to a shared resource increases computation speed functionality data availability and reliability. some operating systems generalize network access as a form of file access with the details of networking contained in the network interface's device driver. others make users specifically invoke network functions. generally systems contain a mix of the two modes for example ftp and nfs. the protocols that create a distributed system can greatly affect that system's utility and popularity. a network in the simplest terms is a communication path between two or more systems. distributed systems depend on networking for their functionality. networks vary by the protocols used the distances between nodes and the transport media. tcp ip is the most common network protocol although atm and other protocols are in widespread use. likewise operatingsystem support of protocols varies. most operating systems support tcp ip including the windows and unix operating systems. some systems support proprietary protocols to suit their needs. to an operating system a network protocol simply needs an interface device a network adapter for example with a device driver to manage it as well as software to handle data. these concepts are discussed throughout this book. networks are characterized based on the distances between their nodes. a local area network lan connects computers within a room a floor or a building. a wide area network wan usually links buildings cities or countries. a global company may have a wan to connect its offices worldwide. these networks may run one protocol or several protocols. the continuing advent of new technologies brings about new forms of networks. for example a metropolitan area network man could link buildings within a city. bluetooth and . devices use wireless technology to communicate over a distance of several feet in essence creating a small area network such as might be found in a home. the media to carry networks are equally varied. they include copper wires fiber strands and wireless transmissions between satellites microwave dishes and radios. when computing devices are connected to cellular phones they create a network. even very short range infrared communication can be used for networking. at a rudimentary level whenever computers communicate they use or create a network. these networks also vary in their performance and reliability. some operating systems have taken the concept of networks and distributed systems further than the notion of providing network connectivity. a network operating system is an operating system that provides features such as file sharing across the network and that includes a communication scheme that allows different processes on different computers to exchange messages. a computer running a network operating system acts autonomously from all other computers on the network although it is aware of the network and is able to communicate with other networked computers. a distributed operating system provides a less autonomous environment the different operating
 systems communicate closely enough to provide the illusion that only a single operating system controls the network. we cover computer networks and distributed systems in chapters through . . special purpose systems the discussion thus far has focused on general purpose computer systems that we are all familiar with. there are however different classes of computer systems whose functions are more limited and whose objective is to deal with limited computation domains. . . real time embedded systems embedded computers are the most prevalent form of computers in existence. these devices are found everywhere from car engines and manufacturing robots to vcrs and microwave ovens. they tend to have very specific tasks. the systems they run on are usually primitive and so the operating systems provide limited features. usually they have little or no user interface preferring to spend their time monitoring and managing hardware devices such as automobile engines and robotic arms. these embedded systems vary considerably. some are general purpose computers running standard operating systems such as unix with special purpose applications to implement the functionality. others are hardware devices with a special purpose embedded operating system providing just the functionality desired. yet others are hardware devices with application specific integrated circuits asics that perform their tasks without an operating system. the use of embedded systems continues to expand. the power of these devices both as standalone units and as members of networks and the web is sure to increase as well. even now entire houses can be computerized so that a central computer either a general purpose computer or an embedded system can control heating and lighting alarm systems and even coffee makers. web access can enable a home owner to tell the house to heat up before she arrives home. someday the refrigerator may call the grocery store when it notices the milk is gone. embedded systems almost always run real time operating systems. a real time system is used when rigid time requirements have been placed on the operation of a processor or the flow of data thus it is often used as a control device in a dedicated application. sensors bring data to the computer. the computer must analyze the data and possibly adjust controls to modify the sensor inputs. systems that control scientific experiments medical imaging systems industrial control systems and certain display systems are realtime systems. some automobile engine fuel injection systems home appliance controllers and weapon systems are also real time systems. a real time system has well defined fixed time constraints. processing mustbe done within the defined constraints or the system will fail. for instance it would not do for a robot arm to be instructed to halt after it had smashed into the car it was building. a real time system functions correctly only if it chapter introduction returns the correct result within its time constraints. contrast this system with a time sharing system where it is desirable but not mandatory to respond quickly or a batch system which may have no time constraints at all. in chapter we cover real time embedded systems in great detail. in chapter we consider the scheduling facility needed to implement real time functionality in an operating system. in chapter we describe the design of memory management for real time computing. finally in chapter we describe the real time components of the windows xp operating system. . . multimedia systems most operating systems are designed to handle conventional data such as text files programs word processing documents and spreadsheets. however a recent trend in technology is the incorporation of multimedia data into computer systems. multimedia data consist of audio and video files as well as conventional files. these data differ from conventional data in that multimedia data such as frames of video must be delivered streamed according to certain time restrictions for example frames per second . multimedia describes a wide range of applications that are in popular use today. these include audio files such as mp dvd movies video conferencing and short video clips of movie previews or news stories downloaded over the internet. multimedia applications may also include live webcasts broadcasting over the world wide web of speeches or sporting events and even live webcams that allow a viewer in manhattan to observe customers at a cafe in paris. multimedia applications need not be either audio or video rather a multimedia application often includes a combination of both. for example a movie may consist of separate audio and video tracks. nor must multimedia applications be delivered only to desktop personal computers. increasingly they are being directed toward smaller devices including pdas and cellular telephones. for example a stock trader may have stock quotes delivered wirelessly and in real time to his pda. in chapter we explore the demands of multimedia applications how multimedia data differ from conventional data and how the nature of these data affects the desigii of operating systems that support the requirements of multimedia systems. . . handheld systems handheld systems include personal digital assistants pdas such as palm and pocket pcs and cellular telephones many of which use special purpose embedded operating systems. developers of handheld systems and applications face many challenges most of which are due to the limited size of such devices. for example a pda is typically about inches in height and inches in width and it weighs less than one half pound. because of their size most handheld devices have a small amount of memory slow processors and small display screens. we will take a look now at each of these limitations. the amount of physical memory in a handheld depends upon the device but typically is is somewhere between kb and mb. contrast this with a typical pc or workstation which may have several gigabytes of memory! as a result the operating system and applications must manage memory efficiently. this includes returning all allocated memory back to the memory
 manager when the memory is not being used. in chapter we will explore virtual memory which allows developers to write programs that behave as if the system has more memory than is physically available. currently not many handheld devices use virtual memory techniques so program developers must work within the confines of limited physical memory. a second issue of concern to developers of handheld devices is the speed of the processor used in the devices. processors for most handheld devices run at a fraction of the speed of a processor in a pc. faster processors require more power. to include a faster processor in a handheld device would require a larger battery which would take up more space and would have to be replaced or recharged more frequently. most handheld devices use smaller slower processors that consume less power. therefore the operating system and applications must be designed not to tax the processor. the last issue confronting program designers for handheld devices is i o. a lack of physical space limits input methods to small keyboards handwriting recognition or small screen based keyboards. the small display screens limit output options. whereas a monitor for a home computer may measure up to inches the display for a handheld device is often no more than inches square. familiar tasks such as reading e mail and browsing web pages must be condensed into smaller displays. one approach for displaying the content in web pages is web clipping where only a small subset of a web page is delivered and displayed on the handheld device. some handheld devices use wireless technology such as bluetooth or . allowing remote access to e mail and web browsing. cellular telephones with connectivity to the internet fall into this category. however for pdas that do not provide wireless access downloading data typically requires the user to first download the data to a pc or workstation and then download the data to the pda. some pdas allow data to be directly copied from one device to another using an infrared link. generally the limitations in the functionality of pdas are balanced by their convenience and portability. their use continues to expand as network connections become more available and other options such as digital cameras and mp players expand their utility. . computing environments so far we have provided an overview of computer system organization and major operating system components. we conclude with a brief overview of how these are used in a variety of computing environments. . . traditional computing as computing matures the lines separating many of the traditional computing environments are blurring. consider the typical office environment. just a few years ago this environment consisted of pcs connected to a network with servers providing file and print services. remote access was awkward and portability was achieved by use of laptop computers. terminals attached to mainframes were prevalent at many companies as well with even fewer remote access and portability options. chapter introduction the current trend is toward providing more ways to access these computing environments. web technologies are stretching the boundaries of traditional computing. companies establish portals which provide web accessibility to their internal servers. network computers are essentially terminals that understand web based computing. handheld computers can synchronize with pcs to allow very portable use of company information. handheld pdas can also connect to wireless networks to use the company's web portal as well as the myriad other web resources . at home most users had a single computer with a slow modem connection to the office the internet or both. today network connection speeds once available only at great cost are relatively inexpensive giving home users more access to more data. these fast data connections are allowing home computers to serve up web pages and to run networks that include printers client pcs and servers. some homes even have firewalls to protect their networks from security breaches. those firewalls cost thousands of dollars a few years ago and did not even exist a decade ago. in the latter half of the previous century computing resources were scarce. before that they were nonexistent! for a period of time systems were either batch or interactive. batch system processed jobs in bulk with predetermined input from files or other sources of data . interactive systems waited for input from users. to optimize the use of the computing resources multiple users shared time on these systems. time sharing systems used a timer and scheduling algorithms to rapidly cycle processes through the cpu giving each user a share of the resources. today traditional time sharing systems are uncommon. the same scheduling technique is still in use on workstations and servers but frequently the processes are all owned by the same user or a single user and the operating system . user processes and system processes that provide services to the user are managed so that each frequently gets a slice of computer time. consider the windows created while a user is working on a pc for example and the fact that they may be performing different tasks at the same time. . . client server computing as pcs have become faster more powerful and cheaper designers have shifted away from centralized system architecture. terminals connected to centralized systems are now being supplanted by pcs. correspondingly userinterface functionality once handled directly by the centralized systems is increasingly being handled by the pcs. as a result many of todays systems act as server systems to satisfy requests generated by client systems. this form of specialized distributed system called client server system has the general structure depicted in figure . . server systems can be broadly categorized as compute servers and file servers the compute server system provides an interface to which a client can send a request to perform an action for example read data in response the server executes the action and sends back results to the client. a server running a database that responds to client requests for data is an example of such a svstem. . computing environments client client ! i client client network server figure . general structure of a client server system. the file server system provides a file system interface where clients can create update read and delete files. an example of such a system is a web server that delivers files to clients running web browsers.' . . peer to peer computing another structure for a distributed system is the peer to peer p p system model. in this model clients and servers are not distinguished from one another instead all nodes within the system are considered peers and each may act as either a client or a server depending on whether it is requesting or providing a service. peer to peer systems offer an advantage over traditional client server systems. in a client server system the server is a bottleneck but in a peer to peer system services can be provided by several nodes distributed throughout the network. to participate in a peer to peer system a node must first join the network of peers. once a node has joined the network it can begin providing services to and requesting services from other nodes in the network. determining what services are available is accomplished in one of two general ways when a node joins a network it registers its service with a centralized lookup service on the network. any node desiring a specific service first contacts this centralized lookup service to determine which node provides the service. the remainder of the communication takes place between the client and the service provider. a peer acting as a client must first discover what node provides a desired service by broadcasting a request for the service to all other nodes in the network. the node or nodes providing that service responds to the peer making the request. to support this approach a discovery protocol must be provided that allows peers to discover services provided by other peers in the network. peer to peer networks gained widespread popularity in the late s with several file sharing services such as napster and gnutella that enable peers to exchange files with one another. the napster system uses an approach similar to the first type described above a centralized server maintains an index of all files stored on peer nodes in the napster network and the actual exchanging of files takes place between the peer nodes. the gnutella system uses a technique similar to the second type a client broadcasts file requests to other nodes in the system and nodes that can service the request respond directly to the client. the future of exchanging files remains uncertain because chapter introduction many of the files are copyrighted music for example and there are laws governing the distribution of copyrighted material. in any case though peerto peer technology undoubtedly will play a role in the future of many sendees such as searching file exchange and e mail. . . web based computing the web has become ubiquitous leading to more access by a wider variety of devices than was dreamt of a few years ago. pcs are still the most prevalent access devices with workstations handheld pdas and even cell phones also providing access. web computing has increased the emphasis on networking. devices that were not previously networked now include wired or wireless access. devices that were networked now have faster network connectivity provided by either improved networking technology optimized network implementation code or both. the implementation of web based computing has given rise to new categories of devices such as load balancers which distribute network connections among a pool of similar servers. operating systems like windows which acted as web clients have evolved into linux and windows xp which can act as web servers as well as clients. generally the web has increased the complexity of devices because their users require them to be web enabled
 an operating system is software that manages the computer hardware as well as providing an environment for application programs to run. perhaps the most visible aspect of an operating system is the interface to the computer system it provides to the human user. for a computer to do its job of executing programs the programs must be in main memory. main memory is the only large storage area that the processor can access directly. it is an array of words or bytes ranging in size from millions to billions. each word in memory has its own address. the main memory is usually a volatile storage device that loses its contents when power is turned off or lost. most computer systems provide secondary storage as an extension of main memory. secondary storage provides a form of non volatile storage that is capable of holding large quantities of data permanently. the most common secondary storage device is a magnetic disk which provides storage of both programs and data. the wide variety of storage systems in a computer system can be organized in a hierarchy according to speed and cost. the higher levels are expensive but they are fast. as we move down the hierarchy the cost per bit generallydecreases whereas the access time generally increases. there are several different strategies for designing a computer system. uniprocessor systems have only a single processor while multiprocessor systems contain two or more processors that share physical memory and peripheral devices. the most common multiprocessor design is symmetric multiprocessing or smp where all processors are considered peers and run . summary independently of one another. clustered systems are a specialized form of multiprocessor systems and consist of multiple computer systems connected by a local area network. to best utilize the cpu modern operating systems employ multiprogramming which allows several jobs to be in memory at the same time thus ensuring the cpu always has a job to execute. timesharing systems are an extension of multiprogramming whereby cpu scheduling algorithms rapidly switch between jobs thus providing the illusion each job is running concurrently. the operating system must ensure correct operation of the computer system. to prevent user programs from interfering with the proper operation of the system the hardware has two modes user mode and kernel mode. various instructions such as i o instructions and halt instructions are privileged and can be executed only in kernel mode. the memory in which the operating system resides must also be protected from modification by the user. a timer prevents infinite loops. these facilities dual mode privileged instructions memory protection and timer interrupt are basic building blocks used by operating systems to achieve correct operation. a process or job is the fundamental unit of work in an operating system. process management includes creating and deleting processes and providing mechanisms for processes to communicate and synchronize with another. an operating system manages memory by keeping track of what parts of memory are being used and by whom. the operating system is also responsible for dynamically allocating and freeing memory space. storage space is also managed by the operating system and this includes providing file systems for representing files and directories and managing space on mass storage devices. operating systems must also be concerned with protecting and securing the operating system and users. protection are mechanisms that control the access of processes or users to the resources made available by the computer system. security measures are responsible for defending a computer system from external or internal attacks. distributed systems allow users to share resources on geographically dispersed hosts connected via a computer network. services may be provided through either the client server model or the peer to peer model. in a clustered system multiple machines can perform computations on data residing on shared storage and computing can continue even when some subset of cluster members fails. lans and wans are the two basic types of networks. lans enable processors distributed over a small geographical area to communicate whereas wans allow processors distributed over a larger area to communicate. lans typically are faster than wans. there are several computer systems that serve specific purposes. these include real time operating systems designed for embedded environments such as consumer devices automobiles and robotics. real time operating systems have well defined fixed time constraints. processing must be done within the defined constraints or the system will fail. multimedia systems involve the delivery of multimedia data and often have special requirements of displaying or playing audio video or synchronized audio and video streams. recently the influence of the internet and the world wide web has encouraged the development of modern operating systems that include web browsers and networking and communication software as integral features. chapter introduction exercises . in a multiprogramming and time sharing environment several users share the system simultaneously. this situation can result in various security problems. a. what are two such problems? b. can we ensure the same degree of security in a time shared machine as in a dedicated machine? explain your answer. . the issue of resource utilization shows up in different forms in different types of operating systems. list what resources must be managed carefully in the following settings a. mainframe or minicomputer systems b. workstations connected to servers c. handheld computers . under what circumstances would a user be better off using a timesharing system rather than a pc or single user workstation? . which of the functionalities listed below need to be supported by the operating system for the following two settings a handheld devices and b real time systems. a. batch programming b. virtual memory c. time sharing . describe the differences between symmetric and asymmetric multiprocessing. what are three advantages and one disadvantage of multiprocessor systems? . how do clustered systems differ from multiprocessor systems? what is required for two machines belonging to a cluster to cooperate to provide a highly available service? . distinguish between the client server and peer to peer models of distributed systems. . consider a computing cluster consisting of two nodes running a database. describe two ways in which the cluster software can manage access to the data on the disk. discuss the benefits and disadvantages of each. . how are network computers different from traditional personal com puters? describe some usage scenarios in which it is advantageous to use network computers. . what is the purpose of interrupts? what are the differences between a trap and an interrupt? can traps be generated intentionally by a user program? if so for what purpose? exercises . direct memory access is used for high speed i o devices in order to avoid increasing the cpu's execution load. a. how does the cpu interface with the device to coordinate the transfer? b. how does the cpu know when the memory operations are complete? c. the cpu is allowed to execute other programs while the dma controller is transferring data. does this process interfere with the execution of the user programs? if so describe what forms of interference are caused. . some computer systems do not provide a privileged mode of operation in hardware. is it possible to construct a secure operating system for these computer systems? give arguments both that it is and that it is not possible. . give two reasons why caches are useful. what problems do they solve? what problems do they cause? if a cache can be made as large as the device for which it is caching for instance a cache as large as a disk why not make it that large and eliminate the device? . discuss with examples how the problem of maintaining coherence of cached data manifests itself in the following processing environments a. single processor systems b. multiprocessor systems c. distributed systems . describe a mechanism for enforcing memory protection in order to prevent a program from modifying the memory associated with other programs. . what network configuration would best suit the following environments? a. a dormitory floor b. a university campus c. a state d. a nation . define the essential properties of the following types of operating systems a. batch b. interactive c. time sharing d. real time e. network chapter introduction f. parallel g. distributed h. clustered i. handheld . what are the tradeoffs inherent in handheld computers? bibliographical notes brookshear provides an overview of computer science in general. an overview of the linux operating system is presented in bovet and cesati . solomon and russinovich give an overview of microsoft windows and considerable technical detail about the system internals and components. mauro and mcdougall cover the solaris operating system. mac os x is presented at http www.apple.com macosx. coverage of peer to peer systems includes parameswaran et al. gong ripeanu et al. agre balakrisfrnan et al. and loo . a discussion on peer to peer file sharing systems can be found in lee . a good coverage of cluster computing is presented by buyya . recent advances in cluster computing are described by ahmed . a survey of issues relating to operating systems support for distributed systems can be found in tanenbaum and van renesse . many general textbooks cover operating systems including stallings b nutt and tanenbaum . hamacher et al. describes computer organization. hennessy and patterson provide coverage of i o systems and buses and of system architecture in general. cache memories including associative memory are described and analyzed by smith . that paper also includes an extensive bibliography on the subject. discussions concerning magnetic disk technology are presented by freedman and by harker et al. . optical disks are covered by kenville fujitani o'leary and kitts gait and olsen and kenley . discussions of floppy disks are offered by pechura and schoeffler and by sarisky . general discussions concerning mass storage technology are offered by chi and by hoagland . kurose and ross tanenbaum peterson and davie and halsall provide general overviews of computer networks. fortier presents a detailed discussion of networking hardware and software. wolf discusses recent developments in developing embedded systems. issues related to handheld devices can be found in myers and beigl and di pietro and mancini 
 an operating system provides the environment within which programs are executed. internally operating systems vary greatly in their makeup since they are organized along many different lines. the design of a new operating system is a major task. it is important that the goals of the system be well defined before the design begins. these goals form the basis for choices among various algorithms and strategies. we can view an operating system from several vantage points. one view focuses on the services that the system provides another on the interface that it makes available to users and programmers a third on its components and their interconnections. in this chapter we explore all three aspects of operating systems showing the viewpoints of users programmers and operating system designers. we consider what services an operating system provides how they are provided and what the various methodologies are for designing such systems. finally we describe how operating systems are created and how a computer starts its operating system. objectives to describe the services an operating system provides to users processes and other systems. to discuss the various ways of structuring an operating system. to explain how operating systems are installed and customized and how they boot
 an operating system provides an environment for the execution of programs. it provides certain services to programs and to the users of those programs. the specific services provided of course differ from one operating system to another but we can identify common classes. these operating system services are provided for the convenience of the programmer to make the programming task easier. chapter operating system structures one set of operating system services provides functions that are helpful to the user. user interface. almost all operating systems have a user interface ui . this interface can take several forms. one is a command line interface cli which uses text commands and a method for entering them say a program to allow entering and editing of commands . another is a batch interface in which commands and directives to control those commands are entered into files and those files are executed. most commonly a graphical user interface gui is used. here the interface is a window system with a pointing device to direct i o choose from menus and make selections and a keyboard to enter text. some systems provide two or all three of these variations. program execution. the system must be able to load a program into memory and to run that program. the program must be able to end its execution either normally or abnormally indicating error . i o operations. a running program may require i o which may involve a file or an i o device. for specific devices special functions may be desired such as recording to a cd or dvd drive or blanking a crt screen . for efficiency and protection users usually cannot control i o devices directly. therefore the operating system must provide a means to do i o. file system manipulation. the file system is of particular interest. obviously programs need to read and write files and directories. they also need to create and delete them by name search for a given file and list file information. finally some programs include permissions management to allow or deny access to files or directories based on file ownership. communications. there are many circumstances in which one process needs to exchange information with another process. such communication may occur between processes that are executing on the same computer or between processes that are executing on different computer systems tied together by a computer network. communications may be implemented via shared memory or through message passing in which packets of information are moved between processes by the operating system. error detection. the operating system needs to be constantly aware of possible errors. errors may occur in the cpu and memory hardware such as a memory error or a power failure in i o devices such as a parity error on tape a connection failure on a network or lack of paper in the printer and in the user program such as an arithmetic overflow an attempt to access an illegal memory location or a too great use of cpu time . for each type of error the operating system should take the appropriate action to ensure correct and consistent computing. debugging facilities can greatly enhance the user's and programmer's abilities to use the system efficiently. another set of operating system functions exists not for helping the user but rather for ensuring the efficient operation of the system itself. systems with multiple users can gain efficiency by sharing the computer resources among the users
 resource allocation. when there are multiple users or multiple jobs running at the same time resources must be allocated to each of hem. many different types of resources are managed by the operating system. some such as cpu cycles main memory and file storage may have special allocation code whereas others such as i o devices may have much more general request and release code. for instance in determining how best to use the cpu operating systems have cpu scheduling routines that take into account the speed of the cpu the jobs that must be executed the number of registers available and other factors. there may also be routines to allocate printers modems usb storage drives and other peripheral devices. accounting. we want to keep track of which users use how much and what kinds of computer resources. this record keeping may be used for accounting so that users can be billed or simply for accumulating usage statistics. usage statistics may be a valuable tool for researchers who wish to reconfigiire the system to improve computing services. protection and security. the owners of information stored in a multiuser or networked computer system may want to control use of that information. when several separate processes execute concurrently it should not be possible for one process to interfere with the others or with the operating system itself. protection involves ensuring that all access to system resources is controlled. security of the system from outsiders is also important. such security starts with requiring each user to authenticate himself or herself to the system usually by means of a password to gain access to system resources. it extends to defending external i o devices including modems and network adapters from invalid access attempts and to recording all such connections for detection of break ins. if a system is to be protected and secure precautions must be instituted throughout it. a chain is only as strong as its weakest link. . user operating system interface there are two fundamental approaches for users to interface with the operating system. one technique is to provide a command line interface or command interpreter that allows users to directly enter commands that are to be performed by the operating system. the second approach allows the user to interface with the operating system via a graphical user interface or gui. . . command interpreter some operating systems include the command interpreter in the kernel. others such as windows xp and unix treat the command interpreter as a special program that is running when a job is initiated or when a user first logs on on interactive systems . on systems with multiple command interpreters to choose from the interpreters are known as shells. for example on unix and linux systems there are several different shells a user may choose from including the bourne shell c shell bourne again shell the korn shell etc. most shells provide similar functionality with only minor differences most users choose a shell based upon personal preference. chapter operating system structures the main function of the command interpreter is to get and execute the next user specified command. many of the commands given at this level manipulate files create delete list print copy execute and so on. the ms dos and unix shells operate in this way. there are two general ways in which these commands can be implemented. in one approach the command interpreter itself contains the code to execute the command. for example a command to delete a file may cause the command interpreter to jump to a section of its code that sets up the parameters and makes the appropriate system call. in this case the number of commands that can be given determines the size of the command interpreter since each command requires its own implementing code. an alternative approach used by unix among other operating systems implements most commands through system programs. in this case the command interpreter does not understand the command in any way it merely uses the command to identify a file to be loaded into memory and executed. thus the unix command to delete a file rm file.txt would search for a file called rm load the file into memory and execute it with the parameter f i l e . txt. the function associated with the rm command would be defined completely by the code in the file rm. in this way programmers can add new commands to the system easily by creating new files with the proper names. the command interpreter program which can be small does not have to be changed for new commands to be added. . . graphical user interfaces a second strategy for interfacing with the operating system is through a userfriendly graphical user interface or gui. rather than having users directly enter commands via a command line interface a gui allows provides a mouse based window and menu system as an interface. a gui provides a desktop metaphor where the mouse is moved to position its pointer on images or icons on the screen the desktop that represent programs files directories and system functions. depending on the mouse pointer's location clicking a button on the mouse can invoke a program select a file or directory known as a folder or pull down a menu that contains commands. graphical user interfaces first appeared due in part to research taking place in the early s at xerox parc research facility. the first gui appeared on the xerox alto computer in . however graphical interfaces became more widespread with the advent of apple macintosh computers in the s. the user interface to the macintosh operating system mac os has undergone various changes over the years the most significant being the adoption of the aqua interface that appeared with mac os x. microsoft's first version of windows version . was based upon a gui interface to the ms dos operating system. the various versions of windows systems proceeding this initial version have made cosmetic changes to the appearance of the gui and several enhancements to its functionality including the windows explorer. traditionally unix systems have been dominated by command line interfaces although there are various gui interfaces available including the common desktop environment cde and x windows systems that are common on
 commercial versions of unix such as solaris and ibm's aix system. however there has been significant development in gui designs from various opensource projects such as k desktop environment or kde and the gnome desktop by the gnu project. both the kde and gnome desktops rim on linux and various unix systems and are available under open source licenses which means their source code is in the public domain. the choice of whether to use a command line or gui interface is mostly one of personal preference. as a very general rule many unix users prefer a command line interface as they often provide powerful shell interfaces. alternatively most windows users are pleased to use the windows gui environment and almost never use the ms dos shell interface. the various changes undergone by the macintosh operating systems provides a nice study in contrast. historically mac os has not provided a command line interface always requiring its users to interface with the operating system using its gui. however with the release of mac os x which is in part implemented using a unix kernel the operating system now provides both a new aqua interface and command line interface as well. the user interface can vary from system to system and even from user to user within a system. it typically is substantially removed from the actual system structure. the design of a useful and friendly user interface is therefore not a direct function of the operating system. in this book we concentrate on the fundamental problems of providing adequate service to user programs. from the point of view of the operating system we do not distinguish between user programs and system programs. . system calls system calls provide an interface to the services made available by an operating system. these calls are generally available as routines written in c and c although certain low level tasks for example tasks where hardware must be accessed directly may need to be written using assembly language instructions. before we discuss how an operating system makes system calls available let's first use an example to illustrate how system calls are used writing a simple program to read data from one file and copy them to another file. the first input that the program will need is the names of the two files the input file and the output file. these names can be specified in many ways depending on the operating system design. one approach is for the program to ask the user for the names of the two files. in an interactive system this approach will require a sequence of system calls first to write a prompting message on the screen and then to read from the keyboard the characters that define the two files. on mouse based and icon based systems a menu of file names is usually displayed in a window. the user can then use the mouse to select the source name and a window can be opened for the destination name to be specified. this sequence requires many i o system calls. once the two file names are obtained the program must open the input file and create the output file. each of these operations requires another system call. there are also possible error conditions for each operation. when the program tries to open the input file it may find that there is no file of that name or that chapter operating system structures the file is protected against access. in these cases the program should print a message on the console another sequence of system calls and then terminate abnormally another system call . if the input file exists then we must create a new output file. we may find that there is already an output file with the same name. this situation may cause the program to abort a system call or we may delete the existing file another system call and create a new one another system call . another option in an interactive system is to ask the user via a sequence of system calls to output the prompting message and to read the response from the terminal whether to replace the existing file or to abort the program. now that both files are set up we enter a loop that reads from the input file a system call and writes to the output file another system call . each read and write must return status information regarding various possible error conditions. on input the program may find that the end of the file has been reached or that there was a hardware failure in the read such as a parity error . the write operation may encounter various errors depending on the output device no more disk space printer out of paper and so on . finally after the entire file is copied the program may close both files another system call write a message to the console or window more system calls and finally terminate normally the final system call . as we can see even simple programs may make heavy use of the operating system. frequently systems execute thousands of system calls per second. this systemcall sequence is shown in figure . . most programmers never see this level of detail however. typically application developers design programs according to an application programming interface api . the api specifies a set of functions that are available to an application programmer including the parameters that are passed to each source file destination file example system call sequence acquire input file name write prompt to screen accept input acquire output file name write prompt to screen accept input open the input file if file doesn't exist abort create output file if file exists abort loop read from input file write to output file until read fails close output file write completion message to screen terminate normally figure . example of how system calls are used. . system calls example of standard api as an example of a standard api consider the readfileq function in the win api a function for reading from a file. the api for this function appears ln figure . . return value i bool readfile c handle file lpvoid buffer t dwwoorrd bbyytteess ttoo rreeaadd parameters lpdword bytec read function name lpoverlapped ov . figure . the api for the readfileo function. a description of the parameters passed to readfileo is as follows 'handle file the file to be read. lpvoid buffer a buffer where the data will be read into and written from. dword bytestoread the number of bytes to be read into the buffer. lpdword bytesread the number of bytes read during the last read. lpoverlapped ovl i ndicates if overlapped i o is being used. function and the return values the programmer can expect. three of the most common apis available to application programmers are the win api for windows systems the posix api for posix based systems which includes virtually all versions of unix linux and mac os x and the java api for designing programs that run on the java virtual machine. note that the system call names used throughout this text are generic examples. each operating system has its own name for each system call. behind the scenes the functions that make up an api typically invoke the actual system calls on behalf of the application programmer. for example the win function createprocess which unsurprisingly is used to create a new process actually calls the ntcreateprocess system call in the windows kernel. why would an application programmer prefer programming according to an api rather than invoking actual system calls? there are several reasons for doing so. one benefit of programming according to an api concerns program portability an application programmer designing a program using an api can expect her program to compile and run on any system that supports the same api although in reality architectural differences often make this more difficult than it may appear . furthermore actual system calls can often be more detailed chapter operating system structures and difficult to work with than the api available to an application programmer. regardless there often exists a strong correlation between invoking a function in the api and its associated system call within the kernel. in fact many of the posix and win apis are similar to the native system calls provided by the unix linux and windows operating systems. the run time support system a set of functions built into libraries included with a compiler for most programming languages provides a system call interface that serves as the link to system calls made available by the operating system. the system call interface intercepts function calls in the api and invokes the necessary system call within the operating system. typically a number is associated with each system call and the system call interface maintains a table indexed according to these numbers. the system call interface then invokes the intended system call in the operating system kernel and returns the status of the system call and any return values. the caller needs to know nothing about how the system call is implemented or what it does during execution. rather it just needs to obey the api and understand what the operating system will do as a result of the execution of that system call. thus most of the details of the operating system interface are hidden from the programmer by the api and are managed by the run time support library. the relationship between an api the system call interface and the operating system is shown in figure . which illustrates how the operating system handles a user application invoking the open system call. system calls occur in different ways depending on the computer in use. often more information is required than simply the identity of the desired system call. the exact type and amount of information vary according to the particular operating system and call. for example to get input we may need to specify the file or device to use as the source as well as the address and open user mode system call interface kernel mode open implementation of open system call return figure . the handling of a user application invoking the openq system call
 fc y register it 'parameters i code for t 'from tefe x i i system systern eailt call ' ' user program operating system figure . passing of parameters as a table. length of the memory buffer into which the input should be read. of course the device or file and length may be implicit in the call. three general methods are used to pass parameters to the operating system. the simplest approach is to pass the parameters in registers. in some cases however there may be more parameters than registers. in these cases the parameters are generally stored in a block or table in memory and the address of the block is passed as a parameter in a register figure . . this is the approach taken by linux and solaris. parameters also can be placed or pushed onto the stack by the program and popped off the stack by the operating system. some operating systems prefer the block or stack method because those approaches do not limit the number or length of parameters being passed. . types of system calls system calls can be grouped roughly into five major categories process control file manipulation device manipulation information maintenance and communications. in sections . . through . . we discuss briefly the types of system calls that may be provided by an operating system. most of these system calls support or are supported by concepts and functions that are discussed in later chapters. figure . summarizes the types of system calls normally provided by an operating system. . . process control a running program needs to be able to halt its execution either normally end or abnormally abort . if a system call is made to terminate the currently running program abnormally or if the program runs into a problem and causes an error trap a dump of memory is sometimes taken and an error message generated. the dump is written to disk and may be examined by a debugger a system program designed to aid the programmer in finding and correcting bugs to determine the cause of the problem. under either normal or abnormal circumstances the operating system must transfer control to the chapter operating system structures process control o end abort o load execute o create process terminate process o get process attributes set process attributes o wait for time o wait event signal event o allocate and free memory file management create file delete file o open close read write reposition o get file attributes set file attributes device management o request device release device read write reposition o get device attributes set device attributes logically attach or detach devices information maintenance o get time or date set time or date o get system data set system data o get process file or device attributes o set process file or device attributes communications create delete communication connection send receive messages o transfer status information o attach or detach remote devices figure . types of system calls. invoking command interpreter. the command interpreter then reads the next command. in an interactive system the command interpreter simply continues with the next command it is assumed that the user will issue an appropriate command to respond to any error. in a gui system a pop up window might alert the user to the error and ask for guidance. in a batch system the command interpreter usually terminates the entire job and continues with the next job. . types of system calls example of standard c library the standard c library provides a portion of the system call interface for many versions of unix and linux. as an example lot's assume a c program invokes the p r i n t f statement. the c library intercepts this call and invokes the necessary system call s in the operating system in this instance the write system call. the c library takes the value returned by w r i t e and passes it back to the user program. this is shown in figure . . include stdio.h int main printf greetings i return o user mode standard c library kernel mode figure . c library handling of w r i t e . some systems allow control cards to indicate special recovery actions in case an error occurs. a control card is a batch system concept. it is a command to manage the execution of a process. if the program discovers an error in its input and wants to terminate abnormally it may also want to define an error level. more severe errors can be indicated by a higher level error parameter. it is then possible to combine normal and abnormal termination by defining a normal termination as an error at level . the command interpreter or a following program can use this error level to determine the next action automatically. a process or job executing one program may want to load and execute another program. this feature allows the command interpreter to execute a program as directed by for example a user command the click of a mouse or a batch command. an interesting question is where to return control when the loaded program terminates. this question is related to the problem of whether the existing program is lost saved or allowed to continue execution concurrently with the new program. chapter operating system structures if control returns to the existing program when the new program terminates we must save the memory image of the existing program thus we have effectively created a mechanism for one program to call another program. if both programs continue concurrently we have created a new job or process to be multiprogrammed. often there is a system call specifically for this purpose create process or submit job . if we create a new job or process or perhaps even a set of jobs or processes we should be able to control its execution. this control requires the ability to determine and reset the attributes of a job or process including the job's priority its maximum allowable execution time and so on get process attributes and set process attributes . we may also want to terminate a job or process that we created terminate process if we find that it is incorrect or is no longer needed. having created new jobs or processes we may need to wait for them to finish their execution. we may want to wait for a certain amount of time to pass wait time more probably we will want to wait for a specific event to occur wait event . the jobs or processes should then signal when that event has occurred signal event . system calls of this type dealing with the coordination of concurrent processes are discussed in great detail in chapter . another set of system calls is helpful in debugging a program. many systems provide system calls to dump memory. this provision is useful for debugging. a program trace lists each instruction as it is executed it is provided by fewer systems. even microprocessors provide a cpu mode known as single step in which a trap is executed by the cpu after every instruction. the trap is usually caught by a debugger. many operating systems provide a time profile of a program to indicate the amount of time that the program executes at a particular location or set of locations. a time profile requires either a tracing facility or regular timer interrupts. at every occurrence of the timer interrupt the value of the program free memory free memory process iinterpfefer jrrterfjre er kernel kernel a b figure . ms dos execution a at system startup b running a program. . types of system calls counter is recorded. with sufficiently frequent timer interrupts a statistical picture of the time spent on various parts of the program can be obtained. there are so many facets of and variations in process and job control that we next use two examples one involving a single tasking system and the other a multitasking system to clarify these concepts. the ms dos operating system is an example of a single tasking system. it has a command interpreter that is invoked when the computer is started figure . a . because ms dos is single tasking it uses a simple method to run a program and does not create a new process. it loads the program into memory writing over most of itself to give the program as much memory as possible figure . b . next it sets the instruction pointer to the first instruction of the program. the program then runs and either an error causes a trap or the program executes a system call to terminate. in either case the error code is saved in the system memory for later use. following this action the small portion of the command interpreter that was not overwritten resumes execution. its first task is to reload the rest of the command interpreter from disk. then the command interpreter makes the previous error code available to the user or to the next program. freebsd derived from berkeley unix is an example of a multitasking system. when a user logs on to the system the shell of the user's choice is run. this shell is similar to the ms dos shell in that it accepts commands and executes programs that the user requests. however since freebsd is a multitasking system the command interpreter may continue running while another program is executed figure . . to start a new process the shell executes a fork system call. then the selected program is loaded into memory via an exec system call and the program is executed. depending on the way the command was issued the shell then either waits for the process to finish or runs the process in the background. in the latter case the shell immediately reqviests another command. when a process is running in the background it cannot receive input directly from the keyboard because the shell is using this resource. i o is therefore done through files or through a gui interface. meanwhile the user is free to ask the shell to run other programs to monitor the progress of the running process to change that program's priority process d free memory process c interpreter process b kernel figure . freebsd running multiple programs. chapter operating system structures solaris dynamic tracing facility making running operating systems easier'to understand debug and tune is an active area of operating system research and implementation. for example solaris includes the d t r a c e dynamic tracing facility. this facility dynamically adds probes to a running system. these probes can be queried via the d programming language to determine an astonishing amount about the kernel the system state and process activities. for example figure . follows an application as it executes a system call ioctl and further shows the functional calls within the kernel as they execute lo perform the system call. lines ending with 'it' are executed in user mode and lines ending in k in kernel mode. l . all . d pqrep xclock' xever.tsqueued dtrace script '. all.d' matched probes cpu function xeventsqueued u xeventsqueued u xlltransbytesreadable u xlltransbytesreadable u xlitranssocketbytesreadable u xlltranssocketbytesreadable u ioctl u ioctl k getf k set active fd k set active fd k getf k get udatamodel k get udatamodel k releasef k clear active fd k n clear active fd k c cv broadcast k cv broadcast k releasef k ioctl k ioctl u xeventsqueued u c xeventsqueued ..i figure . solaris d t r a c e f o l l o w s a s y s t e m call w i t h i n t h e kernel i ! !! other operating systems are starting to include various perfojj figej and tracing tools fostered by research at various institutions including jfe and so on. when the process is done it executes an exit system call to terminate returning to the invoking process a status code of or a nonzero error code. this status or error code is then available to the shell or other programs. processes are discussed in chapter with an program example using the fork andexeco system calls. . types of system calls . . file management a the file system will be discussed in more detail in chapters and . we can however identify several common system calls dealing with files we first need to be able to create and delete files. either system call requires the name of the file and perhaps some of the file's attributes. once the file is created we need to open it and to use it. we may also read write or reposition rewinding or skipping to the end of the file for example . finally we need to close the file indicating that we are no longer using it. we may need these same sets of operations for directories if we have a directory structure for organizing files in the file system. in addition for either files or directories we need to be able to determine the values of various attributes and perhaps to reset them if necessary. file attributes include the file name a file type protection codes accounting information and so on. at least two system calls get file attribute and set file attribute are required for this function. some operating systems provide many more calls such as calls for file move and copy. others might provide an api that performs those operations using code and other system calls and others might just provide system programs to perform those tasks. if the system programs are callable by other programs then each can be considered an api by other system programs. . . device management a process may need several resources to execute main memory disk drives access to files and so on. if the resources are available they can be granted and control can be returned to the user process. otherwise the process will have to wait until sufficient resources are available. the various resources controlled by the operating sysstem can be thought of as devices. some of these devices are physical devices for example tapes while others can be thought of as abstract or virtual devices for example files . if there are multiple users of the system the system may require us to first request the device to ensure exclusive use of it. after we are finished with the device we release it. these functions are similar to the open and close system calls for files. other operating systems allow unmanaged access to devices. the hazard then is the potential for device contention and perhaps deadlock which is described in chapter . once the device has been requested and allocated to us we can read write and possibly reposition the device just as we can with files. in fact the similarity between i o devices and files is so great that many operating systems including unix merge the two into a combined file device structure. in this case a set of system calls is used on files and devices. sometimes i o devices are identified by special file names directory placement or file attributes. the ui can also make files and devices appear to be similar even though the underlying system calls are dissimilar. this is another example of the many design decisions that go into building an operating system and user interface. . . information maintenance many system calls exist simply for the purpose of transferring information between the user program and the operating system. for example most chapter operating system structures systems have a system call to return the current time and date. other system calls may return information about the system such as the number of current users the version number of the operating system the amount of free memory or disk space and so on. in addition the operating system keeps information about all its processes and svstem calls are used to access this information. generally calls are also used to reset the process information get process attributes and set process a t t r i b u t e s . in section . . we discuss what information is normally kept. . . communication there are two common models of interprocess communication the messagepassing model and the shared memory model. in the message passing model the communicating processes exchange messages with one another to transfer information. messages can be exchanged between the processes either directly or indirectly through a common mailbox. before communication can take place a connection must be opened. the name of the other communicator must be known be it another process on the same system or a process on another computer connected by a communications network. each computer in a network has a host name by which it is commonly known. a host also has a network identifier such as an ip address. similarly each process has a process name and this name is translated into an identifier by which the operating system can refer to the process. the get host id and get processid system calls do this translation. the identifiers are then passed to the generalpurpose open and close calls provided by the file system or to specific open connection and close connection system calls depending on the system's model of communication. the recipient process usually must give its permission for communication to take place with an accept connection call. most processes that will be receiving connections are special purpose daemons which are systems programs provided for that purpose. they execute a wait for c onnect ion call and are awakened when a connection is made. the source of the communication known as the client and the receiving daemon known as a server then exchange messages by using read message and write message system calls. the close connection call terminates the communication. in the shared memory model processes use shared memory create and shared memory attach system calls to create and gain access to regions of memory owned by other processes. recall that normally the operating system tries to prevent one process from accessing another process's memory. shared memory requires that two or more processes agree to remove this restriction. they can then exchange information by reading and writing data in the shared areas. the form of the data and the location are determined by the processes and are not under the operating system's control. the processes are also responsible for ensuring that they are not writing to the same location simultaneously. such mechanisms are discussed in chapter . in chapter we look at a variation of the process scheme threads in which memory is shared by default. both of the models just discussed are common in operating systems and most systems implement both. message passing is useful for exchanging smaller amounts of data because no conflicts need be avoided. it is also easier to implement than is shared memory for intercomputer communication. shared
 memory allows maximum speed and convenience of communication since it can be done at memory speeds when it takes place within a computer. problems exist however in the areas of protection and synchronization between the processes sharing memory. . system programs another aspect of a modern system is the collection of system programs. recall figure . which depicted the logical computer hierarchy. at the lowest level is hardware. next is the operating system then the system programs and finally the application programs. system programs provide a convenient environment for program development and execution. some of them are simply user interfaces to system calls others are considerably more complex. they can be divided into these categories file management. these programs create delete copy rename print dump list and generally manipulate files and directories. status information. some programs simply ask the system for the date time amount of available memory or disk space number of users or similar status information. others are more complex providing detailed performance logging and debugging information. typically these programs format and print the output to the terminal or other output devices or files or display it in a window of the gui. some systems also support a registry which is used to store and retrieve configuration information. file modification. several text editors may be available to create and modify the content of files stored on disk or other storage devices. there may also be special commands to search contents of files or perform transformations of the text. programming language support. compilers assemblers debuggers and interpreters for common programming languages such as c c java visual basic and perl are often provided to the user with the operating system. program loading and execution. once a program is assembled or compiled it must be loaded into memory to be executed. the system may provide absolute loaders relocatable loaders linkage editors and overlay loaders. debugging systems for either higher level languages or machine language are needed as well. communications. these programs provide the mechanism for creating virtual connections among processes users and computer systems. they allow users to send messages to one another's screens to browse web pages to send electronic mail messages to log in remotely or to transfer files from one machine to another. in addition to systems programs most operating systems are supplied with programs that are useful in solving common problems or performing common operations. such programs include web browsers word processors and text formatters spreadsheets database systems compilers plotting and chapter
s if it is written in a higher level language. for example ms dos was wrftten in intel assembly language. consequently it is available on only the intel family of cpus. the linux operating system in contrast is written mostly in c and is available on a number of different cpus including intel x motorola x sparc and mips rxoo . the only possible disadvantages of implementing an operating system in a higher level language are reduced speed and increased storage requirements. this however is no longer a major issue in today's systems. although an expert assembly language programmer can produce efficient small routines for large programs a modern compiler can perform complex analysis and apply sophisticated optimizations that produce excellent code. modern processors have deep pipelining and multiple functional units that can handle complex dependencies that can overwhelm the limited ability of the human mind to keep track of details. as is true in other systems major performance improvements in operating systems are more likely to be the result of better data structures and algorithms than of excellent assembly language code. in addition although operating systems are large only a small amount of the code is critical to high performance the memory manager and the cpu scheduler are probably the most critical routines. after the system is written and is working correctly bottleneck routines can be identified and can be replaced with assembly language equivalents. to identify bottlenecks we must be able to monitor system performance. code must be added to compute and display measures of system behavior. in a number of systems the operating system does this task by producing trace listings of system behavior. all interesting events are logged with their time and important parameters and are written to a file. later an analysis program can process the log file to determine system performance and to identify bottlenecks and inefficiencies. these same traces can be run as input for a simulation of a suggested improved system. traces also can help people to find errors in operating system behavior. . operating system structure a system as large and complex as a modern operating system must be engineered carefully if it is to function properly and be modified easily. a common approach is to partition the task into small components rather than have one monolithic system. each of these modules should be a well defined portion of the system with carefully defined inputs outputs and functions. we have already discussed briefly in chapter the common components of operating systems. in this section we discuss how these components are interconnected and melded into a kernel. . . simple structure many commercial systems do not have well defined structures. frequently such operating systems started as small simple and limited systems and then grew beyond their original scope. ms dos is an example of such a system. it was originally designed and implemented by a few people who had no idea that it would become so popular. it was written to provide the most functionality in . operating system structure application program resident system program rom bios device drivers figure . ms dos layer structure. the least space so it was not divided into modules carefully. figure . shows its structure. in ms dos the interfaces and levels of functionality are not well separated. for instance application programs are able to access the basic i o routines to write directly to the display and disk drives. such freedom leaves ms dos vulnerable to errant or malicious programs causing entire system crashes when user programs fail. of course ms dos was also limited by the hardware of its era. because the intel for which it was written provides no dual mode and no hardware protection the designers of ms dos had no choice but to leave the base hardware accessible. another example of limited structuring is the original unix operating system. unix is another system that initially was limited by hardware functionality. it consists of two separable parts the kernel and the system programs. the kernel is further separated into a series of interfaces and device drivers which have been added and expanded over the years as unix has evolved. we can view the traditional unix operating system as being layered as shown in figure . . everything below the system call interface and above the physical hardware is the kernel. the kernel provides the file system cpu scheduling memory management and other operating system functions through system calls. taken in sum that is an enormous amount of functionality to be combined into one level. this monolithic structure was difficult to implement and maintain. . . layered approach with proper hardware support operating systems can be broken into pieces that are smaller and more appropriate than those allowed by the original ms dos or unix systems. the operating system can then retain much greater control over the computer and over the applications that make use of that computer. implementers have more freedom in changing the inner workings of the system and in creating modular operating systems. under the topdown approach the overall functionality and features are determined and are chapter operating system structures the users shells and commands compilers and interpreters . system libraries system call interface to the kernel signals terminal file system cpu scheduling handling swapping block i o page replacement character i o system system demand paging terminal drivers disk and tape drivers virtual memory kernel interface to the hardware terminal controllers device controllers memory controllers terminals disks and tapes physical memory figure . unix system structure. separated into components. information hiding is also important because it leaves programmers free to implement the low level routines as they see fit provided that the external interface of the routine stays unchanged and that the routine itself performs the advertised task. a system can be made modular in many ways. one method is the layered approach in which the operating system is broken up into a number of layers levels . the bottom layer layer is the hardware the highest layer n is the user interface. this layering structure is depicted in figure . . an operating system layer is an implementation of an abstract object made up of data and the operations that can manipulate those data. a typical operating system layer say layer m consists of data structures and a set of routines that can be invoked by higher level layers. layer m in turn can invoke operations on lower level layers. the main advantage of the layered approach is simplicity of construction and debugging. the layers are selected so that each uses functions operations and services of only lower level layers. this approach simplifies debugging and system verification. the first layer can be debugged without any concern for the rest of the system because by definition it uses only the basic hardware which is assumed correct to implement its functions. once the first layer is debugged its correct functioning can be assumed while the second layer is debugged and so on. if an error is found during the debugging of a particular layer the error must be on that layer because the layers below it are already debugged. thus the design and implementation of the system is simplified. each layer is implemented with only those operations provided by lowerlevel layers. a layer does not need to know how these operations are implemented it needs to know only what these operations do. hence each layer hides the existence of certain data structures operations and hardware from higher level layers. the major difficulty with the layered approach involves appropriately defining the various layers. because a layer can use only lower level layers careful planning is necessary. for example the device driver for the backing . operating system structure ' layer hardware i figure . a layered operating system. store disk space used by virtual memory algorithms must be at a lower level than the memory management routines because memory management requires the ability to use the backing store. other requirements may not be so obvious. the backing store driver would normally be above the cpu scheduler because the driver may need to wait for i o and the cpu can be rescheduled during this time. however on a large system the cpu scheduler may have more information about all the active processes than can fit in memory. therefore this information may need to be swapped in and out of memory requiring the backing store driver routine to be below the cpu scheduler. a final problem with layered implementations is that they tend to be less efficient than other types. for instance when a user program executes an i o operation it executes a system call that is trapped to the i o layer which calls the memory management layer which in turn calls the cpu scheduling layer which is then passed to the hardware. at each layer the parameters may be modified data may need to be passed and so on. each layer adds overhead to the system call the net result is a system call that takes longer than does one on a nonlayered system. these limitations have caused a small backlash against layering in recent years. fewer layers with more functionality are being designed providing most of the advantages of modularized code while avoiding the difficult problems of laver definition and interaction. . . microkernels we have already seen that as unix expanded the kernel became large and difficult to manage. in the mid s researchers at carnegie mellon university developed an operating system called mach that modularized the kernel using the microkernel approach. this method structures the operating system by removing all nonessential components from the kernel and chapter operating system structures implementing them as system and user level programs. the result is a smaller kernel. there is little consensus regarding which services should remain in the kernel and which should be implemented in user space. typically however microkernels provide minimal process and memory management in addition to a communication facility. the main function of the microkernel is to provide a communication facility between the client program and the various services that are also running in user space. communication is provided by message passing which was described in section . . . for example if the client program wishes to access a file it must interact with the file server. the client program and service never interact directly. rather they communicate indirectly by exchanging messages with the microkernel. one benefit of the microkernel approach is ease of extending the operating system. all new services are added to user space and consequently do not require modification of the kernel. when the kernel does have to be modified the changes tend to be fewer because the microkernel is a smaller kernel. the resulting operating system is easier to port from one hardware design to another. the microkernel also provides more security and reliability since most services are running as user rather than kernel processes. if a service fails the rest of the operating system remains untouched. several contemporary operating systems have used the microkernel approach. tru unix formerly digital unix provides a unix interface to the user but it is implemented with a mach kernel. the mach kernel maps unix system calls into messages to the appropriate user level services. another example is qnx. qnx is a real time operating system that is also based on the microkernel design. the qnx microkernel provides services for message passing and process scheduling. it also handles low level network communication and hardware interrupts. all other services in qnx are provided by standard processes that run outside the kernel in user mode. unfortunately microkernels can suffer from performance decreases due to increased system function overhead. consider the history of windows nt. the first release had a layered microkernel organization. however this version delivered low performance compared with that of windows . windows nt . partially redressed the performance problem by moving layers from user space to kernel space and integrating them more closely. by the time windows xp was designed its architecture was more monolithic than microkernel. . . modules perhaps the best current methodology for operating system design involves using object oriented programming techniques to create a modular kernel. here the kernel has a set of core components and dynamically links in additional services either during boot time or during run time. such a strategy uses dynamically loadable modules and is common in modern implementations of unix such as solaris linux and mac os x. for example the solaris operating system structure shown in figure . is organized around a core kernel with seven types of loadable kernel modules . scheduling classes . file systems . operating system structure figure . solaris loadable modules. . loadable system calls . executable formats . streams modules . miscellaneous . device and bus drivers such a design allows the kernel to provide core services yet also allows certain features to be implemented dynamically. for example device and bus drivers for specific hardware can be added to the kernel and support for different file systems can be added as loadable modules. the overall result resembles a layered system in that each kernel section has defined protected interfaces but it is more flexible than a layered system in that any module can call any other module. furthermore the approach is like the microkernel approach in that the primary module has only core functions and knowledge of how to load and communicate with other modules but it is more efficient because modules do not need to invoke message passing in order to communicate. the apple macintosh mac os x operating system uses a hybrid structure. mac os x also known as danvin structures the operating system using a layered technique where one layer consists of the mach microkernel. the structure of mac os x appears in figure . . the top layers include application environments and a set of services providing a graphical interface to applications. below these layers is the kernel environment which consists primarily of the mach microkernel and the bsd kernel. mach provides memory management support for remote procedure calls rpcs and interprocess communication ipc facilities including message passing and thread scheduling. the bsd component provides a bsd command line interface support for networking and file systems and an implementation of posix apis including pthreads. in addition to mach and bsd the kernel environment provides an i o kit for development of device drivers and dynamically loadable modules which mac os x refers to as kernel extensions . as shown in the figure applications and common services can make use of either the mach or bsd facilities directly. chapter operating system structures application environments and common services ik i r r kernel bsd environment i .. .. p . .ijl l. .. ... .. i figure . the mac os x structure
 the layered approach described in section . . is taken to its logical conclusion in the concept of a virtual machine. the fundamental idea behind a virtual machine is to abstract the hardware of a single computer the cpu memory disk drives network interface cards and so forth into several different execution environments thereby creating the illusion that each separate execution environment is running its own private computer. by using cpu scheduling chapter and virtual memory techniques chapter an operating system can create the illusion that a process has its own processor with its own virtual memory. normally a process has additional features such as system calls and a file system that are not provided by the bare hardware. the virtual machine approach does not provide any such additional functionality but rather provides an interface that is identical to the underlying bare hardware. each process is provided with a virtual copy of the underlying computer figure . . there are several reasons for creating a virtual machine all of which are fundamentally related to being able to share the same hardware yet run several different execution environments that is different operating systems concurrently. we will explore the advantages of virtual machines in more detail in section . . . throughout much of this section we discuss the vm operating system for ibm systems as it provides a useful working example furthermore ibm pioneered the work in this area. a major difficulty with the virtual machine approach involves disk systems. suppose that the physical machine has three disk drives but wants to support seven virtual machines. clearly it cannot allocate a disk drive to each virtual machine because the virtual machine software itself will need substantial disk space to provide virtual memory and spooling. the solution is to provide virtual disks termed minidisks in ibm's vm operating system that are identical in all respects except size. the system implements each minidisk by allocating as many tracks on the physical disks as the minidisk needs. obviously the sum of the sizes of all minidisks must be smaller than the size of the physical disk space available. users thus are given their own virtual machines. they can then run any of the operating systems or software packages that are available on the underlying . virtual machines j processes processes processes i iliill . hte i . i programming interface vm vm vm ijj . f i j!tsj rti h ini'ji '. hardware a b figure . system models a nonvirtual machine b virtual machine. machine. for the ibm vm system a user normally runs cms a single user interactive operating system. the virtual machine software is concerned with multiprogramming multiple virtual machines onto a physical machine but it does not need to consider any user support software. this arrangement may provide a useful way to divide the problem of designing a multiuser interactive system into two smaller pieces. . . implementation although the virtual machine concept is useful it is difficult to implement. much work is required to provide an exact duplicate of the underlying machine. remember that the underlying machine has two modes user mode and kernel mode. the virtual machine software can run in kernel mode since it is the operating system. the virtual machine itself can execute in only user mode. just as the physical machine has two modes however so must the virtual machine. consequently we must have a virtual user mode and a virtual kernel mode both of which run in a physical user mode. those actions that cause a transfer from user mode to kernel mode on a real machine such as a system call or an attempt to execute a privileged instruction must also cause a transfer from virtual user mode to virtual kernel mode on a virtual machine. such a transfer can be accomplished as follows. when a system call for example is made by a program running on a virtual machine in virtual user mode it will cause a transfer to the virtual machine monitor in the real machinewhen the virtual machine monitor gains control it can change the register contents and program counter for the virtual machine to simulate the effect of the system call. it can then restart the virtual machine noting that it is now in virtual kernel mode. the major difference of course is time. whereas the real i o might have taken milliseconds the virtual i o might take less time because it is chapter operating system structures spooled or more time because it is interpreted . in addition the cpu is being multiprogrammed among many virtual machines further slowing down the virtual machines in unpredictable ways. in the extreme case it may be necessary to simulate all instructions to provide a true virtual machine. vm works for ibm machines because normal instructions for the virtual machines can execute directly on the hardware. only the privileged instructions needed mainly for i o must be simulated and hence execute more slowly. . . benefits the virtual machine concept has several advantages. notice that in this environment there is complete protection of the various system resources. each virtual machine is completely isolated from all other virtual machines so there are no protection problems. at the same time however there is no direct sharing of resources. two approaches to provide sharing have been implemented. first it is possible to share a minidisk and thus to share files. this scheme is modeled after a physical shared disk but is implemented by software. second it is possible to define a network of virtual machines each of which can send information over the virtual communications network. again the network is modeled after physical communication networks but is implemented in software. such a virtual machine system is a perfect vehicle for operating systems research and development. normally changing an operating system is a difficult task. operating systems are large and complex programs and it is difficult to be sure that a change in one part will not cause obscure bugs in some other part. the power of the operating system makes changing it particularly dangerous. because the operating system executes in kernel mode a wrong change in a pointer could cause an error that would destroy the entire file system. thus it is necessary to test all changes to the operating system carefully. the operating system however runs on and controls the entire machine. therefore the current system must be stopped and taken out of use while changes are made and tested. this period is commonly called systemdevelopment time. since it makes the system unavailable to users systemdevelopment time is often scheduled late at night or on weekends when system load is low. a virtual machine system can eliminate much of this problem. system programmers are given their own virtual machine and system development is done on the virtual machine instead of on a physical machine. normal system operation seldom needs to be disrupted for system development. . . examples despite the advantages of virtual machines they received little attention for a number of years after they were first developed. today however virtual machines are coming back into fashion as a means of solving system compatibility problems. in this section we explore two popular contemporary virtual machines vmware and the java virtual machine. as we will see these virtual machines typically run on top of an operating system of any of the design types discussed earlier. thus operating system design methods . virtual machines simple layers microkernel modules and virtual machines are not nuitually exclusive. . . . vmware vmware is a popular commercial application that abstracts intel x hardware into isolated virtual machines. vmware runs as an application on a host operating system such as windows or linux and allows this host system to concurrently run several different guest operating systems as independent virtual machines. consider the following scenario a developer has designed an application and would like to test it on linux freebsd windows nt and windows xp. one option is for her to obtain four different computers each running a copy of one of these operating systems. another alternative is for her first to install linux on a computer system and test the application then to install freebsd and test the application and so forth. this option allows her to use the same physical computer but is time consuming since she must install a new operating system for each test. such testing could be accomplished concurrently on the same physical computer using vmware. in this case the programmer could test the application on a host operating system and on three guest operating systems with each system running as a separate virtual machine. the architecture of such a system is shown in figure . . in this scenario linux is running as the host operating system freebsd windows nt and windows xp are running as guest operating systems. the virtualization layer is the heart of vmware as it abstracts the physical hardware into isolated virtual machines running as guest operating systems. each virtual machine has its own virtual cpu memory disk drives network interfaces and so forth. application application application application guest operating guest operating guest operating system system system free bsd windows nt windows xp virtual cpu virtual cpu virtual cpu virtual memory virtual memory virtual memory virtual devices virtual devices virtual devices virtualization layer host operating system . a z' isis'm linux wit a a iva v hardware cpu memory i o devices j figure . vmware architecture. chapter operating system structures . . . the java virtual machine java is a popular object oriented programming language introduced by sun microsystems in . in addition to a language specification and a large api library java also provides a specification for a java virtual machine or jvm. java objects are specified with the class construct a java program consists of one or more classes. for each java class the compiler produces an architecture neutral bytecode output .class file that will run on any implementation of the jvm. the jvmis a specification for an abstract computer. it consists of a class loader and a java interpreter that executes the architecture neutral bytecodes as diagrammed in figure . . the class loader loads the compiled . class files from both the java program and the java api for execution by the java interpreter. after a class is loaded the verifier checks that the . class file is valid java bytecode and does not overflow or underflow the stack. it also ensures that the bytecode does not perform pointer arithmetic which could provide illegal memory access. if the class passes verification it is run by the java interpreter. the jvm also automatically manages memory by performing garbage collection the practice of reclaiming memory from objects no longer in use and returning it to the system. much research focuses on garbage collection algorithms for increasing the performance of java programs in the virtual machine. the jvm may be implemented in software on top of a host operating system such as windows linux or mac os x or as part of a web browser. alternatively the jvm may be implemented in hardware on a chip specifically designed to run java programs. if the jvm is implemented in software the java interpreter interprets the bytecode operations one at a time. a faster software technique is to use a just in time jit compiler. here the first time a java method is invoked the bytecodes for the method are turned into native machine language for the host system. these operations are then cached so that subsequent invocations of a method are performed using the native machine instructions and the bytecode operations need not be interpreted all over again. a technique that is potentially even faster is to run the jvm in hardware on a special java chip that executes the java bytecode operations as native code thus bypassing the need for either a software interpreter or a just in time compiler. class loader java interpreter . . . . . .' ' '.' . . . . . . . .' '.'' figure . the java virtual machine. . virtual machines the .net framework the .met framework is a collection of technologies including a set of class libraries and an execution environment that come together to provide a platform for developing software. this platform allows programs to be written to target the .ntt framework instead of a specific architecture. a program written for the .net framework need not worry about the specifics of the hardware or the operating system on which it will run. thus any architecture implementing .net will be able to successfully execute the program this is because the execution environment abstracts these details and provides a virtual machine as an intermediary between the executing program and the underlying a rchitecture at the core of the .net framework is the common language runtime clr . the clr is the implementation of the .net virtual machine. it provides an environment for execution of programs written in any of the languages targeted at the .net framework. programs written in languages such as c pronounced c sharp and vb.net are compiled into an intermediate architecture independent language called i icrosoft intermediate language ms l . these compiled files called assemblies include ms il instructions and metadata. they have a file extension of either .exe or .dll. upon execution of a program the clr loads assemblies into what is known as the application domain. as instructions are requested by the executing program the clr converts the ms il instructions inside the assemblies into native code that is specific to the underlying arcliitecture using just in time compilation. once instructions have been converted to native code they are kept and will continue to run as native code for the cpu. the architecture of the clr for the .net framework is shown in figure . . . c vb.net source source compilation ms il ms il assembly assembly clr just in time compiler host system figure . architecture of the clr for the .net framework. chapter operating system structures
 it is possible to design code and implement an operating system specifically for one machine at one site. more commonly however operating systems are designed to run on any of a class of machines at a variety of sites with a variety of peripheral configurations. the system must then be configured or generated for each specific computer site a process sometimes known as system generation sysgen . the operating system is normally distributed on disk or cd rom. to generate a system we use a special program. the sysgen program reads from a given file or asks the operator of the system for information concerning the specific configuration of the hardware system or probes the hardware directly to determine what components are there. the following kinds of information must be determined. what cpu is to be used? what options extended instruction sets floatingpoint arithmetic and so on are installed? for multiple cpu systems each cpu must be described. how much memory is available? some systems will determine this value themselves by referencing memory location after memory location until an illegal address fault is generated. this procedure defines the final legal address and hence the amount of available memory. what devices are available? the system will need to know how to address each device the device number the device interrupt number the device's type and model and any special device characteristics. what operating system options are desired or what parameter values are to be used? these options or values might include how many buffers of which sizes should be used what type of cpu scheduling algorithm is desired what the maximum number of processes to be supported is and soon. once this information is determined it can be used in several ways. at one extreme a system administrator can use it to modify a copy of the source code of the operating system. the operating system then is completely compiled. data declarations initializations and constants along with conditional compilation produce an output object version of the operating system that is tailored to the system described. at a slightly less tailored level the system description can cause the creation of tables and the selection of modules from a precompiled library. these modules are linked together to form the generated operating system. selection allows the library to contain the device drivers for all supported i o devices but only those needed are linked into the operating system. because the system is not recompiled system generation is faster but the resulting system may be overly general. at the other extreme it is possible to construct a system that is completely table driven. all the code is always part of the system and selection occurs at execution time rather than at compile or link time. system generation involves simply creating the appropriate tables to describe the system
 the major differences among these approaches are the size and generality of the generated system and the ease of modification as the hardware configuration changes. consider the cost of modifying the system to support a newly acquired graphics terminal or another disk drive. balanced against that cost of course is the frequency or infrequency of such changes. . system boot after an operating system is generated it must be made available for use by the hardware. but how does the hardware know where the kernel is or how to load that kernel? the procedure of starting a computer by loading the kernel is known as booting the system. on most computer systems a small piece of code known as the bootstrap program or bootstrap loader locates the kernel loads it into main memory and starts its execution. some computer systems such as pcs use a two step process in which a simple bootstrap loader fetches a more complex boot program from disk which in turn loads the kernel. when a cpu receives a reset event for instance when it is powered up or rebooted the instruction register is loaded with a predefined memory location and execution starts there. at that location is the initial bootstrap program. this program is in the form of read only memory rom because the ram is in an unknown state at system startup. rom is convenient because it needs no initialization and cannot be infected by a computer virus. the bootstrap program can perform a variety of tasks. usually one task is to run diagnostics to determine the state of the machine. if the diagnostics pass the program can continue with the booting steps. it can also initialize all aspects of the system from cpu registers to device controllers and the contents of main memory. sooner or later it starts the operating system. some systems such as cellular phones pdas and game consoles store the entire operating system in rom. storing the operating system in rom is suitable for small operating systems simple supporting hardware and rugged operation. a problem with this approach is that changing the bootstrap code requires changing the rom hardware chips. some systems resolve this problem by using erasable programmable read only memory eprom which is readonly except when explicitly given a command to become writable. all forms of rom are also known as firmware since their characteristics fall somewhere between those of hardware and those of software. a problem with firmware in general is that executing code there is slower than executing code in ram. some systems store the operating system in firmware and copy it to ram for fast execution. a final issue with firmware is that it is relatively expensive so usually only small amounts are available. for large operating systems including most general purpose operating systems like windows mac os x and unix or for systems that change frequently the bootstrap loader is stored in firmware and the operating system is on disk. in this case the bootstrap runs diagnostics and has a bit of code that can read a single block at a fixed location say block zero from disk into memory and execute the code from that boot block. the program stored in the boot block may be sophisticated enough to load the entire operating system into memory and begin its execution. more typically it is simple code as it fits in a single disk block and only knows the address on disk and length of the chapter operating system structures remainder of the bootstrap program. all of the disk bound bootstrap artd the operating system itself can be easily changed by writing new versions to disk. a disk that has a boot partition more on that in section . . is called a boot disk or system disk. now that the full bootstrap program has been loaded it can traverse the file system to find the operating system kernel load it into memory and start its execution. it is only at this point that the system is said to be running
 a question that arises in discussing operating systems involves what to call all the cpu activities. a batch system executes jobs whereas a time shared system has user programs or tasks. even on a single user system such as microsoft windows a user may be able to run several programs at one time a word processor a web browser and an e mail package. even if the user can execute chapter processes only one program at a time the operating system may need to suppoft its own internal programmed activities such as memory management. in many respects all these activities are similar so we call all of them processes. the terms job and process are used almost interchangeably in this text. although we personally prefer the term process much of operating system theory and terminology was developed during a time when the major activity of operating systems was job processing. it would be misleading to avoid the use of commonly accepted terms that include the word job such as job scheduling simply because process has superseded job. . . the process informally as mentioned earlier a process is a program in execution. a process is more than the program code which is sometimes known as the text section. it also includes the current activity as represented by the value of the program counter and the contents of the processor's registers. a process generally also includes the process stack which contains temporary data such as function parameters return addresses and local variables and a data section which contains global variables. a process may also include a heap which is memory that is dynamically allocated during process run time. the structure of a process in memory is shown in figure . . we emphasize that a program by itself is not a process a program is a passive entity such as a file containing a list of instructions stored on disk often called an executable file whereas a process is an active entity with a program counter specifying the next instruction to execute and a set of associated resources. a program becomes a process when an executable file is loaded into memory. two common techniques for loading executable files are double clicking an icon representing the executable file and entering the name of the executable file on the command line as in prog. exe or a. out. although two processes may be associated with the same program they are nevertheless considered two separate execution sequences. for instance max stack heap data text figure . process in memory. . process concept .. x scheduler dispatch i o or event completion ' y i o or event wait figure . diagram of process state. several users may be running different copies of the mail program or the same user may invoke many copies of the web browser program. each of these is a separate process and although the text sections are equivalent the data heap and stack sections vary. it is also common to have a process that spawns many processes as it runs. we discuss such matters in section . . . . process state as a process executes it changes state. the state of a process is defined in part by the current activity of that process. each process may be in one of the following states new. the process is being created. running. instructions are being executed. waiting. the process is waiting for some event to occur such as an i o completion or reception of a signal . ready. the process is waiting to be assigned to a processor. terminated. the process has finished execution. these names are arbitrary and they vary across operating systems. the states that they represent are fotind on all systems however. certain operating systems also more finely delineate process states. it is important to realize that only one process can be running on any processor at any instant. many processes may be ready and limiting however. the state diagram corresponding to these states is presented in figure . . . . process control block each process is represented in the operating system by a process control block pcb also called a task control block. a pcb is shown in figure . . it contains many pieces of information associated with a specific process including these process state. the state may be new ready running waiting halted and soon. chapter processes process state process number program counter registers memory limits list of open files figure . process control block pcb . program counter. the counter indicates the address of the next instruction to be executed for this process. cpu registers. the registers vary in number and type depending on the computer architecture. they include accumulators index registers stack pointers and general purpose registers plus any condition code information. along with the program counter this state information must be saved when an interrupt occurs to allow the process to be continued correctly afterward figure . . cpu scheduling information. this information includes a process priority pointers to scheduling queues and any other scheduling parameters. chapter describes process scheduling. memory management information. this information may include such information as the value of the base and limit registers the page tables or the segment tables depending on the memory system used by the operating system chapter . accounting information. this information includes the amount of cpu and real time used time limits account mimbers job or process numbers and so on. i o status information. this information includes the list of i o devices allocated to the process a list of open files and so on. in brief the pcb simply serves as the repository for any information that may vary from process to process. . . threads the process model discussed so far has implied that a process is a program that performs a single thread of execution. for example when a process is running a word processor program a single thread of instructions is being executed. this single thread of control allows the process to perform only one task at one time. the user cannot simultaneously type in characters and run the spell checker within the same process for example. many modern operating systems have extended the process concept to allow a process to have multiple . process scheduling process p operating system process interrupt or system call executing save state into pcb mdle reload state from pcb idle j r terrupt or system call exe save state into pcb hdle reload state from pcb executing figure . diagram showing cpu switch from process to process. threads of execution and thus to perform more than one task at a time. chapter explores multithreaded processes in detail. . process scheduling the objective of multiprogramming is to have some process running at all times to maximize cpu utilization. the objective of time sharing is to switch the cpu among processes so frequently that users can interact with each program while it is running. to meet these objectives the process scheduler selects an available process possibly from a set of several available processes for program execution on the cpu. for a single processor system there will never be more than one running process. if there are more processes the rest will have to wait until the cpu is free and can be rescheduled. . . scheduling queues as processes enter the system they are put into a job queue which consists of all processes in the system. the processes that are residing in main memory and are ready and waiting to execute are kept on a list called the ready queue. this queue is generally stored as a linked list. a ready queue header contains pointers to the first and final pcbs in the list. each pcb includes a pointer field that points to the next pcb in the ready queue. the system also includes other queues. when a process is allocated the cpu it executes for a while and eventually quits is interrupted or waits for the occurrence of a particular event such as the completion of an i o request. chapter processes process representation in linux the process control block in the linux operating system is represented by the c structure task strtict. this structure contains all the necessary information for 'representing a process including the state of the process scheduling and memory management information list of open files and pointers to the process's parent and any of its children. a process's parent is the process that created it its children are any processes that it creates. some of these fields include pid t pid process identifier long state state of the process unsigned int time..slice scheduling information struct files struct files list of open files struct mm struct mm address space of this process for example the state of a process is represented by the field long state in this structure. within the linux kernel all active processes are represented using a doubly linked list of task struct and the kernel maintains a pointer current to the process currently executing on the system. this is shown in figure . . struct task struct struct task struct struct task struct process information process information process information current currently executing proccess figure active processes in linux. as an illustration of how the kernel might manipulate one of the fields in the task struct for a specified process let's assume the system would like to change the state of the process currently running to the value new .state. if current is a pointer to the process currently executing its state is changed with the following current state new..state suppose the process makes an i o request to a shared device such as a disk. since there are many processes in the system the disk may be busy with the i o request of some other process. the process therefore may have to wait for the disk. the list of processes waiting for a particular i o device is called a device queue. each device has its own device queue figure . . . process scheduling queue header pcb pcbz ready queue mag tape unit mag tape unit disk unit pcb terminal head unit tail figure . the ready queue and various i o device queues. a common representation for a discussion of process scheduling is a queueing diagram such as that in figure . . each rectangular box represents a queue. two types of queues are present the ready queue and a set of device queues. the circles represent the resources that serve the queues and the arrows indicate the flow of processes in the system. a new process is initially put in the ready queue. it waits there tmtil it is selected for execution or is dispatched. once the process is allocated the cpu and is executing one of several events could occur the process could issue an i o request and then be placed in an i o queue. the process could create a new subprocess and wait for the subprocess's termination. the process could be removed forcibly from the cpu as a result of an interrupt and be put back in the ready queue. in the first two cases the process eventually switches from the waiting state to the ready state and is then put back in the ready queue. a process continues this cycle until it terminates at which time it is removed from all queues and has its pcb and resources deallocated. . . schedulers a process migrates among the various scheduling queues throughout its lifetime. the operating system must select for scheduling purposes processes chapter processes i o request time slice expired fork a child wait for an interrupt figure . queueing diagram representation of process scheduling. from these queues in some fashion. the selection process is carried out by the appropriate scheduler. often in a batch system more processes are submitted than can be executed immediately. these processes are spooled to a mass storage device typically a disk where they are kept for later execution. the long term scheduler or job scheduler selects processes from this pool and loads them into memory for execution. the short term scheduler or cpu scheduler selects from among the processes that are ready to execute and allocates the cpu to one of them. the primary distinction between these two schedulers lies in frequency of execution. the short term scheduler must select a new process for the cpu frequently. a process may execute for only a few milliseconds before waiting for an i o request. often the short term scheduler executes at least once every milliseconds. because of the short time between executions the short term scheduler must be fast. if it takes milliseconds to decide to execute a process for milliseconds then percent of the cpu is being used wasted simply for scheduling the work. the long term scheduler executes much less frequently minutes may separate the creation of one new process and the next. the long term scheduler controls the degree of multiprogramming the number of processes in memory . if the degree of multiprogramming is stable then the average rate of process creation must be equal to the average departure rate of processes leaving the system. thus the long term scheduler may need to be invoked only when a process leaves the system. because of the longer interval between executions the long term scheduler can afford to take more time to decide which process should be selected for execution. it is important that the long term scheduler make a careful selection. in general most processes can be described as either l o bound or cpu bound. an i o bound process is one that spends more of its time doing i o than it spends doing computations. a cpu bound process in contrast generates i o requests infrequently using more of its time doing computations. it is important that the long term scheduler select a good process mix of i o bound and cpu bound . process scheduling swap in partially executed swap out swapped out processes end figure . addition of medium term scheduling to the queueing diagram. processes. if all processes are i o bound the ready queue will almost always be empty and the short term scheduler will have little to do. if all processes are cpu bound the i o waiting queue will almost always be empty devices will go unused and again the system will be unbalanced. the system with the best performance will thus have a combination of cpu bound and i o bound processes. on some systems the long term scheduler may be absent or minimal. for example time sharing systems such as unix and microsoft windows systems often have no long term scheduler but simply put every new process in memory for the short term scheduler. the stability of these systems depends either on a physical limitation such as the number of available terminals or on the self adjusting nature of human users. if the performance declines to unacceptable levels on a multiuser system some users will simply quit. some operating systems such as time sharing systems may introduce an additional intermediate level of scheduling. this medium term scheduler is diagrammed in figure . . the key idea behind a medium term scheduler is that sometimes it can be advantageous to remove processes from memory and from active contention for the cpu and thus reduce the degree of multiprogramming. later the process can be reintroduced into memory and its execution can be continued where it left off. this scheme is called swapping. the process is swapped out and is later swapped in by the medium term scheduler. swapping may be necessary to improve the process mix or because a change in memory requirements has overcommitted available memory requiring memory to be freed up. swapping is discussed in chapter . . . context switch as mentioned in . . interrupts cause the operating system to change a cpu from its current task and to run a kernel routine. such operations happen frequently on general purpose systems. when an interrupt occurs the system needs to save the current context of the process currently running on the cpu so that it can restore that context when its processing is done essentially suspending the process and then resuming it. the context is represented in the pcb of the process it includes the value of the cpu registers the process state see figure . and memory management information. generically we perform a state save of the current state of the cpu be it in kernel or user mode and then a state restore to resume operations. chapter processes switching the cpu to another process requires performing a stat save of the current process and a state restore of a different process. this task is known as a context switch. when a context switch occurs the kernel saves the context of the old process in its pcb and loads the saved context of the new process scheduled to run. context switch time is pure overhead because the system does no useful work while switching. its speed varies from machine to machine depending on the memory speed the number of registers that must be copied and the existence of special instructions such as a single instruction to load or store all registers . typical speeds are a few milliseconds. context switch times are highly dependent on hardware support. for instance some processors such as the sun ultrasparc provide multiple sets of registers. a context switch here simply requires changing the pointer to the current register set. of course if there are more active processes than there are register sets the system resorts to copying register data to and from memory as before. also the more complex the operating system the more work must be done during a context switch. as we will see in chapter advanced memory management techniques may require extra data to be switched with each context. for instance the address space of the current process must be preserved as the space of the next task is prepared for use. how the address space is preserved and what amount of work is needed to preserve it depend on the memory management method of the operating system
 the processes in most systems can execute concurrently and they may be created and deleted dynamically. thus these systems must provide a mechanism for process creation and termination. in this section we explore the mechanisms involved in creating processes and illustrate process creation on unix and windows systems. . . process creation a process may create several new processes via a create process system call during the course of execution. the creating process is called a parent process and the new processes are called the children of that process. each of these new processes may in turn create other processes forming a tree of processes. most operating systems including unix and the windows family of operating systems identify processes according to a unique process identifier or pid which is typically an integer number. figure . illustrates a typical process tree for the solaris operating system showing the name of each process and its pid. in solaris the process at the top of the tree is the sched process with pid of . the sched process creates several children processes including pageout and f sf lush. these processes are responsible for managing memory and file systems. the sched process also creates the i n i t process which serves as the root parent process for all user processes. in figure . we see two children of init inetd and dtlogin. inetd is responsible for networking services such as t e l n e t and ftp d t l o g i n is the process representing a user login screen. when a user logs in dtlogin creates an x windows session xsession which in turns creates the sdt shel process. below sdt shel a . operations on processes user's command line shell the c shell or csh is created. it is this commandline interface where the user then invokes various child processes such as the i s and cat commands. we also see a csh process with pid of representing a user who has logged onto the system using t e l n e t . this user has started the netscape browser pid of and the emacs editor pid of . on unix a listing of processes can be obtained using the ps command. for example entering the command ps e l will list complete information for all processes currently active in the system. it is easy to construct a process tree similar to what is shown in figure . by recursively tracing parent processes all the way to the i n i t process. in general a process will need certain resources cpu time memory files i o devices to accomplish its task. when a process creates a subprocess that subprocess may be able to obtain its resources directly from the operatiiig system or it may be constrained to a subset of the resources of the parent process. the parent may have to partition its resources among its children or it may be able to share some resources such as memory or files among several of its children. restricting a child process to a subset of the parent's resources prevents any process from overloading the system by creating too many subprocesses. in addition to the various physical and logical resources that a process obtains when it is created initialization data input may be passed along by the parent process to the child process. for example consider a process whose function is to display the contents of a file say img.jpg on the screen of a figure . a tree of processes on a typical solaris system. chapter processes terminal. when it is created it will get as an input from its parent process the name of the file img.jpg and it will use that file name open the file and write the contents out. it may also get the name of the output device. some operating systems pass resources to child processes. on such a system the new process may get two open files img.jpg and the terminal device and may simply transfer the datum between the two. when a process creates a new process two possibilities exist in terms of execution . the parent continues to execute concurrently with its children. . the parent waits until some or all of its children have terminated. there are also two possibilities in terms of the address space of the new process . the child process is a duplicate of the parent process it has the same program and data as the parent . . the child process has a new program loaded into it. to illustrate these differences let's first consider the unix operating system. in unix as we've seen each process is identified by its process identifier include sys types.h include stdio.h include unistd.h int main pid t pid fork a child process pid fork if pid error occurred fprintf stderr fork failed exit else if pid child process execlpf bin is is null else parent process parent will wait for the child to complete wait null printf child complete exit figure . c program forking a separate process. . operations on processes which is a unique integer. a new process is created by the forko system call. the new process consists of a copy of the address space of the original process. this mechanism allows the parent process to communicate easily with its child process. both processes the parent and the child continue execution at the instruction after the f o r k with one difference the return code for the forko is zero for the new child process whereas the nonzero process identifier of the child is returned to the parent. typically the execo system call is used after a forko system call by one of the two processes to replace the process's memory space with a new program. the exec system call loads a binary file into memory destroying the memory image of the program containing the execo system call and starts its execution. in this manner the two processes are able to communicate and then go their separate ways. the parent can then create more children or if it has nothing else to do while the child runs it can issue a wait system call to move itself off the ready queue until the termination of the child. the c program shown in figure . illustrates the unix system calls previously described. we now have two different processes running a copy of the same program. the value of pid for the child process is zero that for the parent is an integer value greater than zero. the child process overlays its address space with the unix command b i n i s used to get a directory listing using the execlpo system call execlpo is a version of the execo system call . the parent waits for the child process to complete with the wait system call. when the child process completes by either implicitly or explicitly invoking e x i t the parent process resumes from the call to wait where it completes using the e x i t system call. this is also illustrated in figure . . as an alternative example we next consider process creation in windows. processes are created in the win api using the createprocesso function which is similar to f ork in that a parent creates a new child process. however whereas f ork has the child process inheriting the address space of its parent createprocess requires loading a specified program into the address space of the child process at process creation. furthermore whereas f ork is passed no parameters createprocess expects no fewer than ten parameters. the c program shown in figure . illustrates the createprocesso function which creates a child process that loads the application mspaint. exe. we opt for many of the default values of the ten parameters passed to createprocesso. readers interested in pursuing the details on process creation and management in the win api are encouraged to consult the bibliographical notes at the end of this chapter. figure . process creation. chapter processes include stdio.h i include windows.h int main void startupinfo si process information pi allocate memory zeromemory si sizeof si si.cb sizeof si zeromemory pi sizeof pi create child process if !createprocess null use command line c windows system mspaint.exe command line null don't inherit process handle null don't inherit thread handle false disable handle inheritance no creation flags null use parent's environment block null use parent's existing directory si fprintf stderr create process failed return parent will wait for the child to complete waitforsingleobject pi.hprocess infinite printf child complete close handles closehandle pi.hprocess closehandle pi.hthread figure . creating a separate process using the win api. two parameters passed to createprocess are instances of the startupinfo and processjnformation structures. startupinfo specifies many properties of the new process such as window size and appearance and handles to standard input and output files. the processjnformation structure contains a handle and the identifiers to the newly created process and its thread. we invoke the zeromemoryo function to allocate memory for each of these structures before proceeding with createprocess . the first two parameters passed to createprocess are the application name and command line parameters. if the application name is null which in this case it is the command line parameter specifies the application to load. in this instance we are loading the microsoft windows mspaint.exe . operations on processes application. beyond these two initial parameters we use the default parameters for inheriting process and thread handles as well as specifying no creation flags. we also use the parent's existing environment block and starting directory. last we provide two pointers to the startupinfo and process information structures created at the beginning of the program. in figure . the parent process waits for the child to complete by invoking the w a i t o system call. the equivalent of this in win is waitforsingleobj ect which is passed a handle of the child process pi . hprocess that it is waiting for to complete. once the child process exits control returns from the waitforsingleob j ect function in the parent process. . . process termination a process terminates when it finishes executing its final statement and asks the operating system to delete it by using the e x i t system call. at that point the process may return a status value typically an integer to its parent process via the wait system call . all the resources of the process including physical and virtual memory open files and i o buffers are deallocated by the operating system. termination can occur in other circumstances as well. a process can cause the termination of another process via an appropriate system call for example terminateprocesso in win . usually such a system call can be invoked only by the parent of the process that is to be terminated. otherwise users could arbitrarily kill each other's jobs. note that a parent needs to know the identities of its children. thus when one process creates a new process the identity of the newly created process is passed to the parent. a parent may terminate the execution of one of its children for a variety of reasons such as these the child has exceeded its usage of some of the resources that it has been allocated. to determine whether this has occurred the parent must have a mechanism to inspect the state of its children. the task assigned to the child is no longer required. the parent is exiting and the operating system does not allow a child to continue if its parent terminates. some systems including vms do not allow a child to exist if its parent has terminated. in such systems if a process terminates either normally or abnormally then all its children must also be terminated. this phenomenon referred to as cascading termination is normally initiated by the operating system. to illustrate process execution and termination consider that in unix we can terminate a process by using the exitq system call its parent process may wait for the termination of a child process by using the waito system call. the wait system call returns the process identifier of a terminated child so that the parent can tell which of its possibly many children has terminated. if the parent terminates however all its children have assigned as their new parent the i n i t process. thus the children still have a parent to collect their status and execution statistics. chapter processes
 . . an example posix shared memory several ipc mechanisms are available for posix systems including shared memory and message passing. here we explore the posix api for shared memory. a process must first create a shared memory segment using the shmget system call shmget is derived from shared memory get . the following example illustrates the use of shmget segment id shmget ipcjprivate size sjrusr sjvvusr this first parameter specifies the key or identifier of the shared memory segment. if this is set to ipc private a new shared memory segment is created. the second parameter specifies the size in bytes of the shared memory segment. finally the third parameter identifies the mode which indicates how the shared memory segment is to be used that is for reading writing or both. by setting the mode to sjrusr sjvvusr we are indicating that the owner may read or write to the shared memory segment. a successful call to shmget returns an integer identifier for the shared memory segment. other processes that want to use this region of shared memory must specify this identifier. processes that wish to access a shared memory segment must attach it to their address space using the shmat shared memory attach system call. the call to shmat expects three parameters as well. the first is the integer identifier of the shared memory segment being attached and the second is a pointer location in memory indicating where the shared memory will be attached. if we pass a value of null the operating system selects the location on the user's behalf. the third parameter identifies a flag that allows the sharedmemory region to be attached in read only or read write mode by passing a parameter of we allow both reads and writes to the shared region. the third parameter identifies a mode flag. if set the mode flag allows the shared memory region to be attached in read only mode if set to the flag allows both reads and writes to the shared region. we attach a region of shared memory using shmat as follows shared memory char shmat id null if successful shmat returns a pointer to the beginning location in memory where the shared memory region has been attached. once the region of shared memory is attached to a process's address space the process can access the shared memory as a routine memory access using the pointer returned from shmat . in this example shmat returns a pointer to a character string. thus we could write to the shared memory region as follows sprintf sharedjnemory writing to shared memory other processes sharing this segment would see the updates to the sharedmemory segment. typically a process using an existing shared memory segment first attaches the shared memory region to its address space and then accesses and possibly updates the region of shared memory. when a process no longer requires access to the shared memory segment it detaches the segment from its address chapter processes include stdio.h include sys shm.h include sys stat. h int main the identifier for the shared memory segment int segment id a pointer to the shared memory segment char shared memory the size in bytes of the shared memory segment const int size allocate a shared memory segment segmented shmget ipc private size s irusr s iwusr attach the shared memory segment shared.memory char shmat segment id null write a message to the shared memory segment sprint f shared memory hi there! now print out the string from shared memory printf s n shared memory now detach the shared memory segment shmdt shareclmemory now remove the shared memory segment shmctl segment id ipc rmid null return figure . c program illustrating posix shared memory api. space. to detach a region of shared memory the process can pass the pointer of the shared memory region to the shmdt system call as follows shmdt shared memory finally a shared memory segment can be removed from the system with the shmctl system call which is passed the identifier of the shared segment along with the flag ipcjrmid. the program shown in figure . illustrates the posix shared memory apidiscussed above. this program creates a byte shared memory segment. once the region of shared memory is attached the process writes the message hi there! to shared memory. after outputting the contents of the updated memory it detaches and removes the shared memory region. we provide further exercises using the posix shared memory api in the programming exercises at the end of this chapter. . examples of ipc systems . . an example mach ? as an example of a message based operating system we next consider the mach operating system developed at carnegie mellon university. we introduced mach in chapter as part of the mac os x operating system. the mach kernel supports the creation and destruction of multiple tasks which are similar to processes but have multiple threads of control. most communication in mach including most of the system calls and all intertask information is carried out by messages. messages are sent to and received from mailboxes called ports in mach. even system calls are made by messages. when a task is created two special mailboxes the kernel mailbox and the notify mailbox are also created. the kernel mailbox is used by the kernel to communicate with the task. the kernel sends notification of event occurrences to the notify port. only three system calls are needed for message transfer. the msg send call sends a message to a mailbox. a message is received via msg receive . remote procedure calls rpcs are executed via msg rpc which sends a message and waits for exactly one return message from the sender. in this way the rpc models a typical subroutine procedure call but can work between systems hence the term remote. the port allocate system call creates a new mailbox and allocates space for its queue of messages. the maximum size of the message queue defaults to eight messages. the task that creates the mailbox is that mailbox's owner. the owner is also allowed to receive from the mailbox. only one task at a time can either own or receive from a mailbox but these rights can be sent to other tasks if desired. the mailbox has an initially empty queue of messages. as messages are sent to the mailbox the messages are copied into the mailbox. all messages have the same priority. mach guarantees that multiple messages from the same sender are queued in first in first out fifo order but does not guarantee an absolute ordering. for instance messages from two senders may be queued in any order. the messages themselves consist of a fixed length header followed by a variable length data portion. the header indicates the length of the message and includes two mailbox names. one mailbox name is the mailbox to which the message is being sent. commonly the sending thread expects a reply so the mailbox name of the sender is passed on to the receiving task which can use it as a return address. the variable part of a message is a list of typed data items. each entry in the list has a type size and value. the type of the objects specified in the message is important since objects defined by the operating system such as ownership or receive access rights task states and memory segments may be sent in messages. the send and receive operations themselves are flexible. for instance when a message is sent to a mailbox the mailbox may be full. if the mailbox is not full the message is copied to the mailbox and the sending thread continues. if the mailbox is full the sending thread has four options . wait indefinitely until there is room in the mailbox. . wait at most n milliseconds. chapter processes . do not wait at all but rather return immediately. . temporarily cache a message. one message can be given to the operating system to keep even though the mailbox to which it is being sent is full. when the message can be put in the mailbox a message is sent back to the sender only one such message to a full mailbox can be pending at any time for a given sending thread. the final option is meant for server tasks such as a line printer driver. after finishing a request such tasks may need to send a one time reply to the task that had requested service but they must also continue with other service requests even if the reply mailbox for a client is full. the receive operation must specify the mailbox or mailbox set from which a message is to be received a mailbox set is a collection of mailboxes as declared by the task which can be grouped together and treated as one mailbox for the purposes of the task. threads in a task can receive only from a mailbox or mailbox set for which the task has receive access. a port status system call returns the number of messages in a given mailbox. the receive operation attempts to receive from any mailbox in a mailbox set or a specific named mailbox. if no message is waiting to be received the receiving thread can either wait at most n milliseconds or not wait at all. the mach system was especially designed for distributed systems which we discuss in chapters through but mach is also suitable for singleprocessor systems as evidenced by its inclusion in the mac os x system. the major problem with message systems has generally been poor performance caused by double copying of messages the message is copied first from the sender to the mailbox and then from the mailbox to the receiver. the mach message system attempts to avoid double copy operations by using virtual memory management techniques chapter . essentially mach maps the address space containing the sender's message into the receiver's address space. the message itself is never actually copied. this message management technique provides a large performance boost but works for only intrasystem messages. the mach operating system is discussed in an extra chapter posted on our website. . . an example windows xp the windows xp operating system is an example of modern design that employs modularity to increase functionality and decrease the time needed to implement new features. windows xp provides support for multiple operating environments or subsystems with which application programs communicate via a message passing mechanism. the application programs can be considered clients of the windows xp subsystem server. the message passing facility in windows xp is called the local procedurecall lpc facility. the lpc in windows xp communicates between two processes on the same machine. it is similar to the standard rpc mechanism that is widely used but it is optimized for and specific to windows xp. like mach windows xp uses a port object to establish and maintain a connection between two processes. every client that calls a subsystem needs a communication channel which is provided by a port object and is never inherited. windows xp uses two types of ports connection ports and communication ports. they . examples of ipc systems are really the same but are given different names according to how they are used. connection ports are named objects and are visible to all processes sthey give applications a way to set up communication channels chapter . the communication works as follows the client opens a handle to the subsystem's connection port object. the client sends a connection request. the server creates two private communication ports and returns the handle to one of them to the client. the client and server use the corresponding port handle to send messages or callbacks and to listen for replies. windows xp uses two types of message passing techniques over a port that the client specifies when it establishes the channel. the simplest which is used for small messages uses the port's message queue as intermediate storage and copies the message from one process to the other. under this method messages of up to bytes can be sent. if a client needs to send a larger message it passes the message through a section object which sets up a region of shared memory. the client has to decide when it sets up the channel whether or not it will need to send a large message. if the client determines that it does want to send large messages it asks for a section object to be created. similarly if the server decides that replies will be large it creates a section object. so that the section object can be used a small message is sent that contains a pointer and size information about the section object. this method is more complicated than the first method but it avoids data copying. in both cases a callback mechanism can be used when either the client or the server cannot respond immediately to a request. the callback mechanism allows them to perform asynchronous message handling. the structure of local procedure calls in windows xp is shown in figure . . it is important to note that the lpc facility in windows xp is not part of the win api and hence is not visible to the application programmer. rather client server connectior request connection handle port handle client communication port server handle communication port shared section object bytes figure . local procedure calls in windows xp. chapter processes applications using the win api invoke standard remote procedure calls. when the rpc is being invoked on a process on the same system the rpc is indirectly handled through a local procedure call. lpcs are also used in a few other functions that are part of the win api. . communication in client server systems in section . we described how processes can communicate using shared memory and message passing. these techniques can be used for communication in client server systems . . as well. in this section we explore three other strategies for communication in client server systems sockets remote procedure calls rpcs and java's remote method invocation rmi . . . sockets a socket is defined as an endpoint for communication. a pair of processes communicating over a network employ a pair of sockets one for each process. a socket is identified by an ip address concatenated with a port number. in general sockets use a client server architecture. the server waits for incoming client requests by listening to a specified port. once a request is received the server accepts a connection from the client socket to complete the connection. servers implementing specific services such as telnet ftp and http listen to well known ports a telnet server listens to port an ftp server listens to port and a web or http server listens to port . all ports below are considered ivell known we can use them to implement standard services. when a client process initiates a request for a connection it is assigned a port by the host computer. this port is some arbitrary number greater than . for example if a client on host x with ip address . . . wishes to establish a connection with a web server which is listening on port at address . . . host x may be assigned port . the connection will consist of a pair of sockets . . . on host x and . . . on the web server. this situation is illustrated in figure . . the packets hostx . . . socket . . . web server . . . figure . communication using sockets. . communication in client server systems traveling between the hosts are delivered to the appropriate process based on the destination port number. all connections must be unique. therefore if another process also on host x wished to establish another connection with the same web server it would be assigned a port number greater than and not equal to . this ensures that all connections consist of a unique pair of sockets. although most program examples in this text use c we will illustrate sockets using java as it provides a much easier interface to sockets and has a rich library for networking utilities. those interested in socket programming in c or c should consult the bibliographical notes at the end of the chapter. java provides three different types of sockets. connection oriented tcp sockets are implemented with the socket class. connectionless udp sockets use the datagramsocket class. finally the mult icastsocket class is a subclass of the datagramsocket class. a multicast socket allows data to be sent to multiple recipients. our example describes a date server that uses connection oriented tcp sockets. the operation allows clients to request the current date and time from import java.net. import java.io. public class dateserver public static void main string args try serversocket sock new serversocket now listen for connections while true socket client sock.accept printwriter pout new printwriter client.getoutputstream true write the date to the socket pout.println new java.util.date .tostring close the socket and resume listening for connections client.close catch ioexception ioe system.err.println ioe figure . date server. chapter processes the server. the server listens to port although the port could have any arbitrary number greater than . when a connection is received the server returns the date and time to the client. the date server is shown in figure . . the server creates a serversocket that specifies it will listen to port . the server then begins listening to the port with the accept method. the server blocks on the accept o method waiting for a client to request a connection. when a connection request is received accept returns a socket that the server can use to communicate with the client. the details of how the server communicates with the socket are as follows. the server first establishes a p r i n t w r i t e r object that it will use to communicate with the client. a p r i n t w r i t e r object allows the server to write to the socket using the routine p r i n t and print in methods for output. the server process sends the date to the client calling the method p r i n t l n o . once it has written the date to the socket the server closes the socket to the client and resumes listening for more requests. a client communicates with the server by creating a socket and connecting to the port on which the server is listening. we implement such a client in the java program shown in figure . . the client creates a socket and requests import j ava.net. import java.io. public class dateclient public static void main string args try make connection to server socket socket sock new socket . . . inputstream in sock.getlnputstream bufferedreader bin new bufferedreader new inputstreamreader in read the date from the socket string line while line bin.readline ! null system.out.println line ii close the socket connection sock.close catch ioexception ioe system.err.println ioe figure . date client. . communication in client server systems a connection with the server at ip address . . . on port . once the connection is made the client can read front the socket using normal stream i o statements. after it has received the date from the server the client closes the socket and exits. the ip address . . . is a special ip address known as the loopback. when a computer refers to ip address . . . it is referring to itself. this mechanism allows a client and server on the same host to communicate using the tcp ip protocol. the ip address . . . could be replaced with the ip address of another host running the date server. in addition to an ip address an actual host name such as ivrvw.westminstercohege.edu can be used as well. communication using sockets although common and efficient is considered a low level form of communication between distributed processes. one reason is that sockets allow only an unstructured stream of bytes to be exchanged between the communicating threads. it is the responsibility of the client or server application to impose a structure on the data. in the next two subsections we look at two higher level methods of communication remote procedure calls rpcs and remote method invocation rmi . . . remote procedure calls one of the most common forms of remote service is the rpc paradigm which we discussed briefly in section . . . the rpc was designed as a way to abstract the procedure call mechanism for use between systems with network connections. it is similar in many respects to the ipc mechanism described in section . and it is usually built on top of such a system. here however because we are dealing with an environment in which the processes are executing on separate systems we must use a message based communication scheme to provide remote service. in contrast to the ipc facility the messages exchanged in rpc communication are well structured and are thus no longer just packets of data. each message is addressed to an rpc daemon listening to a port on the remote system and each contains an identifier of the function to execute and the parameters to pass to that function. the function is then executed as requested and any output is sent back to the requester in a separate message. a port is simply a number included at the start of a message packet. whereas a system normally has one network address it can have many ports within that address to differentiate the many network services it supports. if a remote process needs a service it addresses a message to the proper port. for instance if a system wished to allow other systems to be able to list its current users it would have a daemon supporting such an rpc attached to a port say port . any remote system could obtain the needed information that is the list of current users by sending an rpc message to port on the server the data would be received in a reply message. the semantics of rpcs allow a client to invoke a procedure on a remote host as it would invoke a procedure locally. the rpc system hides the details that allow communication to take place by providing a stub on the client side. typically a separate stub exists for each separate remote procedure. when the client invokes a remote procedure the rpc system calls the appropriate stub passing it the parameters provided to the remote procedure. this stub locates the port on the server and marshals the parameters. parameter marshalling involves packaging the parameters into a form that can be transmitted over chapter processes a network. the stub then transmits a message to the server using message passing. a similar stub on the server side receives this message and invokes the procedure on the server. if necessary return values are passed back to the client using the same technique. one issue that must be dealt with concerns differences in data representation on the client and server machines. consider the representation of bit integers. some systems known as big endian use the high memory address to store the most significant byte while other systems known as little endian store the least significant byte at the high memory address. to resolve differences like this many rpc systems define a machine independent representation of data. one such representation is known as external data representation xdr . on the client side parameter marshalling involves converting the machinedependent data into xdr before they are sent to the server. on the server side the xdr data are unmarshalled and converted to the machine dependent representation for the server. another important issue involves the semantics of a call. whereas local procedure calls fail only under extreme circumstances rpcs can fail or be duplicated and executed more than once as a result of common network errors. one way to address this problem is for the operating system to ensure that messages are acted on exactly once rather than at most once. most local procedure calls have the exactly once functionality but it is more difficult to implement. first consider at most once . this semantic can be assured by attaching a timestamp to each message. the server must keep a history of all the timestamps of messages it has already processed or a history large enough to ensure that repeated messages are detected. incoming messages that have a timestamp already in the history are ignored. the client can then send a message one or more times and be assured that it only executes once. generation of these timestamps is discussed in section . . for exactly once we need to remove the risk that the server never receives the request. to accomplish this the server must implement the at most once protocol described above but must also acknowledge to the client that the rpc call was received and executed. these ack messages are common throughout networking. the client must resend each rpc call periodically until it receives the ack for that call. another important issue concerns the communication between a server and a client. with standard procedure calls some form of binding takes place during link load or execution time chapter so that a procedure call's name is replaced by the memory address of the procedure call. the rpc scheme requires a similar binding of the client and the server port but how does a client know the port numbers on the server? neither system has full information about the other because they do not share memory. two approaches are common. first the binding information may be predetermined in the form of fixed port addresses. at compile time an rpc call has a fixed port number associated with it. once a program is compiled the server cannot change the port number of the requested service. second binding can be done dynamically by a rendezvous mechanism. typically an operating system provides a rendezvous also called a matchmaker daemon on a fixed rpc port. a client then sends a message containing the name of the rpc to the rendezvous daemon requesting the port address of the rpc it . communication in client server systems client messages server j user calls kernel to send rpc message to procedure x kernel sends from matchmaker message to to seirver receives matchmaker to message looks find port number up answer kernel places matchmaker port pin user pprtt kernel replies to client rpc message pie fipg?x with port p p rt p from client daemon kernel sends to server listening to rpc port port p port p receives contents message from rpc daemon kernel receives port p processes reply passes to client request and it to user port kernel processes send output output figure . execution of a remote procedure call rpc . needs to execute. the port number is returned and the rpc calls can be sent to that port until the process terminates or the server crashes . this method requires the extra overhead of the initial request but is more flexible than the first approach. figure . shows a sample interaction. the rpc scheme is useful in implementing a distributed file system chapter . such a system can be implemented as a set of rpc daemons and clients. the messages are addressed to the distributed file system port on a server on which a file operation is to take place. the message contains the disk operation to be performed. the disk operation might be read write rename d e l e t e or s t a t u s corresponding to the usual file related system calls. the return message contains any data resulting from that call which is executed by the dfs daemon on behalf of the client. for instance a message might contain a request to transfer a whole file to a client or be limited to a simple block request. in the latter case several such requests may be needed if a whole file is to be transferred. chapter processes . . remote method invocation remote method invocation rmi is a java feature similar to rpcs. rmi allows a thread to invoke a method on a remote object. objects are considered remote if they reside in a different java virtual machine jvm . therefore the remote object may be in a different jvm on the same computer or on a remote host connected by a network. this situation is illustrated in figure . . rmi and rpcs differ in two fundamental ways. first rpcs support procedural programming whereby only remote procedures or functions can be called. in contrast rmi is object based it supports invocation of methods on remote objects. second the parameters to remote procedures are ordinary data structures in rpc with rmi it is possible to pass objects as parameters to remote methods. by allowing a java program to invoke methods on remote objects rmi makes it possible for users to develop java applications that are distributed across a network. to make remote methods transparent to both the client and the server rmi implements the remote object using stubs and skeletons. a stub is a proxy for the remote object it resides with the client. when a client invokes a remote method the stub for the remote object is called. this client side stub is responsible for creating a parcel consisting of the name of the method to be invoked on the server and the marshalled parameters for the method. the stub then sends this parcel to the server where the skeleton for the remote object receives it. the skeleton is responsible for unmarshalling the parameters and invoking the desired method on the server. the skeleton then marshals the return value or exception if any into a parcel and returns this parcel to the client. the stub unmarshals the return value and passes it to the client. lets look more closely at how this process works. assume that a client wishes to invoke a method on a remote object server with a signature somemethod object object that returns a boolean value. the client executes the statement boolean val server.somemethod a b the call to somemethod with the parameters a and b invokes the stub for the remote object. the stub marshals into a parcel the parameters a and b and the name of the method that is to be invoked on the server then sends this parcel to the server. the skeleton on the server unmarshals the parameters and invokes the method somemethod . the actual implementation of somemethod resides on the server. once the method is completed the skeleton marshals jvm jvm figure . remote method invocation
 client remote object val server.somemethod a b boolean somemeihod object x object y implementation of somemethod ii stub skeleton a b somemethod boolean return value figure . marshalling parameters. the boolean value returned from somemethod and sends this value back to the client. the stub unmarshals this return value and passes it to the client. the process is shown in figure . . fortunately the level of abstraction that rmi provides makes the stubs and skeletons transparent allowing java developers to write programs that invoke distributed methods just as they would invoke local methods. it is crucial however to understand a few rules about the behavior of parameter passing. if the marshalled parameters are local or nonremote objects they are passed by copy using a technique known as object serialization. however if the parameters are also remote objects they are passed by reference. in our example if a is a local object and b a remote object a is serialized and passed by copy and b is passed by reference. this in turn allows the server to invoke methods on b remotely. if local objects are to be passed as parameters to remote objects they must implement the interface j ava. io . s e r i a l i z a b l e . many objects in the core java api implement s e r i a l i z a b l e allowing them to be used with rmi. object serialization allows the state of an object to be written to a byte stream. . summary a process is a program in execution. as a process executes it changes state. the state of a process is defined by that process's current activity. each process may be in one of the following states new ready running waiting or terminated. each process is represented in the operating system by its own process control block pcb . a process when it is not executing is placed in some waiting queue. there are two major classes of queues in an operating system i o request queues chapter processes and the ready queue. the ready queue contains all the processes that areteady to execute and are waiting for the cpu. each process is represented by a pcb and the pcbs can be linked together to form a ready queue. long term job scheduling is the selection of processes that will be allowed to contend for the cpu. normally long term scheduling is heavily influenced by resourceallocation considerations especially memory management. short term cpu scheduling is the selection of one process from the ready queue. operating systems must provide a mechanism for parent processes to create new child processes. the parent may wait for its children to terminate before proceeding or the parent and children may execute concurrently. there are several reasons for allowing concurrent execution information sharing computation speedup modularity and convenience. the processes executing in the operating system may be either independent processes or cooperating processes. cooperating processes require an interprocess communication mechanism to communicate with each other. principally communication is achieved through two schemes shared memory and message passing. the shared memory method requires communicating processes to share some variables. the processes are expected to exchange information through the use of these shared variables. in a shared memory system the responsibility for providing communication rests with the application programmers the operating system needs to provide only the shared memory. the message passing method allows the processes to exchange messages. the responsibility for providing communication may rest with the operating system itself. these two schemes are not mutually exclusive and can be used simultaneously within a single operating system. communication in client server systems may use sockets remote procedure calls rpcs or java's remote method invocation rmi . a socket is defined as an endpoint for communication. a connection between a pair of applications consists of a pair of sockets one at each end of the communication channel. rpcs are another form of distributed communication. an rpc occurs when a process or thread calls a procedure on a remote application. rmi is the java version of rpcs. rmi allows a thread to invoke a method on a remote object just as it would invoke a method on a local object. the primary distinction between rpcs and rmi is that in rpcs data are passed to a remote procedure in the form of an ordinary data structure whereas rmi allows objects to be passed in remote method calls. exercises . describe the differences among short term medium term and longterm scheduling. . describe the actions taken by a kernel to context switch between processes. . consider the rpc mechanism. describe the undesirable consequences that could arise from not enforcing either the at most once or exactly once semantic. describe possible uses for a mechanism that has neither of these guarantees. exercises include sys types.h t include stdio.h include unistd.h int value int main pid t pid pid fork if pid child process value else if pid parent process wait null printf parent value d value line a exit figure . c program. . using the program shown in figure . explain what will be output at line a. . what are the benefits and the disadvantages of each of the following? consider both the system level and the programmer level. a. synchronous and asynchronous communication b. automatic and explicit buffering c. send by copy and send by reference d. fixed sized and variable sized messages . the fibonacci sequence is the series of numbers formally it can be expressed as fibo jibi fib fib fib write a c program using the fork system call that that generates the fibonacci sequence in the child process. the number of the sequence will be provided in the command line. for example if is provided the first five numbers in the fibonacci sequence will be output by the child process. because the parent and child processes have their own copies of the data it will be necessary for the child to output the sequence. have the parent invoke the wait call to wait for the child process to complete before exiting the program. perform necessary error checking to ensure that a non negative number is passed on the command line. chapter processes . repeat the preceding exercise this time using the createprocess in the win api. in this instance you will need to specify a separate program to be invoked from createprocessc . it is this separate program that will run as a child process outputting the fibonacci sequence. perform necessary error checking to ensure that a nonnegative number is passed on the command line. . modify the date server shown in figure . so that it delivers random fortunes rather than the current date. allow the fortunes to contain multiple lines. the date client shown in figure . can be used to read the multi line fortunes returned by the fortune server. . an echo server is a server that echoes back whatever it receives from a client. for example if a client sends the server the string hello there! the server will respond with the exact data it received from the client that is hello therei write an echo server using the java networking api described in section . . . this server will wait for a client connection using the accept method. when a client connection is received the server will loop performing the following steps read data from the socket into a buffer. write the contents of the buffer back to the client. the server will break out of the loop only when it has determined that the client has closed the connection. the date server shown in figure . uses the java io .bufferedreader class. buff eredreader extends the java io .reader class which is used for reading character streams. however the echo server cannot guarantee that it will read characters from clients it may receive binary data as well. the class java. io. inputstream deals with data at the byte level rather than the character level. thus this echo server must use an object that extends java. io.inputstream. the read method in the j ava. io. inputstream class returns when the client has closed its end of the socket connection. . in exercise . the child process must output the fibonacci sequence since the parent and child have their own copies of the data. another approach to designing this program is to establish a shared memory segment between the parent and child processes. this technique allows the child to write the contents of the fibonacci sequence to the sharedmemory segment and has the parent output the sequence when the child completes. because the memory is shared any changes the child makes to the shared memory will be reflected in the parent process as well. this program will be structured using posix shared memory as described in section . . . the program first requires creating the data structure for the shared memory segment. this is most easily accomplished using a struct. this data structure will contain two items a fixed sized array of size max sequence that will hold the fibonacci values and the size of the sequence the child process is to generate exercises sequence size where sequence size max..sequence. these items can be represented in a s t r u c t as follows define max sequence typedef struct long f ib sequence max sequence int sequence size shared data the parent process will progress through the following steps a. accept the parameter passed on the command line and perform error checking to ensure that the parameter is max sequence. b. create a shared memory segment of size shared data. c. attach the shared memory segment to its address space. d. set the value of sequence size to the parameter on the command line. e. fork the child process and invoke the wait system call to wait for the child to finish. f. output the value of the fibonacci sequence in the shared memory segment. g. detach and remove the shared memory segment. because the child process is a copy of the parent the shared memory region will be attached to the child's address space as well. the child process will then write the fibonacci sequence to shared memory and finally will detach the segment. one issue of concern with cooperating processes involves synchronization issues. in this exercise the parent and child processes must be synchronized so that the parent does not output the fibonacci sequence until the child finishes generating the sequence. these two processes will be synchronized using the wait system call the parent process will invoke wait which will cause it to be suspended until the child process exits. . most unix and linux systems provide the ipcs command. this command lists the status of various posix interprocess communication mechanisms including shared memory segments. much of the information for the command comes from the data structure s t r u c t shmiclds which is available in the u s r i n c l u d e s y s s h m . h file. some of the fields of this structure include int shm segsz size of the shared memory segment short shmjiattch number of attaches to the shared memory segment struct ipc perm shm perm permission structure of the shared memory segment chapter processes the struct ipc perm data structure which is available in the file u s r i n c l u d e s y s i p c .h contains the fields unsigned short uid identifier of the user of the shared memory segment unsigned short mode permission modes key t key on linux systems key user specified key identifier the permission modes are set according to how the shared memory segment is established with the shmget system call. permissions are identified according to the following mode meaning read permission of owner. write permission of owner. read permission of group. write permission of group read permission of world. write permission of world. permissions can be accessed by using the bitwise and operator . for example if the statement mode evaluates to true the permission mode allows read permission by the owner of the shared memory segment. shared memory segments can be identified according to a userspecified key or according to the integer value returned from the shmget system call which represents the integer identifier of the shared memory segment created. the shm ds structure for a given integer segment identifier can be obtained with the following shmctl system call identifier of the shared memory segment int s egment i d shm ds shmbuffer shmctl segmented ipcstat shmbuf f e r if successful shmctl returns otherwise it returns . write a c program that is passed an identifier for a shared memory segment. this program will invoke the shmctl function to obtain its shnuds structure. it will then output the following values of the given shared memory segment segment id key mode exercises owner ifid size number of attaches project unix shell and history feature this project consists of modifying a c program which serves as a shell interface that accepts user commands and then executes each command in a separate process. a shell interface provides the user a prompt after which the next command is entered. the example below illustrates the prompt sh and the user's next command cat prog. c. this command displays the file prog. c on the terminal using the unix cat command. sh cat prog.c one technique for implementing a shell interface is to have the parent process first read what the user enters on the command line i.e. cat prog. c and then create a separate child process that performs the command unless otherwise specified the parent process waits for the child to exit before continuing. this is similar in functionality to what is illustrated in figure . . however unix shells typically also allow the child process to run in the background or concurrently as well by specifying the ampersand at the end of the command. by rewriting the above command as sh cat prog.c the parent and child processes now run concurrently. the separate child process is created using the f ork system call and the user's command is executed by using one of the system calls in the execo family as described in section . . . simple shell a c program that provides the basic operations of a command line shell is supplied in figure . . this program is composed of two functions main and setup . the setup function reads in the user's next command which can be up to characters and then parses it into separate tokens that are used to fill the argument vector for the command to be executed. if the command is to be run in the background it will end with ' ' and setupo will update the parameter background so the maino function can act accordingly. this program is terminated when the user enters controlxd and setup then invokes exit . the mainc function presents the prompt c mmand and then invokes s e t u p o which waits for the user to enter a command. the contents of the command entered by the user is loaded into the args array. for example if the user enters i s at the c mmand prompt args becomes equal to the string is and args l is set to the string to . by ''string we mean a null terminated c style string variable. chapter processes if include stdio.h include unistd.h define max line setup reads in the next command line separating it into distinct tokens using whitespace as delimiters setup modifies the args parameter so that it holds pointers to the null terminated strings that are the tokens in the most recent user command line as well as a null pointer indicating the end of the argument list which comes after the string pointers that have been assigned to args. void setup char inputbuffer char args int background full source code available online int main void char inputbuffer maxjline buffer to hold command entered int background equals if a command is followed by ' ' char args max lin command line arguments while background printf command setup calls exito when control d is entered setup inputbuffer args fcbackground the steps are fork a child process using fork the child process will invoke execvp if background the parent will wait otherwise it will invoke the setup function again. figure . outline of simple shell. this project is organized into two parts creating the child process and executing the command in the child and modifying the shell to allow a history feature. creating a child process the first part of this project is to modify the mainq function in figure . so that upon returning from s e t u p a child process is forked and executes the command specified by the user. exercises as noted above the setup function loads the contents of the args array with the command specified by the user. this args array will be passed to the execvpo function which has the following interface execvp char command char params where command represents the command to be performed and par ams stores the parameters to this command. for this project the execvp function should be invoked as execvp args args be sure to check the value of background to determine if the parent process is to wait for the child to exit or not. creating a history feature the next task is to modify the program in figure . so that it provides a history feature that allows the user access up to the most recently entered commands. these commands will be numbered starting at and will continue to grow larger even past e.g. if the user has entered commands the most recent commands should be numbered to . this history feature will be implementing using a few different techniques. first the user will be able to list these commands when he she presses control c which is the sigint signal. unix systems use signals to notify a process that a particular event has occurred. signals may be either synchronous or asynchronous depending upon the source and the reason for the event being signaled. once a signal has been generated by the occurrence of a certain event e.g. division by zero illegal memory access user entering control c etc. the signal is delivered to a process where it must be handled. a process receiving a signal may handle it by one of the following techniques ignoring the signal using the default signal handler or providing a separate signal handling function. signals may be handled by first setting certain fields in the c structure struct sigaction and then passing this structure to the sigactionq function. signals are defined in the include file u s r i n c l u d e s y s s i g n a l . h. for example the signal sigint represents the signal for terminating a program with the control sequence control c . the default signal handler for sigint is to terminate the program. alternatively a program may choose to set up its own signal handling function by setting the sajhandler field in s t r u c t sigaction to the name of the function which will handle the signal and then invoking the s i g a c t i o n o function passing it the signal we are setting up a handler for and a pointer to s t r u c t sigaction. in figure . we show a c program that uses the function handle.sigintq for handling the sigint signal. this function prints out the message''caught control c and then invokes the e x i t function to terminate the program. we must use the write function for performing output rather than the more common p r i n t f as the former is known as being chapter processes include signal.h include unistd.h include stdio.h define buffer size char buffer buffer size the signal handling function void handle sigint write stdout fileno buffer s t r l e n buf f er exit int mainfint argc char argv set up the signal handler struct sigaction handler handler . sa handler handle.sigint sigaction sigint chandler null generate the output message strcpy buffer caught control c n loop until we receive controlxc while return figure . signal handling program. signal safe indicating it can be called from inside a signal handling function such guarantees cannot be made of p r i n t f . this program will run in the while l loop until the user enters the sequence control c . when this occurs the signal handling function handle sigint is invoked. the signal handling function should be declared above main and because control can be transferred to this function at any point no parameters may be passed to it this function. therefore any data that it must access in your program must be declared globally i.e. at the top of the source file before your function declarations. before returning from the signal handling function it should reissue the command prompt. if the user enters control c the signal handler will output a list of the most recent commands. with this list the user can run any of the previous commands by entering r x where 'x' is the first letter of that command. if more than one command starts with v execute the most recent one. also the user should be able to run the most recent command again by just entering v. you can assume that only one space will separate the 'r' and the first letter and bibliographical notes that the letter will be followed by ' n'. again 'r' alone will be immediately followed by the n character if it is wished to execute the most recent command. any command that is executed in this fashion should be echoed on the user's screen and the command is also placed in the history buffer as the next command r x does not go into the history list the actual command that it specifies though does. it the user attempts to vise this history facility to run a command and the command is detected to be erroneous an error message should be given to the user and the command not entered into the history list and the execvpq function should not be called. it would be nice to know about improperly formed commands that are handed off to execvpo that appear to look valid and are not and not include them in the history as well but that is beyond the capabilities of this simple shell program. you should also modify setup so it returns an i n t signifying if has successfully created a valid args list or not and the main should be updated accordingly. bibliographical notes interprocess communication in the rc system was discussed by brinchhansen . schlichting and schneider discussed asynchronous message passing primitives. the ipc facility implemented at the user level was described by bershad et al. . details of interprocess communication in unix systems were presented by gray . barrera and vahalia described interprocess communication in the mach system. solomon and russinovich and stevens outlined interprocess communication in windows and unix respectively. the implementation of rpcs was discussed by birrell and nelson . a design of a reliable rpc mechanism was described by shrivastava and panzieri and tay and ananda presented a survey of rpcs. stankovic and staunstrup discussed procedure calls versus message passing communication. grosso discussed rmi in significant detail. calvertand donahoo provided coverage of socket programming in java
 the process model introduced in chapter assumed that a process was an executing program with a single thread of control. most modern operating systems now provide features enabling a process to contain multiple threads of control. this chapter introduces many concepts associated with multithreaded computer systems including a discussion of the apis for the pthreads win and java thread libraries. we look at many issues related to multithreaded programming and how it affects the design of operating systems. finally we explore how the windows xp and linux operating systems support threads at the kernel level. objectives to introduce the notion of a thread a fundamental unit of cpu utilization that forms the basis of multithreaded computer systems. to discuss the apis for phtreads win and java thread libraries
 a thread is a basic unit of cpu utilization it comprises a thread id a program counter a register set and a stack. it shares with other threads belonging to the same process its code section data section and other operating system resources such as open files and signals. a traditional or heavyweight process has a single thread of control. tf a process has multiple threads of control it can perform more than one task at a time. figure . illustrates the difference between a traditional single threaded process and a multithreaded process. . . motivation many software packages that run on modern desktop pcs are multithreaded. an application typically is implemented as a separate process with several threads of control. a web browser might have one thread display images or text while another thread retrieves data from the network for example. a word processor may have a thread for displaying graphics another thread chapter threads code data files code data files registers stack thread thread single threaded process multithreaded process figure . single threaded and multithreaded processes. for responding to keystrokes from the user and a third thread for performing spelling and grammar checking in the background. in certain situations a single application may be required to perform several similar tasks. for example a web server accepts client requests for web pages images sound and so forth. a busy web server may have several perhaps thousands of clients concurrently accessing it. if the web server ran as a traditional single threaded process it would be able to service only one client at a time. the amount of time that a client might have to wait for its request to be serviced could be enormous. one solution is to have the server run as a single process that accepts requests. when the server receives a request it creates a separate process to service that request. in fact this process creation method was in common use before threads became popular. process creation is time consuming and resource intensive as was shown in the previous chapter. if the new process will perform the same tasks as the existing process why incur all that overhead? it is generally more efficient to use one process that contains multiple threads. this approach would multithread the web server process. the server would create a separate thread that would listen for client requests when a request was made rather than creating another process the server would create another thread to service the request. threads also play a vital role in remote procedure call rpc systems. recall from chapter that rpcs allow interprocess communication by providing a communication mechanism similar to ordinary function or procedure calls. typically rpc servers are multithreaded. when a server receives a message it services the message using a separate thread. this allows the server to service several concurrent requests. java's rmi systems work similarly. finally many operating system kernels are now multithreaded several threads operate in the kernel and each thread performs a specific task such as managing devices or interrupt handling. for example solaris creates a set
 of threads in the kernel specifically for interrupt handling linux uses a kernel thread for managing the amount of free memory in the system. . . benefits the benefits of multithreaded programming can be broken down into four major categories . responsiveness. multithreading an interactive application may allow a program to continue running even if part of it is blocked or is performing a lengthy operation thereby increasing responsiveness to the user. for instance a multithreaded web browser could still allow user interaction in one thread while an image was being loaded in another thread. . resource sharing. by default threads share the memory and the resources of the process to which they belong. the benefit of sharing code and data is that it allows an application to have several different threads of activity within the same address space. . economy. allocating memory and resources for process creation is costly. because threads share resources of the process to which they belong it is more economical to create and context switch threads. empirically gauging the difference in overhead can be difficult but in general it is much more time consuming to create and manage processes than threads. in solaris for example creating a process is about thirty times slower than is creating a thread and context switching is about five times slower. . utilization of multiprocessor architectures. the benefits of multithreading can be greatly increased in a multiprocessor architecture where threads may be running in parallel on different processors. a singlethreaded process can only run on one cpu no matter how many are available. multithreading on a multi cpu machine increases concurrency. . multithreading models our discussion so far has treated threads in a generic sense. however support for threads may be provided either at the user level for user threads or by the kernel for kernel threads. user threads are supported above the kernel and are managed without kernel support whereas kernel threads are supported and managed directly by the operating system. virtually all contemporary operating systems including windows xp linux mac os x solaris and tru unix formerly digital unix support kernel threads. ultimately there must exist a relationship between user threads and kernel threads. in this section we look at three common ways of establishing this relationship. . . many to one model the many to one model figure . maps many user level threads to one kernel thread. thread management is done by the thread library in user space so it is efficient but the entire process will block if a thread makes a chapter threads user thread kernel thread figure . many to one model. blocking system call. also because only one thread can access the kernel at a time multiple threads are unable to run in parallel on multiprocessors. green threads a thread library available for solaris uses this model as does gnu portable threads. . . one to one model the one to one model figure . maps each user thread to a kernel thread. it provides more concurrency than the many to one model by allowing another thread to run when a thread makes a blocking system call it also allows multiple threads to run in parallel on multiprocessors. the only drawback to this model is that creating a user thread requires creating the corresponding kernel thread. because the overhead of creating kernel threads can burden the performance of an application most implementations of this model restrict the number of threads supported by the system. linux along with the family of windows operating systems including windows nt and xp implement the one to one model. . . many to many model the many to many model figure . multiplexes many user level threads to a smaller or equal number of kernel threads. the number of kernel threads may be specific to either a particular application or a particular machine an user thread kernel thread figure . one to one model
 user thread kernel thread figure . many to many model. application may be allocated more kernel threads on a multiprocessor than on a uniprocessor . whereas the many to one model allows the developer to create as many user threads as she wishes true concurrency is not gained because the kernel can schedule only one thread at a time. the one to one model allows for greater concurrency but the developer has to be careful not to create too many threads within an application and in some instances may be limited in the number of threads she can create . the many to many model suffers from neither of these shortcomings developers can create as many user threads as necessary and the corresponding kernel threads can run in parallel on a multiprocessor. also when a thread performs a blocking system call the kernel can schedule another thread for execution. one popular variation on the many to many model still multiplexes many user level threads to a smaller or equal number of kernel threads but also allows a user level thread to be bound to a kernel thread. this variation sometimes referred to as the tivo level model figure . is supported by operating systems such as irix hp ux and tru unix. the solaris operating system supported the two level model in versions older than solaris . however beginning with solaris this system uses the one to one model. . thread libraries a thread library provides the programmer an api for creating and managing threads. there are two primary ways of implementing a thread library. the first approach is to provide a library entirely in user space with no kernel support. all code and data structures for the library exist in user space. this means that invoking a function in the library results in a local function call in user space and not a system call. the second approach is to implement a kernel level library supported directly by the operating system. in this case code and data structures for the library exist in kernel space. invoking a function in the api for the library typically results in a system call to the kernel. three main thread libraries are in use today posix pthreads win and java. pthreads the threads extension of the posix standard may be chapter threads user thread kernel thread figure . two level model. provided as either a user or kernel level library. the win thread library is a kernel level library available on windows systems. the java thread api allows thread creation and management directly in java programs. however because in most instances the jvm is running on top of a host operating system the java thread api is typically implemented using a thread library available on the host system. this means that on windows systems java threads are typically implemented using the win api unix and linux systems often use pthreads. in the remainder of this section we describe basic thread creation using these three thread libraries. as an illustrative example we design a multithreaded program that performs the summation of a non negative integer in a separate thread using the well known summation function sum o for example if n were this function would represent the summation from to which is . each of the three programs will be run with the upper bounds of the summation entered on the command line thus if the user enters the summation of the integer values from to will be output. . . pthreads pthreads refers to the posix standard ieee . c defining an api for thread creation and synchronization. this is a specification for thread behavior not an implementation. operating system designers may implement the specification in any way they wish. numerous systems implement the pthreads specification including solaris linux mac os x and tru unix. shareware implementations are available in the public domain for the various windows operating systems as well. the c program shown in figure . demonstrates the basic pthreads api for constructing a multithreaded program that calculates the summation of a nonnegative integer in a separate thread. in a pthreads program separate threads begin execution in a specified function. in figure . this is the runner function. when this program begins a single thread of control begins in . thread libraries include pthread.h include stdio.h int sum this data is shared by the thread s void runner void param the thread int main int argc char argv pthread t tid the thread identifier pthread.attr t attr set of thread attributes if argc ! fprintf stderr usage a.out integer value n return if atoi argv fprintf stderr d must be n atoi argv return get the default attributes pthread.attr.init attr create the thread pthread create tid attr runner argv wait for the thread to exit pthread join tid null printf sum d n sum the thread will begin control in this function void runner void param int i upper atoi param sum for i i upper i sum i pthread exit figure . multithreaded c program using the pthreads api. maino. after some initialization maino creates a second thread that begins control in the runner function. both threads share the global data sum. let's look more closely at this program. all pthreads programs must include the pthread.h header file. the statement pthreadjt t i d declares the identifier for the thread we will create. each thread has a set of attributes including stack size and scheduling information. the pthread attr t attr chapter threads declaration represents the attributes for the thread. we set the attributes in the function call pthread attr init c attr . because we did not explicitly set any attributes we use the default attributes provided. in chapter we will discuss some of the scheduling attributes provided by the pthreads api. a separate thread is created with the pthread creat e function call. in addition to passing the thread identifier and the attributes for the thread we also pass the name of the function where the new thread will begin execution in this case the runner function. last we pass the integer parameter that was provided on the command line argv . at this point the program has two threads the initial or parent thread in maino and the summation or child thread performing the summation operation in the runner function. after creating the summation thread the parent thread will wait for it to complete by calling the pthread join function. the summation thread will complete when it calls the function pthread.exit . once the summation thread has returned the parent thread will output the value of the shared data sum. . . win threads the technique for creating threads using the win thread library is similar to the pthreads technique in several ways. we illustrate the win thread api in the c program shown in figure . . notice that we must include the windows. h header file when using the win api. just as in the pthreads version shown in figure . data shared by the separate threads in this case sum are declared globally the dword data type is an unsigned bit integer. we also define the summationo function that is to be performed in a separate thread. this function is passed a pointer to a void which win defines as lpvoid. the thread performing this function sets the global data sum to the value of the summation from to the parameter passed to summationo. threads are created in the win api using the createthreado function and just as in pthreads a set of attributes for the thread is passed to this function. these attributes include security information the size of the stack and a flag that can be set to indicate if the thread is to start in a suspended state. in this program we use the default values for these attributes which do not initially set the thread to a suspended state and instead make it eligible to be run by the cpu scheduler . once the summation thread is created the parent must wait for it to complete before outputting the value of sum as the value is set by the summation thread. recall that the pthread program figure . had the parent thread wait for the summation thread using the pthread j oin statement. we perform the equivalent of this in the win api using the waitforsingleobj ect function which causes the creating thread to block until the summation thread has exited. we will cover synchronization objects in more detail in chapter . . . java threads threads are the fundamental model of program execution in a java program and the java language and its api provide a rich set of features for the creation and management of threads. all java programs comprise at least a single thread . thread libraries inciude windows.h include stdio.h dword sum data is shared by the thread s the thread runs in this separate function dword winapi summation lpvoid param dword upper dword param for dword i i upper i sum i return int main int argc char argv dword threadld handle threadhandle int param perform some basic error checking if argc ! fprintf stderr an integer parameter is required n return param atoi argv l if param fprintf stderr an integer is required n return create the thread threadhandle createthread null default security attributes default stack size summation thread function param parameter to thread function default creation flags sthreadld returns the thread identifier if threadhandle ! null now wait for the thread to finish waitforsingleobject threadhandle infinite close the thread handle closehandle threadhandle printfc'sum d n sum figure . multithreaded c program using the win api. chapter threads of control even a simple java program consisting of only a main. method runs as a single thread in the jvm. there are two techniques for creating threads in a java program. one approach is to create a new class that is derived from the thread class and to override its run method. an alternative and more commonly used technique is to define a class that implements the runnable interface. the runnable interface is defined as follows public interface runnable public abstract void run when a class implements runnable it must define a run method. the code implementing the run method is what runs as a separate thread. figure . shows the java version of a multithreaded program that determines the summation of a non negative integer. the summation class implements the runnable interface. thread creation is performed by creating an object instance of the thread class and passing the constructor a runnable object. creating a thread object does not specifically create the new thread rather it is the s t a r t method that actually creates the new thread. calling the s t a r t method for the new object does two things . it allocates memory and initializes a new thread in the jvm. . it calls the run method making the thread eligible to be run by the jvm. note that we never call the run method directly. rather we call the s t a r t method and it calls the run method on our behalf. when the summation program runs two threads are created by the jvm. the first is the parent thread which starts execution in the main method. the second thread is created when the s t a r t method on the thread object is invoked. this child thread begins execution in the run method of the summation class. after outputting the value of the summation this thread terminates when it exits from its run method. sharing of data between threads occurs easily in win and pthreads as shared data are simply declared globally. as a pure object oriented language java has no such notion of global data if two or more threads are to share data in a java program the sharing occurs by passing reference to the shared object to the appropriate threads. in the java program shown in figure . the main thread and the summation thread share the the object instance of the sum class. this shared object is referenced through the appropriate getsumo and setsumo methods. you might wonder why we don't use an integer object rather than designing a new sum class. the reason is that the integer class is immutable that is once its value is set it cannot change. recall that the parent threads in the pthreads and win libraries use pthreacljoino and waitforsingleobject respectively to wait for the summation threads to finish before proceeding. the joino method in java provides similar functionality. notice that joino can throw an interruptedexception which we choose to ignore. . thread libraries lass sura private int sum public int getsumo return sum public void setsum ir.t sum this.sum sum class summation implements runnable private int upper private suit. sumvalue public summation int upper sum sumvalue this.upper upper this.sumvalue sumvalue public void run int sum for int i i upper i sum i sumvalue.setsum sum public class driver public static void main string args if args.length if integer.parseint args system.err.println args must be . else create the object to be shared sum sumobject new sum int upper integer.parseint args thread thrd new thread new summation upper sumobject thrd.start try thrd.join system.out.println the sum of upper is sumobject.getsum catch interruptedexception ie else system.err.println usage summation integer value figure . java program for the summation of a non negative integer. chapter threads the jvm and host operating system the jvm is typically implemented on top of a host operating system see pigure . . this setup allows the jvm to bide the implementation details of the underlying operating system and to provide a consistent abstract environment that allows java programs to operate on any platform that supports a jvm. the specification for the jvm does not indicate how java 'threads are to be mapped to the underlying operating system instead leaving that decision to the particular implementation.of the jvm. for example the windows xp operating system uses the one to one model therefore each java thread for a' jvvi running on such a system maps to a kernel thread. on operating systems that use the m.any to many model. such as tru unix a java thread is mapped according to the many to many model. solaris ini tially implemented the jvm using the many to one model the green thre'adslibrary ' mentioned earlier . later releases of the jvm were implemented using the many to many model. beginning with solaris java threads were mapped using the one to one model. in addition there may be a relationship between the java thread library and the thread library on the host operating system. for example implementations of a. jvm for the windows family of operating systems might use the win api when creating java threads linux and solaris systems might use the pthreads apl
 in this section we discuss some of the issues to consider with multithreaded programs. . . the fork and exec system calls in chapter we described how the forkq system call is used to create a separate duplicate process. the semantics of the f ork and exec system calls change in a multithreaded program. if one thread in a program calls f ork does the new process duplicate all threads or is the new process single threaded? some unix systems have chosen to have two versions of forkq one that duplicates all threads and another that duplicates only the thread that invoked the forko system call. the execo system call typically works in the same way as described in chapter . that is if a thread invokes the exec system call the program specified in the parameter to exec will replace the entire process including all threads. which of the two versions of f orko to use depends on the application. if execo is called immediately after forking then duplicating all threads is unnecessary as the program specified in the parameters to exec will replace the process. in this instance duplicating only the calling thread is appropriate. if however the separate process does not call exec after forking the separate process should duplicate all threads. . threading issues . . cancellation ? thread cancellation is the task of terminating a thread before it has completed. for example if multiple threads are concurrently searching through a database and one thread returns the result the remaining threads might be canceled. f another situation might occur when a user presses a button on a web browser i that stops a web page from loading any further. often a web page is loaded using several threads each image is loaded in a separate thread. when a user presses the stop button on the browser all threads loading the page are . canceled. a thread that is to be canceled is often referred to as the target thread. cancellation of a target thread may occur in two different scenarios . asynchronous cancellation. one thread immediately terminates the target thread. . deferred cancellation. the target thread periodically checks whether it should terminate allowing it an opportunity to terminate itself in an orderly fashion. the difficulty with cancellation occurs in situations where resources have been allocated to a canceled thread or where a thread is canceled while in the midst of updating data it is sharing with other threads. this becomes especially troublesome with asynchronous cancellation. often the operating system will reclaim system resources from a canceled thread but will not reclaim all resources. therefore canceling a thread asynchronously may not free a necessary system wide resource. with deferred cancellation in contrast one thread indicates that a target thread is to be canceled but cancellation occurs only after the target thread has checked a flag to determine if it should be canceled or not. this allows a thread to check whether it should be canceled at a point when it can be canceled safely. pthreads refers to such points as cancellation points. . . signal handling a signal is used in unix systems to notify a process that a particular event has occurred. a signal may be received either synchronously or asynchronously 't depending on the source of and the reason for the event being signaled. all i signals whether synchronous or asynchronous follow the same pattern i i. . a signal is generated by the occurrence of a particular event. . a generated signal is delivered to a process. . once delivered the signal must be handled. examples of synchronous signals include illegal memory access and division by . if a running program performs either of these actions a signal is generated. synchronous signals are delivered to the same process that i performed the operation that caused the signal that is the reason they are considered synchronous . chapter threads when a signal is generated by an event external to a running process that process receives the signal asynchronously. examples of such signals iiiclude terminating a process with specific keystrokes such as control c and having a timer expire. typically an asynchronous signal is sent to another process. every signal may be handled by one of two possible handlers . a default signal handler . a user defined signal handler every signal has a default signal handler that is run by the kernel when handling that signal. this default action can be overridden by a user defined signal handler that is called to handle the signal. signals may be handled in different ways. some signals such as changing the size of a window may simply be ignored others such as an illegal memory access may be handled by terminating the program. handling signals in single threaded programs is straightforward signals are always delivered to a process. however delivering signals is more complicated in multithreaded programs where a process may have several threads. where then should a signal be delivered? in general the following options exist . deliver the signal to the thread to which the signal applies. . deliver the signal to every thread in the process. . deliver the signal to certain threads in the process. . assign a specific thread to receive all signals for the process. the method for delivering a signal depends on the type of signal generated. for example synchronous signals need to be delivered to the thread causing the signal and not to other threads in the process. however the situation with asynchronous signals is not as clear. some asynchronous signals such as a signal that terminates a process control c for example should be sent to all threads. most multithreaded versions of unix allow a thread to specify which signals it will accept and which it will block. therefore in some cases an asynchronous signal may be delivered only to those threads that are not blocking it. however because signals need to be handled only once a signal is typically delivered only to the first thread found that is not blocking it. the standard unix function for delivering a signal is k i l l aid t aid int signal here we specify the process aid to which a particular signal is to be delivered. however posix pthreads also provides the p t h r e a d j k i l l p t h r e a d t tid int signal function which allows a signal to be delivered to a specified thread tid. although windows does not explicitly provide support for signals they can be emulated using asynchronous procedure calls apcs . the apc facility allows a user thread to specify a function that is to be called when the user thread receives notification of a particular event. as indicated by its name an apc is roughly equivalent to an asynchronous signal in unix. however . threading issues whereas unix must contend with how to deal with signals in a multithreaded environment the apc facility is more straightforward as an apc is delivered to a particular thread rather than a process. . . thread pools in section . we mentioned multithreading in a web server. in this situation whenever the server receives a request it creates a separate thread to service the request. whereas creating a separate thread is certainly superior to creating a separate process a multithreaded server nonetheless has potential problems. the first concerns the amount of time required to create the thread prior to servicing the request together with the fact that this thread will be discarded once it has completed its work. the second issue is more troublesome if we allow all concurrent requests to be serviced in a new thread we have not placed a bound on the number of threads concurrently active in the system. unlimited threads could exhaust system resources such as cpu time or memory. one solution to this issue is to use a thread pool. the general idea behind a thread pool is to create a number of threads at process startup and place them into a pool where they sit and wait for work. when a server receives a request it awakens a thread from this pool if one is available and passes it the request to service. once the thread completes its service it returns to the pool and awaits more work. if the pool contains no available thread the server waits until one becomes free. thread pools offer these benefits . servicing a request with an existing thread is usually faster than waiting to create a thread. . a thread pool limits the number of threads that exist at any one point. this is particularly important on systems that cannot support a large number of concurrent threads. the number of threads in the pool can be set heuristically based on factors such as the number of cpus in the system the amount of physical memory and the expected number of concurrent client requests. more sophisticated thread pool architectures can dynamically adjust the number of threads in the pool according to usage patterns. such architectures provide the further benefit of having a smaller pool thereby consuming less memory when the load on the system is low. the win api provides several functions related to thread pools. using the thread pool api is similar to creating a thread with the thread create function as described in section . . . here a function that is to run as a separate thread is defined. such a function may appear as follows dword winapi poolfunction avoid param this function runs as a separate thread. a pointer to poolfunctionq is passed to one of the functions in the thread pool api and a thread from the pool executes this function. one such member chapter threads in the thread pool api is the queueuserworkltemo function which is passed three parameters lpthread start routine function a pointer to the function that is to run as a separate thread pvoid param the parameter passed to function ulong flags flags indicating how the thread pool is to create and manage execution of the thread an example of an invocation is queueuserworkltemc poolfunction null this causes a thread from the thread pool to invoke poolfunction on behalf of the programmer. in this instance we pass no parameters to poolfunct i o n . because we specify as a flag we provide the thread pool with no special instructions for thread creation. other members in the win thread pool api include utilities that invoke functions at periodic intervals or when an asynchronous i o request completes. the j a v a . u t i l . concurrent package in java . provides a thread pool utility as well. . . thread specific data threads belonging to a process share the data of the process. indeed this sharing of data provides one of the benefits of multithreaded programming. however in some circumstances each thread might need its own copy of certain data. we will call such data thread specific data. for example in a transaction processing system we might service each transaction in a separate thread. furthermore each transaction may be assigned a unique identifier. to associate each thread with its unique identifier we could use thread specific data. most thread libraries including win and pthreads provide some form of support for thread specific data. java provides support as well. . . scheduler activations a final issue to be considered with multithreaded programs concerns communication between the kernel and the thread library which may be required by the many to many and two level models discussed in section . . . such coordination allows the number of kernel threads to be dynamically adjusted to help ensure the best performance. many systems implementing either the many to many or two level model place an intermediate data structure between the user and kernel threads. this data structure typically known as a lightweight process or lwp is shown in figure . . to the user thread library the lwp appears to be a virtual processor on which the application can schedule a user thread to run. each lwp is attached to a kernel thread and it is kernel threads that the operating system schedules to run on physical processors. if a kernel thread blocks such as while waiting for an i o operation to complete the lwp blocks as well. up the chain the user level thread attached to the lwp also blocks
 user thread uwp lightweight process kernel thread figure . lightweight process lwp. an application may require any number of lwps to run efficiently. consider a cpu bound application running on a single processor. in this scenario only one thread can run at once so one lwp is sufficient. an application that is i ointensive may require multiple lwps to execute however. typically an lwp is required for each concurrent blocking system call. suppose for example that five different file read requests occur simultaneously. five lwps are needed because all could be waiting for i o completion in the kernel. if a process has only four lwps then the fifth request must wait for one of the lwps to return from the kernel. one scheme for communication between the user thread library and the kernel is known as scheduler activation. it works as follows the kernel provides an application with a set of virtual processors lwps and the application can schedule user threads onto an available virtual processor. furthermore the kernel must inform an application about certain events. this procedure is known as an upcall. upcalls are handled by the thread library with an upcall handler and upcall handlers must run on a virtual processor. one event that triggers an upcall occurs when an application thread is about to block. in this scenario the kernel makes an upcall to the application informing it that a thread is about to block and identifying the specific thread. the kernel then allocates a new virtual processor to the application. the application runs an upcall handler on this new virtual processor which saves the state of the blocking thread and relinquishes the virtual processor on which the blocking thread is running. the upcall handler then schedules another thread that is eligible to run on the new virtual processor. when the event that the blocking thread was waiting for occurs the kernel makes another upcall to the thread library informing it that the previously blocked thread is now eligible to run. the upcall handler for this event also requires a virtual processor and the kernel may allocate a new virtual processor or preempt one of the user threads and run the upcall handler on its virtual processor. after marking the unblocked thread as eligible to run the application schedules an eligible thread to run on an available virtual processor. . operating system examples in this section we explore how threads are implemented in windows xp and linux systems. chapter threads . . windows xp threads windows xp implements the win api. the win api is the primary api for the family of microsoft operating systems windows nt and xp . indeed much of what is mentioned in this section applies to this entire family of operating systems. a windows xp application runs as a separate process and each process may contain one or more threads. the win api for creating threads is covered in section . . . windows xp uses the one to one mapping described in section . . where each user level thread maps to an associated kernel thread. however windows xp also provides support for a fiber library which provides the functionality of the many to many model section . . . by using the thread library any thread belonging to a process can access the address space of the process. the general components of a thread include a thread id uniquely identifying the thread a register set representing the status of the processor a user stack employed when the thread is running in user mode and a kernel stack employed when the thread is running in kernel mode a private storage area used by various run time libraries and dynamic link libraries dlls the register set stacks and private storage area are known as the context of the thread. the primary data structures of a thread include ethread executive thread block kthread kernel thread block teb thread environment block the key components of the ethread include a pointer to the process to which the thread belongs and the address of the routine in which the thread starts control. the ethread also contains a pointer to the corresponding kthread. the kthread includes scheduling and synchronization information for the thread. in addition the kthread includes the kernel stack used when the thread is running in kernel mode and a pointer to the teb. the ethread and the kthread exist entirely in kernel space this means that only the kernel can access them. the teb is a user space data structure that is accessed when the thread is running in user mode. among other fields the teb contains the thread identifier a user mode stack and an array for threadspecific data which windows xp terms thread local storage . the structure of a windows xp thread is illustrated in figure . . . . linux threads linux provides the f ork system call with the traditional functionality of duplicating a process as described in chapter . linux also provides the ability . operating system examples ethread i tteeacfi sfer i . kthread . . sclngdiujing . m syrjekronizatitin! ! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ' . .. . ... . ... i ' . . .. .' .. . .. . ... .teb thread identifier . . . .. i. !.. .. . . . .. !. ... !. .. . .. i.?r.. .. . . .. . !.. .. . . user slack . thread local storage . . . ... kernel s pace user space figure . data structures of a windows xp thread. to create threads using the clone system call. however linux does not distinguish between processes and threads. in fact linux generally uses the term task rather than process or thread when referring to a flow of control within a program. when clone is invoked it is passed a set of flags which determine how much sharing is to take place between the parent and child tasks. some of these flags are listed below flag meaning clone fs file system information is shared. cl ne vm the same memory space is shared. clone sighand signal handlers are shared. clone files the set of open fifes is shared. for example if clone is passed the flags cl ne fs clonejm clone sighand and clone files the parent and child tasks will share the same file system information such as the current working directory the same memory space the same signal handlers and the same set of open files. using clone in this fashion is equivalent to creating a thread as described in this chapter since the parent task shares most of its resources with its child task. however if none of these flags are set when clone is invoked no chapter threads sharing takes place resulting in functionality similar to that provided by the forko system call. the varying level of sharing is possible because of the way a task is represented in the linux kernel. a unique kernel data structure specifically struct task.struct exists for each task in the system. this data structure instead of storing data for the task contains pointers to other data structures where these data are stored for example data structures that represent the list of open files signal handling information and virtual memory. when f ork is invoked a new task is created along with a copy of all the associated data structures of the parent process. a new task is also created when the clone system call is made. however rather than copying all data structures the new task points to the data structures of the parent task depending on the set of flags passed to clone 
 in a single processor system only one process can run at a time any others must wait until the cpu is free and can be rescheduled. the objective of multiprogramming is to have some process running at all times to maximize cpu utilization. the idea is relatively simple. a process is executed until it must wait typically for the completion of some i o request. in a simple computer system the cpu then just sits idle. all this waiting time is wasted no useful work is accomplished. with multiprogramming we try to use this time productively. several processes are kept in memory at one time. when one process has to wait the operating system takes the cpu away from that chapter cpu scheduling process and gives the cpu to another process. this pattern continues. every time one process has to wait another process can take over use of the cpu. scheduling of this kind is a fundamental operating system function. almost all computer resources are scheduled before use. the cpu is of course one of the primary computer resources. thus its scheduling is central to operating system design. . . cpu i o burst cycle the success of cpu scheduling depends on an observed property of processes process execution consists of a cycle of cpu execution and i o wait. processes alternate between these two states. process execution begins with a cpu burst. that is followed by an i o burst which is followed by another cpu burst then another i o burst and so on. eventually the final cpu burst ends with a system request to terminate execution figure . . the durations of cpu bursts have been measured extensively. although they vary greatly from process to process and from computer to computer they tend to have a frequency curve similar to that shown in figure . . the curve is generally characterized as exponential or hyperexponential with a large number of short cpu bursts and a small number of long cpu bursts. an i o bound program typically has many short cpu bursts. a cpu bound load store add store cpu burst read from file wait for i o i o burst store increment index cpu burst write to file wait for i o i o burst load store add store cpu burst read from file wait for i o i o burst figure . alternating sequence of cpu and i o bursts. . basic concepts burst duration milliseconds figure . histogram of cpu burst durations. program might have a few long cpu bursts. this distribution can be important in the selection of an appropriate cpu scheduling algorithm. . . cpu scheduler whenever the cpu becomes idle the operating system must select one of the processes in the ready queue to be executed. the selection process is carried out by the short term scheduler or cpu scheduler . the scheduler selects a process from the processes in memory that are ready to execute and allocates the cpu to that process. note that the ready queue is not necessarily a first in first out fifo queue. as we shall see when we consider the various scheduling algorithms a ready queue can be implemented as a fifo queue a priority queue a tree or simply an unordered linked list. conceptually however all the processes in the ready queue are lined up waiting for a chance to run on the cpu. the records in the queues are generally process control blocks pcbs of the processes. . . preemptive scheduling cpu scheduling decisions may take place under the following four circumstances . when a process switches from the running state to the waiting state for example as the result of an i o request or an invocation of wait for the termination of one of the child processes chapter cpu scheduling . when a process switches from the running state to the ready state ioi example when an interrupt occurs . when a process switches from the waiting state to the ready state for example at completion of i o . when a process terminates for situations and there is no choice in terms of scheduling. a new process if one exists in the ready queue must be selected for execution. there is a choice however for situations and . when scheduling takes place only under circumstances and we say that the scheduling scheme is nonpreemptive or cooperative otherwise it is preemptive. under nonpreemptive scheduling once the cpu has been allocated to a process the process keeps the cpu until it releases the cpu either by terminating or by switching to the waiting state. this scheduling method was vised by microsoft windows .x windows introduced preemptive scheduling and all subsequent versions of windows operating systems have used preemptive scheduling. the mac os x operating system for the macintosh uses preemptive scheduling previous versions of the macintosh operating system relied on cooperative scheduling. cooperative scheduling is the only method that can be used on certain hardware platforms because it does not require the special hardware for example a timer needed for preemptive scheduling. unfortunately preemptive scheduling incurs a cost associated with access to shared data. consider the case of two processes that share data. while one is updating the data it is preempted so that the second process can run. the second process then tries to read the data which are in an inconsistent state. in such situations we need new mechanisms to coordinate access to shared data we discuss this topic in chapter . preemption also affects the design of the operating system kernel. during the processing of a system call the kernel may be busy with an activity on behalf of a process. such activities may involve changing important kernel data for instance i o queues . what happens if the process is preempted in the middle of these changes and the kernel or the device driver needs to read or modify the same structure? chaos ensues. certain operating systems including most versions of unix deal with this problem by waiting either for a system call to complete or for an i o block to take place before doing a context switch. this scheme ensures that the kernel structure is simple since the kernel will not preempt a process while the kernel data structures are in an inconsistent state. unfortunately this kernel execution model is a poor one for supporting real time computing and multiprocessing. these problems and their solutions are described in sections . and . . because interrupts can by definition occur at any time and because they cannot always be ignored by the kernel the sections of code affected by interrupts must be guarded from simultaneous use. the operating system needs to accept interrupts at almost all times otherwise input might be lost or output overwritten. so that these sections of code are not accessed concurrently by several processes they disable interrupts at entry and reenable interrupts at exit. it is important to note that sections of code that disable interrupts do not occur very often and typically contain few instructions
 . . dispatcher f another component involved in the cpu scheduling function is the dispatcher. hie dispatcher is the module that gives control of the cpu to the process selected by the short term scheduler. this function involves the following switching context switching to user mode jumping to the proper location in the user program to restart that program the dispatcher should be as fast as possible since it is invoked during every process switch. the time it takes for the dispatcher to stop one process and start another running is known as the dispatch latency. . scheduling criteria different cpu scheduling algorithms have different properties and the choice of a particular algorithm may favor one class of processes over another. in choosing which algorithm to use in a particular situation we must consider the properties of the various algorithms. many criteria have been suggested for comparing cpu scheduling algorithms. which characteristics are used for comparison can make a substantial difference in which algorithm is judged to be best. the criteria include the following cpu utilization. we want to keep the cpu as busy as possible. conceptually cpu utilization can range from to percent. in a real system it should range from percent for a lightly loaded system to percent for a heavily used system . throughput. if the cpu is busy executing processes then work is being done. one measure of work is the number of processes that are completed per time unit called throughput. for long processes this rate may be one process per hour for short transactions it may be processes per second. turnaround time. from the point of view of a particular process the important criterion is how long it takes to execute that process. the interval from the time of submission of a process to the time of completion is the turnaround time. turnaround time is the sum of the periods spent waiting to get into memory waiting in the ready queue executing on the cpu and doing i o. waiting time. the cpu scheduling algorithm does not affect the amount of time during which a process executes or does i o it affects only the amount of time that a process spends waiting in the ready queue. waiting time is the sum of the periods spent waiting in the ready queue. response time. in an interactive system turnaround time may not be the best criterion. often a process can produce some output fairly early and can continue computing new results while previous results are being chapter cpu scheduling output to the user. thus another measure is the time from the submission of a request until the first response is produced. this measure called response time is the time it takes to start responding not the time it takes to output the response. the turnaround time is generally limited by the speed of the output device. it is desirable to maximize cpu utilization and throughput and to minimize turnaround time waiting time and response time. in most cases we optimize the average measure. however under some circumstances it is desirable to optimize the minimum or maximum values rather than the average. for example to guarantee that all users get good service we may want to minimize the maximum response time. investigators have suggested that for interactive systems such as timesharing systems it is more important to minimize the variance in the response time than to minimize the average response time. a system with reasonable and predictable response time may be considered more desirable than a system that is faster on the average but is highly variable. however little work has been done on cpu scheduling algorithms that minimize variance. as we discuss various cpu scheduling algorithms in the following section we will illustrate their operation. an accurate illustration should involve many processes each being a sequence of several hundred cpu bursts and i o bursts. for simplicity though we consider only one cpu burst in milliseconds per process in our examples. our measure of comparison is the average waiting time. more elaborate evaluation mechanisms are discussed in section
 cpu scheduling deals with the problem of deciding which of the processes in the ready queue is to be allocated the cpu. there are many different cpu scheduling algorithms. in this section we describe several of them. . . first come first served scheduling by far the simplest cpu scheduling algorithm is the first come first served fcfs scheduling algorithm. with this scheme the process that requests the cpu first is allocated the cpu first. the implementation of the fcfs policy is easily managed with a fifo queue. when a process enters the ready queue its pcb is linked onto the tail of the queue. when the cpu is free it is allocated to the process at the head of the queue. the running process is then removed from the queue. the code for fcfs scheduling is simple to write and understand. the average waiting time under the fcfs policy however is often quite long. consider the following set of processes that arrive at time with the length of the cpu burst given in milliseconds process burst time p pi p . scheduling algorithms if the processes arrive in the order pi po p and are served in fcfs rder we get the result shown in the following gantt chart p the waiting time is milliseconds for process pi milliseconds for process pn and milliseconds for process pj. thus the average waiting time is milliseconds. if the processes arrive in the order pi p pi however the results will be as showrn in the following gantt chart the average waiting time is now milliseconds. this reduction is substantial. thus the average waiting time under an fcfs policy is generally not minimal and may vary substantially if the process's cpu burst times vary greatly. in addition consider the performance of fcfs scheduling in a dynamic situation. assume we have one cpu bound process and many i o bound processes. as the processes flow around the system the following scenario may result. the cpu bound process will get and hold the cpu. during this time all the other processes will finish their i o and will move into the ready queue waiting for the cpu. while the processes wait in the ready queue the i o devices are idle. eventually the cpu bound process finishes its cpu burst and moves to an i o device. all the i o bound processes which have short cpu bursts execute quickly and move back to the i o queues. at this point the cpu sits idle. the cpu bound process will then move back to the ready queue and be allocated the cpu. again all the i o processes end up waiting in the ready queue until the cpu bound process is done. there is a convoy effect as all the other processes wait for the one big process to get off the cpu. this effect results in lower cpu and device utilization than might be possible if the shorter processes were allowed to go first. the fcfs scheduling algorithm is nonpreemptive. once the cpu has been allocated to a process that process keeps the cpu until it releases the cpu either by terminating or by requesting i o. the fcfs algorithm is thus particularly troublesome for time sharing systems where it is important that each user get a share of the cpu at regular intervals. it would be disastrous to allow one process to keep the cpu for an extended period. . . shortest job first scheduling a different approach to cpu scheduling is the shortest job first sjf scheduling algorithm. this algorithm associates with each process the length of the process's next cpu burst. when the cpu is available it is assigned to the process that has the smallest next cpu burst. if the next cpu bursts of two processes are chapter cpu scheduling the same fcfs scheduling is used to break the tie. note that a more appropriate term for this scheduling method would be the shortest next cpu burst algorithm because scheduling depends on the length of the next cpu burst of a process rather than its total length. we use the term sjf because most people and textbooks use this term to refer to this type of scheduling. as an example of sjf scheduling consider the following set of processes with the length of the cpu burst given in milliseconds process burst time pi pi p pa using sjf scheduling we would schedule these processes according to the following gantt chart pa pi p p the waiting time is milliseconds for process p milliseconds for process pi milliseconds for process p and milliseconds for process p . thus the average waiting time is milliseconds. by comparison if we were using the fcfs scheduling scheme the average waiting time would be . milliseconds. the sjf scheduling algorithm is provably optimal in that it gives the minimum average waiting time for a given set of processes. moving a short process before a long one decreases the waiting time of the short process more than it increases the waiting time of the long process. consequently the average waiting time decreases. the real difficulty with the sjf algorithm is knowing the length of the next cpu request. for long term job schedtiling in a batch system we can use as the length the process time limit that a user specifies when he submits the job. thus users are motivated to estimate the process time limit accurately since a lower value may mean faster response. too low a value will cause a time limit exceeded error and require resubmission. sjf scheduling is used frequently in long term scheduling. although the sjf algorithm is optimal it cannot be implemented at the level of short term cpu scheduling. there is no way to know the length of the next cpu burst. one approach is to try to approximate sjf scheduling. we may not know the length of the next cpu burst but we may be able to predict its value. we expect that the next cpu burst will be similar in length to the previous ones. thus by computing an approximation of the length of the next cpu burst we can pick the process with the shortest predicted cpu burst. the next cpu burst is generally predicted as an exponential average of the measured lengths of previous cpu bursts. let tn be the length of the th cpu . scheduling algorithms burst and let t i be our predicted value for the next cpu burst. then for a a define t atn l a in. this formula defines an exponential average. the value of tn contains our most recent information in stores the past history. the parameter a controls the relative weight of recent and past history in our prediction. if a then t i t and recent history has no effect current conditions are assumed to be transient if a then t ! i tn and only the most recent cpu burst matters history is assumed to be old and irrelevant . more commonly a so recent history and past history are equally weighted. the initial t can be defined as a constant or as an overall system average. figure . shows an exponential average with a and to . to understand the behavior of the exponential average we can expand the formula for t i by substituting for th to find at a atn i h since both a and a are less than or equal to each successive term has less weight than its predecessor. the sjf algorithm can be either preemptive or nonpreemptive. the choice arises when a new process arrives at the ready queue while a previous process is still executing. the next cpu burst of the newly arrived process may be shorter than what is left of the currently executing process. a preemptive sjf algorithm x ti i i i i i i time cpu burst f guess i figure . prediction of the length of the next cpu burst. chapter cpu scheduling will preempt the currently executing process whereas a nonpreemptite sjf algorithm will allow the currently running process to finish its cpu burst. preemptive sjf scheduling is sometimes called shortest remaining time first scheduling. as an example consider the following four processes with the length of the cpu burst given in milliseconds ocess arrival time burst time pi pi p p if the processes arrive at the ready queue at the times shown and need the indicated burst times then the resulting preemptive sjf schedule is as depicted in the following gantt chart pi p p pi p process pi is started at time since it is the only process in the queue. process p arrives at time . the remaining time for process pi milliseconds is larger than the time required by process p milliseconds so process pi is preempted and process p is scheduled. the average waiting time for this example is . milliseconds. nonpreemptive sjf scheduling would result in an average waiting time of . milliseconds. . . priority scheduling the sjf algorithm is a special case of the general priority scheduling algorithm. a priority is associated with each process and the cpu is allocated to the process with the highest priority. equal priority processes are scheduled in fcfs order. an sjf algorithm is simply a priority algorithm where the priority p is the inverse of the predicted next cpu burst. the larger the cpu burst the lower the priority and vice versa. note that we discuss scheduling in terms of high priority and low priority. priorities are generally indicated by some fixed range of numbers such as to or to . however there is no general agreement on whether is the highest or lowest priority. some systems use low numbers to represent low priority others use low numbers for high priority. this difference can lead to confusion. in this text we assume that low numbers represent high priority. as an example consider the following set of processes assumed to have arrived at time in the order pi p p with the length of the cpu burst given in milliseconds . scheduling algorithms process burst time priority pi pi p pa ps using priority scheduling we would schedule these processes according to the following gantt chart p p pi p p the average waiting time is . milliseconds. priorities can be defined either internally or externally. internally defined priorities use some measurable quantity or quantities to compute the priority of a process. for example time limits memory requirements the number of open files and the ratio of average i o burst to average cpu burst have been used in computing priorities. external priorities are set by criteria outside the operating system such as the importance of the process the type and amount of funds being paid for computer use the department sponsoring the work and other often political factors. priority scheduling can be either preemptive or nonpreemptive. when a process arrives at the ready queue its priority is compared with the priority of the currently running process. a preemptive priority scheduling algorithm will preempt the cpu if the priority of the newly arrived process is higher than the priority of the currently running process. a nonpreemptive priority scheduling algorithm will simply put the new process at the head of the ready queue. a major problem with priority scheduling algorithms is indefinite blocking or starvation. a process that is ready to run but waiting for the cpu can be considered blocked. a priority scheduling algorithm can leave some lowpriority processes waiting indefinitely. in a heavily loaded computer system a steady stream of higher priority processes can prevent a low priority process from ever getting the cpu. generally one of two things will happen. either the process will eventually be run at a.m. sunday when the system is finally lightly loaded or the computer system will eventually crash and lose all unfinished low priority processes. rumor has it that when they shut down the ibm at mit in they found a low priority process that had been submitted in and had not yet been run. a solution to the problem of indefinite blockage of low priority processes is aging. aging is a technique of gradually increasing the priority of processes that wait in the system for a long time. for example if priorities range from low to high we could increase the priority of a waiting process by every minutes. eventually even a process with an initial priority of would have the highest priority in the system and would be executed. in fact chapter cpu scheduling it would take no more than hours for a priority process to age to a priority process. . . round robin scheduling the round robin rr scheduling algorithm is designed especially for timesharing systems. it is similar to fcfs scheduling but preemption is added to switch between processes. a small unit of time called a time quantum or time slice is defined. a time quantum is generally from to milliseconds. the ready queue is treated as a circular queue. the cpu scheduler goes around the ready queue allocating the cpu to each process for a time interval of up to time quantum. to implement rr scheduling we keep the ready queue as a fifo queue of processes. new processes are added to the tail of the ready queue. the cpu scheduler picks the first process from the ready queue sets a timer to interrupt after time quantum and dispatches the process. one of two things will then happen. the process may have a cpu burst of less than time quantum. in this case the process itself will release the cpu voluntarily. the scheduler will then proceed to the next process in the ready queue. otherwise if the cpu burst of the currently running process is longer than time quantum the timer will go off and will cause an interrupt to the operating system. a context switch will be executed and the process will be put at the tail of the ready queue. the cpu scheduler will then select the next process in the ready queue. the average waiting time under the rr policy is often long. consider the following set of processes that arrive at time with the length of the cpu burst given in milliseconds process burst time pi pi if we use a time quantum of milliseconds then process pi gets the first milliseconds. since it requires another milliseconds it is preempted after the first time quantum and the cpu is given to the next process in the queue process p . since process pi does not need milliseconds it quits before its time quantum expires. the cpu is then given to the next process process p . once each process has received time quantum the cpu is returned to process pi for an additional time quantum. the resulting rr schedule is pi p p pi pi pi pi pi the average waiting time is . milliseconds. in the rr scheduling algorithm no process is allocated the cpu for more than time quantum in a row unless it is the only runnable process . if a . scheduling algorithms process's cpu burst exceeds time quantum that process is preempted and is put back in the ready queue. the rr scheduling algorithm is thus preemptive. if there are n processes in the ready queue and the time quantum is q then each process gets n of the cpu time in chunks of at most q time units. each process must wait no longer than n x q time units until its next time quantum. for example with five processes and a time quantum of milliseconds each process will get up to milliseconds every milliseconds. the performance of the rr algorithm depends heavily on the size of the time quantum. at one extreme if the time quantum is extremely large the rr policy is the same as the fcfs policy if the time quantum is extremely small say millisecond the rr approach is called processor sharing and in theory creates the appearance that each of n processes has its own processor running at n the speed of the real processor. this approach was used in control data corporation cdc hardware to implement ten peripheral processors with only one set of hardware and ten sets of registers. the hardware executes one instruction for one set of registers then goes on to the next. this cycle continues resulting in ten slow processors rather than one fast one. actually since the processor was much faster than memory and each instruction referenced memory the processors were not much slower than ten real processors would have been. in software we need also to consider the effect of context switching on the performance of rr scheduling. let us assume that we have only one process of time units. if the quantum is time units the process finishes in less than time quantum with no overhead. if the quantum is time units however the process requires quanta resulting in a context switch. if the time quantum is time unit then nine context switches will occur slowing the execution of the process accordingly figure . . thus we want the time quantum to be large with respect to the contextswitch time. if the context switch time is approximately percent of the time quantum then about percent of the cpu time will be spent in context switching. in practice most modern systems have time quanta ranging from to milliseconds. the time required for a context switch is typically less than microseconds thus the context switch time is a small fraction of the time quantum. process time quantum context switches o figure . the way in which a smaller time quantum increases context switches. chapter cpu scheduling j .p. . time quantum figure . the way in which turnaround time varies with the time quantum. turnaround time also depends on the size of the time quantum. as we can see from figure . the average turnaround time of a set of processes does not necessarily improve as the time quantum size increases. in general the average turnaround time can be improved if most processes finish their next cpu burst in a single time quantum. for example given three processes of time units each and a quantum of time unit the average turnaround time is . if the time quantum is however the average turnaround time drops to . if context switch time is added in the average turnaround time increases for a smaller time quantum since more context switches are required. although the time quantum should be large compared with the contextswitch time it should not be too large. if the time quantum is too large rr scheduling degenerates to fcfs policy. a rule of thumb is that percent of the cpu bursts should be shorter than the time quantum. . . multilevel queue scheduling another class of scheduling algorithms has been created for situations in which processes are easily classified into different groups. for example a common division is made between foreground interactive processes and background batch processes. these two types of processes have different response time requirements and so may have different scheduling needs. in addition foreground processes may have priority externally defined over background processes. a multilevel queue scheduling algorithm partitions the ready queue into several separate queues figure . . the processes are permanently assigned to one queue generally based on some property of the process such as memory size process priority or process type. each queue has its own scheduling . scheduling algorithms highest priority system processes . ' rio'i . j i . r ? student processes lowest priority figure . multilevel queue scheduling. algorithm. for example separate queues might be used for foreground and background processes. the foreground quetie might be scheduled by an rr algorithm while the background queue is scheduled by an fcfs algorithm. in addition there must be scheduling among the queues which is commonly implemented as fixed priority preemptive scheduling. for example the foreground queue may have absolute priority over the background queue. let's look at an example of a multilevel queue scheduling algorithm with five queues listed below in order of priority . system processes . interactive processes . interactive editing processes . batch processes . student processes each queue has absolute priority over lower priority queues. no process in the batch queue for example could run unless the queues for system processes interactive processes and interactive editing processes were all empty. if an interactive editing process entered the ready queue while a batch process was running the batch process would be preempted. another possibility is to time slice among the queues. here each queue gets a certain portion of the cpu time which it can then schedule among its various processes. for instance in the foreground background queue example the foreground queue can be given percent of the cpu time for rr scheduling among its processes whereas the background queue receives percent of the cpu to give to its processes on an fcfs basis. chapter cpu scheduling . . multilevel feedback queue scheduling normally when the multilevel queue scheduling algorithm is used processes are permanently assigned to a queue when they enter the system. if there are separate queues for foreground and background processes for example processes do not move from one queue to the other since processes do not change their foreground or background nature. this setup has the advantage of low scheduling overhead but it is inflexible. the multilevel feedback queue scheduling algorithm in contrast allows a process to move between queues. the idea is to separate processes according to the characteristics of their cpu bursts. if a process uses too much cpu time it will be moved to a lower priority queue. this scheme leaves i o bound and interactive processes in the higher priority queues. in addition a process that waits too long in a lower priority queue may be moved to a higher priority queue. this form of aging prevents starvation. for example consider a multilevel feedback queue scheduler with three queues numbered from to figure . . the scheduler first executes all processes in queue . only when queue is empty will it execute processes in queue . similarly processes in queue will only be executed if queues and are empty. a process that arrives for queue will preempt a process in queue . a process in queue will in turn be preempted by a process arriving for queue . a process entering the ready queue is put in queue . a process in queue is given a time quantum of milliseconds. if it does not finish within this time it is moved to the tail of queue . if queue is empty the process at the head of queue is given a quantum of milliseconds. if it does not complete it is preempted and is put into queue . processes in queue are run on an fcfs basis but are run only when queues and are empty. this scheduling algorithm gives highest priority to any process with a cpu burst of milliseconds or less. such a process will quickly get the cpu finish its cpu burst and go off to its next i o burst. processes that need more than but less than milliseconds are also served quickly although with lower priority than shorter processes. long processes automatically sink to queue and are served in fcfs order with any cpu cycles left over from queues and . figure . multilevel feedback queues
 in general a multilevel feedback queue scheduler is defined by the following parameters the number of queues the scheduling algorithm for each queue the method used to determine when to upgrade a process to a higherpriority queue the method used to determine when to demote a process to a lowerpriority queue the method used to determine which queue a process will enter when that process needs service the definition of a multilevel feedback queue scheduler makes it the most general cpu scheduling algorithm. it can be configured to match a specific system under design. unfortunately it is also the most complex algorithm since defining the best scheduler requires some means by which to select values for all the parameters. . multiple processor scheduling our discussion thus far has focused on the problems of scheduling the cpu in a system with a single processor. if multiple cpus are available load sharing becomes possible however the scheduling problem becomes correspondingly more complex. many possibilities have been tried and as we saw with singleprocessor cpu scheduling there is no one best solution. here we discuss several concerns in multiprocessor scheduling. we concentrate on systems in which the processors are identical homogeneous in terms of their functionality we can then use any available processor to run any process in the queue. note however that even with homogeneous multiprocessors there are sometimes limitations on scheduling. consider a system with an i o device attached to a private bus of one processor. processes that wish to use that device must be scheduled to run on that processor. . . approaches to multiple processor scheduling one approach to cpu scheduling in a multiprocessor system has all scheduling decisions i o processing and other system activities handled by a single processor the master server. the other processors execute only user code. this asymmetric multiprocessing is simple because only one processor accesses the system data structures reducing the need for data sharing. a second approach uses symmetric multiprocessing smp where each processor is self scheduling. all processes may be in a common ready queue or each processor may have its own private queue of ready processes. regardless scheduling proceeds by having the scheduler for each processor examine the ready queue and select a process to execute. as we shall see in chapter if we have multiple processors trying to access and update a common data structure the scheduler must be programmed carefully we must ensure that chapter cpu scheduling two processors do not choose the same process and that processes are n t lost from the queue. virtually all modern operating systems support smp including windows xp windows solaris linux and mac os x. in the remainder of this section we will discuss issues concerning smp systems. . . processor affinity consider what happens to cache memory when a process has been running on a specific processor the data most recently accessed by the process populates the cache for the processor and as a result successive memory accesses by the process are often satisfied in cache memory. now consider what happens if the process migrates to another processor the contents of cache memory must be invalidated for the processor being migrated from and the cache for the processor being migrated to must be re populated. because of the high cost of invalidating and re populating caches most smp systems try to avoid migration of processes from one processor to another and instead attempt to keep a process running on the same processor. this is known as processor affinity meaning that a process has an affinity for the processor on which it is currently running. processor affinity takes several forms. when an operating system has a policy of attempting to keep a process running on the same processor but not guaranteeing that it will do so we have a situation known as soft affinity. here it is possible for a process to migrate between processors. some systems such as linux also provide system calls that support hard affinity thereby allowing a process to specify that it is not to migrate to other processors. . . load balancing on smp systems it is important to keep the workload balanced among all processors to fully utilize the benefits of having more than one processor. otherwise one or more processors may sit idle while other processors have high workloads along with lists of processes awaiting the cpu. load balancing attempts to keep the workload evenly distributed across all processors in an smp system. it is important to note that load balancing is typically only necessary on systems where each processor has its own private queue of eligible processes to execute. on systems with a common run queue load balancing is often unnecessary because once a processor becomes idle it immediately extracts a runnable process from the common run queue. it is also important to note however that in most contemporary operating systems supporting smp each processor does have a private queue of eligible processes. there are two general approaches to load balancing push migration and pull migration. with push migration a specific task periodically checks the load on each processor and if it finds an imbalance evenly distributes the load by moving or pushing processes from overloaded to idle or less busy processors. pull migration occurs when an idle processor pulls a waiting task from a busy processor. push and pull migration need not be mutually exclusive and are in fact often implemented in parallel on load balancing systems. for example the linux scheduler described in section . . and the ule scheduler available for freebsd systems implement both techniques. linux runs its load . multiple processor scheduling balancing algorithm every milliseconds push migration or whenever the run queue for a processor is empty pull migration . interestingly load balancing often counteracts the benefits of processor affinity discussed in section . . . that is the benefit of keeping a process running on the same processor is that the process can take advantage of its data being in that processor's cache memory. by either pulling or pushing a process from one processor to another we invalidate this benefit. as is often the case in systems engineering there is no absolute rule concerning what policy is best. thus in some systems an idle processor always pulls a process from a non idle processor and in other systems processes are moved only if the imbalance exceeds a certain threshold. . . symmetric multithreading smp systems allow several threads to run concurrently by providing multiple physical processors. an alternative strategy is to provide multiple logical rather than physical processors. such a strategy is known as symmetric multithreading or smt it has also been termed hyperthreading technology on intel processors. the idea behind smt is to create multiple logical processors on the same physical processor presenting a view of several logical processors to the operating system even on a system with only a single physical processor. each logical processor has its own architecture state which includes general purpose and machine state registers. furthermore each logical processor is responsible for its own interrupt handling meaning that interrupts are delivered to and handled by logical processors rather than physical ones. otherwise each logical processor shares the resources of its physical processor such as cache memory and buses. figure . illustrates a typical smt architecture with two physical processors each housing two logical processors. from the operating system's perspective four processors are available for work on this system. it is important to recognize that smt is a feature provided in hardware not software. that is hardware must provide the representation of the architecture state for each logical processor as well as interrupt handling. operating systems need not necessarily be designed differently if they are to run on an smt system however certain performance gains are possible if the operating system is aware that it is running on such a system. for example consider a system with two physical processors both of which are idle. the scheduler should first try scheduling separate threads on each physical processor rather logical logical logicali logical cpu cpu cpu physical m i gpu . cf system bus figure . a typical smt architecture chapter cpu scheduling than on separate logical processors on the same physical processor. otherwise both logical processors on one physical processor could be busy while the other physical processor remained idle
 in chapter we introduced threads to the process model distinguishing between user level and kernel level threads. on operating systems that support them it is kernel level threads not processes that are being scheduled by the operating system. user level threads are managed by a thread library and the kernel is unaware of them. to run on a cpu user level threads must ultimately be mapped to an associated kernel level thread although this mapping may be indirect and may use a lightweight process lwp . in this section we explore scheduling issues involving user level and kernel level threads and offer specific examples of scheduling for pthreads. . . contention scope one distinction between user level and kernel level threads lies in how they are scheduled. on systems implementing the many to one section . . and many to many section . . models the thread library schedules user level threads to run on an available lwp a scheme known as process contention scope pcs since competition for the cpu takes place among threads belonging to the same process. when we say the thread library schedules user threads onto available lwps we do not mean that the thread is actually running on a cpu this would require the operating system to schedule the kernel thread onto a physical cpu. to decide which kernel thread to schedule onto a cpu the kernel uses system contention scope scs . competition for the cpu with scs scheduling takes place among all threads in the system. systems using the one to one model such as windows xp solaris and linux schedule threads using only scs. typically pcs is done according to priority the scheduler selects the runnable thread with the highest priority to run. user level thread priorities are set by the programmer and are not adjusted by the thread library although some thread libraries may allow the programmer to change the priority of a thread. it is important to note that pcs will typically preempt the thread currently running in favor of a higher priority thread however there is no guarantee of time slicing section . . among threads of equal priority. . . pthread scheduling we provided a sample posix pthread program in section . . along with an introduction to thread creation with pthreads. now we highlight the posix pthread api that allows specifying either pcs or scs during thread creation. pthreads identifies the following contention scope values pthread scopejprocess schedules threads using pcs scheduling. pthread scope system schedules threads using scs scheduling
 on systems implementing the many to many model section . . the pthread scope process policy schedules user level threads onto available lvvps. the number of lwfs is maintained by the thread library perhaps using scheduler activations section . . . the pthread scope system scheduling policy will create and bind an lwp for each user level thread on many to many systems effectively mapping threads using the one to one policy section '. . . the pthread ipc provides the following two functions for getting and setting the contention scope policy pthread attr setscope pthread attr t attr int scope pthread attr getscope pthread attr t attr int scope the first parameter for both functions contains a pointer to the attri ite set for the thread. the second parameter for the pthread attr setscope function is passed either the pthread.scope..system or pthread cope process value indicating how the contention scope is to be set. in the case of pthread attr getscope this second parameter contains a pointer to an i n t value that is set to the current value of the contention scope. if an error occurs each of these functions returns non zero values. in figure . we illustrate a pthread program that first determines the existing contention scope and sets it to pthread.scope.process. it then creates five separate threads that will run using the scs scheduling policy. note that on some systems only certain contention scope values are allowed. for example linux and mac os x systems allow only pthread scope system. . operating system examples we turn next to a description of the scheduling policies of the solaris windows xp and linux operating systems. it is important to remember that we are describing the scheduling of kernel threads with solaris and linux. recall that linux does not distinguish between processes and threads thus we use the term task when discussing the linux scheduler. . . example solaris scheduling solaris uses priority based thread scheduling. it has defined four classes of scheduling which are in order of priority . real time . system . time sharing . interactive within each class there are different priorities and different scheduling algorithms. solaris scheduling is illustrated in figure . . chapter cpu scheduling include pthread.h ? tinclude stdio.h define num.threads int main int argc char argv int i scope pthread t tid numjthreads pthread attr t attr get the default attributes pthread attr init attr first inquire on the current scope if pthread attr getscope fcattr kscope ! fprintf stderr unable to get scheduling scope n else if scope pthread.scope.process printf pthread scope process else if scope pthread.scope.system printf pthread scope system else fprintf stderr illegal scope value. n set the scheduling algorithm to pcs or scs pthread attr setscope attr pthread scope.system create the threads for i i num threads i pthread create tid i attr runner null now join on each thread for i i numjthreads i pthread join tid i null each thread will begin control in this function void runner void param do some work ... dthread exit fo figure . pthread scheduling api. . operating system examples classglobal scheduling specific scheduler run priority order priorities classes queue highest first real time kernel threads of real time lwps system kernel q service threads o interactive kernel time sharing q threads of interactive time sharing lwps o lowest last figure . solaris scheduling. the default scheduling class for a process is time sharing. the scheduling policy for time sharing dynamically alters priorities and assigns time slices of different lengths using a multilevel feedback queue. by default there is an inverse relationship between priorities and time slices the higher the priority the smaller the time slice and the lower the priority the larger the time slice. interactive processes typically have a higher priority cpu bound processes a lower priority. this scheduling policy gives good response time for interactive processes and good throughput for cpu bound processes. the interactive class uses the same scheduling policy as the time sharing class but it gives windowing applications a higher priority for better performance. figure . shows the dispatch table for scheduling interactive and timesharing threads. these two scheduling classes include priority levels but for brevity we display only a handful. the dispatch table shown in figure . contains the following fields priority. the class dependent priority for the time sharing and interactive classes. a higher number indicates a higher priority. time quantum. the time quantum for the associated priority. this illustrates the inverse relationship between priorities and time quanta chapter cpu scheduling . . v i . . w i . iiilkllmil ill i te. i!k . ..... . . . .. .. f i j . . . .. ? . . . .. r. r. .. . r. vt . .. . . .. .. .. . . .. igii . . . .!. . . . ii . .. . . .. . . . . .. i! . .. . . .. .. . o. . o. .o ... .. f. . . . . .. .. .. .. . ...... ... . . . ...... ...... isiisi ! ijiilil. .t ifei ii iii i llliii.ii l illfil'lil li i.imi t!i iisiiri . . f m i. im!i i if m il !. ii! iw l iij m i liiiiirii ! ii i if i l l ii lllpli l i. hi !i ii! m ih ! liillli.l !! n h s i k . l i ! l l i ! v j . q i i ! in lo i .! i iiitm ii ... .l . . v . .. jj . f . . k. . i. . r. .. .... .m ..i ' ' '!' ' ' !' olq ' ' ' ' ' ' !' . i . . i. rtiri . i figure . solaris dispatch table for interactive and time sharing threads. the lowest priority priority has the highest time quantum milliseconds and the highest priority priority has the lowest time quantum milliseconds . time quantum expired. the new priority of a thread that has used its entire time quantum without blocking. such threads are considered cpu intensive. as shown in the table these threads have their priorities lowered. return from sleep. the priority of a thread that is returning from sleeping such as waiting for i o . as the table illustrates when i o is available for a waiting thread its priority is boosted to between and thus supporting the scheduling policy of providing good response time for interactive processes. solaris introduced two new scheduling classes fixed priority and fair share. threads in the fixed priority class have the same priority range as those in the time sharing class however their priorities are not dynamically adjusted. the fair share scheduling class uses cpu shares instead of priorities to make scheduling decisions. cpu shares indicate entitlement to available cpu resources and are allocated to a set of processes known as a project . solaris uses the system class to run kernel processes such as the scheduler and paging daemon. once established the priority of a system process does not change. the system class is reserved for kernel use user processes running in kernel mode are not in the systems class . . operating system examples threads in the real time class are given the highest priority. this assignment allows a real time process to have a guaranteed response from the system within a bounded period of time. a real time process will run before a process in any other class. in general however few processes belong to the real time class. each scheduling class includes a set of priorities. however the scheduler converts the class specific priorities into global priorities and selects the thread with the highest global priority to run. the selected thread runs on the cpu until it blocks uses its time slice or is preempted by a higher priority thread. if there are multiple threads with the same priority the scheduler uses a round robin queue. as mentioned solaris has traditionally used the manyto many model . . but with solaris switched to the one to one model . . . . . example windows xp scheduling windows xp schedules threads using a priority based preemptive scheduling algorithm. the windows xp scheduler ensures that the highest priority thread will always run. the portion of the windows xp kernel that handles scheduling is called the dispatcher. a thread selected to run by the dispatcher will run until it is preempted by a higher priority thread until it terminates until its time quantum ends or until it calls a blocking system call such as for i o. if a higher priority real time thread becomes ready while a lower priority thread is running the lower priority thread will be preempted. this preemption gives a real time thread preferential access to the cpu when the thread needs such access. the dispatcher uses a level priority scheme to determine the order of thread execution. priorities are divided into two classes. the variable class contains threads having priorities from to and the real time class contains threads with priorities ranging from to . there is also a thread running at priority that is used for memory management. the dispatcher uses a queue for each scheduling priority and traverses the set of queues from highest to lowest until it finds a thread that is ready to run. if no ready thread is found the dispatcher will execute a special thread called the idle thread. there is a relationship between the numeric priorities of the windows xp kernel and the win api. the win api identifies several priority classes to which a process can belong. these include realtime priority class high priority class above normal.priority class normal priority class below.normal priority class idle priority class priorities in all classes except the realtime priority class are variable meaning that the priority of a thread belonging to one of these classes can change. chapter cpu scheduling . . ?. i . . iii i i isi i iii iiils iii iii iii ii ii..iiii z isi iii iiii iii i ii ' . . . . . . . . f i timlli . iii ii iiiiii .iii r iii iiisi iii fcw. . . . i ' ' i ' f fif!j f'ff iiiii iiiii hotft m ii .' ''.i s .ii! iii..ii iii iii iii i iifj i i ilj iii ii iisiii.iiiiii iii iii iii iii iiiiii iii ii ii iii . iiifijiij mi!' i iii ii iii.iii iiijj iiii iii iii iiisjiiiii niuiisii ii iii i t i iii .. ..i i.. f i . . il i y ' . . . ' ' . ' . ' . ' . ' ' . ' ' . ' . ' .'' ' ' ' ' iii i iiiii' iii i ! i iii idle i i i t ' ii . iiti ii figure . windows xp priorities. within each of the priority classes is a relative priority. the values for relative priority include timejzritical highest above normal normal below normal lowest idle the priority of each thread is based on the priority class it belongs to and its relative priority within that class. this relationship is shown in figure . . the values of the priority classes appear in the top row. the left column contains the values for the relative priorities. for example if the relative priority of a thread in the above.normal priority class is normal the numeric priority of that thread is . furthermore each thread has a base priority representing a value in the priority range for the class the thread belongs to. by default the base priority is the value of the normal relative priority for that specific class. the base priorities for each priority class are realtime priortty class high priority class above norm al.priorjty class normal priority.class below.normal priority class idle priority class . operating system examples processes are typically members of the normal.priority class. a process will belong to this class unless the parent of the process was of the idle priority class or unless another class was specified when the process was created. the initial priority of a thread is typically the base priority of the process the thread belongs to. when a thread's time quantum runs out that thread is interrupted if the thread is in the variable priority class its priority is lowered. the priority is never lowered below the base priority however. lowering the thread's priority tends to limit the cpu consumption of compute bound threads. when a variable priority thread is released from a wait operation the dispatcher boosts the priority. the amount of the boost depends on what the thread was waiting for for example a thread that was waiting for keyboard i o would get a large increase whereas a thread waiting for a disk operation would get a moderate one. this strategy tends to give good response times to interactive threads that are using the mouse and windows. it also enables i o bound threads to keep the i o devices busy while permitting compute bound threads to use spare cpu cycles in the background. this strategy is used by several time sharing operating systems including unix. in addition the window with which the user is currently interacting receives a priority boost to enhance its response time. when a user is running an interactive program the system needs to provide especially good performance for that process. for this reason windows xp has a special scheduling rule for processes in the normal pr ority class. windows xp distinguishes between the foreground process that is currently selected on the screen and the background processes that are not currently selected. when a process moves into the foreground windows xp increases the scheduling quantum by some factor typically by . this increase gives the foreground process three times longer to run before a time sharing preemption occurs. . . example linux scheduling prior to version . the linux kernel ran a variation of the traditional unix scheduling algorithm. two problems with the traditional unix scheduler are that it does not provide adequate support for smp systems and that it does not scale well as the number of tasks on the system grows. with version . the scheduler was overhauled and the kernel now provides a scheduling algorithm that runs in constant time known as o l regardless of the number of tasks on the system. the new scheduler also provides increased support for smp including processor affinity and load balancing as well as providing fairness and support for interactive tasks. the linux scheduler is a preemptive priority based algorithm with two separate priority ranges a real time range from to and a nice value ranging from to . these two ranges map into a global priority scheme whereby numerically lower values indicate higher priorities. unlike schedulers for many other systems including solaris . . and windows xp . . linux assigns higher priority tasks longer time quanta and lower priority tasks shorter time quanta. the relationship between priorities and time slice length is shown in figure . . chapter cpu scheduling numeric relative time priority priority quantum highest ms real time tasks other ft tasks lowest ms figure . the relationship between priorities and time slice length. a runnable task is considered eligible for execution on the cpu as long as it has time remaining in its time slice. when a task has exhausted its time slice it is considered expired and is not eligible for execution again until all other tasks have also exhausted their time quanta. the kernel maintains a list of all runnable tasks in a runqueue data structure. because of its support for smp each processor maintains its own runqueue and schedules itself independently. each runqueue contains two priority arrays active and expired. the active array contains all tasks with time remaining in their time slices and the expired array contains all expired tasks. each of these priority arrays contains a list of tasks indexed according to priority figure . . the scheduler chooses the task with the highest priority from the active array for execution on the cpu. on multiprocessor machines this means that each processor is scheduling the highest priority task from its own runqueue structure. when all tasks have exhausted their time slices that is the active array is empty the two priority arrays are exchanged the expired array becomes the active array and vice versa. linux implements real time scheduling as defined by posix.lb which is fully described in section . . . real time tasks are assigned static priorities. all other tasks have dynamic priorities that are based on their nice values plus or minus the value . the interactivity of a task determines whether the value will be added to or subtracted from the nice value. a task's interactivity is determined by how long it has been sleeping while waiting for i o. tasks active expired array array priority task lists priority task lists o o o figure . list of tasks indexed according to priority
 that are more interactive typically have longer sleep times and therefore are more likely to have adjustments closer to as the scheduler favors interactive tasks. the result of such adjtistments will be higher priorities for these tasks. conversely tasks with shorter sleep times are often more cpu bound and thus will have their priorities lowered. the recalculation of a task's dynamic priority occurs when the task has exhausted its time quantum and is to be moved to the expired array. thus when the two arrays are exchanged all tasks in the new active array have been assigned new priorities and corresponding time slices. . algorithm evaluation how do we select a cpu scheduling algorithm for a particular system? as we saw in section . there are many scheduling algorithms each with its own parameters. as a result selecting an algorithm can be difficult. the first problem is defining the criteria to be used in selecting an algorithm. as we saw in section . criteria are often defined in terms of cpu utilization response time or throughput. to select an algorithm we must first define the relative importance of these measures. our criteria may include several measures such as maximizing cpu utilization under the constraint that the maximum response time is second maximizing throughput such that turnaround time is on average linearly proportional to total execution time once the selection criteria have been defined we want to evaluate the algorithms under consideration. we next describe the various evaluation methods we can use. . . deterministic modeling one major class of evaluation methods is analytic evaluation. analytic evaluation uses the given algorithm and the system workload to produce a formula or number that evaluates the performance of the algorithm for that workload. one type of analytic evaluation is deterministic modeling. this method takes a particular predetermined workload and defines the performance of each algorithm for that workload. for example assume that we have the workload shown below. all five processes arrive at time in the order given with the length of the cpu burst given in milliseconds process burst time pi p p pi p chapter cpu scheduling consider the fcfs sjf and rr quantum milliseconds scheduling algorithms for this set of processes. which algorithm would give the minimum average waiting time? for the fcfs algorithm we would execute the processes as pi p p p p the waiting time is milliseconds for process pi milliseconds for process p? milliseconds for process p milliseconds for process p and milliseconds for process p . thus the average waiting time is milliseconds. with nonpreemptive sjf scheduling we execute the processes as p p px p p the waiting time is milliseconds for process p milliseconds for process p milliseconds for process p milliseconds for process p and milliseconds for process p . thus the average waiting time is milliseconds. with the rr algorithm we execute the processes as pi p p p ps p ps p the waiting time is milliseconds for process pi milliseconds for process p milliseconds for process p milliseconds for process p and milliseconds for process p . thus the average waiting time is milliseconds. we see that in this case the average waiting time obtained with the sjf policy is less than half that obtained with fcfs scheduling the rr algorithm gives us an intermediate value. deterministic modeling is simple and fast. it gives us exact numbers allowing us to compare the algorithms. however it requires exact numbers for input and its answers apply only to those cases. the main uses of deterministic modeling are in describing scheduling algorithms and providing examples. in cases where we are running the same program over and over again and can measure the program's processing requirements exactly we may be able to use deterministic modeling to select a scheduling algorithm. furthermore over a set of examples deterministic modeling may indicate trends that can then be analyzed and proved separately. for example it can be shown that for the environment described all processes and their times available at time the sjf policy will always result in the minimum waiting time. . algorithm evaluation . . queueing models on many systems the processes that are run vary from day to day so there is no static set of processes or times to use for deterministic modeling. what can be determined however is the distribution of cpu and i o bursts. these distributions can be measured and then approximated or simply estimated. the result is a mathematical formula describing the probability of a particular cpu burst. commonly this distribution is exponential and is described by its mean. similarly we can describe the distribution of times when processes arrive in the system the arrival time distribution . from these two distributions it is possible to compute the average throughput utilization waiting time and so on for most algorithms. the computer system is described as a network of servers. each server has a queue of waiting processes. the cpu is a server with its ready queue as is the i o system with its device queues. knowing arrival rates and service rates we can compute utilization average queue length average wait time and so on. this area of study is called queueing network analysis. as an example let n be the average queue length excluding the process being serviced let w be the average waiting time in the queue and let x be the average arrival rate for new processes in the queue such as three processes per second . we expect that during the time w that a process waits x w new processes will arrive in the queue. if the system is in a steady state then the number of processes leaving the queue must be equal to the number of processes that arrive. thus this equation known as little's formula is particularly useful because it is valid for any scheduling algorithm and arrival distribution. we can use little's formula to compute one of the three variables if we know the other two. for example if we know that processes arrive every second on average and that there are normally processes in the queue then we can compute the average waiting time per process as seconds. queueing analysis can be useful in comparing scheduling algorithms but it also has limitations. at the moment the classes of algorithms and distributions that can be handled are fairly limited. the mathematics of complicated algorithms and distributions can be difficult to work with. thus arrival and service distributions are often defined in mathematically tractable but unrealistic ways. it is also generally necessary to make a number of independent assumptions which may not be accurate. as a result of these difficulties queueing models are often only approximations of real systems and the accuracy of the computed results may be questionable. . . simulations to get a more accurate evaluation of scheduling algorithms we can use simulations. running simulations involves programming a model of the computer system. software data structures represent the major components of the system. the simulator has a variable representing a clock as this variable's value is increased the simulator modifies the system state to reflect the activities of the devices the processes and the scheduler. as the simulation chapter cpu scheduling performance statistics for fcfs ' ' slffltitatio!i b performance execution statistics for sjf if sje nl trace tape performance lisirhtilqtior statistics forrr g figure . evaluation of cpu schedulers by simulation. executes statistics that indicate algorithm performance are gathered and printed. the data to drive the simulation can be generated in several ways. the most common method uses a random number generator which is programmed to generate processes cpu burst times arrivals departures and so on according to probability distributions. the distributions can be defined mathematically uniform exponential poisson or empirically. if a distribution is to be defined empirically measurements of the actual system under study are taken. the results define the distribution of events in the real system this distribution can then be used to drive the simulation. a distribution driven simulation may be inaccurate however because of relationships between successive events in the real system. the frequency distribution indicates only how many instances of each event occur it does not indicate anything about the order of their occurrence. to correct this problem we can use trace tapes. we create a trace tape by monitoring the real system and recording the sequence of actual events figure . . we then use this sequence to drive the simulation. trace tapes provide an excellent way to compare two algorithms on exactly the same set of real inputs. this method can produce accurate results for its inputs. simulations can be expensive often requiring hours of computer time. a more detailed simulation provides more accurate results but it also requires more computer time. in addition trace tapes can require large amounts of storage space. finally the design coding and debugging of the simulator can be a major task. . . implementation even a simulation is of limited accuracy. the only completely accurate way to evaluate a scheduling algorithm is to code it up put it in the operating system and see how it works. this approach puts the actual algorithm in the real system for evaluation under real operating conditions
 the major difficulty with this approach is the high cost. the expense is incurred not only in coding the algorithm and modifying the operating system to support it along with its required data structures but also in the reaction of the users to a constantly changing operating system. most users are not interested in building a better operating system they merely want to get their processes executed and use their results. a constantly changing operating system does not help the users to get their work done. another difficulty is that the environment in which the algorithm is used will change. the environment will change not only in the usual way as new programs are written and the types of problems change but also as a result of the performance of the scheduler. if short processes are given priority then users may break larger processes into sets of smaller processes. if interactive processes are given priority over noninteractive processes then users may switch to interactive use. for example researchers designed one system that classified interactive and noninteractive processes automatically by looking at the amount of terminal i o. if a process did not input or output to the terminal in a second interval the process was classified as noninteractive and was moved to a lower priority queue. in response to this policy one programmer modified his programs to write an arbitrary character to the terminal at regular intervals of less than second. the system gave his programs a high priority even though the terminal output was completely meaningless. the most flexible scheduling algorithms are those that can be altered by the system managers or by the users so that they can be tuned for a specific application or set of applications. for instance a workstation that performs high end graphical applications may have scheduling needs different from those of a web server or file server. some operating systems particularly several versions of unix allow the system manager to fine tune the scheduling parameters for a particular system configuration. for example solaris provides the dispadmin command to allow the system administrator to modify the parameters of the scheduling classes described in section . . . another approach is to use apis that modify the priority of a process or thread. the java posix and winapi provide such functions. the downfall of this approach is that performance tuning a system or application most often does not result in improved performance in more general situations. . summary cpu scheduling is the task of selecting a waiting process from the ready queue and allocating the cpu to it. the cpu is allocated to the selected process by the dispatcher. first come first served fcfs scheduling is the simplest scheduling algorithm but it can cause short processes to wait for very long processes. shortestjob first sjf scheduling is provably optimal providing the shortest average waiting time. implementing sjf scheduling is difficult however because predicting the length of the next cpu burst is difficult. the sjf algorithm is a special case of the general priority scheduling algorithm which simply allocates the cpu to the highest priority process. both priority and sjf scheduling may suffer from starvation. aging is a technique to prevent starvation. chapter cpu scheduling round robin rr scheduling is more appropriate for a time shared interactive system. rr scheduling allocates the cpu to the first process in the ready queue for q time units where q is the time quantum. after q time units if the process has not relinquished the cpu it is preempted and the process is put at the tail of the ready queue. the major problem is the selection of the time quantum. if the quantum is too large rr scheduling degenerates to fcfs scheduling if the quantum is too small scheduling overhead in the form of context switch time becomes excessive. the fcfs algorithm is nonpreemptive the rr algorithm is preemptive. the sjf and priority algorithms may be either preemptive or nonpreemptive. multilevel queue algorithms allow different algorithms to be used for different classes of processes. the most common model includes a foreground interactive queue that uses rr scheduling and a background batch queue that vises fcfs scheduling. multilevel feedback queues allow processes to move from one queue to another. many contemporary computer systems support multiple processors and allow each processor to schedule itself independently. typically each processor maintains its own private queue of processes or threads all of which are available to run. issues related to multiprocessor scheduling include processor affinity and load balancing. operating systems supporting threads at the kernel level must schedule threads not processes for execution. this is the case with solaris and windows xp. both of these systems schedule threads using preemptive priority based scheduling algorithms including support for real time threads. the linux process scheduler uses a priority based algorithm with real time support as well. the scheduling algorithms for these three operating systems typically favor interactive over batch and cpu bound processes. the wide variety of scheduling algorithms demands that we have methods to select among algorithms. analytic methods use mathematical analysis to determine the performance of an algorithm. simulation methods determine performance by imitating the scheduling algorithm on a representative'' sample of processes and computing the resulting performance. however simulation can at best provide an approximation of actual system performance the only reliable technique for evaluating a scheduling algorithm is to implement the algorithm on an actual system and monitor its performance in a real world environment. exercises . why is it important for the scheduler to distinguish i o bound programs from cpu bound programs? . discuss how the following pairs of scheduling criteria conflict in certain settings. a. cpu utilization and response time b. average turnaround time and maximum waiting time c. i o device utilization and cpu utilization exercises . consider the exponential average formula used to predict the length of the next cpu burst. what are the implications of assigning the following values to the parameters used by the algorithm? a. a and to milliseconds b. a . and tq milliseconds . consider the following set of processes with the length of the cpu burst given in milliseconds process burst time priority pt p p p p the processes are assumed to have arrived in the order pi p p p p all at time . a. draw four gantt charts that illustrate the execution of these processes using the following scheduling algorithms fcfs sjf nonpreemptive priority a smaller priority number implies a higher priority and rr quantum . b. what is the turnaround time of each process for each of the scheduling algorithms in part a? c. what is the waiting time of each process for each of the scheduling algorithms in part a? d. which of the algorithms in part a results in the minimum average waiting time over all processes ? . which of the following scheduling algorithms could result in starvation? a. first come first served b. shortest job first c. round robin d. priority . consider a variant of the rr scheduling algorithm in which the entries in the ready queue are pointers to the pcbs. a. what would be the effect of putting two pointers to the same process in the ready queue? b. what would be two major advantages and two disadvantages of this scheme? c. how would you modify the basic rr algorithm to achieve the same effect without the duplicate pointers? chapter cpu scheduling . consider a system running ten i obound tasks and one cpu bound task. assume that the i o bound tasks issue an i o operation once for every millisecond of cpu computing and that each i o operation takes milliseconds to complete. also assume that the context switching overhead is . millisecond and that all processes are long running tasks. what is the cpu utilization for a round robin scheduler when a. the time quantum is millisecond b. the time quantum is milliseconds . consider a system implementing multilevel queue scheduling. what strategy can a computer user employ to maximize the amount of cpu time allocated to the user's process? . consider a preemptive priority scheduling algorithm based on dynamically changing priorities. larger priority numbers imply higher priority. when a process is waiting for the cpu in the ready queue but not running its priority changes at a rate a when it is running its priority changes at a rate . all processes are given a priority of when they enter the ready queue. the parameters a and p can be set to give many different scheduling algorithms. a. what is the algorithm that results from a ? b. what is the algorithm that results from a pi ? . explain the differences in the degree to which the following scheduling algorithms discriminate in favor of short processes a. fcfs b. rr c. multilevel feedback queues . using the windows xp scheduling algorithm what is the numeric priority of a thread for the following scenarios? a. a thread in the realtime priority.class with a relative priority of highest b. a thread in the normal priority.class with a relative priority of normal c. a thread in the high priority class with a relative priority of abovejvormal . consider the scheduling algorithm in the solaris operating system for time sharing threads. a. what is the time quantum in milliseconds for a thread with priority ? with priority ? b. assume that a thread with priority has used its entire time quantum without blocking. what new priority will the scheduler assign this thread? bibliographical notes c. assume that a thread with priority blocks for i o before its time quantum has expired. what new priority will the scheduler assign this thread? . the traditional unix scheduler enforces an inverse relationship between priority numbers and priorities the higher the number the lower the priority. the scheduler recalculates process priorities once per second using the following function priority recent cpu usage base where base and recent cpu usage refers to a value indicating how often a process has used the cpu since priorities were last recalculated. assume that recent cpu usage for process pi is process pi is and process p is . what will be the new priorities for these three processes when priorities are recalculated? based on this information does the traditional unix scheduler raise or lower the relative priority of a cpu bound process? bibliographical notes feedback queues were originally implemented on the ctss system described in corbato et al. . this feedback queue scheduling system was analyzed by schrage . the preemptive priority scheduling algorithm of exercise . was suggested by kleinrock . anderson et al. lewis and berg and philbin et al. talked about thread scheduling. multiprocessor scheduling was discussed by tucker and gupta zahorjan and mccann feitelson and rudolph leutenegger and vernon blumofe and leiserson polychronopoulos and kuck and lucco . scheduling techniques that take into account information regarding process execution times from previous runs were described in fisher hall et al. and lowney etal. . scheduling in real time systems was discussed by liu and layland abbot jensen et al. hong et al. and khanna et al. . a special issue of operating system review on real time operating systems was edited by zhao . fair share schedulers were covered by henry woodside and kay and lauder . scheduling policies used in the unix v operating system were described by bach those for unix bsd . were presented by mckusick et al. and those for the mach operating system were discussed by black bovet and cesati covered scheduling in linux. solaris scheduling was described by mauro and mcdougall . solomon and solomon and russinovich discussed scheduling in windows nt and windows respectively. butenhof and lewis and berg described scheduling in pthreads systems. apter
 a cooperating process is one that can affect or be affected by other processes executing in the system. cooperating processes can either directly share a logical address space that is both code and data or be allowed to share data only through files or messages. the former case is achieved through the use of lightweight processes or threads which we discussed in chapter . concurrent access to shared data may result in data inconsistency. in this chapter we discuss various mechanisms to ensure the orderly execution of cooperating processes that share a logical address space so that data consistency is maintained. objectives to introduce the critical section problem whose solutions can be used to ensure the consistency of shared data. to present both software and hardware solutions of the critical section problem. to intoduce the concept of atomic transaction and describe mechanisms to ensure atomicity
 in chapter we developed a model of a system consisting of cooperating sequential processes or threads all running asynchronously and possibly sharing data. we illustrated this model with the producer consumer problem which is representative of operating systems. specifically in section . . we described how a bounded buffer could be used to enable processes to share memory. let us return to our consideration of the bounded buffer. as we pointed out our solution allows at most buffer.size items in the buffer at the same time. suppose we want to modify the algorithm to remedy this deficiency. one possibility is to add an integer variable counter initialized to . counter is incremented every time we add a new item to the buffer and is decremented chapter process synchronization every time we remove one item from the buffer. the code for the producer process can be modified as follows while true produce an item in nextproduced while counter buffer.size do nothing buffer in nextproduced in in buffer size counter the code for the consumer process can be modified as follows while true while counter do nothing nextconsumed buffer out out out buffer size counter consume the item in nextconsumed although both the producer and consumer routines are correct separately they may not function correctly when executed concurrently. as an illustration suppose that the value of the variable counter is currently and that the producer and consumer processes execute the statements counter and counter concurrently. following the execution of these two statements the value of the variable counter may be or ! the only correct result though is counter which is generated correctly if the producer and consumer execute separately. we can show that the value of counter may be incorrect as follows. note that the statement counter may be implemented in machine language on a typical machine as register counter registeri registeri counter registeri where register is a local cpu register. similarly the statement counter is implemented as follows register counter register register counter registeri where again register is a local cpu register. even though register and register may be the same physical register an accumulator say remember
 that the contents of this register will be saved and restored by the interrupt handler section . . . the concurrent execution of counter and counter is equivalent to a sequential execution where the lower level statements presented previously are interleaved in some arbitrary order but the order within each high level statement is preserved . one such interleaving is to producer execute registeri counter registeri ti producer execute register i register registeri tr. consumer execute register . counter register ty consumer execute register registeri register t producer execute counter registeri counter t consumer execute counter register counter notice that we have arrived at the incorrect state counter indicating that four buffers are full when in fact five buffers are full. if we reversed the order of the statements at t and t we would arrive at the incorrect state counter . we would arrive at this incorrect state because we allowed both processes to manipulate the variable counter concurrently. a situation like this where several processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the access takes place is called a race condition. to guard against the race condition above we need to ensure that only one process at a time can be manipulating the variable counter. to make such a guarantee we require that the processes be synchronized in some way. situations such as the one just described occur frequently in operating systems as different parts of the system manipulate resources. clearly we want the resulting changes not to interfere with one another. because of the importance of this issue a major portion of this chapter is concerned with process synchronization and coordination. . the critical section problem consider a system consisting of n processes pq pi ... p . each process has a segment of code called a critical section in which the process may be changing common variables updating a table writing a file and so on. the important feature of the system is that when one process is executing in its critical section no other process is to be allowed to execute in its critical section. that is no two processes are executing in their critical sections at the same time. the critical section problem is to design a protocol that the processes can use to cooperate. each process must request permission to enter its critical section. the section of code implementing this request is the entry section. the critical section may be followed by an exit section. the remaining code is the remainder section. the general structure of a typical process p is shown in figure . . the entry section and exit section are enclosed in boxes to highlight these important segments of code. chapter process synchronization do entry section critical section exitsection remainder section while true figure . general structure of a typical process p . a solution to the critical section problem must satisfy the following three requirements . mutual exclusion. if process p is executing in its critical section then no other processes can be executing in their critical sections. . progress. if no process is executing in its critical section and some processes wish to enter their critical sections then only those processes that are not executing in their remainder sections can participate in the decision on which will enter its critical section next and this selection cannot be postponed indefinitely. . bounded waiting. there exists a bound or limit on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted. we assume that each process is executing at a nonzero speed. however we can make no assumption concerning the relative speed of the n processes. at a given point in time many kernel mode processes may be active in the operating system. as a result the code implementing an operating system kernel code is subject to several possible race conditions. consider as an example a kernel data structure that maintains a list of all open files in the system. this list must be modified when a new file is opened or closed adding the file to the list or removing it from the list . if two processes were to open files simultaneously the separate updates to this list could result in a race condition. other kernel data structures that are prone to possible race conditions include structures for maintaining memory allocation for maintaining process lists and for interrupt handling. it is up to kernel developers to ensure that the operating system is free from such race conditions. two general approaches are used to handle critical sections in operating systems preemptive kernels and nonpreemptive kernels. a preemptive kernel allows a process to be preempted while it is running in kernel mode. a nonpreemptive kernel does not allow a process running in kernel mode to be preempted a kernel mode process will run until it exits kernel mode blocks or voluntarily yields control of the cpu. obviously a nonpreemptive kernel is essentially free from race conditions on kernel data structures as . peterson's solution only one process is active in the kernel at a time. we cannot say the same about nonpreemptive kernels so they must be carefully designed to ensure that shared kernel data are free from race conditions. preemptive kernels are especially difficult to design for mp architectures since in these environments it is possible for two kernel mode processes to run simultaneously on different processors. why then would anyone favor a preemptive kernel over a nonpreemptive one? a preemptive kernel is more suitable for real time programming as it will allow a real time process to preempt a process currently running in the kernel. furthermore a preemptive kernel may be more responsive since there is less risk that a kernel mode process will run for an arbitrarily long period before relinquishing the processor to waiting processes. of course this effect can be minimized by designing kernel code that does not behave in this way. windows xp and windows are nonpreemptive kernels as is the traditional unix kernel. prior to linux . the linux kernel was nonpreemptive as well. however with the release of the . kernel linux changed to the preemptive model. several commercial versions of unix are preemptive including solaris and irix. . peterson's solution next we illustrate a classic software based solution to the critical section problem known as peterson's solution. because of the way modern computer architectures perform basic machine language instructions such as load and store there are no guarantees that peterson's solution will work correctly on such architectures. however we present the solution because it provides a good algorithmic description of solving the critical section problem and illustrates some of the complexities involved in designing software that addresses the requirements of mutual exclusion progress and bounded waiting requirements. peterson's solution is restricted to two processes that alternate execution between their critical sections and remainder sections. the processes are numbered po and pi. for convenience when presenting p we use pj to denote the other process that is j equals i. peterson's solution requires two data items to be shared between the two processes int turn boolean f l a g the variable turn indicates whose turn it is to enter its critical section. that is if turn i then process p is allowed to execute in its critical section. the flag array is used to indicate if a process is ready to enter its critical section. for example if f lag i is true this value indicates that p is ready to enter its critical section. with an explanation of these data structures complete we are now ready to describe the algorithm shown in figure . to enter the critical section process p first sets flag i to be true and then sets turn to the value j thereby asserting that if the other process wishes to enter the critical section it can do so. if both processes try to enter at the same time turn will be set to both i and j at roughly the same time. only chapter process synchronization do flag i true turn j while flag j turn j critical section flag i false remainder section while true figure . the structure of process p in peterson's solution. one of these assignments will last the other will occur but will be overwritten immediately. the eventual value of turn decides which of the two processes is allowed to enter its critical section first. we now prove that this solution is correct. we need to show that . mutual exclusion is preserved. . the progress requirement is satisfied. . the bounded waiting requirement is met. to prove property we note that each p enters its critical section only if either f l a g j false or turn i. also note that if both processes can be executing in their critical sections at the same time then flag flag true. these two observations imply that po and pi could not have successfully executed their while statements at about the same time since the value of turn can be either or but cannot be both. hence one of the processes say pj must have successfully executed the while statement whereas p had to execute at least one additional statement turn j . however since at that time f l a g j true and turn j and this condition will persist as long as pj is in its critical section the result follows mutual exclusion is preserved. to prove properties and we note that a process p can be prevented from entering the critical section only if it is stuck in the while loop with the condition flag j true and turn j this loop is the only one possible. if p is not ready to enter the critical section then flag j false and p can enter its critical section. if pj has set flag j to t r u e and is also executing in its while statement then either turn i or turn j . if turn i then p will enter the critical section. if turn j then pj will enter the critical section. however once p exits its critical section it will reset f l a g j to false allowing p to enter its critical section. if pj resets flag j to true it must also set turn to i. thus since p does not change the value of the variable turn while executing the while statement p will enter the critical section progress after at most one entry by p bounded waiting 
 y do acquire lock critical section releaselock remainder section while true figure . solution to the critical section problem using locks. . synchronization hardware we have just described one software based solution to the critical section problem. in general we can state that any solution to the critical section problem requires a simple tool a lock. race conditions are prevented by requiring that critical regions be protected by locks. that is a process must acquire a lock before entering a critical section it releases the lock when it exits the critical section. this is illustrated in figure . . in the following discussions we explore several more solutions to the critical section problem using techniques ranging from hardware to softwarebased apis available to application programmers. all these solutions are based on the premise of locking however as we shall see the design of such locks can be quite sophisticated. hardware features can make any programming task easier and improve system efficiency. in this section we present some simple hardware instructions that are available on many systems and show how they can be used effectively in solving the critical section problem. the critical section problem could be solved simply in a uniprocessor environment if we could prevent interrupts from occurring while a shared variable was being modified. in this manner we could be sure that the current sequence of instructions would be allowed to execute in order without preemption. no other instructions would be run so no unexpected modifications could be made to the shared variable. this is the approach taken by nonpreemptive kernels. unfortunately this solution is not as feasible in a multiprocessor environment. disabling interrupts on a multiprocessor can be time consuming as the boolean testandset boolean target boolean rv target target true return rv figure . the definition of the testandset instruction. chapter process synchronization do while testandsetlock lock do nothing critical section lock false remainder section while true figure . mutual exclusion implementation with testands et . message is passed to all the processors. this message passing delays entry into each critical section and system efficiency decreases. also consider the effect on a system's clock if the clock is kept updated by interrupts. many modern computer systems therefore provide special hardware instructions that allow us either to test and modify the content of a word or to swap the contents of two words atomically that is as one uninterruptible unit. we can use these special instructions to solve the critical section problem in a relatively simple manner. rather than discussing one specific instruction for one specific machine we abstract the main concepts behind these types of instructions. the testandset instruction can be defined as shown in figure . . the important characteristic is that this instruction is executed atomically. thus if two testandset c instructions are executed simultaneously each on a different cpu they will be executed sequentially in some arbitrary order. if the machine supports the testandset instruction then we can implement mutual exclusion by declaring a boolean variable lock initialized to f a l s e . the structure of process p is shown in figure . . the swapo instruction in contrast to the testandset instruction operates on the contents of two words it is defined as shown in figure . . like the testandset instruction it is executed atomically. if the machine supports the swapo instruction then mutual exclusion can be provided as follows. a global boolean variable lock is declared and is initialized to f a l s e . in addition each process has a local boolean variable key. the structure of process p is shown in figure . . although these algorithms satisfy the mutual exclusion requirement they do not satisfy the bounded waiting requirement. in figure . we present void swap boolean a boolean b boolean temp a a b b temp figure . the definition of the swap instruction. . synchronization hardware do key true while key true swap lock key critical section lock false remainder section jwhile true figure . mutual exclusion implementation with the swapo instruction. another algorithm using the testandseto instruction that satisfies all the critical section requirements. the common data structures are boolean waiting n boolean lock these data structures are initialized to false. to prove that the mutualexclusion requirement is met we note that process p can enter its critical section only if either waiting i false or key false. the value of key can become false only if the testandseto is executed. the first process to execute the testandset will find key false all others must do waiting i true key true while waiting i key key testandset lock waiting i false critical section j i n while ! i scsc !waiting j j j n if j i lock false else waiting j false remainder section while true figure . bounded waiting mutual exclusion with test a n d s et o . chapter process synchronization wait. the variable waiting i can become false only if another process leaves its critical section only one waiting i is set to false maintaining the mutual exclusion requirement. to prove that the progress requirement is met we note that the arguments presented for mutual exclusion also apply here since a process exiting the critical section either sets lock to false or sets waiting j to false. both allow a process that is waiting to enter its critical section to proceed. to prove that the bounded waiting requirement is met we note that when a process leaves its critical section it scans the array waiting in the cyclic ordering z' i ... n ... i . it designates the first process in this ordering that is in the entry section waiting j true as the next one to enter the critical section. any process waiting to enter its critical section will thus do so within n turns. unfortunately for hardware designers implementing atomic testandsetq instructions on multiprocessors is not a trivial task. such implementations are discussed in books on computer architecture
 the various hardware based solutions to the critical section problem using the testandsetc and swapo instructions presented in section . are complicated for application programmers to use. to overcome this difficulty we can use a synchronization tool called a semaphore. a semaphore s is an integer variable that apart from initialization is accessed only through two standard atomic operations wait and signal . the waito operation was originally termed p from the dutch probercn to test signal was originally called v from verhogen to increment . the definition of wait is as follows wait s while s no op s the definition of signal is as follows signal s s all the modifications to the integer value of the semaphore in the wait and signal operations must be executed indivisibly. that is when one process modifies the semaphore value no other process can simultaneously modify that same semaphore value. in addition in the case of wait s the testing of the integer value of s s and its possible modification s must also be executed without interruption. we shall see how these operations can be implemented in section . . first let us see how semaphores can be used. . semaphores . . usage ' operating systems often distinguish between counting and binary semaphores. the value of a counting semaphore can range over an unrestricted domain. the value of a binary semaphore can range only between and . on some systems binary semaphores are known as mutex locks as they are locks that provide mutual t'.rclusion. we can use binary semaphores to deal with the critical section problem for multiple processes. the n processes share a semaphore mutex initialized to . each process p is organized as shown in figure . . counting semaphores can be used to control access to a given resource consisting of a finite number of instances. the semaphore is initialized to the number of resources available. each process that wishes to use a resource performs a waitq operation on the semaphore thereby decrementing the count . when a process releases a resource it performs a signal operation incrementing the count . when the count for the semaphore goes to all resources are being used. after that processes that wish to use a resource will block until the count becomes greater than . we can also use semaphores to solve various synchronization problems. for example consider two concurrently running processes p with a statement si and pi with a statement si. suppose we require that so be executed only after si has completed. we can implement this scheme readily by letting pi and pi share a common semaphore synch initialized to and by inserting the statements si signal synch in process p and the statements wait synch si in process p?. because synch is initialized to p? will execute s only after p has invoked s i g n a l synch which is after statement si has been executed. do waiting mutex critical section signal mutex remainder section while true figure . mutual exclusion implementation with semaphores. chapter process synchronization . . implementation ? the main disadvantage of the semaphore definition given here is that it requires busy waiting. while a process is in its critical section any other process that tries to enter its critical section must loop continuously in the entry code. this continual looping is clearly a problem in a real multiprogramming system where a single cpu is shared among many processes. busy waiting wastes cpu cycles that some other process might be able to use productively. this type of semaphore is also called a spinlock because the process spins while waiting for the lock. spinlocks do have an advantage in that no context switch is required when a process must wait on a lock and a context switch may take considerable time. thus when locks are expected to be held for short times spinlocks are useful they are often employed on multiprocessor systems where one thread can spin on one processor while another thread performs its critical section on another processor. to overcome the need for busy waiting we can modify the definition of the wait and signal semaphore operations. when a process executes the wait operation and finds that the semaphore value is not positive it must wait. however rather than engaging in busy waiting the process can block itself. the block operation places a process into a waiting queue associated with the semaphore and the state of the process is switched to the waiting state. then control is transferred to the cpu scheduler which selects another process to execute. a process that is blocked waiting on a semaphore s should be restarted when some other process executes a signal operation. the process is restarted by a wakeup operation which changes the process from the waiting state to the ready state. the process is then placed in the ready queue. the cpu may or may not be switched from the running process to the newly ready process depending on the cpu scheduling algorithm. to implement semaphores under this definition we define a semaphore as a c struct typedef struct int value struct process list semaphore each semaphore has an integer value and a list of processes list. when a process must wait on a semaphore it is added to the list of processes. a signal operation removes one process from the list of waiting processes and awakens that process. the wait semaphore operation can now be defined as wait semaphore s s value if s value add this process to s list block . semaphores the signal semaphore operation can now be defined as signal semaphore s s value if s value remove a process p from s list wakeup p the blocko operation suspends the process that invokes it. the wakeup p operation resumes the execution of a blocked process p. these two operations are provided by the operating system as basic system calls. note that although under the classical definition of semaphores with busy waiting the semaphore value is never negative this implementation may have negative semaphore values. if the semaphore value is negative its magnitude is the number of processes waiting on that semaphore. this fact results from switching the order of the decrement and the test in the implementation of the waito operation. the list of waiting processes can be easily implemented by a link field in each process control block pcb . each semaphore contains an integer value and a pointer to a list of pcbs. one way to add and remove processes from the list in a way that ensures bounded waiting is to use a fifo queue where the semaphore contains both head and tail pointers to the queue. in general however the list can use any queueing strategy. correct usage of semaphores does not depend on a particular queueing strategy for the semaphore lists. the critical aspect of semaphores is that they be executed atomically we must guarantee that no two processes can execute waito and signal operations on the same semaphore at the same time. this is a critical section problem and in a single processor environment that is where only one cpu exists we can solve it by simply inhibiting interrupts during the time the wait and signal operations are executing. this scheme works in a singleprocessor environment because once interrupts are inhibited instructions from different processes cannot be interleaved. only the currently running process executes until interrupts are reenabled and the scheduler can regain control. in a multiprocessor environment interrupts must be disabled on every processor otherwise instructions from different processes running on different processors may be interleaved in some arbitrary way. disabling interrupts on every processor can be a difficult task and furthermore can seriously diminish performance. therefore smp systems must provide alternative locking techniques such as spinlocks to ensure that waito and signal are performed atomically. it is important to admit that we have not completely eliminated busy waiting with this definition of the waito and signal operations. rather we have removed busy waiting from the entry section to the critical sections of application programs. furthermore we have limited busy waiting to the critical sections of the wait and signal operations and these sections are short if properly coded they should be no more than about ten instructions . chapter process synchronization thus the critical section is almost never occupied and busy waiting occurs rarely and then for only a short time. an entirely different situation exists with application programs whose critical sections may be long minutes or even hours or may almost always be occupied. in such cases busy waiting is extremely inefficient. . . deadlocks and starvation the implementation of a semaphore with a waiting queue may result in a situation where two or more processes are waiting indefinitely for an event that can be caused only by one of the waiting processes. the event in question is the execution of a s i g n a l operation. when such a state is reached these processes are said to be deadlocked. to illustrate this we consider a system consisting of two processes pq and pi each accessing two semaphores s and q set to the value wait s wait q wait q wait s signal s signal q signal q signal s suppose that p executes wait s and then pi executes wait q . when po executes wait q it must wait until pi executes signal q . similarly when pi executes wait s it must wait until po executes signal s . since these s i g n a l operations cannot be executed po and pi are deadlocked. we say that a set of processes is in a deadlock state when every process in the set is waiting for an event that can be caused only by another process in the set. the events with which we are mainly concerned here are resource acquisition and release. however other types of events may result in deadlocks as we shall show in chapter . in that chapter we shall describe various mechanisms for dealing with the deadlock problem. another problem related to deadlocks is indefinite blocking or starvation a situation in which processes wait indefinitely within the semaphore. indefinite blocking may occur if we add and remove processes from the list associated with a semaphore in lifo last in first out order. . classic problems of synchronization in this section we present a number of synchronization problems as examples of a large class of concurrency control problems. these problems are used for testing nearly every newly proposed synchronization scheme. in our solutions to the problems we use semaphores for synchronization. . classic problems of synchronization do produce an item in nextp wait empty wait mutex add nextp to buffer signal mutex signal full while true figure . the structure of the producer process. . . the bounded buffer problem the bounded buffer problem was introduced in section . it is commonly used to illustrate the power of synchronization primitives. we present here a general structure of this scheme without committing ourselves to any particular implementation we provide a related programming project in the exercises at the end of the chapter. we assume that the pool consists of n buffers each capable of holding one item. the mutex semaphore provides mutual exclusion for accesses to the buffer pool and is initialized to the value . the empty and f u l l semaphores count the number of empty and full buffers. the semaphore empty is initialized to the value n the semaphore f u l l is initialized to the value . the code for the producer process is shown in figure . the code for the consumer process is shown in figure . . note the symmetry between the producer and the consumer. we can interpret this code as the producer producing full buffers for the consumer or as the consumer producing empty buffers for the producer. do wait full wait mutex remove an item from buffer to nextc signal mutex signal empty consume the item in nextc while true figure . the structure of the consumer process. chapter process synchronization . . the readers writers problem a database is to be shared among several concurrent processes. some of these processes may want only to read the database whereas others may want to update that is to read and write the database. we distinguish between these two types of processes by referring to the former as readers and to the latter as writers. obviously if two readers access the shared data simultaneously no adverse affects will result. however if a writer and some other thread either a reader or a writer access the database simultaneously chaos may ensue. to ensure that these difficulties do not arise we require that the writers have exclusive access to the shared database. this synchronization problem is referred to as the readers writers problem. since it was originally stated it has been used to test nearly every new synchronization primitive. the readerswriters problem has several variations all involving priorities. the simplest one referred to as the first readers writers problem requires that no reader will be kept waiting unless a writer has already obtained permission to use the shared object. in other words no reader should wait for other readers to finish simply because a writer is waiting. the second readers writers problem requires that once a writer is ready that writer performs its write as soon as possible. in other words if a writer is waiting to access the object no new readers may start reading. a solution to either problem may result in starvation. in the first case writers may starve in the second case readers may starve. for this reason other variants of the problem have been proposed. in this section we present a solution to the first readers writers problem. refer to the bibliographical notes at the end of the chapter for references describing starvation free solutions to the second readers writers problem. in the solution to the first readers writers problem the reader processes share the following data structures semaphore mutex wrt int readcount the semaphores mutex and wrt are initialized to readcount is initialized to . the semaphore wrt is common to both reader and writer processes. the mutex semaphore is used to ensure mutual exclusion when the variable readcount is updated. the readcount variable keeps track of how many processes are currently reading the object. the semaphore wrt functions as a mutual exclusion semaphore for the writers. it is also used by the first or last do wait wrt writing is performed signal wrt while true figure . the structure of a writer process. . classic problems of synchronization do wait mutex readcount if readcount wait wrt signal mutex reading is performed wait mutex readcount if readcount signal wrt signal mutex jwhile true figure . the structure of a reader process. reader that enters or exits the critical section. it is not used by readers who enter or exit while other readers are in their critical sections. the code for a writer process is shown in figure . the code for a reader process is shown in figure . . note that if a writer is in the critical section and n readers are waiting then one reader is queued on wrt and n readers are queued on mutex. also observe that when a writer executes s i g n a l wrt we may resume the execution of either the waiting readers or a single waiting writer. the selection is made by the scheduler. the readers writers problem and its solutions has been generalized to provide reader writer locks on some systems. acquiring a reader writer lock requires specifying the mode of the lock either read or write access. when a process only wishes to read shared data it requests the reader wrriter lock in read mode a process wishing to modify the shared data must request the lock in write mode. multiple processes are permitted to concurrently acquire a reader writer lock in read mode only one process may acquire the lock for writing as exclusive access is required for writers. reader writer locks are most useful in the following situations in applications where it is easy to identify which processes only read shared data and which threads only write shared data. in applications that have more readers than writers. this is because readerwriter locks generally require more overhead to establish than semaphores or mutual exclusion locks and the overhead for setting up a reader writer lock is compensated by the increased concurrency of allowing multiple readers. . . the dining philosophers problem consider five philosophers who spend their lives thinking and eating. the philosophers share a circular table surrounded by five chairs each belonging to one philosopher. in the center of the table is a bowl of rice and the table is laid chapter process synchronization o o figure . the situation of the dining philosophers. with five single chopsticks figure . . when a philosopher thinks she does not interact with her colleagues. from time to time a philosopher gets hungry and tries to pick up the two chopsticks that are closest to her the chopsticks that are between her and her left and right neighbors . a philosopher may pick up only one chopstick at a time. obviously she cannot pick up a chopstick that is already in the hand of a neighbor. when a hungry philosopher has both her chopsticks at the same time she eats without releasing her chopsticks. when she is finished eating she puts down both of her chopsticks and starts thinking again. the dining philosophers problem is considered a classic synchronization problem neither because of its practical importance nor because computer scientists dislike philosophers but because it is an example of a large class of concurrency control problems. it is a simple representation of the need to allocate several resources among several processes in a deadlock free and starvation free manner. one simple solution is to represent each chopstick with a semaphore. a philosopher tries to grab a chopstick by executing a wait operation on that semaphore she releases her chopsticks by executing the signal operation on the appropriate semaphores. thus the shared data are semaphore chopstick where all the elements of chopstick are initialized to . the structure of philosopher is shown in figure . . although this solution guarantees that no two neighbors are eating simultaneously it nevertheless must be rejected because it could create a deadlock. suppose that all five philosophers become hungry simultaneously and each grabs her left chopstick. all the elements of chopstick will now be equal to . when each philosopher tries to grab her right chopstick she will be delayed forever. several possible remedies to the deadlock problem are listed next. in section . we present a solution to the dining philosophers problem that ensures freedom from deadlocks. allow at most four philosophers to be sitting simultaneously at the table
 do wait chopstick i wait chopstick i eat signal chopstick i signal chopstick i think while true figure . the structure of philosopher i. allow a philosopher to pick up her chopsticks only if both chopsticks are available to do this she must pick them up in a critical section . use an asymmetric solution that is an odd philosopher picks up first her left chopstick and then her right chopstick whereas an even philosopher picks up her right chopstick and then her left chopstick. finally any satisfactory solution to the dining philosophers problem must guard against the possibility that one of the philosophers will starve to death. a deadlock free solution does not necessarily eliminate the possibility of starvation. . monitors although semaphores provide a convenient and effective mechanism for process synchronization using them incorrectly can result in timing errors that are difficult to detect since these errors happen only if some particular execution sequences take place and these sequences do not always occur. we have seen an example of such errors in the use of counters in our solution to the producer consumer problem section . . in that example the timing problem happened only rarely and even then the counter value appeared to be reasonable off by only nevertheless the solution is obviously not an acceptable one. it is for this reason that semaphores were introduced in the first place. unfortunately such timing errors can still occur when semaphores are used. to illustrate how we review the semaphore solution to the criticalsection problem. all processes share a semaphore variable mutex which is. initialized to . each process must execute wait mutex before entering the critical section and s i g n a l mutex afterward. if this sequence is not observed two processes may be in their critical sections simultaneously. let us examine the various difficulties that may result. note that these difficulties will arise even if a single process is not well behaved. this situation may be caused by an honest programming error or an uncooperative programmer. chapter process synchronization suppose that a process interchanges the order in which the wait j and signal operations on the semaphore mutex are executed resulting in the following execution signal mutex critical section wait mutex in this situation several processes may be executing in their critical sections simultaneously violating the rmitual exclusion requirement. this error may be discovered only if several processes are simultaneously active in their critical sections. note that this situation may not always be reproducible. suppose that a process replaces signal mutex with wait mutex . that is it executes wait mutex critical section wait mutex in this case a deadlock will occur. suppose that a process omits the wait mutex or the signal mutex or both. in this case either mutual exclusion is violated or a deadlock will occur. these examples illustrate that various types of errors can be generated easily when programmers use semaphores incorrectly to solve the critical section problem. similar problems may arise in the other synchronization models that we discussed in section . . to deal with such errors researchers have developed high level language constructs. in this section we describe one fundamental high level synchronization construct the monitor type. . . usage a type or abstract data type encapsulates private data with public methods to operate on that data. a monitor type presents a set of programmer defined operations that are provided mutual exclusion within the monitor. the monitor type also contains the declaration of variables whose values define the state of an instance of that type along with the bodies of procedures or functions that operate on those variables. the syntax of a monitor is shown in figure . . the representation of a monitor type cannot be used directly by the various processes. thus a procedure defined within a monitor can access only those variables declared locally within the monitor and its formal parameters. similarly the local variables of a monitor can be accessed by only the local procedures. . monitors monitor monitor name f ii shared variable declarations procedure pi ... procedure p . . . procedure pn . . . initialization code . . . figure . syntax of a monitor. the monitor construct ensures that only one process at a time can be active within the monitor. consequently the programmer does not need to code this synchronization constraint explicitly figure . . however the monitor construct as defined so far is not sufficiently powerful for modeling some synchronization schemes. for this purpose we need to define additional synchronization mechanisms. these mechanisms are provided by the condition construct. a programmer who needs to write a tailor made synchronization scheme can define one or more variables of type condition condition x y the only operations that can be invoked on a condition variable are wait and s i g n a l . the operation x.waito means that the process invoking this operation is suspended until another process invokes x.signal the x. s i g n a l operation resumes exactly one suspended process. if no process is suspended then the signal operation has no effect that is the state of x is the same as if the operation had never been executed figure . . contrast this operation with the signal operation associated with semaphores which always affects the state of the semaphore. chapter process synchronization figure . schematic view of a monitor. now suppose that when the x. s ignal operation is invoked by a process p there is a suspended process q associated with condition x. clearly if the suspended process q is allowed to resume its execution the signaling process p must wait. otherwise both p and q would be active simultaneously within the monitor. note however that both processes can conceptually continue with their execution. two possibilities exist . signal and wait. p either waits until q leaves the monitor or waits for another condition. . signal and continue. q either waits until p leaves the monitor or waits for another condition. there are reasonable arguments in favor of adopting either option. on the one hand since p was already executing in the monitor the signal and continue method seems more reasonable. on the other hand if we allow thread p to continue then by the time q is resumed the logical condition for which q was waiting may no longer hold. a compromise between these two choices was adopted in the language concurrent pascal. when thread p executes the signal operation it immediately leaves the monitor. hence q is immediately resumed. . . dining philosophers solution using monitors we now illustrate monitor concepts by presenting a deadlock free solution to the dining philosophers problem. this solution imposes the restriction that a philosopher may pick up her chopsticks only if both of them are available. to . monitors queues associated with f x yconditions initialization code figure . monitor with condition variables. code this solution we need to distinguish among three states in which we may find a philosopher. for this purpose we introduce the following data structure enum thinking hungry eating s t a t e philosopher i can set the variable state i eating only if her two neighbors are not eating state i ! eating and state i ! eating . we also need to declare condition self where philosopher ' can delay herself when she is hungry but is unable to obtain the chopsticks she needs. we are now in a position to describe our solution to the diiiing philosophers problem. the distribution of the chopsticks is controlled by the monitor dp whose definition is shown in figure . . each philosopher before starting to eat must invoke the operation pi ckup . this may result in the suspension of the philosopher process. after the successful completion of the operation the philosopher may eat. following this the philosopher invokes the putdowno operation. thus philosopher i must invoke the operations pi ckup and putdowno in the following sequence dp.pickup i eat dp.putdown i chapter process synchronization monitor dp enum thinking hungry eating state condition self void pickup int i state i hungry test i if state i ! eating self i .wait void putdown int i state til thinking test i test i void test int i if state i ! eating state i hungry state i ! eating state i eating self i .signal initialization code for int i i i state i thinking figure . a monitor solution to the dining philosopher problem. it is easy to show that this solution ensures that no two neighbors are eating simultaneously and that no deadlocks will occur. we note however that it is possible for a philosopher to starve to death. we do not present a solution to this problem but rather leave it as an exercise for you. . . implementing a monitor using semaphores we now consider a possible implementation of the monitor mechanism using semaphores. for each monitor a semaphore mutex initialized to is provided. a process must execute wait mutex before entering the monitor and must execute signal mutex after leaving the monitor. since a signaling process must wait until the resumed process either leaves or waits an additional semaphore next is introduced initialized to on which the signaling processes may suspend themselves. an integer variable . monitors next count is also provided to count the number of processes suspended on next. thus each external procedure f is replaced by uait mutex body of f if next count signal next else signal mutex mutual exclusion within a monitor is ensured. we can now describe how condition variables are implemented. for each condition x we introduce a semaphore x sem and an integer variable x count both initialized to . the operation x. wait can now be implemented as x count if next count signal next else signal mutex wait x sem x count the operation x. signal can be implemented as if x count next count signal x sem wait next next count this implementation is applicable to the definitions of monitors given by both hoare and brinch hansen. in some cases however the generality of the implementation is unnecessary and a significant improvement in efficiency is possible. we leave this problem to you in exercise . . . . resuming processes within a monitor we turn now to the subject of process resumption order within a monitor. if several processes are suspended on condition x and an x. signal operation is executed by some process then how do we determine which of the suspended processes should be resumed next? one simple solution is to use an fcfs ordering so that the process waiting the longest is resumed first. in many circumstances however such a simple scheduling scheme is not adequate. for this purpose the conditional wait construct can be used it has the form x.wait c chapter process synchronization monitor resourceallocator boolean busy condition x void acquire int time if busy x.wait time busy true void release busy false x.signal initialization code busy false figure . a monitor to allocate a single resource. where c is an integer expression that is evaluated when the wait operation is executed. the value of c which is called a priority number is then stored with the name of the process that is suspended. when x. signal is executed the process with the smallest associated priority number is resumed next. to illustrate this new mechanism we consider the resourceallocator monitor shown in figure . which controls the allocation of a single resource among competing processes. each process when requesting an allocation of this resource specifies the maximum time it plans to use the resource. the monitor allocates the resource to the process that has the shortest timeallocation request. a process that needs to access the resource in question must observe the following sequence r.acquire t access the resource r. releaseo where r is an instance of type resourceallocator. unfortunately the monitor concept cannot guarantee that the preceding access sequence will be observed. in particular the following problems can occur a process might access a resource without first gaining access permission to the resource. a process might never release a resource once it has been granted access to the resource
 a process might attempt to release a resource that it never requestecj. a process might request the same resource twice without first releasing the resource . the same difficulties are encountered with the use of semaphores and these difficulties are similar in nature to those that encouraged us to develop the monitor constructs in the first place. previously we had to worry about the correct use of semaphores. now we have to worry about the correct use of higher level programmer defined operations with which the compiler can no longer assist us. one possible solution to the current problem is to include the resourceaccess operations within the resourceallocator monitor. however using this solution will mean that scheduling is done according to the built in monitor scheduling algorithm rather than the one we have coded. to ensure that the processes observe the appropriate sequences we must inspect all the programs that make use of the resourceallocator monitor and its managed resource. we must check two conditions to establish the correctness of this system. first user processes must always make their calls on the monitor in a correct sequence. second we must be sure that an uncooperative process does not simply ignore the mutual exclusion gateway provided by the monitor and try to access the shared resource directly without using the access protocols. only if these two conditions can be ensured can we guarantee that no time dependent errors will occur and that the scheduling algorithm will not be defeated. although this inspection may be possible for a small static system it is not reasonable for a large system or a dynamic system. this access control problem can be solved only by additional mechanisms that will be described in chapter . many programming languages have incorporated the idea of the monitor as described in this section including concurrent pascal mesa c pronounced c sharp and java. other languages such as erlang provide some type of concurrency support using a similar mechanism. . synchronization examples we next describe the synchronization mechanisms provided by the solaris windows xp and linux operating systems as well as the pthreads api. we have chosen these three systems because they provide good examples of different approaches for synchronizing the kernel and we have included the pthreads api because it is widely used for thread creation and synchronization by developers on unix and linux systems. as you will see in this section the synchronization methods available in these differing systems vary in subtle and significant ways. . . synchronization in solaris to control access to critical sections solaris provides adaptive mutexes condition variables semaphores reader writer locks and turnstiles. solaris implements semaphores and condition variables essentially as they are presented chapter process synchronization java monitors java pros de .a monitor like concurrency mechani. m tor thread synchronization l verv nhjivl in ja a has as. ouated with it a single lurk.. when a method i declared to be synchron l zed calling thi method requires ouning the lovk tor the objivl. we declare a synchronized method by pkxing iiil synclirrm . zod ke vvd in the method definition. i in. following defines the safemelhcdo as synchronized for example ulii.j yyiiciiorii r.e.ri void r . .f 'u' lio..i . ltpli mi r i . .r ion n ijtshj'.nudu next .l i uiiu m crciilc on object instnncc of sircploclass lidi as siir.pleclass sc new simpleclasso invoking lln sc.safeketliod nu tliod n quirt owning ilio lock on liuobject inslaikl sc. if tlu lock is already ownod b anollk r thn id. the thread calling the synchronizfij mclhod blocks and is pl.u.ed in the entry sol lor ilio object's lock. the unlrv si l rqiresitrn the sel of lhn.md nailing lor tin luck to becomu available. if the lock is available vvhun a ayi chrondr ed method is called the calling ihivad lh. omh's the owner of the object' lo k and can enter the mclhod. the lock i released vvhon the lha ad exit i he inetlmd a thread from theenln sel is then sek cled . hie new owner of the lock. java also provides w a i t o and n o t i f y melhods. which are similar in function to t h r w a i t o and signal. o slalements lor a monitor. release l. i of the java virhial fachine pro ides aim support for semaphores condition variables jnd mute locks among other loncurreikv ineih.inisins' in the j a v a . irti . cor.currenl package. in sections . and . . in this section we describe adaptive mutexes readerwriter locks and turnstiles. an adaptive mutex protects access to every critical data item. on a multiprocessor system an adaptive mutex starts as a standard semaphore implemented as a spinlock. if the data are locked and therefore already in use the adaptive mutex does one of two things. if the lock is held by a thread that is currently running on another cpu the thread spins while waiting for the lock to become available because the thread holding the lock is likely to finish soon. if the thread holding the lock is not currently in run state the thread blocks going to sleep until it is awakened by the release of the lock. it is put to sleep so that it will not spin while waiting since the lock will not be freed very soon. a lock held by a sleeping thread is likely to be in this category. on a single processor system the thread holding the lock is never running if the . synchronization examples lock is being tested by another thread because only one thread can rijn at a time. therefore on this type of system threads always sleep rather than spin if they encounter a lock. solaris uses the adaptive mutex method to protect only data that are accessed by short code segments. that is a mutex is used if a lock will be held for less than a few hundred instructions. if the code segment is longer than that spin waiting will be exceedingly inefficient. for these longer code segments condition variables and semaphores are used. if the desired lock is already held the thread issues a wait and sleeps. when a thread frees the lock it issues a signal to the next sleeping thread in the queue. the extra cost of putting a thread to sleep and waking it and of the associated context switches is less than the cost of wasting several hundred instructions waiting in a spinlock. reader writer locks are used to protect data that are accessed frequently but are usually accessed in a read only manner. in these circumstances reader writer locks are more efficient than semaphores because multiple threads can read data concurrently whereas semaphores always serialize access to the data. reader writer locks are relatively expensive to implement so again they are used on only long sections of code. solaris uses turnstiles to order the list of threads waiting to acquire either an adaptive mutex or a reader writer lock. a turnstile is a queue structure containing threads blocked on a lock. for example if one thread currently owns the lock for a synchronized object all other threads trying to acquire the lock will block and enter the turnstile for that lock. when the lock is released the kernel selects a thread from the turnstile as the next owner of the lock. each synchronized object with at least one thread blocked on the object's lock requires a separate turnstile. however rather than associating a turnstile with each synchronized object solaris gives each kernel thread its own turnstile. because a thread can be blocked only on one object at a time this is more efficient than having a turnstile per object. the turnstile for the first thread to block on a synchronized object becomes the turnstile for the object itself. subsequent threads blocking on the lock will be added to this turnstile. when the initial thread ultimately releases the lock it gains a new turnstile from a list of free turnstiles maintained by the kernel. to prevent a priority inversion turnstiles are organized according to a priorityinheritance protocol section . . this means that if a lower priority thread currently holds a lock that a higher priority thread is blocked on the thread with the lower priority will temporarily inherit the priority of the higherpriority thread. upon releasing the lock the thread will revert to its original priority. note that the locking mechanisms used by the kernel are implemented for user level threads as well so the same types of locks are available inside and outside the kernel. a crucial implementation difference is the priorityinheritance protocol. kernel locking routines adhere to the kernel priorityinheritance methods used by the scheduler as described in section . user level thread locking mechanisms do not provide this functionality. to optimize solaris performance developers have refined and fine tuned the locking methods. because locks are used frequently and typically are used for crucial kernel functions tuning their implementation and use can produce great performance gains. chapter process synchronization . . synchronization in windows xp ? the windows xp operating system is a multithreaded kernel that provides support for real time applications and multiple processors. when the windows xp kernel accesses a global resource on a uniprocessor system it temporarily masks interrupts for all interrupt handlers that may also access the global resource. on a multiprocessor system windows xp protects access to global resources using spinlocks. just as in solaris the kernel uses spinlocks only to protect short code segments. furthermore for reasons of efficiency the kernel ensures that a thread will never be preempted while holding a spinlock. for thread synchronization outside the kernel windows xp provides dispatcher objects. using a dispatcher object threads synchronize according to several different mechanisms including mutexes semaphores events and timers. the system protects shared data by requiring a thread to gain ownership of a mutex to access the data and to release ownership when it is finished. semaphores behave as described in section . . events are similar to condition variables that is they may notify a waiting thread when a desired condition occurs. finally timers are used to notify one or more than one thread that a specified amount of time has expired. dispatcher objects may be in either a signaled state or a nonsignaled state. a signaled state indicates that an object is available and a thread will not block when acquiring the object. a nonsignaled state indicates that an object is not available and a thread will block when attempting to acquire the object. we illustrate the state transitions of a mutex lock dispatcher object in figure . . a relationship exists between the state of a dispatcher object and the state of a thread. when a thread blocks on a nonsignaled dispatcher object its state changes from ready to waiting and the thread is placed in a waiting queue for that object. when the state for the dispatcher object moves to signaled the kernel checks whether any threads are waiting on the object. if so the kernel moves one thread or possibly more threads from the waiting state to the ready state where they can resume executing. the number of threads the kernel selects from the waiting queue depends on the type of dispatcher object it is waiting on. the kernel will select only one thread from the waiting queue for a mutex since a mutex object may be owned by only a single thread. for an event object the kernel will select all threads that are waiting for the event. we can use a mutex lock as an illustration of dispatcher objects and thread states. if a thread tries to acquire a mutex dispatcher object that is in a nonsignaled state that thread will be suspended and placed in a waiting queue for the mutex object. when the mutex moves to the signaled state because another thread has released the lock on the mutex the thread waiting at the owner thread releases mutex lock thread acquires mutex lock figure . mutex dispatcher object. . synchronization examples front of the queue will be moved from the waiting state to the ready state and will acquire the mutex lock. we provide a programming project at the end of this chapter that uses mutex locks and semaphores in the win api. . . synchronization in linux prior to version . linux was a nonpreemptive kernel meaning that a process running in kernel mode could not be preempted even if a higher priority process became available to run. now however the linux kernel is fully preemptive so a task can be preempted when it is running in the kernel. the linux kernel provides spinlocks and semaphores as well as reader writer versions of these two locks for locking in the kernel. on smp machines the fundamental locking mechanism is a spinlock and the kernel is designed so that the spinlock is held only for short durations. on single processor machines spinlocks are inappropriate for use and are replaced by enabling and disabling kernel preemption. that is on single processor machines rather than holding a spinlock the kernel disables kernel preemption and rather than releasing the spinlock it enables kernel preemption. this is summarized below single processor multiple processors disable kernel preemption. acquire spin lock. enable kernel preemption. release spin lock. linux uses an interesting approach to disable and enable kernel preemption. it provides two simple system calls preempt disable and preempt .enable for disabling and enabling kernel preemption. in addition however the kernel is not preemptible if a kernel mode task is holding a lock. to enforce this each task in the system has a t h r e a d i n f o structure containing a counter preempt .count to indicate the number of locks being held by the task. when a lock is acquired preempt xount is incremented. it is decremented when a lock is released. if the value of preempt count for the task currently running is greater than zero it is not safe to preempt the kernel as this task currently holds a lock. if the count is zero the kernel can safely be interrupted assuming there are no outstanding calls to preempt disable . spinlocks along with enabling and disabling kernel preemption are used in the kernel only when a lock or disabling kernel preemption is held for a short duration. when a lock must be held for a longer period semaphores are appropriate for use. . . synchronization in pthreads the pthreads api provides mutex locks condition variables and read write locks for thread synchronization. this api is available for programmers and is not part of any particular kernel. mutex locks represent the fundamental synchronization technique used with pthreads. a mutex lock is used to protect critical sections of code that is a thread acquires the lock before entering a critical section and releases it upon exiting the critical section. condition variables in pthreads behave much as described in section . . read write chapter process synchronization locks behave similarly to the locking mechanism described in section . . . many systems that implement pthreads also provide semaphores although they are not part of the pthreads standard and instead belong to the posix sem extension. other extensions to the pthreads api include spinlocks although not all extensions are considered portable from one implementation to another. we provide a programming project at the end of this chapter that uses pthreads mutex locks and semaphores
 the mutual exclusion of critical sections ensures that the critical sections are executed atomically. that is if two critical sections are executed concurrently the result is equivalent to their sequential execution in some unknown order. although this property is useful in many application domains in many cases we would like to make sure that a critical section forms a single logical unit of work that either is performed in its entirety or is not performed at all. an example is funds transfer in which one account is debited and another is credited. clearly it is essential for data consistency either that both the credit and debit occur or that neither occur. consistency of data along with storage and retrieval of data is a concern often associated with database systems. recently there has been an upsurge of interest in using database systems techniques in operating systems. operating systems can be viewed as manipulators of data as such they can benefit from the advanced techniques and models available from database research. for instance many of the ad hoc techniques used in operating systems to manage files could be more flexible and powerful if more formal database methods were used in their place. in sections . . to . . we describe some of these database techniques and explain how they can be used by operating systems. first however we deal with the general issue of transaction atomicity. it is this property that the database techniques are meant to address. . . system model a collection of instructions or operations that performs a single logical function is called a transaction. a major issue in processing transactions is the preservation of atomicity despite the possibility of failures within the computer system. we can think of a transaction as a program unit that accesses and perhaps updates various data items that reside on a disk within some files. from our point of view such a transaction is simply a sequence of read and write operations terminated by either a commit operation or an abort operation. a commit operation signifies that the transaction has terminated its execution successfully whereas an abort operation signifies that the transaction has ended its normal execution due to some logical error or a system failure. if a terminated transaction has completed its execution successfully it is committed otherwise it is aborted. since an aborted transaction may already have modified the data that it has accessed the state of these data may not be the same as it would have been if the transaction had executed atomically. so that atomicity is ensured . atomic transactions an aborted transaction must have no effect on the state of the data that it has already modified. thus the state of the data accessed by an aborted transaction must be restored to what it was just before the transaction started executing. we say that such a transaction has been rolled back. it is part of the responsibility of the system to ensure this property. to determine how the system should ensure atomicity we need first to identify the properties of devices used for storing the various data accessed by the transactions. various types of storage media are distinguished by their relative speed capacity and resilience to failure. volatile storage. information residing in volatile storage does not usually survive system crashes. examples of such storage are main and cache memory. access to volatile storage is extremely fast both because of the speed of the memory access itself and because it is possible to access directly any data item in volatile storage. nonvolatile storage. information residing in nonvolatile storage usually survives system crashes. examples of media for such storage are disks and magnetic tapes. disks are more reliable than main memory but less reliable than magnetic tapes. both disks and tapes however are subject to failure which may result in loss of information. currently nonvolatile storage is slower than volatile storage by several orders of magnitude because disk and tape devices are electromechanical and require physical motion to access data. stable storage. information residing in stable storage is never lost never should be taken with a grain of salt since theoretically such absolutes cannot be guaranteed . to implement an approximation of such storage we need to replicate information in several nonvolatile storage caches usually disk with independent failure modes and to update the information in a controlled manner section . . here we are concerned only with ensuring transaction atomicity in an environment where failures result in the loss of information on volatile storage. . . log based recovery one way to ensure atomicity is to record on stable storage information describing all the modifications made by the transaction to the various data it accesses. the most widely used method for achieving this form of recording is write ahead logging. here the system maintains on stable storage a data structure called the log. each log record describes a single operation of a transaction write and has the following fields transaction name. the unique name of the transaction that performed the write operation data item name. the unique name of the data item written old value. the value of the data item prior to the write operation new value. the value that the data item will have after the write chapter process synchronization other special log records exist to record significant events during transaction processing such as the start of a transaction and the commit or abort of a transaction. before a transaction t starts its execution the record t s t a r t s is written to the log. during its execution any write operation by t is preceded by the writing of the appropriate new record to the log. when commits the record t commits is written to the log. because the information in the log is used in reconstructing the state of the data items accessed by the various transactions we cannot allow the actual update to a data item to take place before the corresponding log record is written out to stable storage. we therefore require that prior to execution of a write x operation the log records corresponding to x be written onto stable storage. note the performance penalty inherent in this system. two physical writes are required for every logical write requested. also more storage is needed both for the data themselves and for the log recording the changes. in cases where the data are extremely important and fast failure recovery is necessary the price is worth the functionality. using the log the system can handle any failure that does not result in the loss of information on nonvolatile storage. the recovery algorithm uses two procedures undo tj which restores the value of all data updated by transaction t to the old values redo tj which sets the value of all data updated by transaction t to the new values the set of data updated by and their respective old and new values can be found in the log. the undo and redo operations must be idempotent that is multiple executions must have the same result as does one execution to guarantee correct behavior even if a failure occurs during the recovery process. if a transaction aborts then we can restore the state of the data that it has updated by simply executing undo . if a system failure occurs we restore the state of all updated data by consulting the log to determine which transactions need to be redone and which need to be undone. this classification of transactions is accomplished as follows transaction needs to be undone if the log contains the t s t a r t s record but does not contain the t commits record. transaction t needs to be redone if the log contains both the t s t a r t s and the commits records. . . checkpoints when a system failure occurs we must consult the log to determine those transactions that need to be redone and those that need to be undone. in principle we need to search the entire log to make these determinations. there are two major drawbacks to this approach . atomic transactions . the searching process is time consuming. . most of the transactions that according to our algorithm need to be redone have already actually updated the data that the log says they need to modify. although redoing the data modifications will cause no harm due to idempotency it will nevertheless cause recovery to take longer. to reduce these types of overhead we introduce the concept of checkpoints. during execution the system maintains the write ahead log. in addition the system periodically performs checkpoints that require the following sequence of actions to take place . output all log records currently residing in volatile storage usually main memory onto stable storage. . output all modified data residing in volatile storage to the stable storage. . output a log record checkpoint onto stable storage. the presence of a checkpoint record in the log allows the system to streamline its recovery procedure. consider a transaction tj that committed prior to the checkpoint. the t commit s record appears in the log before the checkpoints record. any modifications made by tj must have been written to stable storage either prior to the checkpoint or as part of the checkpoint itself. thus at recovery time there is no need to perform a redo operation on tj. this observation allows us to refine our previous recovery algorithm. after a failure has occurred the recovery routine examines the log to determine the most recent transaction that started executing before the most recent checkpoint took place. it finds such a transaction by searching the log backward to find the first checkpoint record and then finding the subsequent ti s t a r t record. once transaction tj has been identified the redo and undo operations need be applied only to transaction tj and all transactions tj that started executing after transaction tj . we'll call these transactions set t. the remainder of the log can thus be ignored. the recovery operations that are required are as follows a for all transactions tjt in t such that the record tj commits appears in the log execute redo t t . for all transactions tj in t that have no ti commits record in the log execute undo to . . concurrent atomic transactions we have been considering an environment in which only one transaction can be executing at a time. we now turn to the case where multiple transactions are active simultaneously. because each transaction is atomic the concurrent execution of transactions must be equivalent to the case where these transactions are executed serially in some arbitrary order. this property called serializability can be maintained by simply executing each transaction within chapter process synchronization a critical section. that is all transactions share a common semaphore mutex which is initialized to . when a transaction starts executing its first action is to execute wa. t mutex . after the transaction either commits or aborts it executes signal ?z ta' although this scheme ensures the atomicity of all concurrently executing transactions it is nevertheless too restrictive. as we shall see in many cases we can allow transactions to overlap their execution while maintaining serializability. a number of different concurrency control algorithms ensure serializability. these algorithms are described below. . . . serializability consider a system with two data items a and b that are both read and written by two transactions to and t . suppose that these transactions are executed atomically in the order to followed by t . this execution sequence which is called a schedule is represented in figure . . in schedule of figure . the sequence of instruction steps is in chronological order from top to bottom with instructions of to appearing in the left column and instructions of t appearing in the right column. a schedule in which each transaction is executed atomically is called a serial schedule. a serial schedule consists of a sequence of instructions from various transactions wherein the instructions belonging to a particular transaction appear together. thus for a set of n transactions there exist n different valid serial schedules. each serial schedule is correct because it is equivalent to the atomic execution of the various participating transactions in some arbitrary order. if we allow the two transactions to overlap their execution then the resulting schedule is no longer serial. a nonserial schedule does not necessarily imply an incorrect execution that is an execution that is not equivalent to one represented by a serial schedule . to see that this is the case we need to define the notion of conflicting operations. consider a schedule s in which there are two consecutive operations o and oj of transactions t and tj respectively. we say that o and oj conflict if they access the same data item and at least one of them is a w r i t e operation. to illustrate the concept of conflicting operations we consider the nonserial tn t read a write a read b write b read a write a read b write b figure . schedule a serial schedule in which to is followed by i. . atomic transactions read a write a read a write a read b write b read b write b figure . schedule a concurrent serializable schedule. schedule of figure . . the write a operation of to conflicts with the read a operation of ti. however the write a operation of t does not conflict with the read b operation of to because the two operations access different data items. let oj and oj be consecutive operations of a schedule s. if o and o are operations of different transactions and o and oj do not conflict then we can swap the order of o and to produce a new schedule s'. we expect s to be equivalent to s' as all operations appear in the same order in both schedules except for o and oj whose order does not matter. we can illustrate the swapping idea by considering again schedule of figure . . as the write a operation of t does not conflict with the read b operation of to we can swap these operations to generate an equivalent schedule. regardless of the initial system state both schedules produce the same final system state. continuing with this procedure of swapping nonconflicting operations we get swap the read b operation of tq with the read a operation of t . swap the write b operation of to with the write a operation of t . swap the write b operation of to with the read a operation of t . the final result of these swaps is schedule in figure . which is a serial schedule. thus we have shown that schedule is equivalent to a serial schedule. this result implies that regardless of the initial system state schedule will produce the same final state as will some serial schedule. if a schedule s can be transformed into a serial schedule s' by a series of swaps of nonconflicting operations we say that a schedule s is conflict serializable. thus schedule is conflict serializable because it can be transformed into the serial schedule . . . . locking protocol one way to ensure serializability is to associate with each data item a lock and to require that each transaction follow a locking protocol that governs how locks are acquired and released. there are various modes in which a data item can be locked. in this section we restrict our attention to two modes chapter process synchronization shared. if a transaction x has obtained a shared mode lock denoted by s on data item q then can read this item but cannot write q. exclusive. if a transaction t has obtained an exclusive mode lock denoted by x on data item q then can both read and write q. we require that every transaction request a lock in an appropriate mode on data item q depending on the type of operations it will perform on q. to access data item q transaction must first lock q in the appropriate mode. if q is not currently locked then the lock is granted and t can now access it. however if the data item q is currently locked by some other transaction then may have to wait. more specifically suppose that requests an exclusive lock on q. in this case must wait until the lock on q is released. if t requests a shared lock on q then must wait if q is locked in exclusive mode. otherwise it can obtain the lock and access q. notice that this scheme is quite similar to the readers writers algorithm discussed in section . . . a transaction may unlock a data item that it locked at an earlier point. it must however hold a lock on a data item as long as it accesses that item. moreover it is not always desirable for a transaction to unlock a data item immediately after its last access of that data item because serializability may not be ensured. one protocol that ensures serializability is the two phase locking protocol. this protocol requires that each transaction issue lock and unlock requests in two phases growing phase. a transaction may obtain locks but may not release any lock. shrinking phase. a transaction may release locks but may not obtain any new locks. initially a transaction is in the growing phase. the transaction acquires locks as needed. once the transaction releases a lock it enters the shrinking phase and no more lock requests can be issued. the two phase locking protocol ensures conflict serializability exercise . . it does not however ensure freedom from deadlock. in addition it is possible that for a given set of transactions there are conflict serializable schedules that cannot be obtained by use of the two phase locking protocol. however to improve performance over two phase locking we need either to have additional information about the transactions or to impose some structure or ordering on the set of data. . . . timestamp based protocols in the locking protocols described above the order followed by pairs of conflicting transactions is determined at execution time by the first lock that both request and that involves incompatible modes. another method for determining the serializability order is to select an order in advance. the most common method for doing so is to use a timestamp ordering scheme. with each transaction t in the system we associate a unique fixed timestamp denoted by ts t . this timestamp is assigned by the system . atomic transactions before the transaction t starts execution. if a transaction has been assigned timestamp ts tj and later a new transaction enters the system then ts ts tj . there are two simple methods for implementing this scheme use the value of the system clock as the timestamp that is a transaction's timestamp is equal to the value of the clock when the transaction enters the system. this method will not work for transactions that occur on separate systems or for processors that do not share a clock. use a logical counter as the timestamp that is a transaction's timestamp is equal to the value of the counter when the transaction enters the system. the counter is incremented after a new timestamp is assigned. the timestamps of the transactions determine the serializability order. thus if ts t ts t then the system must ensure that the produced schedule is equivalent to a serial schedule in which transaction t appears before transaction t . to implement this scheme we associate with each data item q two timestamp values w timestamp q denotes the largest timestamp of any transaction that successfully executed write q . r timestamp q denotes the largest timestamp of any transaction that successfully executed read q . these timestamps are updated whenever a new read q or write q instruction is executed. the timestamp ordering protocol ensures that any conflicting read and write operations are executed in timestamp order. this protocol operates as follows suppose that transaction t issues read q o if ts t w timestamp then t needs to read a value of q that was already overwritten. hence the read operation is rejected and tj is rolled back. o if ts tj w timestamp q then the read operation is executed and r timestamp q is set to the maximum of r timestamp q and ts t . suppose that transaction issues write q o if ts t r timestamp q then the value of q that is producing was needed previously and t assumed that this value would never be produced. hence the write operation is rejected and is rolled back. if ts t w timestamp q then t is attempting to write an obsolete value of q. hence this write operation is rejected and t is rolled back. o otherwise the write operation is executed. a transaction t that is rolled back as a result of the issuing of either a read or write operation is assigned a new timestamp and is restarted. chapter process synchronization t read b read b write b read a read a write a figure . schedule a schedule possible under the timestamp protocol. to illustrate this protocol consider schedule of figure . which includes transactions and t . we assume that a transaction is assigned a timestamp immediately before its first instruction. thus in schedule ts t ts t and the schedule is possible under the timestamp protocol. this execution can also be produced by the two phase locking protocol. however some schedules are possible under the two phase locking protocol but not under the timestamp protocol and vice versa. the timestamp protocol ensures conflict serializability. this capability follows from the fact that conflicting operations are processed in timestamp order. the protocol also ensures freedom from deadlock because no transaction ever waits
 a system consists of a finite number of resources to be distributed among a number of competing processes. the resources are partitioned into several types each consisting of some number of identical instances. memory space cpu cycles files and i o devices such as printers and dvd drives are examples chapter deadlocks of resource types. if a system has two cpus then the resource type cpu has two instances. similarly the resource type printer may have five instances. if a process requests an instance of a resource type the allocation of any instance of the type will satisfy the request. if it will not then the instances are not identical and the resource type classes have not been defined properly. for example a system may have two printers. these two printers may be defined to be in the same resource class if no one cares which printer prints which output. however if one printer is on the ninth floor and the other is in the basement then people on the ninth floor may not see both printers as equivalent and separate resource classes may need to be defined for each printer. a process must request a resource before using it and must release the resource after using it. a process may request as many resources as it requires to carry out its designated task. obviously the number of resources requested may not exceed the total number of resources available in the system. in other words a process cannot request three printers if the system has only two. under the normal mode of operation a process may utilize a resource in only the following sequence . request. if the request cannot be granted immediately for example if the resource is being used by another process then the requesting process must wait until it can acquire the resource. . use the process can operate on the resource for example if the resource is a printer the process can print on the printer . . release. the process releases the resource. the request and release of resources are system calls as explained in chapter . examples are the request and release device open and close file and a l l o c a t e and free memory system calls. request and release of resources that are not managed by the operating system can be accomplished through the waito and signal operations on semaphores or through acquisition and release of a mutex lock. for each use of a kernelmanaged resource by a process or thread the operating system checks to make sure that the process has requested and has been allocated the resource. a system table records whether each resource is free or allocated for each resource that is allocated the table also records the process to which it is allocated. if a process requests a resource that is currently allocated to another process it can be added to a queue of processes waiting for this resource. a set of processes is in a deadlock state when every process in the set is waiting for an event that can be caused only by another process in the set. the events with which we are mainly concerned here are resource acquisition and release. the resources maybe either physical resources for example printers tape drives memory space and cpu cycles or logical resources for example files semaphores and monitors . however other types of events may result in deadlocks for example the pc facilities discussed in chapter . to illustrate a deadlock state consider a system with three cd rvv drives. suppose each of three processes holds one of these cd rw drives. if each process now requests another drive the three processes will be in a deadlock state. each is waiting for the event cd rvv is released which can be caused
 only by one of the other waiting processes. this example illustrates a deadlock involving the same resource type. deadlocks may also involve different resource types. for example consider a system with one printer and one dvd d rive. suppose that process p. is holding the dvd and process p is holding the printer. if p requests the printer and p. requests the dvd drive a deadlock occurs. a programmer who is developing multithreaded applications must pay particular attention to this problem. multithreaded programs are good candidates for deadlock because multiple threads can. compete for shared resources. . deadlock characterization in a deadlock processes never finish executing and system resources are tied up preventing other jobs from starting. before we discuss the various methods for dealing with the deadlock problem we look more closely at features that characterize deadlocks. . . necessary conditions a deadlock situation can arise if the following four conditions hold simultaneously in a system . mutual exclusion. at least one resource must be held in a nonsharable mode that is only one process at a time can use the resource. if another process requests that resource the requesting process must be delayed until the resource has been released. deadlock with mutex locks let's see how deadlock can occur in a multithreaded pthread program using mutex locks. the pthreadjnutex iaitd function initializes an unlocked mutex. mutex locks are acquired and released using ptiar ead.b'u i ex. ldclc a nd p thre adjmitex. unlock x ' respec ' tively. if a th raad .attempts to acquire a . locked niutex . ihg . call ita x.. ptiireati.inviubx lacikio blocks the thready until the ovvner of the rnufiex ieok invokes pt jire ad. iinjitexi uril c k . locks are createci inihe following cad? example . i .. .. . . create and .initialize .the .mut ex locks 'xx . p trire.adjmitex..t i i.r.st.jjiiitez . . .. l. !i.. i ....!...i .. dthread.ifflitex t secon d miitex 'm l i pthread mitex. init.c f.i.rst.mutfix. ..elill . . .. ... .. . ... . next two threads thread one and thxead.twp are crea ed and both tliese threads have access to both mutex locks thrfac cine and t h r e a d ..two run in the functions do..work oneo and do.work twc respectively as shown in figure . . s chapter deadlocks eli rsa d .on riirfs ici siife gij i t igii s sofaej dhirsaeiiimia sjsiufl. jcitr i if . ' tliread .t wo ruris in tti veld gto wqrk j wo !ydid jparanj do scbtrie work k if f r s t jmit ex pthread rnubek unlock i sec figure deadlock example. i .. in this example threaclpne aherripts toagquiire' sie iixvupx iilocks an the ordex first jnutex seeandjmiltbx i h ! e ttesadltwo'aiiteniipfento acgujre the rriutex locks in the order tq secbn m l p j i r l nites tspossibfcjif tliread q ne acquires mote that even though dead lock is pfossi ble i twill riot eeeuhiifirie a t o is able to acquire and release the rrvutex locks lor fiest utex ahd secoiid.mutex before threkd fwo atteiiipfe to acquire tke ibcks this example tllustratey a probiem with handjing deadlocks i t is c!i!tieult ts identify and test for deadlocks thai mav occttr omly tinder certain ckfetims teiinces. . . hold and wait. a process must be holding at least one resource and waiting to acquire additional resources that are currently being held by other processes. . no preemption. resources cannot be preempted. that is a resource can be released only voluntarily by the process holding it after that process has completed its task. . deadlock characterization . circular wait. a set p pi ... pn of waiting processes must exist such that p is waiting for a resource held by p p is waiting for a resource held by p? p. i is waiting for a resource held by pn and p is waiting for a resource held by pn. we emphasize that all four conditions must hold for a deadlock to occur. the circular wait condition implies the hold and wait condition so the four conditions are not completely independent. we shall see in section . however that it is useful to consider each condition separately . . resource allocation graph deadlocks can be described more precisely in terms of a directed graph called a system resource allocation graph. this graph consists of a set of vertices v and a set of edges e. the set of vertices v is partitioned into two different types of nodes p pi pi .. p the set consisting of all the active processes in the system and r r r? rm the set consisting of all resource types in the system. a directed edge from process p to resource type rj is denoted by p r it signifies that process p has requested an instance of resource type r and is currently waiting for that resource. a directed edge from resource type rj to process p is denoted by rj p it signifies that an instance of resource type rj has been allocated to process p . a directed edge p rj is called a request edge a directed edge rj p is called an assignment edge. pictorially we represent each process p as a circle and each resource type ri as a rectangle. since resource type rj may have more than one instance we represent each such instance as a dot within the rectangle. note that a request edge points to only the rectangle r whereas an assignment edge must also designate one of the dots in the rectangle. when process p requests an instance of resource type rj a request edge is inserted in the resource allocation graph. when this request can be fulfilled the request edge is instantaneously transformed to an assignment edge. when the process no longer needs access to the resource it releases the resource as a result the assignment edge is deleted. the resource allocation graph shown in figure . depicts the following situation. the sets p r and o p php p? o r ?! rz r r o p ru p r r p f r p r p. r p resource instances o one instance of resource type r o two instances of resource type i?? ' one instance of resource type rj r three instances of resource type r chapter deadloc s figure . resource allocation graph. process states o process p is holding an instance of resource type r and is waiting for an instance of resource type r . o process pn is holding an instance of r and an instance of r and is waiting for an instance of r . o process p is holding an instance of r . given the definition of a resource allocation graph it can be shown that if the graph contains no cycles then no process in the system is deadlocked. if the graph does contain a cycle then a deadlock may exist. if each resource type has exactly one instance then a cycle implies that a deadlock has occurred. if the cycle involves only a set of resource types each of which has only a single instance then a deadlock has occurred. each process involved in the cycle is deadlocked. in this case a cycle in the graph is both a necessary and a sufficient condition for the existence of deadlock. if each resource type has several instances then a cycle does not necessarily imply that a deadlock has occurred. in this case a cycle in the graph is a necessary but not a sufficient condition for the existence of deadlock. to illustrate this concept we return to the resource allocation graph depicted in figure . . suppose that process p requests an instance of resource type rt. since no resource instance is currently available a request edge p r? is added to the graph figure . . at this point two minimal cycles exist in the svstem pi p. r pt pi processes p p and p are deadlocked. process p is waiting for the resource r which is held by process p . process p is waiting for either process p or . deadlock characterization r figure . resource allocation graph with a deadlock. process pi to release resource ri. in addition process pi is waiting for process p? to release resource ri. now consider the resource allocation graph in figure . . in this example we also have a cycle however there is no deadlock. observe that process p may release its instance of resource type r?. that resource can then be allocated to p breaking the cycle in sunimary if a resource allocation graph does not have a cycle then the system is not in a deadlocked state. if there is a cycle then the system may or may not be in a deadlocked state. this observation is important when we deal with the deadlock problem. figure . resource allocation graph with a cycle but no deadlock. chapter? deadlocks
 generally speaking we can deal with the deadlock problem in one of three ways we can use a protocol to prevent or avoid deadlocks ensuring that the system will never enter a deadlock state. we can allow the system to enter a deadlock state detect it and recover. we can ignore the problem altogether and pretend that deadlocks never occur in the system. the third solution is the one used by most operating systems including ljmtx and windows it is then up to the application developer to write programs that handle deadlocks. next we elaborate briefly on each of the three methods for handling deadlocks. then in sections . through . we present detailed algorithms. however before proceeding we should mention that some researchers have argued that none of the basic approaches alone is appropriate for the entire spectrum of resource allocation problems in operating systems. the basic approaches can be combined however allowing us to select an optimal approach for each class of resources in a system. to ensure that deadlocks never occur the system can use either a deadlockprevention or a deadlock avoidance scheme. deadlock prevention provides a set of methods for ensuring that at least one of the necessary conditions section . . cannot hold. these methods prevent deadlocks by constraining how requests for resources can be made. we discuss these methods in section . . deadlock avoidance requires that the operating system be given in advance additional information concerning which resources a process will request and use during its lifetime. with this additional knowledge it can decide for each request whether or not the process should wait. to decide whether the current request can be satisfied or must be delayed the system must consider the resources currently available the resources currently allocated to each process and the future requests and releases of each process. we discuss these schemes in section . . if a system does not employ either a deadlock prevention or a deadlockavoidance algorithm then a deadlock situation may arise. in this environment the system can provide an algorithm that examines the state of the system to determine whether a deadlock has occurred and an algorithm to recover from the deadlock if a deadlock has indeed occurred . we discuss these issues in section . and section . . if a system neither ensures that a deadlock will never occur nor provides a mechanism for deadlock detection and recovery then we may arrive at a situation where the system is in a deadlocked state yet has no way of recognizing what has happened. in this case the undetected deadlock will result in deterioration of the system's performance because resources are being held by processes that cannot run and because more and more processes as they make requests for resources will enter a deadlocked state. eventually the system will stop functioning and will need to be restarted manually
 although this method may not seem to be a viable approach to the deadlock problem it is nevertheless used in most operating systems as mentioned earlier. in many systems deadlocks occur infrequently say once per year thus this method is cheaper than the prevention avoidance or detection and recovery methods which must be used constantly also in some circumstances a system is in a frozen state but not in a deadlocked state. we see this situation for example with a real time process running at the highest priority or any process running on a nonpreemptive scheduler and never returning control to the operating system. the system must have manual recovery methods for such conditions and may simply use those techniques for deadlock recovery. . deadlock prevention as we noted in section . . for a deadlock to occur each of the four necessary conditions must hold. by ensuring that at least one of these conditions cannot hold we can prevent the occurrence of a deadlock. we elaborate on this approach by examining each of the four necessary conditions separately. . . mutual exclusion the mutual exclusion condition must hold for nonsharable resources. for example a printer cannot be simultaneously shared by several processes. sharable resources in contrast do not require mutually exclusive access and thus cannot be involved in a deadlock. read only files are a good example of a sharable resource. if several processes attempt to open a read only file at the same time they can be granted simultaneous access to the file. a process never needs to wait for a sharable resource. in general however we cannot prevent deadlocks by denying the mutual exclusion condition because some resources are intrinsically nonsharable . . hold and wait to ensure that the hold and wait condition never occurs in the system we must guarantee that whenever a process requests a resource it does not hold any other resources. one protocol that can be used requires each process to request and be allocated all its resources before it begins execution. we can implement this provision by requiring that system calls requesting resources for a process precede all other system calls. an alternative protocol allows a process to request resources only when it has none. a process may request some resources and use them. before it can request any additional resources however it must release all the resources that it is currently allocated. to illustrate the difference between these two protocols we consider a process that copies data from a dvd drive to a file on disk sorts the file and then prints the results to a printer. if all resources must be requested at the beginning of the process then the process must initially request the dvd drive disk file and printer. it will hold the printer for its entire execution even though it needs the printer only at the end. the second method allows the process to request initially only the dvd drive and disk file. it copies from the dvd drive to the disk and then releases chapter deadlocks both the dvd drive and the disk file. the process must then again request the disk file and the printer. after copying the disk file to the printer it releases these two resources and terminates. both these protocols have two main disadvantages. first resource utilization may be low since resources may be allocated but unused for a long period. in the example given for instance we can release the dvd drive and disk file and then again request the disk file and printer only if we can be sure that our data will remain on the disk file. if we cannot be assured that they will then we must request all resources at the beginning for both protocols. second starvation is possible. a process that needs several popular resources may have to wait indefinitely because at least one of the resources that it needs is always allocated to some other process. . . no preemption the third necessary condition for deadlocks is that there be no preemption of resources that have already been allocated. to ensure that this condition does not hold we can use the following protocol. if a process is holding some resources and requests another resource that cannot be immediately allocated to it that is the process must wait then all resources currently being held are preempted. in other words these resources are implicitly released. the preempted resources are added to the list of resources for which the process is waiting. the process will be restarted only when it can regain its old resources as well as the new ones that it is requesting. alternatively if a process requests some resources we first check whether they are available. if they are we allocate them. if they are not we check whether they are allocated to some other process that is waiting for additional resources. if so we preempt the desired resources from the waiting process and allocate them to the requesting process. if the resources are neither available nor held by a waiting process the requesting process must wait. while it is waiting some of its resources may be preempted but only if another process requests them. a process can be restarted only when it is allocated the new resources it is requesting and recovers any resources that were preempted while it was waiting. this protocol is often applied to resources whose state can be easily saved and restored later such as cpu registers and memory space. it cannot generally be applied to such resources as printers and tape drives. . . circular wait the fourth and final condition for deadlocks is the circular wait condition. one way to ensure that this condition never holds is to impose a total ordering of all resource types and to require that each process requests resources in an increasing order of enumeration. to illustrate we let r r ri ... rm be the set of resource types. we assign to each resource type a unique integer number which allows us to compare two resources and to determine whether one precedes another in our ordering. formally we define a one to one function f r n where n is the set of natural numbers. for example if the set of resource types r includes . deadlock prevention tape drives disk drives and printers then the function f might be defined as follows f tape drive f di.s.k drive f printer we can now consider the following protocol to prevent deadlocks each process can request resources only in an increasing order of enumeration. that is a process can initially request any number of instances of a resource type say r . after that the process can request instances of resource type r if and only if f r f r . if several instances of the same resource type are needed a single request for all of them must be issued. for example using the function defined previously a process that wants to use the tape drive and printer at the same time must first request the tape drive and then request the printer. alternatively we can require that whenever a process requests an instance of resource type r it has released any resources r. such that f rj f rj . if these two protocols are used then the circular wait condition cannot hold. we can demonstrate this fact by assuming that a circular wait exists proof by contradiction . let the set of processes involved in the circular wait be pq p ... p where p. is waiting for a resource r which is held by process p i. modulo arithmetic is used on the indexes so that p is waiting for a resource r held by po then since process p. i is holding resource r while requesting resource r i we must have f r f r i for all i. but this condition means that f r f r f r f r . by transitivity f ro f rq which is impossible. therefore there can be no circular wait. we can accomplish this scheme in an application program by developing an ordering among all synchronization objects in the system. all requests for synchronization objects must be made in increasing order. for example if the lock ordering in the pthread program shown in figure . was f first mutex f second mutex then threacltwo could not request the locks out of order. keep in mind that developing an ordering or hierarchy in itself does not prevent deadlock. it is up to application developers to write programs that follow the ordering. also note that the function f should be defined according to the normal order of usage of the resources in a system. for example because the tape drive is usually needed before the printer it would be reasonable to define f tape drive f printer . although ensuring that resources are acquired in the proper order is the responsibility of application developers certain software can be used to verify that locks are acquired in the proper order and to give appropriate warnings when locks are acquired out of order and deadlock is possible. one lock order verifier which works on bsd versions of unix such as freebsd is known as witness. witness uses mutual exclusion locks to protect critical sections as described in chapter it works by dynamically maintaining the relationship of lock orders in a system. let's use the program shown in figure . as an example. assume that threaclone is the tirst to acquire the locks and does so in chapter deadlocks the order firstjnutex secondjnutex. witness records the relationship that f i r s t jnutex must be acquired before secondjnutex. if threacltwo later acquires the locks out of order witness generates a warning message on the system console. 
 deadlock prevention algorithms as discussed in section . prevent deadlocks by restraining how requests can be made. the restraints ensure that at least one of the necessary conditions for deadlock cannot occur and hence that deadlocks cannot hold. possible side effects of preventing deadlocks by this method however are low device utilization and reduced system throughput. an alternative method for avoiding deadlocks is to require additional information about how resources are to be requested. for example in a system with one tape drive and one printer the system might need to know that process p will request first the tape drive and then the printer before releasing both resources whereas process q will request first the printer and then the tape drive. with this knowledge of the complete sequence of requests and releases for each process the system can decide for each request whether or not the process should wait in order to avoid a possible future deadlock. each request requires that in making this decision the system consider the resources currently available the resources currently allocated to each process and the future requests and releases of each process. the various algorithms that use this approach differ in the amount and type of information required. the simplest and most useful model requires that each process declare the maximum number of resources of each type that it may need. given this a priori information it is possible to construct an algorithm that ensures that the system will never enter a deadlocked state. such an algorithm defines the deadlock avoidance approach. a deadlock avoidance algorithm dynamically examines the resource allocation state to ensure that a circularwait condition can never exist. the resource allocation state is defined by the number of available and allocated resources and the maximum demands of the processes. in the following sections we explore two deadlock avoidance algorithms. . . safe state a state is safe if the system can allocate resources to each process up to its maximum in some order and still avoid a deadlock. more formally a system is in a safe state only if there exists a safe sequence. a sequence of processes p p? ... pn is a safe sequence for the current allocation state if for each pi the resource requests that p can still make can be satisfied by the currently available resources plus the resources held by all pi with . in this situation if the resources that pi needs are not immediately available then p can wait until all pj have finished. when they have finished p can obtain all of its needed resources complete its designated task return its allocated resources and terminate. when p terminates p l can obtain its needed resources and so on. if no such sequence exists then the system state is said to be unsafe. deadlock avoidance j deadlock. safe figure . safe unsafe and deadlock state spaces. a safe state is not a deadlocked state. conversely a deadlocked state is an unsafe state. not all unsafe states are deadlocks however figure . . an unsafe state may lead to a deadlock. as long as the state is safe the operating system can avoid unsafe and deadlocked states. in an unsafe state the operating system cannot prevent processes from requesting resources such that a deadlock occurs the behavior of the processes controls unsafe states. to illustrate we consider a system with magnetic tape drives and three processes pll p and p . process pq requires tape drives process pi may need as many as tape drives and process p? may need up to tape drives. suppose that at time to process pq is holding tape drives process p is holding tape drives and process p is holding tape drives. thus there are free tape drives. maximum needs current needs po pi p at time fo the system is in a safe state. the sequence pi po ? satisfies the safety condition. process pj can immediately be allocated all its tape drives and then return them the system will then have available tape drives then process pl can get all its tape drives and return them the system will then have available tape drives and finally process p can get all its tape drives and return them the system will then have all tape drives available . a system can go from a safe state to an unsafe state. suppose that at time t process pz requests and is allocated one more tape drive. the system is no longer in a safe state. at this point only process p can be allocated all its tape drives. when it returns them the system will have only available tape drives. since process pp is allocated tape drives but has a maximum of it may request more tape drives. since they are unavailable process po must wait. similarly process p? may request an additional tape drives and have to wait resulting in a deadlock. our mistake was in granting the request from process pi for one more tape drive. if we had made p wait until either of the other chapter deadlocks processes had finished and released its resources then we could have avoided the deadlock. given the concept of a safe state we can define avoidance algorithms that ensure that the system will never deadlock. the idea is simply to ensure that the system will always remain in a safe state. initially the system is in a safe state. whenever a process requests a resource that is currently available the system must decide whether the resource can be allocated immediately or whether the process must wait. the request is granted only if the allocation leaves the system in a safe state. in this scheme if a process requests a resource that is currently available it may still have to wait. thus resource utilization may be lower than it would otherwise be. . . resource allocation graph algorithm if we have a resource allocation system with only one instance of each resource type a variant of the resource allocation graph defined in section . . can be used for deadlock avoidance. in addition to the request and assignment edges already described we introduce a new type of edge called a claim edge. a claim edge p rj indicates that process p may request resource r at some time in the future. this edge resembles a request edge in direction but is represented in the graph by a dashed line. when process p. requests resource rj the claim edge p rj is converted to a request edge. similarly when a resource rj is released by pj the assignment edge rj p is reconverted to a claim edge p rj. we note that the resources must be claimed a priori in the system. that is before process p starts executing all its claim edges must already appear in the resource allocation graph. we can relax this condition by allowing a claim edge p r to be added to the graph only if all the edges associated with process p are claim edges. suppose that process p requests resource rj. the request can be granted only if converting the request edge p rj to an assignment edge rj p does not result in the formation of a cycle in the resource allocation graph. note that we check for safety by using a cycle detection algorithm. an algorithm for detecting a cycle in this graph requires an order of n operations where n is the number of processes in the system. if no cycle exists then the allocation of the resource will leave the system in a safe state. if a cycle is found then the allocation will put the system in figure . resource allocation graph for deadlock avoidance. . deadlock avoidance figure . an unsafe state in a resource allocation graph. an unsafe state. therefore process p will have to wait for its requests to be satisfied. to illustrate this algorithm we consider the resource allocation graph of figure . . suppose that pi requests r?. although ri is currently free we cannot allocate it to p since this action will create a cycle in the graph figure . . a cycle indicates that the system is in an unsafe state. if pi requests r and po requests r then a deadlock will occur. . . banker's algorithm the resource allocation graph algorithm is not applicable to a resourceallocation system with multiple instances of each resource type. the deadlockavoidance algorithm that we describe next is applicable to such a system but is less efficient than the resource allocation graph scheme. this algorithm is commonly known as the banker's algorithm. the name was chosen because the algorithm could be used in a banking system to ensure that the bank never allocated its available cash in such a way that it could no longer satisfy the needs of all its customers. when a new process enters the system it must declare the maximum number of instances of each resource type that it may need. this number may not exceed the total number of resources in the system. when a user requests a set of resources the system must determine whether the allocation of these resources will leave the system in a safe state. if it will the resources are allocated otherwise the process must wait until some other process releases enough resources. several data structures must be maintained to implement the banker's algorithm. these data structures encode the state of the resource allocation system. let n be the number of processes in the system and m be the number of resource types. we need the following data structures available. a vector of length m indicates the number of available resources of each type. if availab!c f equals k there are k instances of resource type ri available. max. an n x m matrix defines the maximum demand of each process. if m .t equals k then process p may request at most k instances of resource type ? . chapter deadlocks allocation. an n x in matrix defines the number of resources of each type currently allocated to each process. if allocation i j equals k then process pi is currently allocated k instances of resource type ? . need. an n x m matrix indicates the remaining resource need of each process. if need i j equals k then process p may need k more instances of resource type r to complete its task. note that need equals max i j allocntion i j . these data structures vary over time in both size and value. to simplify the presentation of the banker's algorithm we next establish some notation. let x and y be vectors of length n. we say that x y if and only if x i y for all ... n. for example if x and y then y x. y x if y x and y x. we can treat each row in the matrices allocation and need as vectors and refer to them as allocation and need . the vector allocation specifies the resources currently allocated to process p the vector needi specifies the additional resources that process p may still request to complete its task. . . . safety algorithm we can now present the algorithm for finding out whether or not a system is in a safe state. this algorithm can be described as follows . let work and finish be vectors of length in and n respectively. initialize work available and fiiush i false for ... n l. . find an such that both a. finish i false b. need work if no such exists go to step . . work work allocation finish i true go to step . . if finisli i true for all. then the system is in a safe state. this algorithm may require an order of m x it operations to determine whether a state is safe. . . . resource request algorithm we now describe the algorithm which determines if requests can be safely granted. let request be the request vector for process p . if request ' k then process p wants k instances of resource type r . when a request for resources is made by process p the following actions are taken . if request need go to step . otherwise raise an error condition since the process has exceeded its maximum claim. . deadlock avoidance . if request available go to step . otherwise ps must wait since the resources are not available. . have the system pretend to have allocated the requested resources to process p by modifying the state as follows available available request allocation allocation request need necdj request if the resulting resource allocation state is safe the transaction is completed and process p is allocated its resources. however if the new state is unsafe then p must wait for request and the old resource allocation state is restored. . . . an illustrative example finally to illustrate the use of the banker's algorithm consider a system with five processes pq through p and three resource types a b and c. resource type a has instances resource type b has instances and resource type c has instances. suppose that at time to the following snapshot of the system has been taken allocation max available abc abc abc po p pi pj pi the content of the matrix need is defined to be max allocation and is as follows need abc pi pi p p we claim that the system is currently in a safe state. indeed the sequence p p pa pi po satisfies the safety criteria. suppose now that process p requests one additional instance of resource type a and two instances of resource type c so request . to decide whether this request can be immediately granted we first check that request available that is that which is true. we then pretend that this request has been fulfilled and we arrive at the following new state chapter deadlocks allocation need av abc abc abc p ! pi p p pi we must determine whether this new system state is safe. to do so we execute our safety algorithm and find that the sequence p pj pi po pi satisfies the safety requirement. hence we can immediately grant the request of process p . you should be able to see however that when the system is in this state a request for by p cannot be granted since the resources are not available. furthermore a request for by po cannot be granted even though the resources are available since the resulting state is unsafe. we leave it as a programming exercise to implement the banker's algorithm
 if a system does not employ either a deadlock prevention or a deadlockavoidance algorithm then a deadlock situation may occur. in this environment the system must provide an algorithm that examines the state of the system to determine whether a deadlock has occurred an algorithm to recover from the deadlock in the following discussion we elaborate on these two requirements as they pertain to systems with only a single instance of each resource type as well as to systems with several instances of each resource type. at this point however we note that a detection and recovery scheme requires overhead that includes not only the run time costs of maintaining the necessary information and executing the detection algorithm but also the potential losses inherent in recovering from a deadlock. . . single instance of each resource type if all resources have only a single instance then we can define a deadlockdetection algorithm that uses a variant of the resource allocation graph called a wait for graph. we obtain this graph from the resource allocation graph by removing the resource nodes and collapsing the appropriate edges. more precisely an edge from p to p in a wait for graph implies that process p is waiting for process p to release a resource that p needs. an edge p p exists in a wait for graph if and only if the corresponding resourceallocation graph contains two edges p r j and r p for some resource . deadlock detection figure . a resource allocation graph b corresponding wait for graph. r . for example in figure . we present a resource allocation graph and. the corresponding wait for graph. as before a deadlock exists in the system if and only if the wait for graph contains a cycle. to detect deadlocks the system needs to maintain the wait for graph and periodically invoke an algorithm that searches for a cycle in the graph. an algorithm to detect a cycle in a graph requires an order of n operations where n is the number of vertices in the graph. . . several instances of a resource type the wait for graph scheme is not applicable to a resource allocation system with multiple instances of each resource type. we turn now to a deadlockdetection algorithm that is applicable to such a system. the algorithm employs several time varying data structures that are similar to those used in the banker's algorithm section . . available. a vector of length m indicates the number of available resources of each type. allocation. an n x m matrix defines the number of resources of each type currently allocated to each process. request. an n x in matrix indicates the current request of each process. if request i j equals k then process p is requesting k more instances of resource type rj. the s relation between two vectors is defined as in section . . . to simplify notation we again treat the rows in the matrices allocation and request as vectors we refer to them as allocation and request . the detection algorithm chapter deadlocks described here simply investigates every possible allocation sequence f r the processes that remain to be completed. compare this algorithm with the banker's algorithm of section . . . . let work and finish be vectors of length in and n respectively. initialize work available. for i ... n if allocation then finish i false otherwise finisli i true. . find an index i such that both a. finish i false b. requesti work if no such exists go to step . . work work allocation! finish i true go to step . . if finish i false for some ' n then the system is in a deadlocked state. moreover if finish i false then process p is deadlocked. this algorithm requires an order of in x n operations to detect whether the system is in a deadlocked state. you may wonder why we reclaim the resources of process p in step as soon as we determine that request work in step b . we know that p is currently not involved in a deadlock since request work . thus we take an optimistic attitude and assume that p will require no more resources to complete its task it will thus soon return all currently allocated resources to the system. if our assumption is incorrect a deadlock may occur later. that deadlock will be detected the next time the deadlock detection algorithm is invoked. to illustrate this algorithm we consider a system with five processes pq through p and three resource types a b and c. resource type a has seven instances resource type b has two instances and resource type c has six instances. suppose that at time to we have the following resource allocation state allocation request available abc abc abc po pj p p p we claim that the system is not in a deadlocked state. indeed if we execute our algorithm we will find that the sequence pn pi pi p pa results in finish i true for all i. . deadlock detection suppose now that process pj makes one additional request for an instance of type c. the request matrix is modified as follows reilitest a bc pi! a i pi p pi we claim that the system is now deadlocked. although we can reclaim the resources held by process po the number of available resources is not sufficient to fulfill the requests of the other processes. thus a deadlock exists consisting of processes pi pi p and p . . . detection algorithm usage when should we invoke the detection algorithm? the answer depends on two factors . how often is a deadlock likely to occur? . how many processes will be affected by deadlock when it happens? if deadlocks occur frequently then the detection algorithm should be invoked frequently. resources allocated to deadlocked processes will be idle until the deadlock can be broken. in addition the number of processes involved in the deadlock cycle may grow. deadlocks occur only when some process makes a request that cannot be granted immediately. this request may be the final request that completes a chain of waiting processes. in the extreme we can invoke the deadlockdetection algorithm every time a request for allocation cannot be granted immediately. in this case we can identify not only the deadlocked set of processes but also the specific process that caused the deadlock. in reality each of the deadlocked processes is a link in the cycle in the resource graph so all of them jointly caused the deadlock. if there are many different resource types one request may create many cycles in the resource graph each cycle completed by the most recent request and caused by the one identifiable process. of course if the deadlock detection algorithm is invoked for every resource request this will incur a considerable overhead in computation time. a less expensive alternative is simply to invoke the algorithm at less frequent intervals for example once per hour or whenever cpu utilization drops below percent. a deadlock eventually cripples system throughput and causes cpu utilization to drop. if the detection algorithm is invoked at arbitrary points in time there may be many cycles in the resource graph. in this case we would generally not be able to tell which of the many deadlocked processes caused the deadlock. chapter? deadlocks
 when a detection algorithm determines that a deadlock exists several alternatives are available. one possibility is to inform the operator that a deadlock has occurred and to let the operator deal with the deadlock manually. another possibility is to let the system recover from the deadlock automatically. there are two options for breaking a deadlock. one is simply to abort one or more processes to break the circular wait. the other is to preempt some resources from one or more of the deadlocked processes. . . process termination to eliminate deadlocks by aborting a process we use one of two methods. in both methods the system reclaims all resources allocated to the terminated processes. abort all deadlocked processes. this method clearly will break the deadlock cycle but at great expense the deadlocked processes may have computed for a long time and the results of these partial computations must be discarded and probably will have to be recomputed later. abort one process at a time until the deadlock cycle is eliminated. this method incurs considerable overhead since after each process is aborted a deadlock detection algorithm must be invoked to determine whether any processes are still deadlocked. aborting a process may not be easy. if the process was in the midst of updating a file terminating it will leave that file in an incorrect state. similarly if the process was in the midst of printing data on a printer the system must reset the printer to a correct state before printing the next job. if the partial termination method is used then we must determine which deadlocked process or processes should be terminated. this determination is a policy decision similar to cpu scheduling decisions. the question is basically an economic one we should abort those processes whose termination will incur the minimum cost. unfortunately the term minimum cost is not a precise one. many factors may affect which process is chosen including . what the priority of the process is . how long the process has computed and how much longer the process will compute before completing its designated task . how many and what type of resources the process has used for example whether the resources are simple to preempt . how many more resources the process needs in order to complete . how many processes will need to be terminated . whether the process is interactive or batch
 as we saw in chapter memory is central to the operation of a modern computer system . memory consists of a large array of words or bytes each with its own address. the cpu fetches instructions from memory according to the value of the program counter. these instructions may cause additional loading from and storing to specific memory addresses. a typical instruction execution cycle for example first fetches an instruction from memory the instruction is then decoded and may cause operands to be fetched from memory. after the instruction has been executed on the chapter main memory operands results may be stored back in memory. the memory unit sees ortly a stream of memory addresses it does not know how they are generated by the instruction counter indexing indirection literal addresses and so on or what they are for instructions or data . accordingly we can ignore ha w a program generates a memory address. we are interested only in the sequence of memory addresses generated by the running program. we begin our discussion by covering several issues that are pertinent to the various techniques for managing memory. this includes an overview of basic hardware issues the binding of symbolic memory addresses to actual physical addresses and distinguishing between logical and physical addresses. we conclude with a discussion of dynamically loading and linking code and shared libraries. . . basic hardware main memory and the registers built into the processor itself are the only storage that the cpu can access directly. there are machine instructions that take memory addresses as arguments but none that take disk addresses. therefore any instructions in execution and any data being used by the instructions must be in one of these direct access storage devices. if the data are not in memory they must be moved there before the cpl can operate on them. registers that are built into the cpu are generally accessible within one cycle of the cpu clock. most cpus can decode instructions and perform simple operations on register contents at the rate of one or more operations per clock tick. the same cannot be said of main memory which is accessed via a transaction on the memory bus. memory access may take many cycles of the cpu clock to complete in which case the processor normally needs to stall since it does not have the data required to complete the instruction that it is executing. this situation is intolerable because of the frequency of memory operating ' . jsystenn process tm process base process limit figure . a base and a limit register define a logical address space. . background accesses. the remedy is to add fast memory between the cpu and main memory. a memory buffer used to accommodate a speed differential called a cache. is described in section . . . not only are we concerned with the relative speed of accessing physical memory but we also must ensure correct operation has to protect the operating system from access by user processes and in addition to protect user processes from one another. this protection must be provided by the hardware. it can be implemented in several ways as we shall see throughout the chapter. in this section we outline one possible implementation. we first need to make sure that each process has a separate memory space. to do this we need the ability to determine the range of legal addresses that the process may access and to ensure that the process can access only these legal addresses. we can provide this protection by using two registers usually a base and a limit as illustrated in figure . . the base register holds the smallest legal physical memory address the limit register specifies the size of the range. for example if the base register holds and limit register is then the program can legally access all addresses from through inclusive . protection of memory space is accomplished by having the cpu hardware compare even address generated in user mode with the registers. any attempt by a program executing in user mode to access operating system memory or other users' memory results in a trap to the operating system which treats the attempt as a fatal error figure . . this scheme prevents a user program from accidentally or deliberately modifying the code or data structures of either the operating system or other users. the base and limit registers can be loaded only by the operating system which uses a special privileged instruction. since privileged instructions can be executed only in kernel mode and since only the operating system executes in kernel mode only the operating system can load the base and limit registers. this scheme allows the operating system to change the value of the registers but prevents user programs from changing the registers' contents. the operating system executing in kernel mode is given unrestricted access to both operating system and users' memory. this provision allows trap to operating system memory monitor addressing error figure . hardware address protection with base and limit registers. chapter main memory the operating system to load users' programs into users' memory to durrtp out those programs in case of errors to access and modify parameters of system calls and so on. . . address binding usually a program resides on a disk as a binary executable file. to be executed the program must be brought into memory and placed within a process. depending on the memory management in use the process may be moved between disk and memory during its execution. the processes on the disk that are waiting to be brought into memory for execution form the input queue. the normal procedure is to select one of the processes in the input queue and to load that process into memory. as the process is executed it accesses instructions and data from memory. eventually the process terminates and its memory space is declared available. most systems allow a user process to reside in any part of the physical memory. thus although the address space of the computer starts at the first address of the user process need not be . this approach affects the addresses that the user program can use. in most cases a user program will go through several steps some of which maybe optional before being executed figure . . addresses may be represented in different ways during these steps. addresses in the source program are generally symbolic such as count . a compiler will typically bind these symbolic addresses to relocatable addresses such as bytes from the beginning of this module'' . the linkage editor or loader will in turn bind the relocatable addresses to absolute addresses such as . each binding is a mapping from one address space to another. classically the binding of instructions and data to memory addresses can be done at any step along the way compile time. if you know at compile time where the process will reside in memory then absolute code can be generated. for example if you know that a user process will reside starting at location r then the generated compiler code will start at that location and extend up from there. if at some later time the starting location changes then it will be necessary to recompile this code. the ms dos .com fo.nn.at programs are bound at compile time. load time. if it is not known at compile time where the process will reside in memory then the compiler must generate relocatable code. in this case final binding is delayed until load time. if the starting address changes we need only reload the user code to incorporate this changed value. execution time. if the process can be moved during its execution from one memory segment to another then binding must be delayed until run time. special hardware must be available for this scheme to work as will be discussed in section . . . most general purpose operating systems use this method. a major portion of this chapter is devoted to showing how these various bindings can be implemented effectively in a computer system and to discussing appropriate hardware support. . background compile time a v ' ' ot ect othe i module i objsct y v modules z . linkage sdiioi oad y load vy module i time system library loader aynamically loaded i systerr . library in mernorydynamic binary executk linking memory time ru image time figure . multistep processing of a user program. . . logical versus physical address space an address generated by the cpu is commonly referred to as a logical address whereas an address seen by the memory unit that is the one loaded into the memory address register of the memory is commonly referred to as a physical address. the compile time and load time address binding methods generate identical logical and physical addresses. however the execution time addressbinding scheme results in differing logical and physical addresses. in this case we usually refer to the logical address as a virtual address. we use logical address and virtual address interchangeably in this text. the set of all logical addresses generated by a program is a logical address space the set of all physical addresses corresponding to these logical addresses is a physical address space. thus in the execution time address binding scheme the logical and physical address spaces differ. the run time mapping from virtual to physical addresses is done by a hardware device called the memory management unit mmu . we can choose from many different methods to accomplish such mapping as we discuss in chapter main memory logical physical address address mmu figure . dynamic relocation using a relocation register. sections . through . . for the time being we illustrate this mapping with a simple mmu scheme which is a generalization of the base register scheme described in section . . . the base register is now called a relocation register. the value in the relocation register is added to every address generated by a user process at the time it is sent to memory see figure . . for example if the base is at then an attempt by the user to address location is dynamically relocated to location an access to location is mapped to location . the ms dos operating system running on. the intel x family of processors uses four relocation registers when loading and running processes. the user program never sees the real physical addresses. the program can create a pointer to location store it in memory manipulate it and compare it with other addresses all as the number . only when it is used as a memory address in an indirect load or store perhaps is it relocated relative to the base register. the user program deals with logical addresses. the memory mapping hardware converts logical addresses into physical addresses. this form of execution time binding was discussed in section . . . the final location of a referenced memory address is not determined until the reference is made. we now have two different types of addresses logical addresses in the range to max and physical addresses in the range r to r max for a base value r . the user generates only logical addresses and thinks that the process runs in locations to max. the user program supplies logical addresses these logical addresses must be mapped to physical addresses before they are used. the concept of a logical address space that is bound to a separate physical address space is central to proper memory management. . . dynamic loading in our discussion so far the entire program and all data of a process must be in physical memory for the process to execute. the size of a process is thus limited to the size of physical memory. to obtain better memory space utilization we can use dynamic loading. with dynamic loading a routine is not loaded until it is called. all routines are kept on disk in a relocatable load format. the main . background program is loaded into memory and is executed. when a routine needs to call another routine the calling routine first checks to see whether the other routine has been loaded. if not the relocatable linking loader is called to load the desired routine into memory and to update the program's address tables to reflect this change. then control is passed to the newly loaded routine. the advantage of dynamic loading is that an unused routine is never loaded. this method is particularly useful when large amounts of code are needed to handle infrequently occurring cases such as error routines. in this case although the total program size may be large the portion that is used and hence loaded may be much smaller. dynamic loading does not require special support from the operating system. it is the responsibility of the users to design their programs to take advantage of such a method. operating systems may help the programmer however by providing library routines to implement dynamic loading. . . dynamic linking and shared libraries figure . also shows dynamically linked libraries. some operating systems support only static linking in which system language libraries are treated like any other object module and are combined by the loader into the binary program image. the concept of dynamic linking is similar to that of dynamic loading. here though linking rather than loading is postponed until execution time. this feature is usually used with system libraries such as language subroutine libraries. without this facility each program on a system must include a copy of its language library or at least the routines referenced by the program in the executable image. this requirement wastes both disk space and main memory. with dynamic linking a stub is included in the image for each libraryroutine reference. the stub is a small piece of code that indicates how to locate the appropriate memory resident library routine or how to load the library if the routine is not already present. when the stub is executed it checks to see whether the needed routine is already in memory. if not the program loads the routine into memory. either way the stub replaces itself with the address of the routine and executes the routine. thus the next time that particular code segment is reached the library routine is executed directly incurring no cost for dynamic linking. under this scheme all processes that use a language library execute only one copy of the library code. this feature can be extended to library updates such as bug fixes . a library may be replaced by a new version and all programs that reference the library wrill automatically use the new version. without dynamic linking all such programs would need to be relinked to gain access to the new library. so that programs will not accidentally execute new incompatible versions of libraries version information is included in both the program and the library. more than one version of a library may be loaded into memory and each program uses its version information to decide which copy of the library to use. minor changes retain the same version number whereas major changes increment the version number. thus only programs that are compiled with the new library version are affected by the incompatible changes incorporated in it. other programs linked before the new library was installed will continue using the older library. this system is also known as shared libraries. chapter s main memory unlike dynamic loading dynamic linking generally requires help from the operating system. if the processes in memory are protected from one another then the operating system is the only entity that can check to see whether the needed routine is in another process's memory space or that can allow multiple processes to access the same memory addresses. we elaborate on this concept when we discuss paging in section
 a process must be in memory to be executed. a process however can be swapped temporarily out of memory to a backing store and then brought back into memory for continued execution. for example assume a multiprogramming environment with a round robin cpu scheduling algorithm. when a quantum expires the memory manager will start to swap out the process that just finished and to swap another process into the memory space that has been freed figure . . in the meantime the cpu scheduler will allocate a time slice to some other process in memory. when each process finishes its quantum it will be swapped with another process. ideally the memory manager can swap processes fast enough that some processes will be in memory ready to execute when the cpu scheduler wants to reschedule the cpu. in addition the quantum must be large enough to allow reasonable amounts of computing to be done between swaps. a variant of this swapping policy is used for priority based scheduling algorithms. if a higher priority process arrives and wants service the memory manager can swap out the lower priority process and then load and execute the higher priority process. when the higher priority process finishes the lower priority process can be swapped back in and continued. this variant of swapping is sometimes called roll out roll in. backing store main memory figure . swapping of two processes using a disk as a backing store. . swapping normally a process that is swapped out will be swapped back into the same memory space it occupied previously. this restriction is dictated by the method of address binding. if binding is done at assembly or load time then the process cannot be easily moved to a different location. if execution time binding is being used however then a process can be swapped into a different memory space because the physical addresses are computed during execution time. swapping requires a backing store. the backing store is commonly a fast disk. it must be large enough to accommodate copies of all memory images for all users and it must provide direct access to these memory images. the system maintains a ready queue consisting of all processes whose memory images are on the backing store or in memory and are ready to run. wlienever the cpu scheduler decides to execute a process it calls the dispatcher. the dispatcher checks to see whether the next process in the queue is in memory. if it is not and if there is no free memory region the dispatcher swaps out a process currently in memory and swaps in the desired process. it then reloads registers and transfers control to the selected process. the context switch time in such a swapping system is fairly high. to get an idea of the context switch time let us assume that the user process is mb in size and the backing store is a standard hard disk with a transfer rate of mb per second. the actual transfer of the mb process to or from main memory takes kb kb per second second milliseconds. assuming that no head seeks are necessary and assuming an average latency of milliseconds the swap time is milliseconds. since we must both swap out and swap in the total swap time is about milliseconds. for efficient cpu utilization we want the execution time for each process to be long relative to the swap time. thus in a round robin cpu scheduling algorithm for example the tune quantum should be substantially larger than . seconds. notice that the major part of the swap time is transfer time. the total transfer time is directly proportional to the amount of memory swapped. if we have a computer system with mb of main memory and a resident operating system taking mb the maximum size of the user process is mb. however many user processes may be much smaller than this say mb. a mb process could be swapped out in milliseconds compared with the . seconds required for swapping mb. clearly it would be useful to know exactly how much memory a user process is using not simply how much it might be using. then we would need to swap only what is actually used reducing swap time. for this method to be effective the user must keep the system informed of any changes in memory requirements. thus a process with dynamic memory requirements will need to issue system calls request memory and r e l e a s e memory to inform the operating system of its changing memory needs. swapping is constrained by other factors as well. if we want to swap a process we must be sure that it is completely idle. of particular concern is any pending i o. a process may be waiting for an i o operation when chapter main memory we want to swap that process to free up memory. however if the i o is asynchronously accessing the user memory for i o buffers then the process cannot be swapped. assume that the i o operation is queued because the device is busy. if we were to swap out process pi and swap in process po the i o operation might then attempt to use memory that now belongs to process pi. there are two main solutions to this problem never swap a process with pending i o or execute i o operations only into operating system buffers. transfers between operating system buffers and process memory then occur only when the process is swapped in. the assumption mentioned earlier that swapping requires few if any head seeks needs further explanation. we postpone discussing this issue until chapter where secondary storage structure is covered. generally swap space is allocated as a chunk of disk separate from the file system so that its use is as fast as possible. currently standard swapping is used in few systems. it requires too much swapping time and provides too little execution time to be a reasonable memory management solution. modified versions of swapping however are found on many systems. a modification of swapping is used in many versions of unix. swapping is normally disabled but will start if many processes are running and are using a threshold amount of memory. swapping is again halted when the load on the system is reduced. memory management in unix is described fully in sections . and a. . early pcs which lacked the sophistication to implement more advanced memory management methods ran multiple large processes by using a modified version of swapping. a prime example is the microsoft windows . operating system which supports concurrent execution of processes in memory. if a new process is loaded and there is insufficient main memory an old process is swapped to disk. this operating system however does not provide full swapping because the user rather than the scheduler decides when it is time to preempt one process for another. any swapped out process remains swapped out and not executing until the user selects that process to run. subsequent versions of microsoft operating systems take advantage of the advanced mmu features now found in pcs. we explore such features in section . and in chapter where we cover virtual memory
 the main memory must accommodate both the operating system and the various user processes. we therefore need to allocate the parts of the main memory in the most efficient way possible. this section explains one common method contiguous memory allocation. the memory is usually divided into two partitions one for the resident operating system and one for the user processes. we can place the operating system in either low memory or high memory. the major factor affecting this decision is the location of the interrupt vector. since the interrupt vector is often in low memory programmers usually place the operating system in low memory as well. thus in this text we discuss only the situation where . contiguous memory allocation the operating system resides in low memory. the development of the? other situation is similar. we usually want several user processes to reside in memory at the same time. we therefore need to consider how to allocate available memory to the processes that are in the input queue waiting to be brought into memory. in this contiguous memory allocation each process is contained in a single contiguous section of memory. . . memory mapping and protection before discussing memory allocation further we must discuss the issue of memory mapping and protection. we can provide these features by using a relocation register as discussed in section . . with a limit register as discussed in section . . . the relocation register contains the value of the smallest physical address the limit register contains the range of logical addresses for example relocation and limit . with relocation and limit registers each logical address must be less than the limit register the vimu maps the logical address dynamically by adding the value in the relocation register. this mapped address is sent to memory figure . . when the cpu scheduler selects a process for execution the dispatcher loads the relocation and limit registers with the correct values as part of the context switch. because every address generated by the cpu is checked against these registers we can protect both the operating system and the other users' programs and data from being modified by this running process. the relocation register scheme provides an effective way to allow the operating system size to change dynamically. this flexibility is desirable in many situations. for example the operating system contains code and buffer space for device drivers. if a device driver or other operating system service is not commonly used we do not want to keep the code and data in memory as we might be able to use that space for other purposes. such code is sometimes called transient operating system code it comes and goes as needed. thus using this code changes the size of the operating system during program execution. limit relocation register registelogical physical address yes y n address cpu no trap addressing error figure . hardware support for relocation and limit registers. chapter main memory . . memory ahocation now we are ready to turn to memory allocation. one of the simplest methods for allocating memory is to divide memory into several fixed sized partitions. each partition may contain exactly one process. thus the degree of multiprogramming is bound by the number of partitions. in this multiplepartition method when a partition is free a process is selected from the input queue and is loaded into the free partition. when the process terminates the partition becomes available for another process. this method was originally used by the ibm os operating system called mft it is no longer in use. the method described next is a generalization of the fixed partition scheme called mvt it is used primarily in batch environments. many of the ideas presented here are also applicable to a time sharing environment in which pure segmentation is used for memory management section . . in the fixed partition scheme the operating system keeps a table indicating which parts of memory are available and which are occupied. initially all memory is available for user processes and is considered one large block of available memory a hole. when a process arrives and needs memory we search for a hole large enough for this process. if we find one we allocate only as much memory as is needed keeping the rest available to satisfy future requests. as processes enter the system they are put into an input queue. the operating system takes into account the memory requirements of each process and the amount of available memory space in determining which processes are allocated memory. when a process is allocated space it is loaded into memory and it can then compete for the cpu. when a process terminates it releases its memory which the operating system may then fill with another process from the input queue. at any given time we have a list of available block sizes and the input queue. the operating system can order the input queue according to a scheduling algorithm. memory is allocated to processes until finally the memory requirements of the next process cannot be satisfied that is no available block of memory or hole is large enough to hold that process. the operating system can then wait until a large enough block is available or it can skip down the input queue to see whether the smaller memory requirements of some other process can be met. in general at any given time we have a set of holes of various sizes scattered throughout memory. when a process arrives and needs memory the system searches the set for a hole that is large enough for this process. if the hole is too large it is split into two parts. one part is allocated to the arriving process the other is returned to the set of holes. when a process terminates it releases its block of memory which is then placed back in the set of holes. if the new hole is adjacent to other holes these adjacent holes are merged to form one larger hole. at this point the system may need to check whether there are processes waiting for memory and whether this newly freed and recombined memory could satisfy the demands of any of these waiting processes. this procedure is a particular instance of the general dynamic storageallocation problem which concerns how to satisfy a request of size n from a list of free holes. there are many solutions to this problem. the first fit best fit and worst fit strategies are the ones most commonly used to select a free hole from the set of available holes. . contiguous memory allocation first fit. allocate the first hole that is big enough. searching can start either at the beginning of the set of holes or where the previous first fit search ended. we can stop searching as soon as we find a free hole that is large enough. best fit. allocate the smallest hole that is big enough. we must search the entire list unless the list is ordered by size. this strategy produces the smallest leftover hole. worst fit. allocate the largest hole. again we must search the entire list unless it is sorted by size. this strategy produces the largest leftover hole which may be more useful than the smaller leftover hole from a best fit approach. simulations have shown that both first fit and best fit are better than worst fit in terms of decreasing time and storage utilization. neither first fit nor best fit is clearly better than the other in terms of storage utilization but first fit is generally faster. . . fragmentation both the first fit and best fit strategies for memory allocation suffer from external fragmentation. as processes are loaded and removed from memory the free memory space is broken into little pieces. external fragmentation exists when there is enough total memory space to satisfy a request but the available spaces are not contiguous storage is fragmented into a large number of small holes. this fragmentation problem can be severe. in the worst case we could have a block of free or wasted memory between every two processes. if all these small pieces of memory were in one big free block instead we might be able to run several more processes. whether we are using the first fit or best fit strategy can affect the amount of fragmentation. first fit is better for some systems whereas best fit is better for others. another factor is which end of a free block is allocated. which is the leftover piece the one on the top or the one on the bottom? no matter which algorithm is used external fragmentation will be a problem. depending on the total amount of memory storage and the average process size external fragmentation may be a .minor or a major problem. statistical analysis of first fit for instance reveals that even with some optimization given n allocated blocks another . n blocks will be lost to fragmentation. that is one third of memory may be unusable! this property is known as the percent rule. memory fragmentation can be internal as well as external. consider a multiple partition allocation scheme with a hole of bytes. suppose that the next process requests bytes. if we allocate exactly the requested block we are left with a hole of bytes. the overhead to keep track of this hole will be substantially larger than the hole itself. the general approach to avoiding this problem is to break the physical memory into fixed sized blocks and allocate memory in units based on block size. with this approach the memory allocated to a process may be slightly larger than the requested memory. the difference between these two numbers is internal fragmentation memory that is internal to a partition but is not being used. chapter main memory one solution to the problem of external fragmentation is compaction. the goal is to shuffle the memory contents so as to place all free memory together in one large block. compaction is not always possible however. if relocation is static and is done at assembly or load time compaction cannot be done compaction is possible only if relocation is dynamic and is done at execution time. if addresses are relocated dynamically relocation requires only moving the program and data and then changing the base register to reflect the new base address. when compaction is possible we must determine its cost. the simplest compaction algorithm is to move all processes toward one end of memory all holes move in the other direction producing one large hole of available memory. this scheme can be expensive. another possible solution to the external fragmentation problem is to permit the logical address space of the processes to be noncontiguous thus allowing a process to be allocated physical memory wherever the latter is available. two complementary techniques achieve this solution paging section . and segmentation section . . these techniques can also be combined section . 
 is a memory management scheme that permits the physical address space of a process to be noncontiguous. paging avoids the considerable problem of fitting memory chunks of varying sizes onto the backing store most memory management schemes used before the introduction of paging suffered from this problem. the problem arises because when some code fragments or data residing in main memory need to be swapped out space must be found logical physical l address address f i it physical memory page table figure . paging hardware. . paging on the backing store. the backing store also has the fragmentation problems discussed in connection with main memory except that access is much slower so compaction is impossible. because of its advantages over earlier methods paging in its various forms is commonly used in. most operating systems. traditionally support for paging has been handled by hardware. however recent designs have implemented paging by closely integrating the hardware and operating system especially on bit microprocessors. . . basic method the basic method for implementing paging involves breaking physical memory into fixed sized blocks called frames and breaking logical memory into blocks of the same size called pages. when a process is to be executed its pages are loaded into any available memory frames from the backing store. the backing store is divided into fixed sized blocks that are of the same size as the memory frames. the hardware support for paging is illustrated in figure . . every address generated by the cpu is divided into two parts a page number p and a page offset d . the page number is used as an index into a page table. the page table contains the base address of each page in physical memory. this base address is combined with the page offset to define the physical memory address that is sent to the memory unit. the paging model of memory is shown in figure . . the page size like the frame size is defined by the hardware. the size of a page is typically a power of varying between bytes and mb per page depending on the computer architecture. the selection of a power of as a page size makes the translation of a logical address into a page number frame number page page op age o ' page w page page table logical page i memory lil'llf page physical memory figure . paging model of logical and physical memory. chapter main memory and page offset particularly easy. if the size of logical address space is ' and a page size is addressing units bytes or words then the high order m n bits of a logical address designate the page number and the n low order bits designate the page offset. thus the logical address is as follows page number page offset m n where p is an index into the page table and d is the displacement within the page. as a concrete although minuscule example consider the memory in figure . . using a page size of bytes and a physical memory of bytes pages we show how the user's view of memory can be mapped into physical memory. logical address is page offset . indexing into the page table we find that page is in frame . thus logical address maps to physical address x . logical address page offset maps to physical address x . logical address is page offset according to the page table page is mapped to frame . thus logical address maps to physical address x . logical address maps to physical address . a a b ! ! ... id e .s f h i ' i!! ! k i page table it! til p. logical memory ?n a la g d e f q ft physical memory figure . paging example for a byte memory with byte pages. . paging you may have noticed that paging itself is a form of dynamic relocation. every logical address is bound by the paging hardware to some physical address. using paging is similar to using a table of base or relocation registers one for each frame of memory. when we use a paging scheme we have no external fragmentation an free frame can be allocated to a process that needs it. however we may have some internal fragmentation. notice that frames are allocated as units. if the memory requirements of a process do not happen to coincide with page boundaries the last frame allocated may not be completely full. for example if page size is bytes a process of bytes would need pages phis bytes. it would be allocated frames resulting in an internal fragmentation of bytes. in the worst case a process would need n pages plus byte. it would be allocated n frames resulting in an internal fragmentation of almost an entire frame. if process size is independent of page size we expect internal fragmentation to average one half page per process. this consideration suggests that small page sizes are desirable. however overhead is involved in each page table entry and this overhead is reduced as the size of the pages increases. also disk i o is more efficient when the number of data being transferred is larger chapter . generally page sizes have grown over time as processes data sets and main memory have become larger. today pages typically are between kb and kb in size and some systems support even larger page sizes. some cpus and kernels even support multiple page sizes. for instance solaris uses page sizes of kb and mb depending on the data stored by the pages. researchers are now developing variable on the fly page size support. usually each page table entry is bytes long but that size can vary as well. a bit entry can point to one of physical page frames. if frame size is kb then a system with byte entries can address bytes or tb of physical memory. when a process arrives in the system to be executed its size expressed in pages is examined. each page of the process needs one frame. thus if the process requires n pages at least n frames must be available in memory. if n frames are available they are allocated to this arriving process. the first page of the process is loaded into one of the allocated frames and the frame number is put in. the page table for this process. the next page is loaded into another frame and its frame number is put into the page table and so on figure . . an important aspect of paging is the clear separation between the user's view of memory and the actual physical memory. the user program views memory as one single space containing only this one program. in fact the user program is scattered throughout physical memory which also holds other programs. the difference between the user's view of memory and the actual physical memory is reconciled by the address translation hardware. the logical addresses are translated into physical addresses. this mapping is hidden from the user and is controlled by the operating system. notice that the user process by definition is unable to access memory it does not own. it has no way of addressing memory outside of its page table and the table includes only those pages that the process owns. since the operating system is managing physical memory it must be aware of the allocation details of physical memory which frames are allocated which frames are available how manv total frames there are and so on. this chapter main memory free frame lis free frame lis jul j nuirtih i nrrr p ge i n j ui i ui 'pdgec page . .! ! ! ipago paye pdse page paije hi new piocesd t v oroceas h hr h' pgge pp. !i iii ! new process page table a b figure . free frames a before allocation and b after allocation. information is generally kept in a data structure called a frame table. the frame table has one entry for each physical page frame indicating whether the latter is free or allocated and if it is allocated to which page of which process or processes. in addition the operating system must be aware that user processes operate in user space and all logical addresses must be mapped to produce physical addresses. if a user makes a system call to do i o for example and provides an address as a parameter a buffer for instance that address must be mapped to produce the correct physical address. the operating system maintains a copy of the page table for each process just as it maintains a copy of the instruction counter and register contents. this copy is used to translate logical addresses to physical addresses whenever the operating system must map a logical address to a physical address manually. it is also used by the cpu dispatcher to define the hardware page table when a process is to be allocated the cpu. paging therefore increases the context switch time. . . hardware support each operating system has its own methods for storing page tables. most allocate a page table for each process. a pointer to the page table is stored with the other register values like the instruction counter in the process control block. when the dispatcher is told to start a process it must reload the user registers and define the correct hardware page table values from the stored user page table. the hardware implementation of the page table can be done in several ways. in the simplest case the page table is implemented as a set of dedicated registers. these registers should be built with very high speed logic to make the paging address translation efficient. every access to memory must go through the paging map so efficiency is a major consideration. the cpu dispatcher . paging reloads these registers just as it reloads the other registers. instructions i load or modify the page table registers are of course privileged so that only the operating system can change the memory map. the dec pdp is an example of such an architecture. the address consists of bits and the page size is kb. the page table thus consists of eight entries that are kept in fast registers. the use of registers for the page table is satisfactory if the page table is reasonably small for example entries . most contemporary computers however allow the page table to be very large for example million entries . for these machines the use of fast registers to implement the page table is not feasible. rather the page table is kept in main memory and a page table base register ptbr points to the page table. changing page tables requires changing only this one register substantially reducing context switch time. the problem with this approach is the time required to access a user memory location. if we want to access location we must first index into the page table using the value in the ptbr offset by the page number for ch . this task requires a memory access. it provides us with the frame number which is combined with the page offset to produce the actual address. we can then access the desired place in memory. with this scheme two memory accesses are needed to access a byte one for the page table entry one for the byte . thus memory access is slowed by a factor of . this delay would be intolerable under most circumstances. we might as well resort to sivapping! the standard solution to this problem is to use a special small fastlookup hardware cache called a translation look aside buffer tlb . the tlb is associative high speed memory. each entry in the tlb consists of two parts a key or tag and a value. when the associative memory is presented with an item the item is compared with all keys simultaneously. if the item is found the corresponding value field is returned. the search is fast the hardware however is expensive. typically the number of entries in a tlb is small often numbering between and . the tlb is used with page tables in the following way. the tlb contains only a few of the page table entries. when a logical address is generated by the cpu its page number is presented to the tlb. if the page number is found its frame number is immediately available and is used to access memory. the whole task may take less than percent longer than it would if an unmapped memory reference were used. if the page number is not in the tlb known as a tlb miss a memory reference to the page table must be made. when the frame number is obtained we can use it to access memory figure . . in addition we add the page number and frame number to the tlb so that they will be found quickly on the next reference. if the tlb is already full of entries the operating system must select one for replacement. replacement policies range from least recently used lru to random. furthermore some tlbs allow entries to be wired down meaning that they cannot be removed from the tlb. typically tlb entries for kernel code are wired down. some tlbs store address space identifiers asids in each tlb entry. an asid uniquely identifies each process and is used to provide address space protection for that process. wtien the tlb attempts to resolve virtual page numbers it ensures that the asid for the currently running process matches the asid associated with the virtual page. if the asids do not match the attempt is treated as a tlb miss. in addition to providing address space protection an asid chapter main memory logical address gpu page frame number number physical memory page table figure . paging hardware with tlb. allows the tlb to contain entries for several different processes simultaneously. if the tlb does not support separate asids then every time a new page table is selected for instance with each context switch the tlb must be flushed or erased to ensure that the next executing process does not use the wrong translation information. otherwise the tlb could include old entries that contain valid virtual addresses but have incorrect or invalid physical addresses left over from the previous process. the percentage of times that a particular page number is found in the tlb is called the hit ratio. an percent hit ratio means that we find the desired page number in the tlb percent of the time. if it takes nanoseconds to search the tlb and nanoseconds to access memory then a mapped memory access takes nanoseconds when the page number is in the tlb. if we fail to find the page number in the tlb nanoseconds then we must first access memory for the page table and frame number nanoseconds and then access the desired byte in memory nanoseconds for a total of nanoseconds. to find the effective memory access time we weight each case by its probability effective access time . x . x nanoseconds. in this example we suffer a percent slowdown in memory access time from to nanoseconds . for a percent hit ratio we have effective access time . x . x nanoseconds. this increased hit rate produces only a percent slowdown in access time. we will further explore the impact of the hit ratio on the tlb in chapter . . paging s . . protection memory protection in a paged environment is accomplished by protection bits associated with each frame. normally these bits are kept in the page table. one bit can define a page to be read write or read only. every reference to memory goes through the page table to find the correct frame number. at the same time that the physical address is being computed the protection bits can be checked to verify that no writes are being made to a read only page. an attempt to write to a read only page causes a hardware trap to the operating system or memory protection violation . we can easily expand this approach to provide a finer level of protection. we can create hardware to provide read only read write or execute only protection or by providing separate protection bits for each kind of access we can allow any combination of these accesses. illegal attempts will be trapped to the operating system. one additional bit is generally attached to each entry in the page table a valid invalid bit. when this bit is set to valid the associated page is in the process's logical address space and is thus a legal or valid page. when the bit is set to invalid ' the page is not in the process's logical address space. illegal addresses are trapped by use of the valid invalid bit. the operating system sets this bit for each page to allow or disallow access to the page. suppose for example that in a system with a bit address space to we have a program that should use only addresses to . given a page size of kb we get the situation shown in figure . . addresses in pages fpage frame number . valid invalid bit page gage fl g mragep natje uaqc oage t ' . page k q p ags t page table pagers ft figure . valid v or invalid i bit in a page table. chapter main memory and are mapped normally through the page table. any attempt to generate an address in pages or however will find that the valid invalid bit is set to invalid and the computer will trap to the operating system invalid page reference . notice that this scheme has created a problem. because the program extends to only address any reference beyond that address is illegal. however references to page are classified as valid so accesses to addresses up to are valid. only the addresses from to are invalid. this problem is a result of the kb page size and reflects the internal fragmentation of paging. rarely does a process use all its address range. in fact many processes use only a small fraction of the address space available to them. it would be wasteful in these cases to create a page table with entries for every page in the address range. most of this table would be unused but would take up valuable memory space. some systems provide hardware in the form of a page table length register ptlr to indicate the size of the page table. this value is checked against every logical address to verify that the address is in the valid range for the process. failure of this test causes an error trap to the operating system. . . shared pages an advantage of paging is the possibility of sharing common code. this consideration is particularly important in a time sharing environment. consider a system that supports users each of whom executes a text editor. if the text editor consists of kb of code and kb of data space we need kb to support the users. if the code is reentrant code or pure code however it can be shared as shown in figure . . here we see a three page editor each page kb in size the large page size is used to simplify the figure being shared among three processes. each process has its own data page. reentrant code is non self modifying code it never changes during execution. thus two or more processes can execute the same code at the same time. each process has its own copy of registers and data storage to hold the data for the process's execution. the data for two different processes will of course be different. only one copy of the editor need be kept in physical memory. each user's page table maps onto the same physical copy of the editor but data pages are mapped onto different frames. thus to support users we need only one copy of the editor kb plus copies of the kb of data space per user. the total space required is now kb instead of kb a significant savings. other heavily used programs can also be shared compilers window systems run time libraries database systems and so on. to be sharable the code must be reentrant. the read only nature of shared code should not be left to the correctness of the code the operating system should enforce this property. the sharing of memory among processes on a system is similar to the sharing of the address space of a task by threads described in chapter . furthermore recall that in chapter we described shared memory as a method
 .! ig . . . ' i m page table forp ed process p. ed ed ed data page table for p data process p bata page table for p process p figure . sharing of code in a paging environment. of interprocess communication. some operating systems implement shared memory using shared pages. organizing memory according to pages provides numerous benefits in addition to allowing several processes to share the same physical pages. we will cover several other benefits in chapter . structure of the page table in this section we explore some of the most common techniques for structuring the page table. . . hierarchical paging most modern computer systems support a large logical address space to . in such an environment the page table itself becomes excessively large. for example consider a system with a bit logical address space. if the page size in such a system is kb then a page table may consist of up to million entries j . assuming that each entry consists of bytes each process may need up to mb of physical address space for the page table alone. clearly we would not want to allocate the page table contiguously in main memory. one simple solution to this problem is to divide the page table into smaller pieces. we can accomplish this division in several ways. one way is to use a two level paging algorithm in which the page table itself is also paged figure . . remember our example of a bit machine chapter s main memory page table memory figure . a two level page table scheme. with a page size of kb. a logical address is divided into a page number consisting of bits and a page offset consisting of bits. because we page the page table the page number is further divided into a bit page number and a bit page offset. thus a logical address is as follows page number page offset where p is an index into the outer page table and p is the displacement within the page of the outer page table. the address translation method for this architecture is shown in figure . . because address translation works from the outer page table inward this scheme is also known as a forward mapped page table. the vax architecture also supports a variation of two level paging. the vax is a bit machine with a page size of bytes. the logical address space of a process is divided into four equal sections each of which consists of ' bytes. each section represents a different part of the logical address space of a process. the first high order bits of the logical address designate the appropriate section. the next bits represent the logical page number of that section and the final bits represent an offset in the desired page. by partitioning the page . structure of the page table logical address c. jliuulj ! . . . . . . outer page i i table page of page table figure . address translation for a two level bit paging architecture. table in this manner the operating system can leave partitions unused until a process needs them. an address on the vax architecture is as follows section page offset where s designates the section number p is an index into the page table and d is the displacement within the page. even when this scheme is used the size of a one level page table for a vax process using one section is bits bytes per entry mb. so that main memory use is reduced further the vax pages the user process page tables. for a system with a bit logical address space a two level paging scheme is no longer appropriate. to illustrate this point let us suppose that the page size in such a system is kb . in this case the page table consists of up to entries. if we use a two level paging scheme then the inner page tables can conveniently be one page long or contain byte entries. the addresses look like this outer page inner page offset the outer page table consists of entries or bytes. the obvious way to avoid such a large table is to divide the outer page table into smaller pieces. this approach is also used on some bit processors for added flexibility and efficiency. we can divide the outer page table in various ways. we can page the outer page table giving us a three level paging scheme. suppose that the outer page table is made up of standard size pages k! entries or ! bytes a bit address space is still daunting nd outer page outer page inner page offset the outer page table is still bytes in size. chapter main memory the next step would be a four level paging scheme where the secondlevel outer page table itself is also paged. the sparc architecture with bit addressing supports a three level paging scheme whereas the bit motorola architecture supports a four level paging scheme. for bit architectures hierarchical page tables are generally considered inappropriate. for example the bit ultrasparc would require seven levels of paging a prohibitive number of memory accesses to translate each logical address. . . hashed page tables a common approach for handling address spaces larger than bits is to use a hashed page table with the hash value being the virtual page number. each entry in the hash table contains a linked list of elements that hash to the same location to handle collisions . each element consists of three fields the virtual page number the value of the mapped page frame and a pointer to the next element in the linked list. the algorithm works as follows the virtual page number in the virtual address is hashed into the hash table. the virtual page number is compared with field in the first element in the linked list. if there is a match the corresponding page frame field is used to form the desired physical address. if there is no match subsequent entries in the linked list are searched for a matching virtual page number. this scheme is shown in figure . . a variation of this scheme that is favorable for bit address spaces has been proposed. this variation uses clustered page tables which are similar to hashed page tables except that each entry in the hash table refers to several pages such as rather than a single page. therefore a single page table entry can store the mappings for multiple physical page frames. clustered page tables are particularly useful for sparse address spaces where memory references are noncontiguous and scattered throughout the address space. logical address physical memory hash table figure . hashed page table. structure of the page table logical physical address address gpu physical d p d memon search page table figure . inverted page table. . . inverted page tables usually each process has an associated page table. the page table has one entry for each page that the process is using or one slot for each virtual address regardless of the latter's validity . this table representation is a natural one since processes reference pages through the pages' virtual addresses. the operating system must then translate this reference into a physical memory address. since the table is sorted by virtual address the operating system is able to calculate where in the table the associated physical address entry is and to use that value directly. one of the drawbacks of this method is that each page table may consist of millions of entries. these tables may consume large amounts of physical memory just to keep track of how other physical memory is being used. to solve this problem we can. use an inverted page table. an inverted page table has one entry for each real page or frame of memory. each entry consists of the virtual address of the page stored in that real memory location with information about the process that owns that page. thus only one page table is in the system and it has only one entry for each page of physical memory. figure . shows the operation of an inverted page table. compare it with figure . which depicts a standard page table in operation. inverted page tables often require that an address space identifier section . . be stored in each entry of the page table since the table usually contains several different address spaces mapping physical memory. storing the address space identifier ensures that a logical page for a particular process is mapped to the corresponding physical page frame. examples of systems using inverted page tables include the bit ultrasparc and powerpc. to illustrate this method we describe a simplified version of the inverted page table used in the ibm rt. each virtual address in the system consists of a triple process id page number offset . chapter s main memoryeach inverted page table entry is a pair process id page number where the process id assumes the role of the address space identifier. when a memory reference occurs part of the virtual address consisting of process id pagenumber is presented to the memory subsystem. the inverted page table is then searched for a match. if a match is found say at entry then the physical address i or'fset is generated. if no match is found then an illegal address access has been attempted. although this scheme decreases the amount of memory needed to store each page table it increases the amount of time needed to search the table when a page reference occurs. because the inverted page table is sorted by physical address but lookups occur on virtual addresses the whole table might need to be searched for a match. this search would take far too long. to alleviate this problem we use a hash table as described in section . . to limit the search to one or at most a few page table entries. of course each access to the hash table adds a memory reference to the procedure so one virtual memoryreference requires at least two real memory reads one for the hash table entry and one for the page table. to improve performance recall that the tlb is searched first before the hash table is consulted. systems that use inverted page tables have difficulty implementing shared memory. shared memory is usually implemented as multiple virtual addresses one for each process sharing the memory that are mapped to one physical address. this standard method cannot be used with inverted page tables because there is only one virtual page entry for every physical page one physical page cannot have two or more shared virtual addresses. a simple technique for addressing this issue is to allow the page table to contain only one mapping of a virtual address to the shared physical address. this means that references to virtual addresses that are not mapped result in page faults
 an important aspect of memory management that became unavoidable with paging is the separation of the user's view of memory and the actual physical memory. as we have already seen the user's view of memory is not the same as the actual physical memory. the user's view is mapped onto physical memory. this mapping allows differentiation between logical memory and. physical memory. . . basic method do users think of memory as a linear array of bytes some containing instructions and others containing data? most people would say no. rather users prefer to view memory as a collection of variable sized segments. with no necessary ordering among segments figure . . consider how you think of a program when you are writing it. you think of it as a main program with a set of methods procedures or functions. it may also include various data structures objects arrays stacks variables and so on. each of these modules or data elements is referred to by name. you talk about the stack the math library ''the main program without caring what addresses in memory these elements occupy you are not concerned s. segmentation logical address figure . user's view of a program. with whether the stack is stored before or after the sqrt function. each of these segments is of variable length the length is intrinsically defined by the purpose of the segment in the program. elements within a segment are identified by their offset from the beginning of the segment the first statement of the program the seventh stack frame entry in the stack the fifth instruction of the sqrt and so on. segmentation is a memory management scheme that supports this user view of memory. a logical address space is a collection of segments. each segment has a name and a length. the addresses specify both the segment name and the offset within the segment. the user therefore specifies each address by two quantities a segment name and an offset. contrast this scheme with the paging scheme in which the user specifies only a single address which is partitioned by the hardware into a page number and an offset all invisible to the programmer. for simplicity of implementation segments are numbered and are referred to by a segment number rather than by a segment name. tluis a logical address consists of a two tuple segment number offset . normally the user program is compiled and the compiler automatically constructs segments reflecting the input program. a c compiler might create separate segments for the following . the code . global variables . the heap from which memory is allocated . the stacks used by each thread . the standard c library chapter emery libraries that are linked in during compile time might be assigned separate segments. the loader would take all these segments and assign them segment numbers. . . hardware although the user can now refer to objects in the program by a two dimensional address the actual physical memory is still of course a one dimensional sequence of bytes. thus we must define an implementation to map twodimensional user defined addresses into one dimensional physical addresses. this .mapping is effected by a segment table. each entry in the segment table has a segment base and a segment limit. the segment base contains the starting physical address where the segment resides in memory whereas the segment limit specifies the length of the segment. the use of a segment table is illustrated in figure . . a logical address consists of two parts a segment number s and an offset into that segment d. the segment number is used as an index to the segment table. the offset d of the logical address must be between and the segment limit. if it is not we trap to the operating system logical addressing attempt beyond end of segment . when an offset is legal it is added to the segment base to produce the address in physical memory of the desired byte. the segment table is thus essentially an array of base limit register pairs. as an example consider the situation shown in figure . . we have five segments numbered from through . the segments are stored in physical memory as shown. the segment table has a separate entry for each segment giving the beginning address of the segment in physical memory or base and the length of that segment or limit . for example segment is bytes long and begins at location . thus a reference to byte of segment is mapped s limit base segment s d table no trap addressing error physical memory figure . segmentation hardware. . example the intel pentium sjd'outins segment q h limit base i i i segment ' c segment table secment logical address space iegment segment i physical memory figure . exampie of segmentation. onto location . a reference to segment r byte is mapped to the base of segment . a reference to byte of segment would result in a trap to the operating system as this segment is only bytes long. . example the intel pentium both paging and segmentation have advantages and disadvantages. in fact some architectures provide both. in this section we discuss the intel pentium architecture which supports both pure segmentation and segmentation with paging. we do not give a complete description of the memory management structure of the pentium in this text. rather we present the major ideas on which it is based. we conclude our discussion with an overview of linux address translation on pentium systems. in pentium systems the cpu generates logical addresses which are given to the segmentation unit. the segmentation unit produces a linear address for each logical address. the linear address is then given to the paging unit which in turn generates the physical address in main memory. thus the segmentation and paging units form the equivalent of the memory management unit vimu . this scheme is shown in figure . . . . pentium segmentation the pentium architecture allows a segment to be as large as gb and the maximum number of segments per process is kb. the logical address space chapter main memory logical linear . physical address j segmeofato.i address n? g og j address mi . lti't i figure . logical to physical address translation in the pentium. of a process is divided into two partitions. the first partition consists of up to kb segments that are private to that process. the second partition consists of up to kb segments that are shared among all the processes. information about the first partition is kept in the local descriptor table ldt information about the second partition is kept in the global descriptor table gdt . each entry in the ldt and gdt consists of an byte segment descriptor with detailed information about a particular segment including the base location and limit of that segment. the logical address is a pair selector offset where the selector is a bit number v in which s designates the segment number g indicates whether the segment is in the gdt or ldt and p deals with protection. the offset is a bit number specifying the location of the byte or word within the segment in question. the machine has six segment registers allowing six segments to be addressed at any one time by a process. it also has six byte microprogram registers to hold the corresponding descriptors from either the ldt or gdt. this cache lets the pentium avoid having to read the descriptor from memory for every memory reference. the linear address on the pentium is bits long and is formed as follows. the segment register points to the appropriate entry in the ldt or gdt. the base and limit information about the segment in question is used to generate a linear address. first the limit is used to check for address validity. if the address is not valid a memory fault is generated resulting in a trap to the operating system. if it is valid then the value of the offset is added to the value of the base resulting in a bit linear address. this is shown in figure . . in the following section we discuss how the paging unit turns this linear address into a physical address. . . pentium paging the pentium architecture allows a page size of either kb or mb. for kb pages the pentium uses a two level paging scheme in which the division of the bit linear address is as follows page number page offset the address translation scheme for this architecture is similar to the scheme shown in figure . . the intel pentium address translation is shown in more . example the intel pentium logical address selector offset descriptor table bit linear address figure . intel pentium segmentation. detail in figure . . the ten high order bits reference an entry in the outermost page table which the pentium terms the page directory. the cr register points to the page directory for the current process. the page directory entry points to an inner page table that is indexed by the contents of the innermost ten bits in the linear address. finally the low order bits refer to the offset in the kb page pointed to in the page table. one entry in the page directory is the page size flag which if set indicates that the size of the page frame is mb and not the standard kb. if this flag is set the page directory points directly to the mb page frame bypassing the inner page table and the low order bits in the linear address refer to the offset in the mb page frame. to improve the efficiency of physical memory use intel pentium page tables can be swapped to disk. in this case an invalid bit is used in the page directory entry to indicate whether the table to which the entry is pointing is in memory or on disk. if the table is on disk the operating system can use the other bits to specify the disk location of the table the table then can be brought into memory on demand. . . linux on pentium systems as an illustration consider the linux operating system running on the intel pentium architecture. because linux is designed to run on a variety of processors many of which may provide only limited support for segmentation linux does not rely on segmentation and uses it minimally on the pentium linux uses only six segments . a segment for kernel code . a segment for kernel data . a segment for user code . a segment for user data . a task state segment tss . a default ldt segment chapter main memory iogica! address age directory page table offset labfe . directory cr register page page directory offsei figure . paging in the pentium architecture. the segments for user code and user data are shared by all processes running in user mode. this is possible because all processes use the same logical address space and all segment descriptors are stored in the global descriptor table gdt . furthermore each process has its own task state segment tss and the descriptor for this segment is stored in the gdt. the tss is used to store the hardware context of each process during context switches. the default ldt segment is normally shared by all processes and is usually not used. however if a process requires its own ldt it can create one and use that instead of the default ldt. as noted each segment selector includes a bit field for protection. thus the pentium allows four levels of protection. of these four levels linux only recognizes two user mode and kernel mode. although the pentium uses a two level paging model linux is designed to run on a variety of hardware platforms many of which are bit platforms where two level paging is not plausible. therefore linux has adopted a threelevel paging strategy that works well for both bit and bit architectures. the linear address in linux is broken into the following four parts globr rjiiectory j duecto'y ticfigure . highlights the three level paging model in linux. the number of bits in each part of the linear address varies according to architecture. however as described earlier in this section the pentium architecture only uses a two level paging model. how then does linux apply its three level model on the pentium in this situation the size of the middle directory is zero bits effectively bypassing the middle directory
 the memory management algorithms outlined in chapter are necessary because of one basic requirement the instructions being executed must be in physical memory. the first approach to meeting this requirement is to place the entire logical address space in physical memory. dynamic loading can help to ease this restriction but it generally requires special precautions and extra work by the programmer. chapter virtual memory the requirement that instructions must be in physical memory te be executed seems both necessary and reasonable but it is also unfortunate since it limits the size of a program to the size of physical memory. in fact an examination of real programs shows us that in many cases the entire program is not needed. for instance consider the following programs often have code to handle unusual error conditions. since these errors seldom if ever occur in practice this code is almost never executed. arrays lists and tables are often allocated more memory than they actually need. an array may be declared bv elements even though it is seldom larger than by elements. an assembler symbol table may have room for symbols although the average program has less than symbols. certain options and features of a program may be used rarely. for instance the routines on u.s. government computers that balance the budget are only rarely used. even in those cases where the entire program is needed it may not all be needed at the same time. the ability to execute a program that is only partially in memory would confer many benefits a program would no longer be constrained by the amount of physical memory that is available. users would be able to write programs for an extremely large virtual address space simplifying the programming task. page page page . memory a map page v physica virtual memory memory figure . diagram showing virtual memory that is larger than physical memory. . background because each user program could take less physical memory ?inore programs could be run at the same time with a corresponding increase in cpu utilization and throughput but with no increase in response time or turnaround time. less i o would be needed to load or swap each user program into memory so each user program would run faster. thus running a program that is not entirely in memory would benefit both the system and the user. virtual memory involves the separation of logical memory as perceived by users from physical memory. this separation allows an extremely large virtual memory to be provided for programmers when only a smaller physical memory is available figure . . virtual memory makes the task of programming much easier because the programmer no longer needs to worry about the amount of physical memory available she can concentrate instead on the problem to be programmed. the virtual address space of a process refers to the logical or virtual view of how a process is stored in memory. typically this view is that a process begins at a certain logical address say address and exists in contiguous memory as shown in figure . . recall from chapter though that in fact physical memory may be organized in page frames arid that the physical page frames assigned to a process may not be contiguous. tt is up to the memorymanagement unit mmu to map logical pages to physical page frames in memory. note in figure . that we allow for the heap to grow upward hi memory as it is used for dynamic memory allocation. similarly we allow for the stack to grow downward in memory through successive function calls. the large blank space or hole between the heap and the stack is part of the virtual address max heap figure . virtual address space. chapter virtual memory space but will require actual physical pages only if the heap or stack grcfvvs. virtual address spaces that include holes are known as sparse address spaces. using a sparse address space is beneficial because the holes can be filled as the stack or heap segments grow or if we wish to dynamically link libraries or possibly other shared objects during program execution. in addition to separating logical memory from physical memory virtual memory also allows files and memory to be shared by two or more processes through page sharing section . . . this leads to the following benefits system libraries can be shared by several processes through mapping of the shared object into a virtual address space. although each process considers the shared libraries to be part of its virtual address space the actual pages where the libraries reside in physical memory are shared by all the processes figure . . typically a library is mapped read only into the space of each process that is linked with it. similarly virtual memory enables processes to share memory. recall from chapter that two or more processes can communicate through the use of shared memory. virtual memory allows one process to create a region of memory that it can share with another process. processes sharing this region consider it part of their virtual address space yet the actual physical pages of memory are shared much as is illustrated in figure . . virtual memory can allow pages to be shared during process creation with the forko system call thus speeding up process creation. we will further explore these and other benefits of virtual memory later in this chapter. first we begin with a discussion of implementing virtual memorythrough demand paging. stack '. stack shared hbrary shared shared library pages heap data code code figure . shared library using virtual memory
 . demand paging consider how an executable program might be loaded from disk into memory. one option is to load the entire program in physical memory at program execution time. however a problem with this approach is that we may not initially need the entire program in memory. consider a program that starts with a list of available options from which the user is to select. loading the entire program into memory results in loading the executable code for all options regardless of whether an option is ultimately selected by the user or not. an alternative strategy is to initially load pages only as they are needed. this technique is known as demand paging and is commonly used in virtual memory systems. with demand paged virtual memory pages are only loaded when they are demanded during program execution pages that are never accessed are thus never loaded into physical memory. a demand paging system is similar to a paging system with swapping figure . where processes reside in secondary memory usually a disk . when we want to execute a process we swap it into memory. rather than swapping the entire process into memory however we use a lazy swapper. a lazy swapper never swaps a page into memory unless that page will be needed. since we are now viewing a process as a sequence of pages rather than as one large contiguous address space use of the term swapper is technically incorrect. a swapper manipulates entire processes whereas a pager is concerned with the individual pages of a process. we thus use pager rather than swapper in connection with demand paging. program a program b prihkr main memory figure . transfer of a paged memory to contiguous disk space. chapter virtual memory . . basic concepts when a process is to be swapped in the pager guesses which pages will be used before the process is swapped out again. instead of swapping in a whole process the pager brings only those necessary pages into memory. thus it avoids reading into memory pages that will not be used anyway decreasing the swap rime and the amount of physical memory needed. with this scheme we need some form of hardware support to distinguish between the pages that are in memory and the pages that are on the disk. the valid invalid bit scheme described in section . can be used for this purpose. this time however when this bit is set to valid the associated page is both legal and in memory. if the bit is set to invalid the page either is not valid that is not in the logical address space of the process or is valid but is currently on the disk. the page table entry for a page that is brovight into memory is set as usual but the page table entry for a page that is not currently in memory is either simply marked invalid or contains the address of the page on disk. this situation is depicted in figure . . notice that marking a page invalid will have no effect if the process never attempts to access that page. hence if we guess right and page in all and only those pages that are actually needed the process will run exactly as though we had brought in all pages. while the process executes and accesses pages that are memory resident execution proceeds normally. a valid invalid b frame c a d e c f g h iff logical page table memory physical memory figure . page table when some pages are not in main memory. . demand paging physical memory figure . steps in handling a page fault. but what happens if the process tries to access a page that was not brought into memory? access to a page marked invalid causes a page fault trap. the paging hardware in translating the address through the page table will notice that the invalid bit is set causing a trap to the operating system. this trap is the result of the operating system's failure to bring the desired page into memory. the procedure for handling this page fault is straightforward figure . . we check an internal table usually kept with the process control block for this process to determine whether the reference was a valid or an invalid memory access. . if the reference was invalid we terminate the process. if it was valid but we have not yet brought in that page we now page it in. . we find a free frame by taking one from the free frame list for example . . we schedule a disk operation to read the desired page into the newly allocated frame. . when the disk read is complete we modify the internal table kept with the process and the page table to indicate that the page is now in memory. . we restart the instruction that was interrupted by the trap. the process can now access the page as though it had always been in memory. in the extreme case we can start executing a process with no pages in memory. when the operating system sets the instruction pointer to the first chapter virtual memory instruction of the process which is on a non memory resident page the process immediately faults for the page. after this page is brought into memory the process continues to execute faulting as necessary until every page that it needs is in memory. at that point it can execute with no more faults. this scheme is pure demand paging never bring a page into memory until it is required. theoretically some programs could access several new pages of memory with each instruction execution one page for the instruction and many for data possibly causing multiple page faults per instruction. this situation would result in unacceptable system performance. fortunately analysis of running processes shows that this behavior is exceedingly unlikely. programs tend to have locality of reference described in section . . which results in reasonable performance from demand paging. the hardware to support demand paging is the same as the hardware for paging and swapping page table. this table has the ability to mark an entry invalid through a valid invalid bit or special value of protection bits. secondary memory. this memory holds those pages that are not present in main memory. the secondary memory is usually a high speed disk. it is known as the swap device and the section of disk used for this purpose is known as swap space. swap space allocation is discussed in chapter . a crucial requirement for demand paging is the need to be able to restart any instruction after a page fault. because we save the state registers condition code instruction counter of the interrupted process when the page fault occurs we must be able to restart the process in exactly the same place and state except that the desired page is now in memory and is accessible. in most cases this requirement is easy to meet. a page fault may occur at any memory reference. if the page fault occurs on the instruction fetch we can restart byfetching the instruction again. if a page fault occurs while we are fetching an operand we must fetch and decode the instruction again and then fetch the operand. as a worst case example consider a three address instruction such as add the content of a to b placing the result in c. these are the steps to execute this instruction . fetch and decode the instruction add . . fetch a. . fetch b. . add a and b. . store the sum in c. if we fault when we try to store in c because c is in a page not currently in memory we will have to get the desired page bring it in correct the page table and restart the instruction. the restart will require fetching the instruction again decoding it again fetching the two operands again and . demand paging then adding again. however there is not much repeated work less than one complete instruction and the repetition is necessary only when a page fault occurs. the major difficulty arises when one instruction may modify several different locations. for example consider the ibm. system mvc move character instruction. which can move up to bytes from one location to another possibly overlapping location. if either block source or destination straddles a page boundary a page fault might occur after the move is partially done. in addition if the source and destination blocks overlap the source block may have been modified in which case we cannot simply restart the instruction. this problem can be solved in two different ways. in one solution the microcode computes and attempts to access both ends of both blocks. if a page fault is going to occur it will happen at this step before anything is modified. the move can then take place wre know that no page fault can occur since all the relevant pages are in memory. the other solution uses temporary registers to hold the values of overwritten locations. if there is a page fault all the old values are written back into memory before the trap occurs. this action restores memory to its state before the instruction was started so that the instruction can be repeated. this is by no means the only architectural problem resulting from adding paging to an existing architecture to allow demand paging but it illustrates some of the difficulties involved. paging is added between the cpu and the memory in a computer system. it should be entirely transparent to the user process. thus people often assume that paging can be added to any system. although this assumption is true for a non demand paging environment where a page fault represents a fatal error it is not true where a page fault means only that an additional page must be brought into memory and the process restarted. . . performance of demand paging demand paging can significantly affect the performance of a computer system. to see why let's compute the effective access time for a demand paged memory. for most computer systems the memory access time denoted ma ranges from to nanoseconds. as long as we have no page faults the effective access time is equal to the memory access time. if however a page fault occurs we must first read the relevant page from disk and then access the desired word. let p be the probability of a page fault s p . we would expect p to be close to zero that is we would expect to have only a few page faults. the effective access time is then effective access time p x ma p x page fault time. to compute the effective access time we must know how much time is needed to service a page fault. a page fault causes the following sequence to occur . trap to the operating system. . save the user registers and process state. chapter virtual memory . determine that the interrupt was a page fault. ' . check that the page reference was legal and determine the location of the page on the disk. . issue a read from the disk to a free frame a. wait in a queue for this device until the read request is serviced. b. wait for the device seek and or latency time. c. begin the transfer of the page to a free frame. . while waiting allocate the cpu to some other user cpu scheduling optional . . receive an interrupt from the disk i o subsystem i o completed . . save the registers and process state for the other user if step is executed . . determine that the interrupt was from the disk. . correct the page table and other tables to show that the desired page is now in memory. . wait for the cpu to be allocated to this process again. . restore the user registers process state and new page table and then resume the interrupted instruction. not all of these steps are necessary in every case. for example we are assuming that in step the cpu is allocated to another process while the i o occurs. this arrangement allows multiprogramming to maintain cpu utilization but requires additional time to resume the page fault service routine when the i o transfer is complete. in any case we are faced with three major components of the page fault service time . service the page fault interrupt. . read in the page. . restart the process. the first and third tasks can be reduced with careful coding to several hundred instructions. these tasks may take from to microseconds each. the page switch time however will probably be close to milliseconds. a typical hard disk has an average latency of milliseconds a seek of milliseconds and a transfer time of . milliseconds. thus the total paging time is about milliseconds including hardware and software time. remember also that we are looking at only the device service time. if a queue of processes is waiting for the device other processes that have caused page faults we have to add device queueing time as we wait for the paging device to be free to service our request increasing even more the time to swap. if we take an average page fault service time of milliseconds and a memory access time of nanoseconds then the effective access time in nanoseconds is
 effective access time p x p milliseconds p x p x . x p. we see then that the effective access time is directly proportional to the page fault rate. if one access out of causes a page fault the effective access time is . microseconds. the computer will be slowed down by a factor of because of demand paging! if we want performance degradation to be less than percent we need x p x p p . . that is to keep the slowdown due to paging at a reasonable level we can allow fewer than one memory access out of to page fault. in sum it is important to keep the page fault rate low in a demand paging system. otherwise the effective access time increases slowing process execution dramatically. an additional aspect of demand paging is the handling and overall use of swap space. disk i o to swap space is generally faster than that to the file system. it is faster because swap space is allocated in much larger blocks and file lookups and indirect allocation methods are not used chapter . the system can therefore gain better paging throughput by copying an entire file image into the swap space at process startup and then performing demand paging from the swap space. another option is to demand pages from the file system initially but to write the pages to swap space as they are replaced. this approach will ensure that only needed pages are read from the file system but that all subsequent paging is done from swap space. some systems attempt to limit the amount of swap space used through demand paging of binary files. demand pages for such files are brought directly from the file system. however when page replacement is called for these frames can simply be overwritten because they are never modified and the pages can be read in from the file system again if needed. using this approach the file system itself serves as the backing store. however swap space must still be used for pages not associated with a file these pages include the stack and heap for a process. this method appears to be a good compromise and is used in several systems including solaris and bsd unix. . copy on wrste in section . we illustrated how a process can start quickly by merely demandpaging in the page containing the first instruction. however process creation using the f ork system call may initially bypass the need for demand paging by using a technique similar to page sharing covered in section . . . this technique provides for rapid process creation and minimizes the number of new pages that must be allocated to the newly created process. chapter virtual memory process. physical memory process hs irnt rr i i ' m. figure . before process modifies page c. recall that the fork system call creates a child process as a duplicate of its parent. traditionally f o r k o worked by creating a copy of the parent's address space for the child duplicating the pages belonging to the parent. however considering that many child processes invoke the exec system call immediately after creation the copying of the parent's address space may be unnecessary. alternatively we can use a technique known as copy on write which works by allowing the parent and child processes initially to share the same pages. these shared pages are marked as copy on write pages meaning that if either process writes to a shared page a copy of the shared page is created. copy on write is illustrated in figures . and figure . which show the contents of the physical memory before and after process modifies page c. for example assume that the child process attempts to modify a page containing portions of the stack with the pages set to be copy on write. the operating system will then create a copy of this page mapping it to the address space of the child process. the child process will then modify its copied page and not the page belonging to the parent process. obviously when the copy onwrite technique is used only the pages that are modified by either process are copied all unmodified pages can be shared by the parent and child processes. physical process memory process. figure . after process modifies page c
 note too that only pages that can be modified need be marked as copy onwrite. pages that cannot be modified pages containing executable code can be shared by the parent and child. copy on write is a common technique used by several operating systems including windows xp linux and solaris. when it is determined that a page is going to be duplicated using copyon write it is important to note the location from which the free page will be allocated. many operating systems provide a pool of free pages for such requests. these free pages are typically allocated when the stack or heap for a process must expand or when there are copy on write pages to be managed. operating systems typically allocate these pages using a technique known as zero fill on demand. zero fill on demand pages have been zeroed out before being allocated thus erasing the previous contents. several versions of unix including solaris and linux also provide a variation of the forkc system call vforko for virtual memory fork . vf ork operates differently from f ork with copy on write. with vf ork the parent process is suspended and the child process uses the address space of the parent. because vf ork does not use copy on write if the child process changes any pages of the parent's address space the altered pages will be visible to the parent once it resumes. therefore vf ork must be used with caution to ensure that the child process does not modify the address space of the parent vf ork is intended to be used when the child process calls execo immediately after creation. because no copying of pages takes place vf ork is an extremely efficient method of process creation and is sometimes used to implement unix command line shell interfaces. . page replacement in our earlier discussion of the page fault rate we assumed that each page faults at most once when it is first referenced. this representation is not strictlyaccurate however. if a process of ten pages actually uses only half of them then demand paging saves the i o necessary to load the five pages that are never used. we could also increase our degree of multiprogramming by running twice as many processes. thus if we had forty frames we could run eight processes rather than the four that could run if each required ten frames five of which were never used . if we increase our degree of multiprogramming we are over ajlocating memory. if we run six processes each of which is ten pages in size but actually uses only five pages we have higher cpu utilization and throughput with ten frames to spare. it is possible however that each of these processes for a particular data set may suddenly try to use all ten of its pages resulting in a need for sixty frames when only forty are available. further consider that system memory is not used only for holding program pages. buffers for i o also consume a significant amount of memory. this use can increase the strain on memory placement algorithms. deciding how much memory to allocate to i o and how much to program pages is a significant challenge. some systems allocate a fixed percentage of memory for i o buffers whereas others allow both user processes and the i o subsystem to compete for all system memory. chapter virtual memory valid invalid frame d h logical memory featrivr for user for user j a valid invalid e m frame bit physical memory i v v logical memory page table for user for user figure . need for page replacement. over allocation of memory manifests itself as follows. while a user process is executing a page fault occurs. the operating system determines where the desired page is residing on the disk but then finds that there are no free frames on the free frame list all memory is in use figure . . the operating system has several options at this point. it could terminate the user process. however demand paging is the operating system's attempt to improve the computer system's utilization and throughput. users should not be aware that their processes are running on a paged system paging should be logically transparent to the user. so this option is not the best choice. the operating system could instead swap out a process freeing all its frames and reducing the level of multiprogramming. this option is a good one in certain circumstances and we consider it further in section . . here we discuss the most common solution page replacement. . . basic page replacement page replacement takes the following approach. if no frame is free we find one that is not currently being used and free it. we can free a frame by writing its contents to swap space and changing the page table and all other tables to indicate that the page is no longer in memory figure . . we can now use the freed frame to hold the page for which the process faulted. we modify the page fault service routine to include page replacement . find the location of the desired page on the disk. . find a free frame a. if there is a free frame use it. . page replacement b. if there is no free frame use a page replacement algorithm toselect a victim frame. c. write the victim frame to the disk change the page and frame tables accordingly. . read the desired page into the newly freed frame change the page and frame tables. . restart the user process. notice that if no frames are free two page transfers one out and one in are required. this situation effectively doubles the page fault service time and increases the effective access time accordingly. we can reduce this overhead by using a modify bit or dirty bit . when this scheme is used each page or frame has a modify bit associated with it in the hardware. the modify bit for a page is set by the hardware whenever any word or byte in the page is written into indicating that the page has been modified. when we select a page for replacement we examine its modify bit. if the bit is set we know that the page has been modified since it was read in from the disk. in this case we must write that page to the disk. if the modify bit is not set however the page has not been modified since it was read into memory. therefore if the copy of the page on the disk has not been overwritten by some other page for example then we need not write the memory page to the disk it is already there. this technique also applies to read only pages for example pages of binary code . such pages cannot be modified thus they may be discarded when desired. this scheme can significantly reduce the time required to service a page fault since it reduces i o time by one halfif the page has not been modified. frame valid invalid bit swap out tnj change victim i vfyto invalid page f v . fi victim reset page page table table for new page physical memory figure . page replacement. chapter virtual memory page replacement is basic to demand paging. it completes the separation between logical memory and physical memory with this mechanism an enormous virtual memory can be provided for programmers on a smaller physical memory. with no demand paging user addresses are mapped into physical addresses so the two sets of addresses can be different. all the pages of a process still must be in physical memory however. with demand paging the size of the logical address space is no longer constrained by physical memory. if we have a user process of twenty pages we can execute it in ten frames simply by using demand paging and using a replacement algorithm to find a free frame whenever necessary. if a page that has been modified is to be replaced its contents are copied to the disk. a later reference to that page will cause a page fault. at that time the page will be brought back into memory perhaps replacing some other page in the process. we must solve two major problems to implement demand paging we must develop a frame allocation algorithm and a page replacement algorithm. if we have multiple processes in memory we must decide how many frames to allocate to each process. further when page replacement is required we must select the frames that are to be replaced. designing appropriate algorithms to solve these problems is an important task because disk i o is so expensive. even slight improvements in demand paging methods yield large gains in system performance. there are many different page replacement algorithms. every operating system probably has its own replacement scheme. how do we select a particular replacement algorithm? in general we want the one with the lowest page fault rate. wte evaluate an algorithm by running it on a particular string of memory references and computing the number of page faults. the string of memory references is called a reference string. we can generate reference strings artificially by using a random number generator for example or we can trace a given system and record the address of each memory reference. the latter choice produces a large number of data on the order of million addresses per second . to reduce the number of data we use two facts. first for a given page size and the page size is generally fixed by the hardware or system we need to consider only the page number rather than the entire address. second if we have a reference to a page p then any immediately following references to page p will never cause a page fault. page p will be in memory after the first reference so the immediately following references will not fault. for example if we trace a particular process we might record the following address sequence at bytes per page this sequence is reduced to the following reference string . page replacement b h m ! a cg o cd number of frames figure . graph of page faults versus number of frames. to determine the number of page faults for a particular reference string and page replacement algorithm we also need to know the number of page frames available. obviously as the number of frames available increases the number of page faults decreases. for the reference string considered previously for example if we had three or more frames we would have only three faults one fault for the first reference to each page. in contrast with only one frame available we would have a replacement with every reference resulting in eleven faults. in general we expect a curve such as that in figure . . as the number of frames increases the number of page faults drops to some minimal level. of course adding physical memory increases the number of frames. we next illustrate several page replacement algorithms. in doing so we use the reference string for a memory with three frames. . . fifo page replacement the simplest page replacement algorithm is a first in first out fifo algorithm. a fifo replacement algorithm associates with each page the time when that page was brought into memory. when a page must be replaced the oldest page is chosen. notice that it is not strictly necessary to record the time when a page is brought in. we can. create a fifo queue to hold all pages in memory. we replace the page at the head of the queue. when a page is brought into memory we insert it at the tail of the queue. for our example reference string our three frames are initially empty. the first three references cause page faults and are brought into these empty frames. the next reference replaces page because page was brought in first. since is the next reference and is already in memory we have no fault for this reference. the first reference to results in replacement of page since chapter virtual memory' reference string j p ' if p i io ' i i ll til e j i page frames figure . fifo page replacement algorithm. it is now first in line. because of this replacement the next reference to will fault. page is then replaced by page . this process continues as shown in figure . . every time a fault occurs we show which pages are in our three frames. there are faults altogether. the fifo page replacement algorithm is easy to understand and program. however its performance is not always good. on the one hand the page replaced may be an initialization module that was used a long time ago and is no longer needed. on the other hand it could contain a heavily used variable that was initialized early and is in constant use. notice that even if we select for replacement a page that is in active use everything still works correctly. after we replace an active page with a new one a fault occurs almost immediately to retrieve the active page. some other page will need to be replaced to bring the active page back into memory. thus a bad replacement choice increases the page fault rate and slows process execution. it does not however cause incorrect execution. to illustrate the problems that are possible with a fifo page replacement algorithm. wte consider the following reference string figure . shows the curve of page faults for this reference string versus the number of available frames. notice that the number of faults for four frames ten is greater than the number of faults for three frames nine ! this most unexpected result is known as belady's anomaly for some page replacement algorithms the page fault rate may increase as the number of allocated frames increases. we would expect that giving more memory to a process would improve its performance. in some early research investigators noticed that this assumption was not always true. belady's anomaly was discovered as a result. . . optimal page replacement one result of the discovery of belady's anomaly was the search for an optimal page replacement algorithm. an optimal page replacement algorithm has the lowest page fault rate of all algorithms and will never suffer from belady's anomaly. such an algorithm does exist and has been called opt or mik. it is simply this . page replacement m j! co cd e number of frames figure . page fault curve for fifo replacement on a reference string. replace the page that will not be used for the longest period of time. use of this page replacement algorithm guarantees the lowest possible pagefault rate for a fixed number of frames. for example on our sample reference string the optimal page replacement algorithm would yield nine page faults as shown in figure . . the first three references cause faults that fill the three empty frames. the reference to page replaces page because will not be used until reference whereas page will be used at and page at . the reference to page replaces page as page will be the last of the three pages in memory to be referenced again. with only nine page faults optimal replacement is much better than a fifo algorithm which resulted in fifteen faults. if we ignore the first three which all algorithms must suffer then optimal replacement is twice as good as fifo replacement. in fact no replacement algorithm can process this reference string in three frames with fewer than nine faults. unfortunately the optimal page replacement algorithm is difficult to implement because it requires future knowledge of the reference string. we encountered a similar situation with the sjf cpu scheduling algorithm in reference string o page frames figure . optimal page replacement algorithm. chapter virtual memory section . . . as a result the optimal algorithm is used mainly for comparison studies. for instance it may be useful to know that although a new algorithm is not optimal it is within . percent of optimal at worst and within . percent on average. . . lru page replacement if the optimal algorithm is not feasible perhaps an approximation of the optima algorithm is possible. the key distinction between the fifo and opt algorithms other than looking backward versus forward in time is that the fifo algorithm uses the time when a page was brought into memory whereas the opt algorithm uses the time when a page is to be used. if we use the recent past as an approximation of the near future then we can replace the page that has not been used for the longest period of time figure . . this approach is the least recently used lru algorithm. lru replacement associates with each page the time of that page's last use. when a page must be replaced lru chooses the page that has not been used for the longest period of time. we can think of this strategy as the optimal page replacement algorithm looking backward in time rather than forward. strangely if we let s be the reverse of a reference string s then the page fault rate for the opt algorithm on is the same as the page fault rate for the opt algorithm on r. similarly the page fault rate for the lru algorithm on s is the same as the page fault rate for the lru algorithm on sr. the result of applying lru replacement to our example reference string is shown in figure . . the lru algorithm produces faults. notice that the first faults are the same as those for optimal replacement. when the reference to page occurs however lru replacement sees that of the three frames in memory page was used least recently. thus the lru algorithm replaces page not knowing that page is about to be used. when it then faults for page the lru algorithm replaces page since it is now the least recently used of the three pages in memory. despite these problems lru replacement with faults is much better than fifo replacement with . the lru policy is often used as a page replacement algorithm and is considered to be good. the major problem is how to implement lru replacement. an lru page replacement algorithm may require substantial hardware assistance. the problem is to determine an order for the frames defined by the time of last use. two implementations are feasible reference string a i a i i ' t page frames figure . lru page replacement algorithm. . page replacement counters. in the simplest case we associate with each page table entry a time of use field and add to the cpu a logical clock or counter. the clock is incremented for every memory reference. whenever a reference to a page is made the contents of the clock register are copied to the time of use field in the page table entry for that page. in this way we always have the time of the last reference to each page. we replace the page with the smallest time value. this scheme requires a search of the page table to find the lru page and a write to memory to the time of use field in the page table for each memory access. the times must also be maintained when page tables are changed due to cpu scheduling . overflow of the clock must be considered. stack. another approach to implementing lru replacement is to keep a stack of page numbers. whenever a page is referenced it is removed from the stack and put on the top. in this way the most recently used page is always at the top of the stack and the least recently used page is always at the bottom figure . . because entries must be removed from the middle of the stack it is best to implement this approach by using a doubly linked list with a head and tail pointer. removing a page and putting it on the top of the stack then requires changing six pointers at worst. each update is a little more expensive but there is no search for a replacement the tail pointer points to the bottom of the stack which is the lru page. this approach is particularly appropriate for software or microcode implementations of lru replacement. like optimal replacement lrl replacement does not suffer from belady's anomaly. both belong to a class of page replacement algorithms called stack algorithms that can never exhibit belady's anomaly. a stack algorithm is an algorithm for which it can be shown that the set of pages in memory for n frames is always a subset of the set of pages that would be in memory with n frames. for lrl replacement the set of pages in memory would be the n most recently referenced pages. if the number of frames is increased these n pages will still be the most recently referenced and so will still be in memory. reference string t t a b d l ' j stack stack before after a b figure . use of a stack to record the most recent page references. chapter virtual memory note that neither implementation of lru would be conceivable without hardware assistance beyond the standard tlb registers. the updating of the clock fields or stack must be done for every memory reference. if we were to use an interrupt for every reference to allow software to update such data structures it would slow every memory reference by a factor of at least ten hence slowing every user process by a factor of ten. few systems could tolerate that level of overhead for memory management. . . lru approximation page replacement few computer systems provide sufficient hardware support for true lru page replacement. some systems provide no hardware support and other pagereplacement algorithms such as a fifo algorithm must be used. many systems provide some help however in the form of a reference bit. the reference bit for a page is set by the hardware whenever that page is referenced either a read or a write to any byte in the page . reference bits are associated with each entry in the page table. initially all bits are cleared to by the operating system. as a user process executes the bit associated with each page referenced is set to by the hardware. after some time we can determine which pages have been used and which have not been used by examining the reference bits although we do not know the order of use. this information is the basis for many page replacement algorithms that approximate lru replacement. . . . additional reference bits algorithm we can gain additional ordering information by recording the reference bits at regular intervals. we can keep an bit byte for each page in a table in memory. at regular intervals say every milliseconds a timer interrupt transfers control to the operating system. the operating system shifts the reference bit for each page into the high order bit of its bit byte shifting the other bits right by bit and discarding the low order bit. these bit shift registers contain the history of page use for the last eight time periods. if the shift register contains for example then the page has not been used for eight time periods a page that is used at least once in each period has a shift register value of . a page with a history register value of has been used more recently than one with a value of . if we interpret these bit bytes as unsigned integers the page with the lowest number is the lru page and it can be replaced. notice that the numbers are not guaranteed to be unique however. we can either replace swap out all pages with the smallest value or use the fifo method to choose among them. the number of bits of history can be varied of course and is selected depending on the hardware available to make the updating as fast as possible. in the extreme case the number can be reduced to zero leaving only the reference bit itself. this algorithm is called the second chance pagereplacement algorithm. . . . second chance algorithm the basic algorithm of second chance replacement is a fifo replacement algorithm. when a page has been selected however we inspect its reference . page replacement reference pages reference pages bits bits i v next victim circular queue of pages circular queue of pages a b figure . second chance clock page replacement algorithm. bit. if the value is we proceed to replace this page but if the reference bit is set to we give the page a second chance and move on to select the next fifo page. when a page gets a second chance its reference bit is cleared and its arrival time is reset to the current time. thus a page that is given a second chance will not be replaced until all other pages have been replaced or given second chances . in addition if a page is used often enough to keep its reference bit set it will never be replaced. one way to implement the second chance algorithm sometimes referred to as the dock algorithm is as a circular queue. a pointer that is a hand on the clock indicates which page is to be replaced next. when a frame is needed the pointer advances until it finds a page with a reference bit. as it advances it clears the reference bits figure . . once a victim page is found the page is replaced and the new page is inserted in the circular queue in that position. notice that in the worst case when all bits are set the pointer cycles through the whole queue giving each page a second chance. tt clears all the reference bits before selecting the next page for replacement. second chance replacement degenerates to fifo replacement if all bits are set. . . . enhanced second chance algorithm we can enhance the second chance algorithm by considering the reference bit and the modify bit described in section . . as an ordered pair. with these two bits we have the following four possible classes chapter virtual memory . neither recently used nor modified best page to replace . not recently used but modified not quite as good because the page will need to be written out before replacement . . recently used but clean probably will be used again soon . recently used and modified probably will be used again soon and the page will be need to be written out to disk before it can be replaced each page is in one of these four classes. when page replacement is called for we use the same scheme as in the clock algorithm but instead of examining whether the page to which we are pointing has the reference bit set to we examine the class to which that page belongs. we replace the first page encountered in the lowest nonempty class. notice that we may have to scan the circular queue several times before we find a page to be replaced. the major difference between this algorithm and the simpler clock algorithm is that here we give preference to those pages that have been modified to reduce the number of os required. . . counting based page replacement there are many other algorithms that can be used for page replacement. for example we can keep a counter of the number of references that have been made to each page and develop the following two schemes. the least frequently used lfu page replacement algorithm requires that the page with the smallest count be replaced. the reason for this selection is that an actively used page should have a large reference count. a problem arises however when a page is used heavily during the initial phase of a process but then is never used again. since it was used heavily it has a large count and remains in memory even though it is no longer needed. one solution is to shift the counts right by bit at regular intervals forming an exponentially decaying average usage count. the most frequently used mfu page replacement algorithm is based on the argument that the page with the smallest count was probably just brought in and has yet to be used. as you might expect neither mfu nor lfu replacement is common. the implementation of these algorithms is expensive and they do not approximate opt replacement well. . . page buffering algorithms other procedures are often used in addition to a specific page replacement algorithm . for example systems commonly keep a pool of free frames. when a page fault occurs a victim frame is chosen as before. however the desired page is read into a free frame from the pool before the victim is written out. this procedure allows the process to restart as soon as possible without waiting . page replacement for the victim page to be written out. when the victim is later written put its frame is added to the free frame pool. an expansion of this idea is to maintain a list of modified pages. whenever the paging device is idle a modified page is selected and is written to the disk. its modify bit is then reset. this scheme increases the probability that a page will be clean when it is selected for replacement and will not need to be written out. another modification is to keep a pool of free frames but to remember which page was in each frame. since the frame contents are not modified when a frame is written to the disk the old page can be reused directly from the free frame pool if it is needed before that frame is reused. no i o is needed in this case. when a page fault occurs we first check whether the desired page is in the free frame pool if it is not we must select a free frame and read into it. this technique is used in the vax vms system along with a fifo replacement algorithm. when the fifo replacement algorithm mistakenly replaces a page that is still in active use that page is quickly retrieved from the free frame pool and no i o is necessary. the free frame buffer provides protection against the relatively poor but simple fifo replacement algorithm. this method is necessary because the early versions of vax did not implement the reference bit correctly. some versions of the unix system use this method in conjunction with the second chance algorithm. it can be a useful augmentation to any pagereplacement algorithm to reduce the penalty incurred if the wrong victim page is selected. . . applications and page replacement in certain cases applications accessing data through the operating system's virtual memory perform worse than if the operating system provided no buffering at all. a typical example is a database which provides its own memory management and i o buffering. applications like this understand their memory use and disk use better than does an operating system that is implementing algorithms for general purpose use. if the operating system is buffering i o and the application is doing so as well then twice the memory is being used for a set of i o. in another example data warehouses frequently perform massive sequential disk reads followed by computations and writes. the lru algorithm would be removing old pages and preserving new ones while the application would more likely be reading older pages than newer ones as it starts its sequential reads again . here mfu would actually be more efficient than lru. because of such problems some operating systems give special programs the ability to use a disk partition as a large sequential array of logical blocks without any file system data structures. this array is sometimes called the raw disk and i o to this array is termed raw i o. raw i o bypasses all the filesystem services such as file i o demand paging file locking prefetchmg space allocation file names and directories. note that although certain applications are more efficient when implementing their own special purpose storage services on a raw partition most applications perform better when they use the regular file system services. chapter virtual memory
 we turn next to the issue of allocation. how do we allocate the fixed amount of free memory among the various processes? if we have free frames and two processes how many frames does each process get? the simplest case is the single user system. consider a single user system with kb of memory composed of pages kb in size. this system has frames. the operating system may take kb leaving frames for the user process. under pure demand paging all frames would initially be put on the free frame list. when a user process started execution it would generate a sequence of page faults. the first page faults would all get free frames from the free frame list. when the free frame list was exhausted a page replacement algorithm would he used to select one of the in memory pages to be replaced with the th and so on. when the process terminated the frames would once again be placed on the free frame list. there are many variations on this simple strategy. we can require that the operating system allocate all its buffer and table space from the free frame list. when this space is not in use by the operating system it can be used to support user paging. we can try to keep three free frames reserved on the free frame list at all times. thus when a page fault occurs there is a free frame available to page into. while the page swap is taking place a replacement can be selected which is then written to the disk as the user process continues to execute. other variants are also possible but the basic strategy is clear the user process is allocated any free frame. . . minimum number of frames our strategies for the allocation of frames are constrained in various ways. we cannot for example allocate more than the total number of available frames unless there is page sharing . we must also allocate at least a minimum number of frames. here we look more closely at the latter requirement. one reason for allocating at least a minimum number of frames involves performance. obviously as the number of frames allocated to each process decreases the page fault rate increases slowing process execution. in addition remember that when a page fault occurs before an executing instruction is complete the instruction must be restarted. consequently we must have enough frames to hold all the different pages that any single instruction can reference. for example consider a machine in which all memory reference instructions have only one memory address. in this case we need at least one frame for the instruction and one frame for the memory reference. in addition if one level indirect addressing is allowed for example a load instruction on page can refer to an address on page which is an indirect reference to page then paging requires at least three frames per process. think about what might happen if a process had only two frames. the minimum number of frames is defined by the computer architecture. for example the move instruction for the pdp includes more than one word for some addressing modes and thus the instruction itself may straddle two pages. in addition each of its two operands may be indirect references for a total of six frames. another example is the ibm mvc instruction. since the . allocation of frames instruction is from storage location to storage location it takes bytes and can straddle two pages. the block of characters to move and the area to which it is to be moved can each also straddle two pages. this situation would require six frames. the worst case occurs when the mvc instruction is the operand of an execute instruction that straddles a page boundary in this case we need eight frames. the worst case scenario occurs in computer architectures that allow multiple levels of indirection for example each bit word could contain a bit address plus a bit indirect indicator . theoretically a simple load instruction could reference an indirect address that could reference an indirect address on another page that could also reference an indirect address on yet another page and so on until every page in virtual memory had been touched. thus in the worst case the entire virtual memory must be in physical memory. to overcome this difficulty we must place a limit on the levels of indirection for example limit an instruction to at most levels of indirection . when the first indirection occurs a counter is set to the counter is then decremented for each successive indirection for this instruction. tf the counter is decremented to a trap occurs excessive indirection . this limitation reduces the maximum number of memory references per instruction to requiring the same number of frames. whereas the minimum number of frames per process is defined by the architecture the maximum number is defined by the amount of available physical memory. in between we are still left with significant choice in frame allocation. . . allocation algorithms the easiest way to split in frames among n processes is to give everyone an equal share m n frames. for instance if there are frames and five processes each process will get frames. the leftover three frames can be used as a free frame buffer pool. this scheme is called equal allocation. an alternative is to recognize that various processes will need differing amounts of memory. consider a system with a kb frame size. if a small student process of kb and an interactive database of kb are the only two processes running in a system with free frames it does not make much sense to give each process frames. the student process does not need more than frames so the other are strictly speaking wasted. to solve this problem we can use proportional allocation in which we allocate available memory to each process according to its size. let the size of the virtual memory for process pt be s and define then if the total number of available frames is m we allocate a frames to process where a is approximately a sj s x m. chapter virtual memory of course we must adjust each to be an integer that is greater rha i the minimum number of frames required by the instruction set with a sum not exceeding m. for proportional allocation we would split frames between two processes one of pages and one of pages by allocating frames and frames respectively since x and x . in this way both processes share the available frames according to their needs rather than equally. in both equal and proportional allocation of course the allocation may vary according to the multiprogramming level. if the multiprogramming level is increased each process will lose some frames to provide the memory needed for the new process. conversely if the multiprogramming level decreases the frames that were allocated to the departed process can be spread over the remaining processes. notice that with either equal or proportional allocation a high priority process is treated the same as a low priority process. by its definition however we may want to give the high priority process more memory to speed its execution to the detriment of low priority processes. one solution is to use a proportional allocation scheme wherein the ratio of frames depends not on the relative sizes of processes but rather on the priorities of processes or on a combination of size and priority. . . global versus local allocation another important factor in the way frames are allocated to the various processes is page replacement. with multiple processes competing for frames we can classify page replacement algorithms into two broad categories global replacement and local replacement. global replacement allows a process to select a replacement frame from the set of all frames even if that frame is currently allocated to some other process that is one process can take a frame from another. local replacement requires that each process select from only its own set of allocated frames. for example consider an allocation scheme where we allow high priority processes to select frames from low priority processes for replacement. a process can select a replacement from among its own frames or the frames of any lower priority process. this approach allows a high priority process to increase its frame allocation at the expense of a low priority process. with a local replacement strategy the number of frames allocated to a process does not change. with global replacement a process may happen to select only frames allocated to other processes thus increasing the number of frames allocated to it assuming that other processes do not choose its frames for replacement . one problem with a global replacement algorithm is that a process cannot control its own page fault rate. the set of pages in memory for a process depends not only on the paging behavior of that process but also on the paging behavior of other processes. therefore the same process may perform quite
 differently for example taking . seconds for one execution and . seconds for the next execution because of totally external circumstances. such is not the case with a local replacement algorithm. under local replacement the set of pages in memory for a process is affected by the paging behavior of only that process. local replacement might hinder a process however by not making available to it other less used pages of memory. thus global replacement generally results in greater system throughput and is therefore the more common method. thrashing if the number of frames allocated to a low priority process falls below the minimum number required by the computer architecture we must suspend that process's execution. we should then page out its remaining pages freeing all its allocated frames. this provision introduces a swap in swap out level of intermediate cpu scheduling. in fact look at any process that does not have ''enough frames. if the process does not have the number of frames it needs to support pages in active use it will quickly page fault. at this point it must replace some page. however since all its pages are in active use it must replace a page that will be needed again right away. consequently it quickly faults again and again and again replacing pages that it must bring back in immediately. this high paging activity is called thrashing. a process is thrashing if it is spending more time paging than executing. . . cause of thrashing thrashing results in severe performance problems. consider the following scenario which is based on the actual behavior of early paging systems. the operating system monitors cpu utilization. if cpu utilization is too low we increase the degree of multiprogramming by introducing a new process to the system. a global page replacement algorithm is used it replaces pages without regard to the process to which they belong. now suppose that a process enters a new phase in its execution and needs more frames. it starts faulting and taking frames away from other processes. these processes need those pages however and so they also fault taking frames from other processes. these faulting processes must use the paging device to swap pages in and out. as they queue up for the paging device the ready queue empties. as processes wait for the paging device cpu utilization decreases. the cpu scheduler sees the decreasing cpu utilization and increases the degree of multiprogramming as a result. the new process tries to get started by taking frames from running processes causing more page faults and a longer queue for the paging device. as a result cpu utilization drops even further and the cpu scheduler tries to increase the degree of multiprogramming even more. thrashing has occurred and system throughput plunges. the pagefault rate increases tremendously as a result the effective memory access time increases. no work is getting done because the processes are spending all their time paging. chapter virtual memory degree of multiprogramming figure . thrashing. this phenomenon is illustrated in figure . in which cpu utilization is plotted against the degree of multiprogramming. as the degree of multiprogramming increases cpu utilization also increases although more slowly until a maximum is reached. if the degree of multiprogramming is increased even further thrashing sets in and cpu utilization drops sharply. at this point to increase cpu utilization and stop thrashing we must decrease the degree of multi pro grammi rig. we can limit the effects of thrashing by using a local replacement algorithm or priority replacement algorithm . with local replacement if one process starts thrashing it cannot steal frames from another process and cause the latter to thrash as well. however the problem is not entirely solved. if processes are thrashing they will be in the queue for the paging device most of the time. the average service time for a page fault will increase because of the longer average queue for the paging device. thus the effective access time will increase even for a process that is not thrashing. to prevent thrashing we must provide a process with as many frames as it needs. but how do we know how many frames it needs'? there are several techniques. the working set strategy section . . starts by looking at how many frames a process is actually using. this approach defines the locality model of process execution. the locality model states that as a process executes it moves from locality to locality. a locality is a set of pages that are actively used together figure . . a program is generally composed of several different localities which may overlap. for example when a function is called it defines a new locality. in this locality memory references are made to the instructions of the function call its local variables and a subset of the global variables. when we exit the function the process leaves this locality since the local variables and instructions of the function are no longer in active use. we may return to this locality later. thus we see that localities are defined by the program structure and its data structures. the locality model states that all programs will exhibit this basic memory reference structure. note that the locality model is the unstated principle behind the caching discussions so far in this book. if accesses to any types of data were random rather than patterned caching would be useless. . thrashing en b a ra b cd e ....ll!! .l. ii r ' . e c cd en execution time figure . locality in a memory reference pattern. suppose we allocate enough frames to a process to accommodate its current locality. it will fault for the pages in its locality until all these pages are in memory then it will not fault again until it changes localities. if we allocate fewer frames than the size of the current locality the process will thrash since it cannot keep in memory all the pages that it is actively using. . . working set mode! as mentioned the working set model is based on the assumption of locality. this model uses a parameter a to define the working set window. the idea is to examine the most recent a page references. the set of pages in the most chapter virtual memory recent a page references is the working set figure . . if a page is in active use it will be in the working set. if it is no longer being used it will drop from the working set a time units after its last reference. thus the working set is an approximation of the program's locality. for example given the sequence of memory references shown in figure . if a memory references then the working set at time t is . by time h the working set has changed to . the accuracy of the working set depends on the selection of a. if a is too small it will not encompass the entire locality if a is too large it may overlap several localities. in the extreme if a is infinite the working set is the set of pages touched during the process execution. the most important property of the working set then is its size. if we compute the working set size wssj for each process in the system we can then consider that where d is the total demand for frames. each process is actively using the pages in its working set. thus process i needs wssj frames. if the total demand is greater than the total number of available frames d m thrashing will occur because some processes will not have enough frames. once a has been selected use of the working set model is simple. the operating system monitors the working set of each process and allocates to that working set enough frames to provide it with its working set size. if there are enough extra frames another process can be initiated. if the sum of the working set sizes increases exceeding the total number of available frames the operating system selects a process to suspend. the process's pages are written out swapped and its frames are reallocated to other processes. the suspended process can be restarted later. this working set strategy prevents thrashing while keeping the degree of multiprogramming as high as possible. thus it optimizes cpu utilization. the difficulty with the working set model is keeping track of the working set. the working set window is a moving window. at each memory reference a new reference appears at one end and the oldest reference drops off the other end. a page is in the working set if it is referenced anywhere in the working set window. we can approximate the working set model with a fixed interval timer interrupt and a reference bit. for example assume that a equals references and that we can cause a timer interrupt every references. when we get a timer interrupt we copy and clear the reference bit values for page reference table ... ws f ws f figure . working set modef. . thrashing each page. thus if a page fault occurs we can examine the current reference bit and two in memory bits to determine whether a page was used within the last to references. if it was used at least one of these bits will be on. if it has not been used these bits will be off. those pages with at least one bit on will be considered to be in the working set. note that this arrangement is not entirely accurate because we cannot tell where within an interval of a reference occurred. we can reduce the uncertainty by increasing the number of history bits and the frequency of interrupts for example bits and interrupts every references . however the cost to service these more frequent interrupts will be correspondingly higher. . . page fault frequency the working set model is successful and knowledge of the working set can be useful for prepaging section . . but it seems a clumsy way to control thrashing. a strategy that uses the page fault frequency pff takes a more direct approach. the specific problem is how to prevent thrashing. thrashing has a high page fault rate. thus we want to control the page fault rate. when it is too high we know that the process needs more frames. conversely if the page fault rate is too low then the process may have too many frames. we can establish upper and lower bounds on the desired page fault rate figure . . if the actual page fault rate exceeds the upper limit we allocate the process another frame if the page fault rate falls below the lower limit we remove a frame from the process. thus we can directly measure and control the page fault rate to prevent thrashing. as with the working set strategy we may have to suspend a process. if the page fault rate increases and no free frames are available we must select some process and suspend it. the freed frames are then distributed to processes with high page fault rates. number of frames figure . page fault frequency. chapter virtual memory t rafcife ifewtrfehgiire sjgji f tiros as .refeifgiifieg m daja amt cocife skciioii r e lie fapft is oceujrs rk! ihis m jni at fe' fafls. flrig w i tj this .the . sta rt ofoneipeak andithestartiofithe ne xt peak iljustifa t js one warkine set to ai
 consider a sequential read of a file on disk using the standard system calls openq r e a d o and w r i t e q . each file access requires a system call and disk access. alternatively we can use the virtual memory techniques discussed so far to treat file i o as routine memory accesses. this approach known as memory mapping a file allows a part of the virtual address space to be logically associated with the file. . . basic mechanism memory mapping a file is accomplished by mapping a disk block to a page or pages in memory. initial access to the file proceeds through ordinary demand paging resulting in a page fault. however a page sized portion of the file is read from the file system into a physical page some systems may opt . memory mapped files to read in more than a page sized chunk of memory at a time . subsequent reads and writes to the file are handled as routine memory accesses thereby simplifying file access and usage by allowing the system to manipulate files through memory rather than incurring the overhead of using the readq and w r i t e o system calls. note that writes to the file mapped in memory are not necessarily immediate synchronous writes to the file on disk. some systems may choose to update the physical file when the operating system periodically checks whether the page in memory has been modified. when the file is closed all the memory mapped data are written back to disk and removed from the virtual memory of the process. some operating systems provide memory mapping only through a specific system call and use the standard system calls to perform all other file i o. however some systems choose to memory map a file regardless of whether the file was specified as memory mapped. let's take solaris as an example. if a file is specified as memory mapped using the mmapo system call solaris maps the file into the address space of the process. if a file is opened and accessed using ordinary system calls such as openo r e a d and w r i t e solaris still memory maps the file however the file is mapped to the kernel address space. regardless of how the file is opened then solaris treats all file i o as memory mapped allowing file access to take place via the efficient memory subsystem. multiple processes may be allowed to map the same file concurrently to allow sharing of data. writes by any of the processes modify the data in virtual memory and can be seen by all others that map the same section of r i i r r . j i i i i i i i i i i l process a i i process b virtual memory virtual memory physical memory i disk file figure . memory mapped files. chapter virtual memory the file. given our earlier discussions of virtual memory it should be clear how the sharing of memory mapped sections of memory is implemented the virtual memory map of each sharing process points to the same page of physical memory the page that holds a copy of the disk block. this memory sharing is illustrated in figure . . the memory mapping system calls can also support copy on write functionality allowing processes to share a file in read only mode but to have their own copies of any data they modify. so that access to the shared data is coordinated the processes involved might use one of the mechanisms for achieving mutual exclusion described in chapter . in many ways the sharing of memory mapped files is similar to shared memory as described in section . . . not all systems use the same mechanism for both on unix and linux systems for example memory mapping is accomplished with the mmap system call whereas shared memory is achieved with the posjx compliant shmgeto and shmato systems calls section . . . on windows nt and xp systems however shared memory is accomplished by memory mapping files. on these systems processes can communicate using shared memory by having the communicating processes memory map the same file into their virtual address spaces. the memorymapped file serves as the region of shared meniory between the communicating processes figure . . in the following section we illustrate support in the win api for shared memory using memory mapped files. . . shared memory in the win api the general outline for creating a region of shared memory using memorymapped files in the win api involves first creating a file mapping for the file to be mapped and then establishing a view of the mapped file in a process's virtual address space. a second process can then open and create a view of the mapped file in its virtual address space. the mapped file represents the shared memory object that will enable communication to take place between the processes. we next illustrate these steps in more detail. in this example a producer process first creates a shared memory object using the memory mapping features available in the win api. the producer then writes a message process process shared .. memory mapped riet?nery v file shared memoryv shiaped rnemdry figure . shared memory in windows using memory mapped i o. . memory mapped files to shared memory. after that a consumer process opens a mapping tp the shared memory object and reads the message written by the consumer. to establish a memory mapped file a process first opens the file to be mapped with the createfileo function which returns a handle to the opened file. the process then creates a mapping of this file handle using the createfilemappingo function. once the file mapping is established the process then establishes a view of the mapped file in its virtual address space with the mapviewof filec function. the view of the mapped file represents the portion of the file being mapped in the virtual address space of the process the entire file or only a portion of it may be mapped. we illustrate this ir.clude windows . h irdude stdio.h inn mainfint argc char argv i handle hfile hkapfile lpvcid lpmapaddress hfile createfile temp txt file name generic read generic write read write access no sharing of the file null default security open always . open new or existing file file attributejsiormal routine file attributes null . no file template hkapfile createfilemapping hfile file handle null . default security page readwrite read write access o mapped pages map entire file text sharedobject named shared memory object lpmapaddress mapviewoffile hmapfile mapped object handle file map allj ccess read write access mapped view of entire file . write to shared memory sprintf lpmapaddress shared memory message unmapviewoffile lpmapaddress closehandle hfile closehandle hmapfile figure . producer writing to shared memory using the win api. chapter virtual memory sequence in the program shown in figure . . we eliminate much of the error checking for code brevity. the call to createfilemapping o creates a named shared memory object calledsharedobject. the consumer process will communicate using this shared memory segment by creating a mapping to the same named object. the producer then creates a view of the memory mapped file in its virtual address space. by passing the last three parameters the value it indicates that the mapped view is the entire file. it could instead have passed values specifying an offset and size thus creating a view containing only a subsection of the file. it is important to note that the entire mapping may not be loaded into memory when the mapping is established. rather the mapped file may be demand paged thus bringing pages into memory only as they are accessed. the mapviewdf f i l e function returns a pointer to the shared memory object any accesses to this memory location are thus accesses to the memory mapped file. in this instance the producer process writes the message shared memory message to shared memory. a program illustrating how the consumer process establishes a view of the named shared memory object is shown in figure . . this program is somewhat simpler than the one shown in figure . as all that is necessary is for the process to create a mapping to the existing named shared memory object. the consumer process must also create a view of the mapped file just as the producer process did in the program in figure . . the consumer then include windows.h include stdio.h int main int argc char argv handle hmapfile lpvoid lpmapaddress hmapfile openfilemapping filejcap fl.llj ccess r w access false no inheritance text sharedobject nane of mapped file object lpmapaddress mapviev.'offile hmapfile mapped object handle file ap all access read write access mapped view of entire file read fron shared memory printf read message s ipmapaddress unmapviewoffile ipmapaddress closehandle hmapfile figure . consumer reading from shared memory using the win api
 s reads from shared memory the message shared memory message that was written by the producer process. finally both processes remove the view of the mapped file with a call to unmapviewoffileo. we provide a programming exercise at the end of this chapter using shared memory with memory mapping in the win api. . . memory mapped i o in the case of i o as mentioned in section . . each i o controller includes registers to hold commands and the data being transferred. usually special i o instructions allow data transfers between these registers and system memory. to allow more convenient access to i o devices many computer architectures provide memory mapped i o. in this case ranges of memory addresses are set aside and are mapped to the device registers. reads and writes to these memory addresses cause the data to be transferred to and from the device registers. this method is appropriate for devices that have fast response times such as video controllers. in the ibm pc each location on the screen is mapped to a memory location. displaying text on the screen is almost as easy as writing the text into the appropriate memory mapped locations. memory mapped i o is also convenient for other devices such as the serial and parallel ports used to connect modems and printers to a computer. the cpu transfers data through these kinds of devices by reading and wrriting a few device registers called an i o port. to send out a long string of bytes through a memory mapped serial port the cpu writes one data byte to the data register and sets a bit in the control register to signal that the byte is available. the device takes the data byte and then clears the bit in the control register to signal that it is ready for the next byte. then the cpu can transfer the next byte. if the cpu uses polling to watch the control bit constantly looping to see whether the device is ready this method of operation is called programmed i o pio . if the cpu does not poll the control bit but instead receives an interrupt when the device is ready for the next byte the data transfer is said to be interrupt driven. . allocating kernel memory when a process running in user mode requests additional memory pages are allocated from the list of free page frames maintained by the kernel. this list is typically populated using a page replacement algorithm such as those discussed in section . and most likely contains free pages scattered throughout physical memory as explained earlier. remember too that if a user process requests a single byte of memory internal fragmentation will result as the process will be granted an entire page frame. kernel memory however is often allocated from a free memory pool different from the list used to satisfy ordinary user mode processes. there are two primary reasons for this . the kernel requests memory for data structures of varying sizes some of which are less than a page in size. as a result the kernel must use memory conservatively and attempt to minimize waste due to fragmentation. this chapter virtual memory is especially important because many operating systems do not subject kernel code or data to the paging system. . pages allocated to user mode processes do not necessarily have to be in contiguous physical memory. however certain hardware devices interact directly with physical memory without the benefit of a virtual memory interface and consequently may require memory residing in physically contiguous pages. in the following sections we examine two strategies for managing free memory that is assigned to kernel processes. . . buddy system the buddy system allocates memory from a fixed size segment consisting of physically contiguous pages. memory is allocated from this segment using a power of allocator which satisfies requests in units sized as a power of kb kb kb and so forth . a request in units not appropriately sized is rounded up to the next highest power of . for example if a request for kb is made it is satisfied with a kb segment. next we explain the operation of the buddy system with a simple example. let's assume the size of a memory segment is initially kb and the kernel requests kb of memory. the segment is initially divided into two buddies which we will call ai and ar each kb in size. one of these buddies is further divided into two kb buddies b and b . however the next highest power of from kb is kb so either b or br is again divided into two kb buddies c . and cr. one of these buddies is used to satisfy the kb request. this scheme is illustrated in figure . where c is the segment allocated to the kb request. physically contiguous pages kb ' ah i o ' ' ... .. .. ... .... ... jvj jq fi 'l j' 'i i' ! 'i kb . ikb l i . b . rkb j k figure . buddy system allocation. . allocating kernel memory an advantage of the buddy system is how quickly adjacent buddies dan be combined to form larger segments using a technique known as coalescing. in figure . for example when the kernel releases the q. unit it was allocated the system can coalesce c l and cr into a kb segment. this segment bl can in turn be coalesced with its buddy br to form a kb segment. ultimately we can end up with the original kb segment. the obvious drawback to the buddy system is that rounding up to the next highest power of is very likely to cause fragmentation within allocated segments. for example a kb request can only be satisfied with a kb segment. in fact we cannot guarantee that less than percent of the allocated unit will be wasted due to internal fragmentation. in the following section we explore a memory allocation scheme where no space is lost due to fragmentation. . . slab allocation a second strategy for allocating kernel memory is known as slab allocation. a slab is made up of one or more physically contiguous pages. a cache consists of one or more slabs. there is a single cache for each unique kernel data structure for example a separate cache for the data structure representing process descriptors a separate cache for file objects a separate cache for semaphores and so forth. each cache is populated with objects that are instantiations of the kernel data structure the cache represents. for example the cache representing semaphores stores instances of semaphores objects the cache representing process descriptors stores instances of process descriptor objects etc. the relationship between slabs caches and objects is shown in figure . . the figure shows two kernel objects kb in size and three objects kb in size. these objects are stored in their respective caches. kernel objects caches slabs kb objects physically contiguous pages kb objects figure . slab allocation. chapter virtual memory the slab allocation algorithm uses caches to store kernel objects. when a cache is created a number of objects which are initially marked as free are allocated to the cache. the number of objects in the cache depends on the size of the associated slab. for example a kb slab comprised of three continguous kb pages could store six kb objects. initially all objects in the cache are marked as free. when a new object for a kernel data structure is needed the allocator can assign any free object from the cache to satisfy the request. the object assigned from the cache is marked as used. let's consider a scenario in which the kernel requests memory from the slab allocator for an object representing a process descriptor. in linux systems a process descriptor is of the type struct task struct which requires approximately . kb of memory. when the linux kernel creates a new task it requests the necessary memory for the s t r u c t t a s k . s t r u c t object from its cache. the cache will fulfill the request using a struct t a s k s t r u c t object that has already been allocated in a slab and is marked as free. in linux a slab may be in one of three possible states . full. all objects in the slab are marked as used. . empty. all objects in the slab are marked as free. . partial. the slab consists of both used and free objects. the slab allocator first attempts to satisfy the request with a free object in a partial slab. if none exist a free object is assigned from an empty slab. if no empty slabs are available a new slab is allocated from contiguous physical pages and assigned to a cache memory for the object is allocated from this slab. the slab allocator provides two main benefits . no memory is wasted due to fragmentation. fragmentation is not an issue because each unique kernel data structure has an associated cache and each cache is comprised of one or more slabs that are divided into chunks the size of the objects being represented. thus when the kernel requests memory for an object the slab allocator returns the exact amount of memory required to represent the object. . memory requests can be satisfied quickly. the slab allocation scheme is thus particularly effective for managing memory where objects are frequently allocated and deallocated as is often the case with requests from the kernel. the act of allocating and releasing memory can be a time consuming process. however objects are created in advance and thus can be quickly allocated from the cache. furthermore when the kernel has finished with an object and releases it it is marked as free and returned to its cache thus making it immediately available for subsequent requests from the kernel. the slab allocator first appeared in the solaris . kernel. because of its general purpose nature this allocator is now also used for certain user mode memory requests in solaris. linux originally used the buddy system however beginning with version . the linux kernel adopted the slab allocator
 . other considerations the major decisions that we make for a paging system are the selections of a replacement algorithm and an allocation policy which we discussed earlier in this chapter. there are many other considerations as welt and we discuss several of them here. . . prepaging an obvious property of pure demand paging is the large number of page faults that occur when a process is started. this situation results from trying to get the initial locality into memory. the same situation may arise at other times. for instance when a swapped out process is restarted all its pages are on the disk and each must be brought in by its own page fault. prepaging is an attempt to prevent this high level of initial paging. the strategy is to bring into memory at one time all the pages that will be needed. some operating systems notably solaris prepage the page frames for small files. in a system using the working set model for example we keep with each process a list of the pages in its working set. if we must suspend a process due to an i o wait or a lack of free frames we remember the working set for that process. when the process is to be resumed because i o has finished or enough free frames have become available we automatically bring back into memory its entire working set before restarting the process. prepaging may offer an advantage in some cases. the question is simply whether the cost of using prepaging is less than the cost of servicing the corresponding page faults. it may well be the case that many of the pages brought back into memory by prepaging will not be used. assume that s pages are prepaged and a fraction a of these s pages is actually used a . the question is whether the cost of the s a saved page faults is greater or less than the cost of prepaging s a unnecessary pages. if a is close to prepaging loses if a is close to prepaging wins. . . page size the designers of an operating system for an existing machine seldom have a choice concerning the page size. however when new machines are being designed a decision regarding the best page size must be made. as you might expect there is no single best page size. rather there is a set of factors that support various sizes. page sizes are invariably powers of generally ranging from to bytes. how do we select a page size? one concern is the size of the page table. for a given virtual memory space decreasing the page size increases the number of pages and hence the size of the page table. for a virtual memory of mb for example there would be pages of bytes but only pages of bytes. because each active process must have its own copy of the page table a large page size is desirable. memory is better utilized with smaller pages however. if a process is allocated memory starting at location and continuing until it has as much as it needs it probably will not end exactly on a page boundary. thus a part of the final page must be allocated because pages are the units of allocation. but will be unused creating internal fragmentation . assuming independence chapter virtual memory of process size and page size we can expect that on the average halfof the final page of each process will be wasted. this loss is only bytes for a page of bytes but is bytes for a page of bytes. to minimize internal fragmentation then we need a small page size. another problem is the time required to read or write a page. i o time is composed of seek latency and transfer times. transfer time is proportional to the amount transferred that is the page size a fact that would seem to argue for a small page size. however as we shall see in section . . latency and seek time normally dwarf transfer time. at a transfer rate of mb per second it takes only . milliseconds to transfer bytes. latency time though is perhaps milliseconds and seek time milliseconds. of the total i o time . milliseconds therefore only percent is attributable to the actual transfer. doubling the page size increases i o time to only . milliseconds. it takes . milliseconds to read a single page of bytes but . milliseconds to read the same amount as two pages of bytes each. thus a desire to minimize i o time argues for a larger page size. with a smaller page size though total i o should be reduced since locality will be improved. a smaller page size allows each page to match program locality more accurately. for example consider a process kb in size of which only half kb is actually used in an execution. if we have only one large page we must bring in the entire page a total of kb transferred and allocated. if instead we had pages of only byte then we could bring in only the kb that are actually used resulting in only kb transferred and allocated. with a smaller page size we have better resolution allowing us to isolate only the memory that is actually needed. with a larger page size we must allocate and transfer not only what is needed but also anything else that happens to be in the page whether it is needed or not. thus a smaller page size should result in less i o and less total allocated memory. but did you notice that with a page size of byte we would have a page fault for each byte? a process of kb that used only half of that memory would generate only one page fault with a page size of kb but page faults with a page size of byte. each page fault generates the large amount of overhead needed for processing the interrupt saving registers replacing a page queueing for the paging device and updating tables. to minimize the number of page faults we need to have a large page size. other factors must be considered as well such as the relationship between page size and sector size on the paging device . the problem has no best answer. as we have seen some factors internal fragmentation locality argue for a small page size whereas others table size i o time argue for a large page size. however the historical trend is toward larger page sizes. indeed the first edition of operating systems concepts used bytes as the upper bound on page sizes and this value was the most common page size in . however modern systems may now use much larger page sizes as we will see in the following section. . . tlb r e a c h in chapter we introduced the hit ratio of the tlb. recall that the hit ratio for the tlb refers to the percentage of virtual address translations that are resolved in the tlb rather than the page table. clearly the hit ratio is related . other considerations to the number of entries in the tlb and the way to increase the hit ratio is by increasing the number of entries in the tlb. this however does not come cheaply as the associative memory used to construct the tlb is both expensive and power hungry. related to the hit ratio is a similar metric the tlb reach. the tlb reach refers to the amount of memory accessible from the tlb and is simply the number of entries multiplied by the page size. ideally the working set for a process is stored in the tlb. if not the process will spend a considerable amount of time resolving memory references in the page table rather than the tlb. if we double the number of entries in the tlb we double the tlb reach. however for some memory intensive applications this may still prove insufficient for storing the working set. another approach for increasing the tlb reach is to either increase the size of the page or provide multiple page sizes. if we increase the page size say from kb to kb we quadruple the tlb reach. however this may lead to an increase in fragmentation for some applications that do not require such a large page size as kb. alternatively an operating system may provide several different page sizes. for example the ultrasparc supports page sizes of kb kb kb and mb. of these available pages sizes solaris uses both kb and mb page sizes. and with a entry tlb the tlb reach for solaris ranges from kb with kb pages to mb with mb pages. for the majority of applications the kb page size is sufficient although solaris maps the first mb of kernel code and data with two mb pages. solaris also allows applications such as databases to take advantage of the large mb page size. providing support for multiple pages requires the operating system not hardware to manage the tlb. for example one of the fields in a tlb entry must indicate the size of the page frame corresponding to the tlb entry. managing the tlb in software and not hardware comes at a cost in performance. however the increased hit ratio and tlb reach offset the performance costs. indeed recent trends indicate a move toward software managed tlbs and operating system support for multiple page sizes. the ultrasparc mips and alpha architectures employ software managed tlbs. the powerpc and pentium manage the tlb in hardware. . . inverted page tables section . . introduced the concept of the inverted page table. the purpose of this form of page management is to reduce the amount of physical memory needed to track virtual to physical address translations. we accomplish this savings by creating a table that has one entry per page of physical memory indexed by the pair process id page number . because they keep information about which virtual memory page is stored in each physical frame inverted page tables reduce the amount of physical memory needed to store this information. however the inverted page table no longer contains complete information about the logical address space of a process and that information is required if a referenced page is not currently in memory. demand paging requires this information to process page faults. for the information to be available an external page table one per process chapter virtual memory must be kept. each such table looks like the traditional per process page table and contains information on where each virtual page is located. but do external page tables negate the utility of inverted page tables? since these tables are referenced only when a page fault occurs they do not need to be available quickly. instead they are themselves paged in and out of memory as necessary. unfortunately a page fault may now cause the virtual memory manager to generate another page fault as it pages in the external page table it needs to locate the virtual page on the backing store. this special case requires careful handling in the kernel and a delay in the page lookup processing. . . program structure demand paging is designed to be transparent to the user program. in many cases the user is completely unaware of the paged nature of memory. in other cases however system performance can be improved if the user or compiler has an awareness of the underlying demand paging. let's look at a contrived but informative example. assume that pages are words in size. consider a c program whose function is to initialize to each element of a by array. the following code is typical int i j int data for j j j for i i i data i j notice that the array is stored row major that is the array is stored data data data data l data l data . for pages of words each row takes one page. thus the preceding code zeros one word in each page then another word in each page and so on. if the operating system allocates fewer than frames to the entire program then its execution will result in x page faults. in. contrast changing the code to int i j int data for i i i for j j j data i j zeros all the words on one page before starting the next page reducing the number of page faults to . careful selection of data structures and programming structures can increase locality and hence lower the page fault rate and the number of pages in the working set. for example a stack has good locality since access is always made to the top. a hash table in contrast is designed to scatter references producing bad locality. of course locality of reference is just one measure of the efficiency of the use of a data structure. other heavily weighted factors . other considerations include search speed total number of memory references and total number of pages touched. at a later stage the compiler and loader can have a significant effect on paging. separating code and data and generating reentrant code means that code pages can he read only and hence will never he modified. clean pages do not have to be paged out to be replaced. the loader can avoid placing routines across page boundaries keeping each routine completely in one page. routines that call each other many times can be packed into the same page. this packaging is a variant of the bin packing problem of operations research try to pack the variable sized load segments into the fixed sized pages so that interpage references are minimized. such an approach is particularly useful for large page sizes. the choice of programming language can affect paging as well. for example c and c use pointers frequently and pointers tend to randomize access to memory thereby potentially diminishing a process's locality. some studies have shown that object oriented programs also tend to have a poor locality of reference. . . i o interlock when demand paging is used we sometimes need to allow some of the pages to be locked in memory. one such situation occurs when i o is done to or from user virtual memory. i o is often implemented by a separate i o processor. for example a controller for a usb storage device is generally given the number of bytes to transfer and a memory address for the buffer figure . . when the transfer is complete the cpu is interrupted. buffer figure . the reason why frames used for i o must be in memory. chapter virtual memory we must be sure the following sequence of events does not occur a process issues an i o request and is put in a queue for that i o device. meanwhile the cpu is given to other processes. these processes cause page faults and one of them using a global replacement algorithm replaces the page containing the memory buffer for the waiting process. the pages are paged out. some time later when the i o request advances to the head of the device queue the i o occurs to the specified address. however this frame is now being used for a different page belonging to another process. there are two common solutions to this problem. one solution is never to execute i o to user memory. instead data are always copied between system memory and user memory. i o takes place only between system memory and the i o device. to write a block on tape we first copy the block to system memory and then write it to tape. this extra copying may result in unacceptably high overhead. another solution is to allow pages to be locked into memory. here a lock bit is associated with every frame. if the frame is locked it cannot be selected for replacement. under this approach to write a block on tape we lock into memory the pages containing the block. the system can then continue as usual. locked pages cannot be replaced. when the i o is complete the pages are unlocked. lock bits are used in various situations. frequently some or all of the operating system kernel is locked into memory as many operating systems cannot tolerate a page fault caused by the kernel. another use for a lock bit involves normal page replacement. consider the following sequence of events a low priority process faults. selecting a replacement frame the paging system reads the necessary page into memory. ready to continue the low priority process enters the ready queue and waits for the cpu. since it is a low priority process it may not be selected by the cpu scheduler for a time. while the low priority process waits a high priority process faults. looking for a replacement the paging system sees a page that is in memory but has not been referenced or modified tt is the page that the low priority process just brought in. this page looks like a perfect replacement it is clean and will not need to be written out and it apparently has not been used for a long time. whether the high priority process should be able to replace the low priority process is a policy decision. after all we are simply delaying the low priority process for the benefit of the high priority process. however we are wasting the effort spent to bring in the page for the low priority process. if we decide to prevent replacement of a newly brought in page until it can be used at least once then we can use the lock bit to implement this mechanism. when a page is selected for replacement its lock bit is turned on it remains on until the faulting process is again dispatched. using a lock bit can be dangerous the lock bit may get turned on but never turned off. should this situation occur because of a bug in the operating system for example the locked frame becomes unusable. on a single user system the overuse of locking would hurt only the user doing the locking. multiuser systems must be less trusting of users. for instance solaris allows locking hints but it is free to disregard these hints if the free frame pool becomes too small or if an individual process requests that too many pages be locked in memory
 . operating system examples in this section we describe how windows xp and solaris implement virtual memory. . . windows xp windows xp implements virtual memory using demand paging with clustering. clustering handles page faults by bringing in not only the faulting page but also several pages following the faulting page. when a process is first created it is assigned a working set minimum and maximum. the working set minimum is the minimum number of pages the process is guaranteed to have in memory. if sufficient memory is available a process may be assigned as many pages as its working set maximum. for most applications the value of working set minimum and working set maximum is and pages respectively. in some circumstances a process may be allowed to exceed its working set maximum. the virtual memory manager maintains a list of free page frames. associated with this list is a threshold value that is used to indicate whether sufficient free memory is available. if a page fault occurs for a process that is below its working set maximum the virtual memory manager allocates a page from this list of free pages. if a process is at its working set maximum and it incurs a page fault it must select a page for replacement using a local page replacement policy. when the amount of free memory falls below the threshold the virtual memory manager uses a tactic known as automatic working set trimming to restore the value above the threshold. automatic working set trimming works by evaluating the number of pages allocated to processes. if a process has been allocated more pages than its working set minimum the virtual memory manager removes pages until the process reaches its working set minimum. a process that is at its working set minimum may be allocated pages from the free page frame list once sufficient free memory is available. the algorithm used to determine which page to remove from a working set depends on the type of processor. on single processor x systems windows xp uses a variation of the clock algorithm discussed in section . . . . on alpha and multiprocessor x systems clearing the reference bit may require invalidating the entry in the translation look aside buffer on other processors. rather than incurring this overhead windows xp uses a variation on the fifo algorithm discussed in section . . . . . solaris in solaris when a thread incurs a page fault the kernel assigns a page to the faulting thread from the list of free pages it maintains. therefore it is imperative that the kernel keep a sufficient amount of free memory available. associated with this list of free pages is a parameter lotsfree that represents a threshold to begin paging. the lotsfree parameter is typically set to the size of the physical memory. four times per second the kernel checks whether the amount of free memory is less than lotsfree. if the number of free pages falls below lotsfree a process known as the pageout starts up. the pageout process is similar to the second chance algorithm described in section . . . except that it uses two hands while scanning pages rather than one as described in section chapter virtual memory fastscan siowscan minfree desfree lotsfree amount of free memory figure . solaris page scanner. . . . . the pageout process works as follows the front hand of the clock scans all pages in memory setting the reference bit to . later the back hand of the clock examines the reference bit for the pages in memory appending those pages whose bit is still set to to the free list and writing to disk their contents if modified. solaris maintains a cache list of pages that have been freed but have not yet been overwritten. the free list contains frames that have invalid contents. pages can be reclaimed from the cache list if they are accessed before being moved to the free list. the pageout algorithm uses several parameters to control the rate at which pages are scanned known as the scanrate . the scanrate is expressed in pages per second and ranges from siowscan to fastscan. when free memory falls below lotsfree scanning occurs at siowscan pages per second and progresses to fastscan depending on the amount of free memory available. the default value of siowscan is pages per second fastscan is typically set to the value total physical pages pages per second with a maximum of pages per second. this is shown in figure . with fastscan set to the maximum . the distance in pages between the hands of the clock is determined by a system parameter lumdspread. the amount of time between the front hand's clearing a bit and the back hand's investigating its value depends on the scanrate and the handspread. if scanrate is pages per second and lmndspread is pages seconds can pass between the time a bit is set by the front hand and the time it is checked by the back hand. however because of the demands placed on the memory system a scanrate of several thousand is not uncommon. this means that the amount of time between clearing and investigating a bit is often a few seconds. as mentioned above the pageout process checks memory four times per second. however if free memory falls below desfree figure . pageout will run times per second with the intention of keeping at least desfree free memory available. if the pageout process is unable to keep the amount
 computers can store information on various storage media such as magnetic disks magnetic tapes and optical disks. so that the computer system will be convenient to use the operating system provides a uniform logical view of information storage. the operating system abstracts from the physical properties of its storage devices to define a logical storage unit the file. files are mapped by the operating system onto physical devices. these storage devices are usually nonvolatile so the contents are persistent through power failures and system reboots. chapter file system interface a file is a named collection of related information that is recorded on secondary storage. from a user's perspective a tile is the smallest allotment of logical secondary storage that is data cannot be written to secondary storage unless they are within a file. commonly files represent programs both source and object forms and data. data files may be numeric alphabetic alphanumeric or binary. files may be free form such as text files or may be formatted rigidly. in general a file is a sequence of bits bytes lines or records the meaning of which is defined by the file's creator and user. the concept of a file is thus extremely general. the information in a file is defined by its creator. many different types of information may be stored in a file source programs object programs executable programs numeric data text payroll records graphic images sound recordings and so on. a file has a certain defined structure which depends on its type. a text file is a sequence of characters organized into lines and possibly pages . a source file is a sequence of subroutines and functions each of which is further organized as declarations followed by executable statements. an object file is a sequence of bytes organized into blocks understandable by the system's linker. an executable file is a series of code sections that the loader can bring into memory and execute. . . file attributes a file is named for the convenience of its human users and is referred to by its name. a name is usually a string of characters such as example.c. some systems differentiate between uppercase and lowercase characters in names whereas other systems do not. when a file is named it becomes independent of the process the user and even the system that created it. for instance one user might create the file example.c and another user might edit that file by specifying its name. the file's owner might write the file to a floppy disk send it in an e mail or copy it across a network and it could still be called example.c on the destination system. a file's attributes vary from one operating system to another but typically consist of these s name. the symbolic file name is the only information kept in humanreadable form . identifier. this unique tag usually a number identifies the file within the file system it is the non human readable name for the file. type. this information is needed for systems that support different types of files. location. this information is a pointer to a device and to the location of the file on that device. size. the current size of the file in bytes words or blocks and possibly the maximum allowed size are included in this attribute. protection. access control information determines who can do reading writing executing and so on. . file concept time date and user identification. this information may be kept for creation last modification and last use. these data can be useful for protection security and usage monitoring. the information about all files is kept in the directory structure which also resides on secondary storage. typically a directory entry consists of the file's name and its unique identifier. the identifier in turn locates the other file attributes. it may take more than a kilobyte to record this information for each. file. in a system with many files the size of the directory itself may be megabytes. because directories like files must be nonvolatile they must be stored on the device and brought into memory piecemeal as needed. . file operations a file is an abstract data type. to define a file properly we need to consider the operations that can be performed on files. the operating system can provide system calls to create write read reposition delete and truncate files. let's examine what the operating system must do to perform each of these six basic file operations. it should then be easy to see how other similar operations such as renaming a file can be implemented. creating a file. two steps are necessary to create a file. first space in the file system must be found for the file. we discuss how to allocate space for the file in chapter . second an entry for the new file must be made in the directory. writing a file. to write a file we make a system call specifying both the name of the file and the information to be written to the file. given the name of the file the system searches the directory to find the file's location. the system must keep a write pointer to the location in the file where the next write is to take place. the write pointer must be updated whenever a write occurs. reading a file. to read from a file we use a system call that specifies the name of the file and where in memory the next block of the file should be put. again the directory is searched for the associated entry and the system needs to keep a read pointer to the location in the file where the next read is to take place. once the read has taken place the read pointer is updated. because a process is usually either reading from or writing to a file the current operation location can be kept as a per process currentfile position pointer. both the read and write operations use this same pointer saving space and reducing system complexity. repositioning within a file. the directory is searched for the appropriate entry and the current file position pointer is repositioned to a given value. repositioning within a file need not involve any actual i o. this file operation is also known as a file seek. deleting a file. to delete a file we search the directory for the named file. having found the associated directory entry we release all file space so that it can be reused bv other files and erase the directory entry. chapter file system interface truncating a file. the user may want to erase the contents of a file but keep its attributes. rather than forcing the user to delete the file and then recreate it this function allows all attributes to remain unchanged except for file length but lets the tile be reset to length zero and its file space released. these six basic operations comprise the minimal set of required file operations. other common operations include appending new information to the end of an existing file and renaming an existing file. these primitive operations can then be combined to perform other file operations. for instance we can create a copy of a file or copy the file to another i o device such as a printer or a display by creating a new file and then reading from the old and writing to the new. we also want to have operations that allow a user to get and set the various attributes of a file. for example we may want to have operations that allow a user to determine the status of a file such as the file's length and to set file attributes such as the file's owner. most of the file operations mentioned involve searching the directory for the entry associated with the named file. to avoid this constant searching many systems require that an openo system call be made before a file is first used actively. the operating system keeps a small table called the open file table containing information about all open files. when a file operation is requested the file is specified via an index into this table so no searching is required. when the file is no longer being actively used it is closed by the process and the operating system removes its entry from the open file table c r e a t e and d e l e t e are system calls that work with closed rather than open files. some systems implicitly open a file when the first reference to it is made. the file is automatically closed when the job or program that opened the file terminates. most systems however require that the programmer open a file explicitly with the openo system call before that file can be used. the openo operation takes a file name and searches the directory copying the directory entry into the open file table. the openo call can also accept accessmode information create read only read write append only and so on. this mode is checked against the file's permissions. if the request mode is allowed the file is opened for the process. the openo system call typically returns a pointer to the entry in the open file table. this pointer not the actual file name is used in all i o operations avoiding any further searching and simplifying the system call interface. the implementation of the openo and close operations is more complicated in an environment where several processes may open the file at the same time. this may occur in a system where several different applications open the same file at the same time. typically the operating system uses two levels of internal tables a per process table and a system wide table. the perprocess table tracks all files that a process has open. stored in this table is information regarding the use of the file by the process. for instance the current file pointer for each file is found here. access rights to the file and accounting information can also be included. each entry in the per process table in turn points to a system wide open file table. the system wide table contains process independent information such as the location of the file on disk access dates and file size. once a file has been opened by one process the system wide table includes an entry for the file. . file concept when another process executes an openq call a new entry is simply added to the process's open file table pointing to the appropriate entry in the systemwide table. typically. the open file table also has an open count associated with each file to indicate how many processes have the file open. each close decreases this open count and when the open count reaches zero the file is no longer in use and the file's entry is removed from the open file table. in summary several pieces of information are associated with an open file. file pointer. on systems that do not include a file offset as part of the reado and write system calls the system must track the last readwrite location as a current file position pointer. this pointer is unique to each process operating on the file and therefore must be kept separate from the on disk file attributes. file open count. as files are closed the operating system must reuse its open file table entries or it could run out of space in the table. because multiple processes may have opened a file the system must wait for the last file to close before removing the open file table entry. the file open counter tracks the number of opens and closes and reaches zero on the last close. the system can then remove the entry. disk location of the file. most file operations require the system to modify data within the file. the information needed to locate the file on disk is kept in memory so that the system does not have to read it from disk for each operation. access rights. each process opens a file in an access mode. this information is stored on the per process table so the operating system can allow or deny subsequent i o requests. some operating systems provide facilities for locking an open file or sections of a file . file locks allow one process to lock a file and prevent other processes from gaining access to it. file locks are useful for files that are shared by several processes for example a system log file that can be accessed and modified by a number of processes in the system. li i the faya ?yn afcq u hng adeck requires for tlnevfite intended to be foekrf. thelaock mei ht is used to acquire the lock. the sj 't f t.h where begin an d erid are the beg i! tn ri g asd nsjn d tti bs o tlig region ibelng loeked. isetr b g sriared i t fco?sje iis ft ihafes ilcjcmsji seltilng isflffii'el to f a l s e acquires the xock excitjtslvely thfi fpek is !eased by iflvplsiilig the r e l e a s e of the fileloick retiurredby tfee lockv optjratipn. acquires two locks oni the fi le ifc fif th e fir t ht f oshfcfife exclusive lock the lock far the second half is a shared lock. chapter file system interface .impairs java. ait! . ctjaniiel ss . piitflic s na tig. final fesoleg .v.v. .ll . .. . . randarfiagcessfire r a f . ns.w 'raildoinsc c e s s p i l e ei l.e . txt' get. the .channel fcr the file .fil.echannel ch raf gefchannel . this locks the first half of t e file sxoluaive e h i o e k to . raf . leketiih j i exigl stve mow modify the data . . . release the lock exdusiveloclv. release this locks the second r.alf c the file shared sharedlock ch . lock raf.. ienc h raf length shared. kow read the data ... ' ii release the lock exclusivelock.release catch j ava . io . ioexcept.ior. ioe i systetr..err pri.ntln ioej sfve ogk ! s hull . sharedlcck.releasei i t figure b. kle ldekiifig exartipte m file locks provide functionality similar to reader writer locks covered in section . . . a shared lock is akin to a reader lock in that several processes can acquire the lock concurrently. an exclusive lock behaves like a writer lock only one process at a time can acquire such a lock. it is important to note . file concept that not all operating systems provide both types of locks some systems only provide exclusive file locking. furthermore operating systems may provide either mandatory or advisory file locking mechanisms. if a lock is mandatory then once a process acquires an exclusive lock the operating system will prevent any other process from accessing the locked file. for example assume a process acquires an exclusive lock on the file system.log. if we attempt to open system.log from another process for example a text editor the operating system will prevent access until the exclusive lock is released. this occurs even if the text editor is not written explicitly to acquire the lock. alternatively if the lock is advisory then the operating system will not prevent the text editor from acquiring access to system. log. rather the text editor must be written so that it manually acquires the lock before accessing the file. in other words if the locking scheme is mandatory the operating system ensures locking integrity. for advisory locking it is up to software developers to ensure that locks are appropriately acquired and released. as a general rule windows operating systems adopt mandatory locking and unix systems employ advisory locks. the use of file locks requires the same precautions as ordinary process synchronization. for example programmers developing on systems with mandatory locking must be careful to hold exclusive file locks only while they are accessing the file otherwise they will prevent other processes from accessing the file as well. furthermore some measures must be taken to ensure that two or more processes do not become involved in a deadlock while trying to acquire file locks. . . fiie types when we design a file system indeed an entire operating system we always consider whether the operating system should recognize and support file types. if an operating system recognizes the type of a file it can then operate on the file in reasonable ways. for example a common mistake occurs when a user tries to print the binary object form of a program. this attempt normally produces garbage however the attempt can succeed if the operating system has been told that the file is a binary object program. a common technique for implementing file types is to include the type as part of the file name. the name is split into two parts a name and an extension usually separated by a period character figure . . in this way the user and the operating system can tell from the name alone what the type of a file is. for example most operating systems allow users to specify file names as a sequence of characters followed by a period and terminated by an extension of additional characters. file name examples include resume.doc scrver.java and readerthread.c. the system uses the extension to indicate the type of the file and the type of operations that can be done on that file. only a file with a .com .cxe or .bat extension can be executed for instance. the .com and .exe files are two forms of binary executable files whereas a .bat file is a batch file containing in ascii format commands to the operating system. ms dos recognizes only a few extensions but application programs also use extensions to indicate file types in which they are interested. for example assemblers expect source files to have an .asm extension and the microsoft word word processor expects its files to end with a .doc extension. these extensions are not required so a user may chapter file system interface multimedia may rm binary file containing mp auicito or a v informcition figure . common file types. specify a file without the extension to save typing and the application will look for a file with the given name and the extension it expects. because these extensions are not supported by the operating system they can be considered as hints to the applications that operate on them. another example of the utility of file types comes from the tops operating system. if the user tries to execute an object program whose source file has been modified or edited since the object file was produced the source file will be recompiled automatically. this function ensures that the user always runs an up to date object file. otherwise the user could waste a significant amount of time executing the old object file. for this function to be possible the operating system must be able to discriminate the source file from the object file to check the time that each file was created or last modified and to determine the language of the source program in order to use the correct compiler . consider too the mac os x operating system. in this system each file has a type such as text for text file or appl for application . each file also has a creator attribute containing the name of the program that created it. this attribute is set by the operating system during the create call so its use is enforced and supported by the system. for instance a file produced by a word processor has the word processor's name as its creator. when the user opens that file by double clicking the mouse on the icon representing the file the word processor is invoked automatically and the file is loaded ready to be edited. . file concept the unix system uses a crude magic number stored at the beginning of some files to indicate roughly the type of the file executable program batch file or shell script postscript file and so on. not all files have magic numbers so system features cannot be based solely on this information. unix does not record the name of the creating program either. unix does allow file nameextension hints but these extensions are neither enforced nor depended on by the operating system they are meant mostly to aid users in determining the type of contents of the file. extensions can be used or ignored by a given application but that is up to the application's programmer. . . file structure file types also can be used to indicate the internal structure of the file. as mentioned in section . . source and object files have structures that match the expectations of the programs that read them. further certain files must conform to a required structure that is understood by the operating system. for example the operating system requires that an executable file have a specific structure so that it can determine where in memory to load the file and what the location of the first instruction is. some operating systems extend this idea into a set of system supported file structures with sets of special operations for manipulating files with those structures. for instance dec's vms operating system has a file system that supports three defined file structures. this point brings us to one of the disadvantages of having the operating system support multiple file structures the resulting size of the operating system is cumbersome. if the operating system defines five different file structures it needs to contain the code to support these file structures. in addition every file may need to be definable as one of the file types supported by the operating system. when new applications require information structured in ways not supported by the operating system severe problems may result. for example assume that a system supports two types of files text files composed of ascii characters separated by a carriage return and line feed and executable binary files. now if we as users want to define an encrypted file to protect the contents from being read by unauthorized people we may find neither file type to be appropriate. the encrypted file is not ascii text lines but rather is apparently random bits. although it may appear to be a binary file it is not executable. as a result we may have to circumvent or misuse the operating system's file types mechanism or abandon our encryption scheme. some operating systems impose and support a minimal number of file structures. this approach has been adopted in unix ms dos and others. unix considers each file to be a sequence of bit bytes no interpretation of these bits is made by the operating system. this scheme provides maximum flexibility but little support. each application program must include its own code to interpret an input file as to the appropriate structure. however all operating systems must support at least one structure that of an executable file so... that the system is able to load and run programs. the macintosh operating system also supports a minimal number of file structures. it expects files to contain two parts a resource fork and a data fork. the resource fork contains information of interest to the user. for instance it holds the labels of any buttons displayed by the program. a foreign user may want to re label these buttons in his own language and chapter file system interface the macintosh operating system provides tools to allow modification ef the data in the resource fork. the data fork contains program code or data the traditional file contents. to accomplish the same task on a unix or ms dos system the programmer would need to change and recompile the source code unless she created her own user changeable data file. clearly it is useful for an operating system to support structures that will be used frequently and that will save the programmer substantial effort. too few structures make programming inconvenient whereas too many cause operating system bloat and programmer confusion. . . internal file structure internally locating an offset within a file can be complicated for the operating system. disk systems typically have a well defined block size determined by the size of a sector. all disk i o is performed in units of one block physical record and all blocks are the same size. it is unlikely that the physical record size will exactly match the length of the desired logical record. logical records may even vary in length. packing a number of logical records into physical blocks is a common solution to this problem. for example the unix operating system defines all files to be simply streams of bytes. each byte is individually addressable by its offset from the beginning or end of the file. in this case the logical record size is byte. the file system automatically packs and unpacks bytes into physical disk blocks say bytes per block as necessary. the logical record size physical block size and packing technique determine how many logical records are in each physical block. the packing can be done either by the user's application program or by the operating system. in either case the file may be considered to be a sequence of blocks. all the basic i o functions operate in terms of blocks. the conversion from logical records to physical blocks is a relatively simple software problem. because disk space is always allocated in blocks some portion of the last block of each file is generally wasted. if each block were bytes for example then a file of bytes would be allocated four blocks bytes the last bytes would be wasted. the waste incurred to keep everything in units of blocks instead of bytes is internal fragmentation. all file systems suffer from internal fragmentation the larger the block size the greater the internal fragmentation
 files store information. when it is used this information must be accessed and read into computer memory. the information in the file can be accessed in several ways. some systems provide only one access method for files. other systems such as those of ibm support many access methods and choosing the right one for a particular application is a major design problem. . . sequential access the simplest access method is sequential access. information in the file is processed in order one record after the other. this mode of access is by far the . access methods beginning current position end rewind read or write s figure . sequential access file. most common for example editors and compilers usually access files in this fashion. reads and writes make up the bulk of the operations on a file. a read operation read next reads the next portion of the file and automatically advances a file pointer which tracks the i o location. similarly the write operation write next appends to the end of the file and advances to the end of the newly written material the new end of file . such a file can be reset to the beginning and on some systems a program .may be able to skip forward or backward n records for some integer n perhaps only for n . sequential access which is depicted in figure . is based on a tape model of a file and works as well on sequential access devices as it does on random access ones. . . direct access another method is direct access or relative access . a file is made up of fixedlength logical records that allow programs to read and write records rapidly in no particular order. the direct access method is based on a disk model of a file since disks allow random access to any file block. for direct access the file is viewed as a numbered sequence of blocks or records. thus we may read block then read block and then write block . there are no restrictions on the order of reading or writing for a direct access file. direct access files are of great use for immediate access to large amounts of information. databases are often of this type. when a query concerning a particular subject arrives we compute which block contains the answer and then read that block directly to provide the desired information. as a simple example on an airline reservation system we might store all the information about a particular flight for example flight in the block identified by the flight number. thus the number of available seats for flight is stored in block of the reservation file. to store information about a larger set such as people we might compute a hash function on the people's names or search a small in memory index to determine a block to read and search. for the direct access method the file operations must be modified to include the block number as a parameter. thus we have read n where n is the block number rather than read next and write n rather than write next. an alternative approach is to retain read next and write next as with sequential access and to add an operation position file to n where n is the block number. then to effect a read n we would position to n and then read next. the block number provided by the user to the operating system is normally a relative block number. a relative block number is an index relative to the chapter file system interface equgfrtia aecess i i a impternantatloa loi d reset a . a limt l readnexl a n a h re ad cp'f x f i ' t ... . . . . . . .t jl. . x j . . ' a i i a n figure . simulation of sequential access on a direct accsss file. beginning of the file. thvis the first relative block of the file is the next is and so on even though the actual absolute disk address of the block may be for the first block and for the second. the use of relative block numbers allows the operating system to decide where the file should be placed called the allocation problem as discussed in chapter and helps to prevent the user from accessing portions of the file system that may not be part of her file. some systems start their relative block numbers at others start at . how then does the system satisfy a request for record n in a file? assuming we have a logical record length l the request for record a is turned into an i o request for l bytes starting at location l n within the file assuming the first record is n . since logical records are of a fixed size it is also easy to read write or delete a record. not all operating systems support both sequential and direct access for files. some systems allow only sequential file access others allow only direct access. some systems require that a file be defined as sequential or direct when it is created such a file can be accessed only in a manner consistent with its declaration. we can easily simulate sequential access on a direct access file by simply keeping a variable cp that defines our current position as shown in figure . . simulating a direct access file on a sequential access file however is extremely inefficient and clumsy. . . other access methods other access methods can be built on top of a direct access method. these methods generally involve the construction of an index for the file. the index like an index in the back of a book contains pointers to the various blocks. to find a record in the file we first search the index and then use the pointer to access the file directly and to find the desired record. for example a retail price file might list the universal product codes upcs for items with the associated prices. each record consists of a digit upc and a digit price for a byte record if our disk has bytes per block we can store records per block. a file of records would occupy about blocks million bytes . by keeping the file sorted by upc we can define an index consisting of the first upc in each block. this index would have entries of digits each or bytes and thus could be kept in memory to find the price of a particular item we can make a binary search of the index. from this search we learn exactly which block contains the desired record and access that block. this structure allows us to search a large file doing little i o
 logical record last name number as tis p p smith . . . . index file relative file j igure . example of index and relative files. with large files the index file itself may become too large to be kept in memory. one solution is to create an index for the index file. the primary index file would contain pointers to secondary index files which would point to the actual data items. for example ibm's indexed sequential access method isam uses a small master index that points to disk blocks of a secondary index. the secondary index blocks point to the actual file blocks. the file is kept sorted on a defined key. to find a particular item we first make a binary search of the master index which provides the block number of the secondary index. this block is read in and again a binary search is used to find the block containing the desired record. finally this block is searched sequentially. in this way any record can be located from its key by at most two direct access reads. figure . shows a similar situation as implemented by vms index and relative files. . directory structure up to this point we have been discussing a file system. in reality systems may have zero or more file systems and the file systems may be of varying types. for example a typical solaris system may have a few ufs file systems a vfs file system and some nfs file systems. the details of file system implementation are found in chapter . the file systems of computers then can be extensive. some systems store millions of files on terabytes of disk. to manage all these data we need to organize them. this organization involves the use of directories. in this section we explore the topic of directory structure. first though we explain some basic features of storage structure. . . storage structure a disk or any storage device that is large enough can be used in its entirety for a file system. sometimes though it is desirable to place multiple file systems chapter file system interface dkectory i. directory' partition a y disk jjiijjij disk ream j partitioned lies partition b a files i i disk figure . a typical file system organization. on a disk or to use parts of a disk for a file system and other parts for other things such as swap space or unformatted raw disk space. these parts are known variously as partitions slices or in the ibm world minidisks. a file system can be created on each of these parts of the disk. as we shall see in the next chapter the parts can also be combined to form larger structures known as volumes and file systems can be created on these as well. for now for clarity we simply refer to a chunk of storage that holds a file system as a volume. each volume can be thought of as a virtual disk. volumes can also store multiple operating systems allowing a system to boot and run more than one. each volume that contains a file system must also contain information about the files in the system. this information is kept in entries in a device directory or volume table of contents. the device directory more commonly known simply as a directory records information such as name location size and type for all files on that volume. figure . shows a typical file system organization. . . directory overview the directory can be viewed as a symbol table that translates file names into their directory entries. if we take such a view we see that the directory itself can be organized in many ways. we want to be able to insert entries to delete entries to search for a named entry and to list all the entries in the directory. in this section we examine several schemes for defining the logical structure of the directory system. when considering a particular directory structure we need to keep in mind the operations that are to be performed on a directory search for a file. we need to be able to search a directory structure to find the entry for a particular file. since files have symbolic names and similar names may indicate a relationship between files we may want to be able to find all files whose names match a particular pattern. create a file. new files need to be created and added to the directory. . directory structure delete a file. when a file is no longer needed we want to be able to remove it from the directory. list a directory. we need to be able to list the files in a directory and the contents of the directory entry for each file in the list. rename a file. because the name of a file represents its contents to its users we must be able to change the name when the contents or use of the file changes. renaming a file may also allow its position within the directory structure to be changed. traverse the file system. we may wish to access every directory and every file within a directory structure. for reliability it is a good idea to save the contents and structure of the entire file system at regular intervals. often we do this by copying all files to magnetic tape. this technique provides a backup copy in case of system failure. in addition if a file is no longer in use. the file can be copied to tape and the disk space of that file released for reuse by another file. in the following sections we describe the most common schemes for defining the logical structure of a directory. . . single level directory the simplest directory structure is the single level directory. all files are contained in the same directory which is easy to support and understand figure . . a single level directory has significant limitations however when the number of files increases or when the system has more than one user. since all files are in the same directory they must have unique names. if two users call their data file test then the unique name rule is violated. for example in one programming class students called the program for their second assignment progl another called i assign!. although file names are generally selected to reflect the content of the file they are often limited in length complicating the task of making file names unique. the ms dos operating system allows only character file names unix in contrast allows characters. even a single user on a single level directory may find it difficult to remember the names of all the files as the number of files increases. it is not uncommon for a user to have hundreds of files on one computer system and an equal number of additional files on another system. keeping track of so many files is a daunting task. directory c. ' figure . single level directory. s chapter file system interface . . two level directory as we have seen a single level directory often leads to confusion of file names among different users. the standard solution is to create a separate directory for each user. in the two level directory structure each user has his own user file directory ltd . the ufds have similar structures but each lists only the files of a single user. when a user job starts or a user logs in the system's master file directory mfd is searched. the mfd is indexed by user name or account number and each entry points to the ufd for that user figure . . when a user refers to a particular file only his own ufd is searched. thus different users may have files with the same name as long as all the file names within each ufd are unique. to create a file for a user the operating system searches only that user's ufd to ascertain whether another file of that name exists. to delete a file the operating system confines its search to the local ufd thus it cannot accidentally delete another user's file that has the same name. the user directories themselves must be created and deleted as necessary. a special system program is run with the appropriate user name and account information. the program creates a new ufd and adds an entry for it to the pvlfd. the execution of this program might be restricted to system administrators. the allocation of disk space for user directories can be handled with the techniques discussed in chapter for files themselves. although the two level directory structure solves the name collision problem it still has disadvantages. this structure effectively isolates one user from another. isolation is an advantage wrhen the users are completely independent but is a disadvantage when the users want to cooperate on some task and to access one another's files. some systems simply do not allow local user files to be accessed by other users. if access is to be permitted one user must have the ability to name a file in another user's directory. to name a particular file uniquely in a two level directory we must give both the user name and the file name. a two level directory can be thought of as a tree or an inverted tree of height . the root of the tree is the mfd. its direct descendants are the ufds. the descendants of the ufds are the files themselves. the files are the leaves of the tree. specifying a user name and a file name defines a path in the tree from the root the mfd to a leaf the specified file . thus a user name and a file name define a path master file car .bo a tesi a d ila i a tost x aata a o figure . two level directory structure. . directory structure name. every file in the system has a path name. to name a file uniquely a user must know the path name of the file desired. for example if user a wishes to access her own test file named test she can simply refer to test. to access the file named test of user b with directory entry name userb however she might have to refer to userb test. every system has its own syntax for naming files in directories other than the user's own. additional syntax is needed to specify the volume of a file. for instance in ms dos a volume is specified by a letter followed by a colon. thus a file specification might be c userb test. some systems go even further and separate the volume directory name and file name parts of the specification. for instance in vms the file login.com might be specified as u sst.jdeckllogin.com l where u is the name of the volume sst is the name of the directory jdeck is the name of the subdirectory and is the version number. other systems simply treat the volume name as part of the directory name. the first name given is that of the volume and the rest is the directory and file. for instance u pbg test might specify volume it directory pbg and file test. a special case of this situation occurs with the system files. programs provided as part of the system loaders assemblers compilers utility routines libraries and so on are generally defined as files. when the appropriate commands are given to the operating system these files are read by the loader and executed. many command interpreters simply treat such a command as the name of a file to load and execute. as the directory system is defined presently this file name would be searched for in the current ufd. one solution would be to copy the system files into each ufd. however copying all the system files would waste an enormous amount of space. if the system files require mb then supporting users would require x mb just for copies of the system files. the standard solution is to complicate the search procedure slightly. a special user directory is defined to contain the system files for example user . whenever a file name is given to be loaded the operating system first searches the local ufd. if the file is found it is used. if it is not found the system automatically searches the special user directory that contains the system files. the sequence of directories searched when a file is named is called the search path. the search path can be extended to contain an unlimited list of directories to search when a command name is given. this method is the one most used in unix and ms dos. systems can also be designed so that each user has his own search path. . . tree structured directories once we have seen how to view a two level directory as a two level tree the natural generalization is to extend the directory structure to a tree of arbitrary height figure . . this generalization allows users to create their own subdirectories and to organize their files accordingly. a tree is the most common directory structure. the tree has a root directory and every file in the system has a unique path name. a directory or subdirectory contains a set of files or subdirectories. a directory is simply another file but it is treated in a special way. all directories have the same internal format. one bit in each directory entry defines the entry chapter file system interface root tft'c ' figure . tree structured directory structure. as a file or as a subdirectory . special system calls are used to create and delete directories. in normal use each process has a current directory. the current directory should contain most of the files that are of current interest to the process. when reference is made to a file the current directory is searched. if a file is needed that is not in the current directory then the user usually must either specify a path name or change the current directory to be the directory holding that file. to change directories a system call is provided that takes a directory name as a parameter and uses it to redefine the current directory. thus the user can change his current directory whenever he desires. from one change d i r e c t o r y system call to the next all open system calls search the current directory for the specified file. note that the search path may or may not contain a special entry that stands for the current directory. the initial current directory of the login shell of a user is designated when the user job starts or the user logs in. the operating system searches the accounting file or some other predefined location to find an entry for this user for accounting purposes . in the accounting file is a pointer to or the name of the user's initial directory. this pointer is copied to a local variable for this user that specifies the user's initial current directory. from that shell other processes can be spawned. the current directory of any subprocess is usually the current directory of the parent when it was spawned. path names can be of two types absolute and relative. an absolute path name begins at the root and follows a path down to the specified file giving the directory names on the path. a relative path name defines a path from the current directory. for example in the tree structured file system of figure . if the current directory is root spell' mail then the relative path name prt first refers to the same file as does the absolute path name root spcll mail prt first. . directory structure allowing a user to define her own subdirectories permits her to impose a structure on her files. this structure might result in separate directories for files associated with different topics for example a subdirectory was created to hold the text of this book or different forms of information for example the directory programs may contain source programs the directory bin may store ail the binaries . an interesting policy decision in a tree structured directory concerns how to handle the deletion of a directory. if a directory is empty its entry in the directory that contains it can simply be deleted. however suppose the directory to be deleted is not empty but contains several files or subdirectories. one of two approaches can be taken. some systems such as ms dos will not delete a directory unless it is empty. thus to delete a directory the user must first delete all the files in that directory. if any subdirectories exist this procedure must be applied recursively to them so that they can be deleted also. this approach can result in a substantial amount of work. an alternative approach such as that taken by the unix rm command is to provide an option when a request is made to delete a directory all that directory's files and subdirectories are also to be deleted. either approach is fairly easy to implement the choice is one of policy. the latter policy is more convenient but it is also more dangerous because an entire directory structure can be removed with one command. if that command is issued in error a large number of files and directories will need to be restored assuming a backup exists . with a tree structured directory system users can be allowed to access in addition to their files the files of other users. for example user b can access a file of user a by specifying its path names. user b can specify either an absolute or a relative path name. alternatively user b can change her current directory to be user a's directory and access the file by its file names. a path to a file in a tree structured directory can be longer than a path in a two level directory. to allow users to access programs without having to remember these long paths the macintosh operating system automates the search for executable programs. it maintains a file called the desktop file containing the names and locations of all executable programs it has seen. when a new hard disk or floppy disk is added to the system or the network is accessed the operating system traverses the directory structure searching for executable programs on the device and recording the pertinent information. this mechanism supports the double click execution functionality described previously. a double click on a file causes its creator attribute to be read and the desktop file to be searched for a match. once the match is found the appropriate executable program is started with the clicked on file as its input. the microsoft windows family of operating systems nt xp maintains an extended two level directory structure with devices and. volumes assigned drive letters section . . . . acyclic graph directories consider two programmers who are working on a joint project. the files associated with that project can be stored in a subdirectory separating them from other projects and files of the two programmers. but since both programmers are equally responsible for the project both want the subdirectory to be in chapter file system interface figure . acyclic graph directory structure. their own directories. the common subdirectory should be shared. a shared directory or file will exist in the file system in two or more places at once. a tree structure prohibits the sharing of files or directories. an acyclic graph that is a graph with no cycles allows directories to share subdirectories and files figure . . the same file or subdirectory may be in two different directories. the acyclic graph is a natural generalization of the tree structured directory scheme. it is important to note that a shared file or directory is not the same as two copies of the file. with two copies each programmer can view the copy rather than the original but if one programmer changes the file the changes will not appear in the other's copy. with a shared file only one actual file exists so any changes made by one person are immediately visible to the other. sharing is particularly important for subdirectories a new file created by one person will automatically appear in all the shared subdirectories. when people are working as a team all the files they want to share can be put into one directory. the ufd of each team member will contain this directory of shared files as a subdirectory. even in the case of a single user the user's file organization may require that some file be placed in different subdirectories. for example a program written for a particular project should be both in the directory of all programs and in the directory for that project. shared files and subdirectories can be implemented in several ways. a common way exemplified by many of the unix systems is to create a new directory entry called a link. a link is effectively a pointer to another file or subdirectory. for example a link may be implemented as an absolute or a relative path name. when a reference to a file is made we search the directory. if the directory entry is marked as a link then the name of the real file is included in the link information. we resolve the link by using that path name to locate the real file. links are easily identified by their format in the directory entry or by their having a special type on systems that support types and are . directory structure effectively named indirect pointers. the operating system ignores these links when traversing directory trees to preserve the acyclic structure of the system. another common approach to implementing shared files is simply to duplicate all information about them in both sharing directories. thus both entries are identical and equal. a link is clearly different from the original directory entry thus the two are not equal. duplicate directory entries however make the original and the copy indistinguishable. a .major problem with duplicate directory entries is maintaining consistency when a file is modified. an acyclic graph directory structure is more flexible than is a simple tree structure but it is also more complex. several problems must be considered carefully. a file may now have multiple absolute path names. consequently distinct file names may refer to the same file. this situation is similar to the aliasing problem for programming languages. if we are trying to traverse the entire file system to find a file to accumulate statistics on all files or to copy all files to backup storage this problem becomes significant since we do not want to traverse shared structures more than once. another problem involves deletion. when can the space allocated to a shared file be deallocated and reused? one possibility is to remove the file whenever anyone deletes it but this action may leave dangling pointers to the now nonexistent file. worse if the remaining file pointers contain actual disk addresses and the space is subsequently reused for other files these dangling pointers may point into the middle of other files. in a system where sharing is implemented by symbolic links this situation is somewhat easier to handle. the deletion of a link need not affect the original file only the link is removed. if the file entry itself is deleted the space for the file is deallocated leaving the links dangling. we can search for these links and remove them as well but unless a list of the associated links is kept with each file this search can be expensive. alternatively we can leave the links until an attempt is made to use them. at that time we can determine that the file of the name given by the link does not exist and can fail to resolve the link name the access is treated just as with any other illegal file name. in this case the system designer should consider carefully what to do when a file is deleted and another file of the same name is created before a symbolic link to the original file is used. in the case of unix symbolic links are left when a file is deleted and it is up to the user to realize that the original file is gone or has been replaced. microsoft windows all flavors uses the same approach. another approach to deletion is to preserve the file until all references to it are deleted. to implement this approach we must have some mechanism for determining that the last reference to the file has been deleted. we could keep a list of all references to a file directory entries or symbolic links . when a link or a copy of the directory entry is established a new entry is added to the file reference list. when a link or directory entry is deleted we remove its entry on the list. the file is deleted when its file reference list is empty. the trouble with this approach is the variable and potentially large size of the file reference list. however we really do not need to keep the entire list we need to keep only a count of the number of references. adding a new link or directory entry increments the reference count deleting a link or entry decrements the count. when the count is the file can be deleted there are no remaining references to it. the unix operating system uses this approach chapter file system interface for nonsymboiic links or hard links keeping a reference count in tile file information block or inode see appendix a. . . by effectively prohibiting multiple references to directories we maintain an acyclic graph structure. to avoid problems such as the ones just discussed some systems do not allow shared directories or links. for example in ms dos the directory structure is a tree structure rather than an acyclic graph. . . general graph directory a serious problem with using an acyclic graph structure is ensuring that there are no cycles. if we start with a two level directory and allow users to create subdirectories a tree structured directory results. it should be fairly easy to see that simply adding new files and subdirectories to an existing tree structured directory preserves the tree structured nature. however when we add links to an existing tree structured directory the tree structure is destroyed resulting in a simple graph structure figure . . the primary advantage of an acyclic graph is the relative simplicity of the algorithms to traverse the graph and to determine when there are no more references to a file. we want to avoid traversing shared sections of an acyclic graph twice mainly for performance reasons. if we have just searched a major shared subdirectory for a particular file without finding it we want to avoid searching that subdirectory again the second search would be a waste of time. if cycles are allowed to exist in the directory we likewise want to avoid searching any component twice for reasons of correctness as well as performance. a poorly designed algorithm might result in an infinite loop continually searching through the cycle and never terminating. one solution is to limit arbitrarily the number of directories that will be accessed during a search. a similar problem exists when we are trying to determine when a file can be deleted. with acyclic graph directory structures a value of in the reference count means that there are no more references to the file or directory root aw ic jim book iml unhcv hyp figure . general graph directory
 and the file can be deleted. however when cycles exist the reference count may not be even when it is no longer possible to refer to a directory or file. this anomaly results from the possibility of self referencing or a cycle in the directory structure. in this case we generally need to use a garbage collection scheme to determine when the last reference has been deleted and the disk space can be reallocated. garbage collection involves traversing the entire file system marking everything that can be accessed. then a second pass collects everything that is not marked onto a list of free space. a similar marking procedure can be used to ensure that a traversal or search will cover everything in the file system once and only once. garbage collection for a disk based file system. however is extremely time consuming and is thus seldom attempted. garbage collection is necessary only because of possible cycles in the graph. thus an acyclic graph structure is much easier to work with. the difficulty is to avoid cycles as new links are added to the structure. how do we know when a new link will complete a cycle? there are algorithms to detect cycles in graphs however they are computationally expensive especially when the graph is on disk storage. a simpler algorithm in the special case of directories and links is to bypass links during directory traversal. cycles are avoided and no extra overhead is incurred. . file system mounting just as a file must be opened before it is used a file system must be mounted before it can be available to processes on the system. more specifically the directory structure can be built out of multiple volumes which must be mounted to make them available within the file system name space. the mount procedure is straightforward. the operating system is given the name of the device and the mount point the location within the file structure where the file system is to be attached. typically a mount point is an empty directory. for instance on a unix system a file system containing a user's home directories might be mounted as home then to access the directory structure within that file system we could precede the directory names with ftiome as in homc janc. mounting that file system under users would result in the path name users jane which we could use to reach the same directory. next the operating system verifies that the device contains a valid file system. it does so by asking the device driver to read the device directory and verifying that the directory has the expected format. finally the operating system notes in its directory structure that a file system is mounted at the specified mount point. this scheme enables the operating system to traverse its directory structure switching among file systems as appropriate. to illustrate file mounting consider the file system depicted in figure . where the triangles represent subtrees of directories that are of interest. figure . a shows an existing file system while figure . b shows an unmounted volume residing on device' dsk. at this point only the files on the existing file system can be accessed. figure . shows the effects of mounting the volume residing on device dsk over users. if the volume is unmounted the file system is restored to the situation depicted in figure . . systems impose semantics to clarify functionality. for example a system may disallow a mount over a directory that contains files or it may make the chapter file system interface users fred sue jane doc a b figure . file system a existing system b unmounted volume. mounted file system available at that directory and obscure the directory's existing files until the file system is unmounted terminating the use of the file system and allowing access to the original files in that directory. as another example a system may allow the same file system to be mounted repeatedly at different mount points or it may only allow one mount per file system. consider the actions of the macintosh operating system. whenever the system encounters a disk for the first time hard disks are found at boot time and floppy disks are seen when they are inserted into the drive the macintosh operating system searches for a file system on the device. if it finds one it automatically mounts the file system at the root level adding a folder icon on the screen labeled with the name of the file system as stored in the device directory . the user is then able to click on the icon and thus display the newly motinted file system. the microsoft windows family of operating systems nt small xp maintains an extended two level directory structure with devices jane doc figure . mount point
 and volumes assigned drive letters. volumes have a general graph directory structure associated with the drive letter. the path to a specific file takes the form of drive letter path to file. the more recent versions of windows allow a file system to he mounted anywhere in the directory tree just as unix does. windows operating systems automatically discover all devices and mount all located file systems at boot time. in some systems like unix the mount commands are explicit. a system configuration file contains a list of devices and mount points for automatic mounting at boot time but other mounts may be executed manually. issues concerning file system mounting are further discussed in section . . and in appendix a. . . . file sharing in the previous sections we explored the motivation for file sharing and some of the difficulties involved in allowing users to share files. such file sharing is very desirable for users who want to collaborate and to reduce the effort required to achieve a computing goal. therefore user oriented operating systems must accommodate the need to share files in spite of the inherent difficulties. in this section we examine more aspects of file sharing. w'e begin by discussing general issues that arise when multiple users share files. once multiple users are allowed to share files the challenge is to extend sharing to multiple file systems including remote file systems and we discuss that challenge as well. finally we consider what to do about conflicting actions occurring on shared files. for instance if multiple users are writing to a file should all the writes be allowed to occur or should the operating system protect the user actions from one another? . . multiple users when an operating system accommodates multiple users the issues of file sharing file naming and file protection become preeminent. given a directory structure that allows files to be shared by users the system must mediate the file sharing. the system can either allow a user to access the files of other users by default or require that a user specifically grant access to the files. these are the issues of access control and protection which are covered in section . . to implement sharing and protection the system must maintain more file and directory attributes than are needed on a single user system. although many approaches have been taken to this requirement historically most systems have evolved to use the concepts of file or directory owner or user and group. the owner is the user who can change attributes and grant access and who has the most control over the file. the group attribute defines a subset of users who can share access to the file. for example the owner of a file on a unix system can issue all operations on a file while members of the file's group can execute one subset of those operations and all other users can execute another subset of operations. exactly which operations can be executed by group members and other users is definable by the file's owner. more details on permission attributes are included in the next section. chapter file system interface the owner and group ids of a given file or directory are stored with the other file attributes. when a user requests an operation on a file the user id can be compared with the owner attribute to determine if the requesting user is the owner of the file. likewise the group ids can be compared. the result indicates which permissions are applicable. the system then applies those permissions to the requested operation and allows or denies it. many systems have multiple local file systems including volumes of a single disk or multiple volumes on multiple attached disks. in these cases the id checking and permission matching are straightforward once the file systems are mounted. . remote fi!e systems with the advent of networks chapter communication among remote computers became possible. networking allows the sharing of resources spread across a campus or even around the world. one obvious resource to share is data in the form of files. through the evolution of network and file technology remote file sharing methods have changed. the first implemented method involves manually transferring files between machines via programs like ftp. the second major method uses a distributed file system dfs in which remote directories are visible from a local machine. in some ways the third method the world wide web is a reversion to the first. a browser is needed to gain access to the remote files and separate operations essentially a wrapper for ftp are used to transfer files. f t p is used for both anonymous and authenticated access. anonymous access allows a user to transfer files without having an account on the remote system. the world wide web uses anonymous file exchange almost exclusively. dfs involves a much tighter integration between the machine that is accessing the remote files and the machine providing the files. this integration adds complexity which we describe in this section. . . . the client server model remote file systems allow a computer to mount one or more file systems from one or more remote machines. in this case the machine containing the files is the server and the machine seeking access to the files is the client. the client server relationship is common with networked machines. generally the server declares that a resource is available to clients and specifies exactly which resource in this case which files and exactly which clients. a server can serve multiple clients and a client can use multiple servers depending on the implementation details of a given client server facility. the server usually specifies the available files on a volume or directory level. client identification is more difficult. a client can be specified by a network name or other identifier such as an ip address but these can be spoofed or imitated. as a result of spoofing an unauthorized client could be allowed access to the server. more secure solutions include secure authentication of the client via encrypted keys. unfortunately with security come many challenges including ensuring compatibility of the client and server they must use the same encryption algorithms and security of key exchanges intercepted keys . file sharing could again allow unauthorized access . because of the difficulty of solving these problems unsecure authentication methods are most commonly used. in the case of unix and its network file system nfs authentication takes place via the client networking information by default. in this scheme the user's ids on the client and server must match. if they do not the server will be unable to determine access rights to files. consider the example of a user who has an id of on the client and on the server. a request from the client to the server for a specific file will not be handled appropriately as the server will determine if user has access to the file rather than basing the determination on the real user id of . access is thus granted or denied based on incorrect authentication information. the server must trust the client to present the correct user id. note that the nfs protocols allow many to many relationships. that is many servers can provide files to many clients. in fact a given machine can be both a server to other nfs clients and a client of other nfs servers. once the remote file system is mounted file operation requests are sent on behalf of the user across the network to the server via the dfs protocol. typically a file open request is sent along with the id of the requesting user. the server then applies the standard access checks to determine if the user has credentials to access the file in the mode requested. the request is either allowed or denied. if it is allowed a file handle is returned to the client application and the application then can perform read write and other operations on the file. the client closes the file when access is completed. the operating system may apply semantics similar to those for a local file system mount or may use different semantics. . . . distributed information systems to make client server systems easier to manage distributed information systems also known as distributed naming services provide unified access to the information needed for remote computing. the domain name system dns provides host name to network address translations for the entire internet including the world wide web . before dnis became widespread files containing the same information were sent via e mail or f t p between all networked hosts. this methodology was not scalable. dns is further discussed in section . . . other distributed information systems provide user name password user id group id space for a distributed facility. unix systems have employed a wide variety of distributed information methods. sun microsystems introduced yellow pages since renamed network information service or nis and most of the industry adopted its use. it centralizes storage of user names host names printer information and the like. unfortunately it uses unsecure authentication methods including sending user passwords unencrypted in clear text and identifying hosts by if address. sun's nis is a much more secure replacement for nis but is also much more complicated and has not been widely adopted. in the case of microsofts common internet file system cifs network information is used in conjunction with user authentication user name and password to create a network login that the server uses to decide whether to allow or deny access to a requested file system. for this authentication to be valid the user names must match between the machines as with chapter file system interface nfs . microsoft uses two distributed naming structures to provide a single name space for users. the older naming technology is domains. the newer technology available in windows xp and windows is active directory. once established the distributed naming facility is used by all clients and servers to authenticate users. the industry is moving toward use of the lightweight directory access protocol ldap as a secure distributed naming mechanism. in fact active directory is based on ldap. sun microsystems includes ldap with the operating system and allows it to be used for user authentication as well as system wide retrieval of information such as availability of printers. conceivably one distributed ldap directory could be used by an organization to store all user and resource information for all the organization's computers. the result would be secure single sign on for users who would enter their authentication information once for access to all computers within the organization. it would also ease systems administration efforts by combining in one location information that is currently scattered in various files on each system or in different distributed information services. . . . failure modes local file systems can fail for a variety of reasons including failure of the disk containing the file system corruption of the directory structure or other disk management information collectively called metadata disk controller failure cable failure and host adapter failure. user or systems administrator failure can also cause files to be lost or entire directories or volumes to be deleted. many of these failures will cause a host to crash and an error condition to be displayed and human intervention will be required to repair the damage. remote file systems have even more failure modes. because of the complexity of network systems and the required interactions between remote machines many more problems can interfere with the proper operation of remote file systems. in the case of networks the network can be interrupted between two hosts. such interruptions can result from hardware failure poor hardware configuration or networking implementation issues. although some networks have built in resiliency including multiple paths between hosts many do not. any single failure can thus interrupt the flow of dfs commands. consider a client in the midst of using a remote file system. it has files open from the remote host among other activities it may be performing directory lookups to open files reading or writing data to files and closing files. now consider a partitioning of the network a crash of the server or even a scheduled shutdown of the server. suddenly the remote file system is no longer reachable. this scenario is rather common so it would not be appropriate for the client system to act as it would if a local file system were lost. rather the system can either terminate all operations to the lost server or delay operations until the server is again reachable. these failure semantics are defined and implemented as part of the remote file system protocol. termination of all operations can result in users' losing data and patience. thus most dfs protocols either enforce or allow delaying of file system operations to remote hosts with the hope that the remote host will become available again. to implement this kind of recovery from failure some kind of state information may be maintained on both the client and the server. if both server . file sharing and client maintain knowledge of their current activities and open files then they can seamlessly recover from a failure. in the situation where the server crashes but must recognize that it has remotely mounted exported file systems and opened files nfs takes a simple approach implementing a stateless dfs. in essence it assumes that a client request for a file read or write would not have occurred unless the file system had been remotely mounted and the file had been previously open. the nfs protocol carries all the information needed to locate the appropriate file and perform the requested operation. similarly it does not track which clients have the exported volumes mounted again assuming that if a request comes in it must be legitimate. while this stateless approach makes nfs resilient and rather easy to implement it also makes it unsecure. for example forged read or write requests could be allowed by an nfs server even though the requisite mount request and permission check have not taken place. these issues are addressed in the industry standard nfs version in which nfs is inade stateful to improve its security performance and functionality. . . consistency semantics consistency semantics represent an important criterion for evaluating any file system that supports file sharing. these semantics specify how multiple users of a system are to access a shared file simultaneously. in particular they specify when modifications of data by one user will be observable by other users. these semantics are typically implemented as code with the file system. consistency semantics are directly related to the process synchronization algorithms of chapter . however the complex algorithms of that chapter tend not to be implemented in the case of file i o because of the great latencies and slow transfer rates of disks and networks. for example performing an atomic transaction to a remote disk could involve several network communications several disk reads and writes or both. systems that attempt such a full set of functionalities tend to perform poorly. a successful implementation of complex sharing semantics can be found in the andrew file system. for the following discussion we assume that a series of file accesses that is reads and writes attempted by a user to the same file is always enclosed between the openq and close operations. the series of accesses between the openo and close operations makes up a file session. to illustrate the concept we sketch several prominent examples of consistency semantics. . . . unix semantics the umix file system chapter uses the following consistency semantics writes to an open file by a user are visible immediately to other users that have this file open. one mode of sharing allows users to share the pointer of current location into the file. thus the advancing of the pointer by one user affects all sharing users. here a file has a single image that interleaves all accesses regardless of their origin. in the unix semantics a file is associated with a single physical image that is accessed as an exclusive resource. contention for this single image causes delays in user processes. chapter file system interface . . . session semantics the andrew file system afs chapter uses the following consistency semantics writes to an open file by a user are not visible immediately to other users that have the same file open. once a file is closed the changes made to it are visible only in sessions starting later. already open instances of the file do not reflect these changes. according to these semantics a file may be associated temporarily with several possibly different images at the same time. consequently multiple xisers are allowed to perform both read and write accesses concurrently on their images of the file without delay. almost no constraints are enforced on scheduling accesses. . . . immutable shared files semantics a unique approach is that of immutable shared files. once a file is declared as shared by its creator it cannot be modified. an immutable file has two key properties its name may not be reused and its contents may not be altered. thus the name of an immutable file signifies that the contents of the file are fixed. the implementation of these semantics in a distributed system chapter is simple because the sharing is disciplined read only . 
 when information is stored in a computer system we want to keep it safe from physical damage reliability and improper access protection . reliability is generally provided by duplicate copies of files. many computers have systems programs that automatically or through computer operator intervention copy disk files to tape at regular intervals once per day or week or month to maintain a copy should a file system be accidentally destroyed. file systems can be damaged by hardware problems such as errors in reading or writing power surges or failures head crashes dirt temperature extremes and vandalism. files may be deleted accidentally. bugs in the file system software can also cause file contents to be lost. reliability is covered in more detail in chapter . protection can be provided in many ways. for a small single user system we might provide protection by physically removing the floppy disks and locking them in a desk drawer or file cabinet. in a multiuser system however other mechanisms are needed. . . types of access the need to protect files is a direct result of the ability to access files. systems that do not permit access to the files of other users do not need protection. thus we could provide complete protection by prohibiting access. alternatively we could provide free access with no protection. both approaches are too extreme for general use. what is needed is controlled access. . protection protection mechanisms provide controlled access by limiting the types of file access that can be made. access is permitted or denied depending on several factors one of which is the type of access requested. several different types of operations may be controlled read. read from the file. write. write or rewrite the file. execute. load the file into memory and execute it. append. write new information at the end of the file. delete. delete the file and tree its space for possible reuse. list. list the name and attributes of the file. other operations such as renaming copying and editing the file may also be controlled. for many systems however these higher level functions may be implemented by a system program that makes lower level system calls. protection is provided at only the lower level. for instance copying a file may be implemented simply by a sequence of read requests. in this case a user with read access can also cause the file to be copied printed and so on. many protection mechanisms have been proposed. each has advantages and disadvantages and must be appropriate for its intended application. a small computer system that is used by only a few members of a research group for example may not need the same types of protection as a large corporate computer that is used for research finance and personnel operations. we discuss some approaches to protection in the following sections and present a more complete treatment in chapter . . . access control the most common approach to the protection problem is to make access dependent on the identity of the user. different users may need different types of access to a. file or directory. the most general scheme to implement identitydependent access is to associate with each file and directory an access control list acl specifying user names and the types of access allowed for each user. when a user requests access to a particular file the operating system checks the access list associated with that file. if that user is listed for the requested access the access is allowed. otherwise a protection violation occurs and the user job is denied access to the file. this approach has the advantage of enabling complex access methodologies. the main problem with access lists is their length. if we want to allow everyone to read a file we must list all users with read access. this technique has two undesirable consequences constructing such a list may be a tedious and unrewarding task especially if we do not know in advance the list of users in the system. the directory entry previously of fixed size now needs to be of variable size resulting in more complicated space management. chapter file system interface these problems can be resolved by use of a condensed version of the afccess list. to condense the length of the access control list many systems recognize three classifications of users in connection with each file owner. the user who created the file is the owner. group. a set of users who are sharing the file and need similar access is a group or work group. universe. all other users in the system constitute the universe. the most common recent approach is to combine access control lists with the more general and easier to implement owner group and universe accesscontrol scheme just described. for example solaris . and beyond use the three categories of access by default but allow access control lists to be added to specific files and directories when more fine grained access control is desired. to illustrate consider a person sara who is writing a new book. she has hired three graduate students jim dawn and jill to help with the project. the text of the book is kept in a file named book. the protection associated with this file is as follows sara should be able to invoke all operations on the file. jim dawn and jill should be able only to read and write the file they should not be allowed to delete the file. all other users should be able to read but not write the file. sara is interested in letting as many people as possible read the text so that she can obtain appropriate feedback. to achieve such protection we must create a new group say text with members jim dawn and jill. the name of the group text must then be associated with the file book and the access rights must be set in accordance with the policy we have outlined. now consider a visitor to whom sara would like to grant temporary access to chapter . the visitor cannot be added to the text group because that would give him access to all chapters. because a file can only be in one group another group cannot be added to chapter . with the addition of access control list functionality the visitor can be added to the access control list of chapter . for this scheme to work properly permissions and access lists must be controlled tightly. this control can be accomplished in several ways. for example in the unix system groups can be created and modified only by the manager of the facility or by any superuser . thus this control is achieved through human interaction. in the vms system the owner of the file can create and modify this list. access lists are discussed further in section . . . with the more limited protection classification only three fields are needed to define protection. often each field is a collection of bits and each bit either allows or prevents the access associated with it. for example the unfx system defines three fields of bits each rwx where r controls read access w controls write access and x controls execution. a separate field is kept for the file owner for the file's group and for all other users. in this scheme nine bits per file are . protection needed to record protection information. thus tor our example the protection fields for the file book are as follows for the owner sara all bits are set for the group text the r and w bits are set and for the universe only the r bit is set. one difficulty in combining approaches comes in the user interface. users must be able to tell when the optional acl perinissions are set on a file. in the solaris example a appends the regular permissions as in rw r r jim staff may filel a separate set of commands setf acl and g e t f a c l are used to manage the acls. windows xp users typically manage access control lists via the gui. figure . shows a file permission window on windows xp's ntfs file system. in this example user guest is specifically denied access to the file .lex. general security
 . allocation methods the direct access nature of disks allows us flexibility in the implementation of files in almost every case many files are stored on the same disk. the main problem is how to allocate space to these files so that disk space is utilized effectively and files can be accessed quickly. three major methods of allocating disk space are in wide use contiguous linked and indexed. each method has advantages and disadvantages. some systems such as data general's rdos for its nova line of computers support all three. more commonly a system vises one method for all files within a file system type. . . contiguous allocation contiguous allocation requires that each file occupy a set of contiguous blocks on the disk. disk addresses define a linear ordering on the disk. with this ordering assuming that only one job is accessing the disk accessing block b after block b normally requires no head movement. when head movement is needed from the last sector of one cylinder to the first sector of the next cylinder the head need only move from one track to the next. thus the number of disk seeks required for accessing contiguously allocated files is minimal as is seek time when a seek is finally needed. the ibm vm cms operating system uses contiguous allocation because it provides such good performance. contiguous allocation of a file is defined by the disk address and length in block units of the first block. if the file is n blocks long and starts at location b then it occupies blocks b b b ... b n . the directory entry for each file indicates the address of the starting block and the length of the area allocated for this file figure . . directory file start ength count tr mail list f figure . contiguous allocation of disk space. chapter file system implementation accessing a file that has been allocated contiguously is easy. for sequential access the file system remembers the disk adciress of the last block referenced and when necessary reads the next block. for direct access to block ' of a file that starts at block b we can immediately access block b i. thus both sequential and direct access can be supported by contiguous allocation. contiguous allocation has some problems however. one difficulty is finding space for a new file. the system chosen to manage free space determines how this task is accomplished these management systems are discussed in section . . any management system can be used but some are slower than others. the contiguous allocation problem can be seen as a particular application of the general dynamic storage allocation problem discussed in section . which involves how to satisfy a request of size n from a list of free holes. first fit and best fit are the most common strategies used to select a free hole from the set of available holes. simulations have shown that both first fit and best fit are more efficient than worst fit in terms of both time and storage utilization. neither first fit nor best fit is clearly best in terms of storage utilization but first fit is generally faster. all these algorithms suffer from the problem of external fragmentation. as files are allocated and deleted the free disk space is broken into little pieces. external fragmentation exists whenever free space is broken into chunks. it becomes a problem when the largest contiguous chunk is insufficient for a request storage is fragmented into a number of holes no one of which is large enough to store the data. depending on the total amount of disk storage and the average file size external fragmentation may be a minor or a major problem. some older pc systems used contiguous allocation on floppy disks. to prevent loss of significant amounts of disk space to external fragmentation the user had to run a repacking routine that copied the entire file system onto another floppy disk or onto a tape. the original floppy disk was then freed completely creating one large contiguous free space. the routine then copied the files back onto the floppy disk by allocating contiguous space from this one large hole. this scheme effectively compacts all free space into one contiguous space solving the fragmentation problem. the cost of this compaction is time. the time cost is particularly severe for large hard disks that use contiguous allocation where compacting all the space may take hours and may be necessary on a weekly basis. some systems require that this function be done off line with the file system unmounted. during this down time normal system operation generally cannot be permitted so such compaction is avoided at all costs on production machines. most modern systems that need defragmentation can perform it on line during normal system operations but the performance penalty can be substantial. another problem with contiguous allocation is determining how much space is needed for a file. when the file is created the total amount of space it will need must be found and allocated. how does the creator program or person know the size of the file to be created? in some cases this determination may be fairly simple copying an existing file for example in general however the size of an output file may be difficult to estimate. if we allocate too little space to a file we may find that the file cannot be extended. especially with a best fit allocation strategy the space on both sides of the file may be in use. hence we cannot make the file larger in place. . allocation methods two possibilities then exist. first the user program can be terminated with an appropriate error message. the user must then allocate more space and run the program again. these repeated runs may be costly. to prevent them the user will normally overestimate the amount of space needed resulting in considerable wasted space. the other possibility is to find a larger hole copy the contents of the file to the new space and release the previous space. this series of actions can be repeated as long as space exists although it can be time consuming. however the user need never be informed explicitly about what is happening the system continues despite the problem although more and more slowly. even if the total amount of space needed for a file is known in advance preallocation may be inefficient. a file that will growr slowly over a long period months or years must be allocated enough space for its final size even though much of that space will be unused for a long time. the file therefore has a large amount of internal fragmentation. to minimize these drawbacks some operating systems use a modified contiguous allocation scheme. here a contiguous chunk of space is allocated initially and then if that amount proves not to be large enough another chunk of contiguous space known as an extent is added. the location of a file's blocks is then recorded as a location and a block count plus a link to the first block of the next extent. on some systems the owner of the file can set the extent size but this setting results in inefficiencies if the owner is incorrect. internal fragmentation can still be a problem if the extents are too large and external fragmentation can become a problem as extents of varying sizes are allocated and deallocated. the commercial veritas file system uses extents to optimize performance. it is a high performance replacement for the standard unix ufs. . . linked allocation linked allocation solves all problems of contiguous allocation. with linked allocation each file is a linked list of disk blocks the disk blocks may be scattered anywhere on the disk. the directory contains a pointer to the first and last blocks of the file. for example a file of five blocks might start at block and continue at block then block then block and finally block figure . . each block contains a pointer to the next block. these pointers are not made available to the user. thus if each block is bytes in size and a disk address the pointer requires bytes then the user sees blocks of bytes. to create a new file we simply create a new entry in the directory. with linked allocation each directory entry has a pointer to the first disk block of the file. this pointer is initialized to nil the end of list pointer value to signify an empty file. the size field is also set to . a write to the file causes the free space management system to find a free block and this new block is written to and is linked to the end of the file. to read a file we simply read blocks by following the pointers from block to block. there is no external fragmentation with linked allocation and any free block on the free space list can be used to satisfy a request. the size of a file need not be declared when that file is created. a file can continue to grow as long as free blocks are available. consequently it is never necessary to compact disk space. chapter file syslem implementation directory file start end jeep figure . linked allocation of disk space. linked allocation does have disadvantages however. the major problem is that it can be used effectively only for sequential access files. to find the ith block of a file we must start at the beginning of that file and follow the pointers until we get to the ith block. each access to a pointer requires a disk read and some require a disk seek. consequently it is inefficient to support a direct access capability for linked allocation files. another disadvantage is the space required for the pointers. if a pointer requires bytes out of a byte block then . percent of the disk is being used for pointers rather than for information. each file requires slightly more space than it would otherwise. the usual solution to this problem is to collect blocks into multiples called clusters and to allocate clusters rather than blocks. for instance the file system may define a cluster as four blocks and operate on the disk only in cluster units. pointers then use a much smaller percentage of the file's disk space. this method allows the logical to physical block mapping to remain simple but improves disk throughput because fewer disk head seeks are required and decreases the space needed for block allocation and free list management. the cost of this approach is an increase in internal fragmentation because more space is wasted when a cluster is partially full than when a block is partially full. clusters can be used to improve the disk access time for many other algorithms as well so they are used in most file systems. yet another problem of linked allocation is reliability. recall that the files are linked together by pointers scattered all over the disk and consider what would happen if a pointer were lost or damaged. a bug in the operating system software or a disk hardware failure might result in picking up the wrong pointer. this error could in turn result in linking into the free space list or into another file. one partial solution is to use doubly linked lists and another is to store the file name and relative block number in each block however these schemes require even more overhead for each file. . allocation methods directory entry test h name start block .. . . .. . no. of disk blocks fat figure . file allocation table. an important variation on linked allocation is the use of a file allocation table fat . this simple but efficient method of disk space allocation is used by the ms dos and os operating systems. a section of disk at the beginning of each volume is set aside to contain the table. the table has one entry for each disk block and is indexed by block number. the fat is used in much the same way as a linked list. the directory entry contains the block number of the first block of the file. the table entry indexed by that block number contains the block number of the next block in the file. this chain continues until the last block which has a special enci of file value as the table entry. unused blocks are indicated by a table value. allocating a new block to a file is a simple matter of finding the first valued table entry and replacing the previous end of file value with the address of the new block. the is then replaced with the end of file value. an illustrative example is the fat structure shown in figure . . for a file consisting of disk blocks and . the fat allocation scheme can result in a significant number of disk head seeks unless the fat is cached. the disk head must move to the start of the volume to read the fat and find the location of the block in question then move to the location of the block itself. in the worst case both moves occur for each of the blocks. a benefit is that random access time is improved because the disk head can find the location of any block by reading the information in the fat. . . indexed allocation linked allocation solves the external fragmentation and size declaration problems of contiguous allocation. however in the absence of a fat linked allocation cannot support efficient direct access since the pointers to the blocks are scattered with the blocks themselves all over the disk and must be retrieved chapter file system implementation directory f . a' k a ill l ! .'j c i i v . . . figure . indexed allocation of disk space. in order. indexed allocation solves this problem by bringing all the pointers together into one location the index block. each file has its own index block which is an array of disk block addresses. the ' entry in the index block points to the ' block of the file. the directory contains the address of the index block figure . . to find and read the th block we use the pointer in the ' index block entry. this scheme is similar to the paging scheme described in section . . when the file is created all pointers in the index block are set to nil. when the ith block is first written a block is obtained from the free space manager and its address is put in the zth index block entry. indexed allocation supports direct access without suffering from external fragmentation because any free block on the disk can satisfy a request for more space. indexed allocation does suffer from wasted space however. the pointer overhead of the index block is generally greater than the pointer overhead of linked allocation. consider a common case in which we have a file of only one or two blocks. with linked allocation we lose the space of only one pointer per block. with indexed allocation an entire index block must be allocated even if only one or two pointers will be non nil. this point raises the question of how large the index block should be. every file must have an index block so we want the index block to be as small as possible. if the index block is too small however it will not be able to hold enough pointers for a large file and a mechanism will have to be available to deal with this issue. mechanisms for this purpose include the following linked scheme. an index block is normally one disk block. thus it can be read and written directly by itself. to allow for large files we can link together several index blocks. for example an index block might contain a small header giving the name of the file and a set of the first disk block . allocation methods addresses. the next address the last word in the index block is nil for a small file or is a pointer to another index block for a large file . ' multilevel index. a variant of the linked representation is to use a firstlevel index block to point to a set of second level index blocks which in turn point to the file blocks. to access a block the operating system uses the first level index to find a second level index block and then uses that block to find the desired data block. this approach could be continued to a third or fourth level depending on the desired maximum file size. with byte blocks we could store byte pointers in an index block. two levels of indexes allow data blocks and a file size of up to gb. combined scheme. another alternative vised in the ufs is to keep the first say pointers of the index block in the file's inode. the first of these pointers point to direct blocks that is they contain addresses of blocks that contain data of the file. thus the data for small files of no more than blocks do not need a separate index block. if the block size is kb then up to kb of data can be accessed directly. the next three pointers point to indirect blocks. the first points to a single indirect block which is an index block containing not data but the addresses of blocks that do contain data. the second points to a double indirect block which contains the address of a block that contains the addresses of blocks that contain pointers to the actual data blocks. the last pointer contains the address of a triple indirect block. under this method the number of blocks that can be allocated to a file exceeds the amount of space addressable by the byte file pointers used by many operating systems. a bit file pointer reaches only bytes or gb. many unix implementations including solaris and ibm's a x now support up to bit file pointers. pointers of this size allow files and file systems to be terabytes in size. a unix inode is shown in figure . . indexed allocation schemes suffer from some of the same performance problems as does linked allocation. specifically the index blocks can be cached in memory but the data blocks may be spread all over a volume. . . performance the allocation methods that we have discussed vary in their storage efficiency and data block access times. both are important criteria in selecting the proper method or methods for an operating system to implement. before selecting an allocation method we need to determine how the systems will be used. a system with mostly sequential access should not use the same method as a system with mostly random access. for any type of access contiguous allocation requires only one access to get a disk block. since we can easily keep the initial address of the file in memory we can calculate immediately the disk address of the th block or the next block and read it directly. for linked allocation we can also keep the address of the next block in memory and read it directly. this method is fine for sequential access for direct access however an access to the th block might require disk reads. this chapter file system implementation figure . the unix inode. problem indicates why linked allocation should not be used for an application requiring direct access. as a result some systems support direct access files by using contiguous allocation and sequential access by linked allocation. for these systems the type of access to be made must be declared when the file is created. a file created for sequential access will be linked and cannot be used for direct access. a file created for direct access will be contiguous and can support both direct access and sequential access but its maximum length must be declared when it is created. in this case the operating system must have appropriate data structures and algorithms to support both allocation methods. files can be converted from one type to another by the creation of a new file of the desired type into which the contents of the old file are copied. the old file may then be deleted and the new file renamed. indexed allocation is more complex. if the index block is already in memory then the access can be made directly. however keeping the index block in memory requires considerable space. if this memory space is not available then we may have to read first the index block and then the desired data block. for a two level index two index block reads might be necessary. for an extremely large file accessing a block near the end of the file would require reading in all the index blocks before the needed data block finally could be read. thus the performance of indexed allocation depends on the index structure on the size of the file and on the position of the block desired. some systems combine contiguous allocation with indexed allocation by using contiguous allocation for small files up to three or four blocks and automatically switching to an indexed allocation if the file grows large. since most files are small and contiguous allocation is efficient for small files average performance can be quite good
 for instance the version of the unix operating system from sun microsystems was changed in to improve performance in the file system allocation algorithm. the performance measurements indicated that the maximum disk throughput on a typical workstation a m ps sparcstationl took percent of the cpu and produced a disk bandwidth of only . mb per second. to improve performance sun made changes to allocate space in clusters of kb whenever possible kb was the maximum size of a dma transfer on sun systems at that time . this allocation reduced external fragmentation and thus seek and latency times. in addition the disk reading routines were optimized to read in these large clusters. the inode structure was left unchanged. as a result of these changes plus the use of read ahead and free behind discussed in section . . percent less cpu was used and throughput substantially improved. many other optimizations are in use. given the disparity between cpu speed and disk speed it is not unreasonable to add thousands of extra instructions to the operating system to save just a fewr disk head movements. furthermore this disparity is increasing over time to the point where hundreds of thousands of instructions reasonably could be used to optimize head movements. . free space management since disk space is limited we need to reuse the space from deleted files for new files if possible. write once optical disks only allow one write to any given sector and thus such reuse is not physically possible. to keep track of free disk space the system maintains a free space list. the free space list records all free disk blocks those not allocated to some file or directory. to create a file we search the free space list for the required amount of space and allocate that space to the new file. this space is then removed from the free space list. when a file is deleted its disk space is added to the free space list. the free space list despite its name might not be implemented as a list as we discuss next. . . bit vector frequently the free space list is implemented as a bit map or bit vector. each block is represented by bit. if the block is free the bit is if the block is allocated the bit is . for example consider a disk where blocks and are free and the rest of the blocks are allocated. the free space bit map would be ... the main advantage of this approach is its relative simplicity and its efficiency in finding the first free block or n consecutive free blocks on the disk indeed many computers supply bit manipulation instructions that can be used effectively for that purpose. for example the intel family starting with the and the motorola family starting with the processors that have powered pcs and macintosh systems respectively have instructions that return the offset in a word of the first bit with the value . one technique chapter file system implementation for finding the first free block on a system that uses a bit vector to allocate disk space is to sequentially check each word in the bit map to see whether that value is not since a valued word has all bits and represents a set of allocated blocks. the first non word is scanned for the first bit which is the location of the first free block. the calculation of the block number is number of bits per word x number of value words offset of first bit. again we see hardware features driving software functionality. unfortunately bit vectors are inefficient unless the entire vector is kept in main memory and is written to disk occasionally for recovery needs . keeping it in main memory is possible for smaller disks but not necessarily for larger ones. a . gb disk with byte blocks would need a bit map of over kb to track its free blocks although clustering the blocks in groups of four reduces this number to over kb per disk. a gb disk with kb blocks requires over mb to store its bit map. . . linked list another approach to free space management is to link together all the free disk blocks keeping a pointer to the first free block in a special location on the disk and caching it in memory. this first block contains a pointer to the next free disk block and so on. in our earlier example section . . we would keep a pointer to block as the first free block. block would contain a pointer to block which would point to block which would point to block which would point to block and so on figure . . however this scheme is not efficient to traverse the list we must read each block which requires substantial i o time. fortunately traversing the free list is not a frequent action. usually the free space list head figure . linked free space list on disk
 operating system simply needs a free block so that it can allocate thatblock to a file so the first block in the free list is used. the fat method incorporates free block accounting into the allocation data structure. no separate method is needed. . . grouping a modification of the free list approach is to store the addresses of n free blocks in the first free block. the first n of these blocks are actually free. the last block contains the addresses of another n free blocks and so on. the addresses of a large number of free blocks can now be found quickly unlike the situation when the standard linked list approach is used. . . counting another approach is to take advantage of the fact that generally several contiguous blocks may be allocated or freed simultaneously particularly when space is allocated with the contiguous allocation algorithm or through clustering. thus rather than keeping a list of n free disk addresses we can keep the address of the first free block and the number n of free contiguous blocks that follow the first block. each entry in the free space list then consists of a disk address and a count. although each entry requires more space than would a simple disk address the overall list will be shorter as long as the count is generally greater than . . efficiency and performance now that we have discussed various block allocation and directorymanagement options we can further consider their effect on performance and efficient disk use. disks tend to represent a major bottleneck in system performance since they are the slowest main computer component. in this section we discuss a variety of techniques used to improve the efficiency and performance of secondary storage. . . efficiency the efficient use of disk space depends heavily on the disk allocation and directory algorithms in use. for instance unix inodes are preallocated on a volume. even an empty disk has a percentage of its space lost to inodes. however by preallocating the inodes and. spreading them across the volume we improve the file system's performance. this improved performance results from the unix allocation and free space algorithms which try to keep a file's data blocks near that file's inode block to reduce seek time. as another example let's reconsider the clustering scheme discussed in section . which aids in file seek and file transfer performance at the cost of internal fragmentation. to reduce this fragmentation bsd unix varies the cluster size as a file grows. large clusters are used where they can be filled and small clusters are used for small files and the last cluster of a file. this system is described in appendix a. the types of data normally kept in a file's directory or inode entry also require consideration. commonly a 'last write date is recorded to supply information to the user and to determine whether the file needs to be backed chapter file system implementation up. some systems also keep a last access date so that a user can determine when the file was last read. the result of keeping this information is that whenever the file is read a field in the directory structure must be written to. that means the block must be read into memory a section changed and the block written back out to disk because operations on disks occur only in block or cluster chunks. so any time a file is opened for reading its directory entry must be read and written as well. this requirement can be inefficient for frequently accessed files so we must weigh its benefit against its performance cost when designing a file system. generally every data item associated with a file needs to be considered for its effect on efficiency and performance. as an example consider how efficiency is affected by the size of the pointers used to access data. most systems use either or bit pointers throughout the operating system. these pointer sizes limit the length of a file to either kb or bytes gb . some systems implement bit pointers to increase this limit to bytes which is a very large number indeed. however bit pointers take more space to store and in turn make the allocation and free space management methods linked lists indexes and so on use more disk space. one of the difficulties in choosing a pointer size or indeed any fixed allocation size within an operating system is planning for the effects of changing technology. consider that the ibm pc xt had a mb hard drive and an ms dos file system that could support only mb. each fat entry was bits pointing to an kb cluster. as disk capacities increased larger disks had to be split into mb partitions because the file system could not track blocks beyond mb. as hard disks with capacities of over mb became common the disk data structures and algorithms in ms dos had to be modified to allow larger file systems. each fat entry was expanded to bits and later to bits. the initial file system decisions were made for efficiency reasons however with the advent of ms dos version millions of computer users were inconvenienced when they had to switch to the new larger file system. sun's zfs file system uses bit pointers which theoretically should never need to be extended. the minimum mass of a device capable of storing ' s bytes using atomic level storage would be about trillion kilograms. as another example consider the evolution of sun's solaris operating system. originally many data structures were of fixed length allocated at system startup. these structures included the process table and the open file table. when the process table became full no more processes could be created. when the file table became full no more files could be opened. the system would fail to provide services to users. table sizes could be increased only by recompiling the kernel and rebooting the system. since the release of solaris almost all kernel structures have been allocated dynamically eliminating these artificial limits on system performance. of course the algorithms that manipulate these tables are more complicated and the operating system is a little slower because it must dynamically allocate and deallocate table entries but that price is the usual one for more general functionality. . . performance even after the basic file system algorithms have been selected we can still improve performance in several ways. as will be discussed in chapter . efficiency and performance ! v pech.o readf s te i ! pace cacne file system figure . i o without a unified buffer cache. most disk controllers include local memory to form an on board cache that is large enough to store entire tracks at a time. once a seek is performed the track is read into the disk cache starting at the sector under the disk head reducing latency time . the disk controller then transfers any sector requests to the operating system. once blocks make it from the disk controller into main memory the operating system may cache the blocks there. some systems maintain a separate section of main memory for a buffer cache where blocks are kept under the assumption that they will be used again shortly. other systems cache file data using a page cache. the page cache uses virtual memory techniques to cache file data as pages rather than as file system oriented blocks. caching file data using virtual addresses is far more efficient than caching through physical disk blocks as accesses interface with virtual memory rather than the file system. several systems including solaris linux and windows nt and xp use page caching to cache both process pages and file data. this is known as unified virtual memory. some versions of unix and linux provide a unified buffer cache. to illustrate the benefits of the unified buffer cache consider the two alternatives for opening and accessing a file. one approach is to use memory mapping section . the second is to use the standard system calls reado and write . without a unified buffer cache we have a situation similar to figure . . here the read and write system calls go through the buffer cache. the memory mapping call however requires using two caches the page cache and the buffer cache. a memory mapping proceeds by reading in disk blocks from the file system and storing them in the buffer cache. because the virtual memory system does not interface with the buffer cache the contents of the file in the buffer cache must be copied into the page cache. this situation is known as double caching and requires caching file system data twice. not only does it waste memory but it also wastes significant cpu and i o cycles due to the extra data movement within system memory. in add ition inconsistencies between the two caches can result in corrupt files. in contrast when a unified chapter file system implementation memory mapped i o figure . i o using a unified buffer cache. buffer cache is provided both memory mapping and the read and write system calls use the same page cache. this has the benefit of avoiding double caching and it allows the virtual memory system to manage file system data. the unified buffer cache is shown in figure . . regardless of whether we are caching disk blocks or pages or both leu section . . seems a reasonable general purpose algorithm for block or page replacement. however the evolution of the solaris page caching algorithms reveals the difficulty in choosing an algorithm. solaris allows processes and the page cache to share unused inemory. versions earlier than solaris . . made no distinction between allocating pages to a process and allocating them to the page cache. as a result a system performing many i o operations used most of the available memory for caching pages. because of the high rates of i o the page scanner section . . reclaimed pages from processes rather than from the page cache when free memory ran low. solaris . and solaris optionally implemented priority paging in which the page scanner gives priority to process pages over the page cache. solaris applied a fixed limit to process pages and the file system page cache preventing either from forcing the other out of memory. solaris and again changed the algorithms to maximize memory use and minimize thrashing. this real world example shows the complexities of performance optimizing and caching. there are other issvies that can affect the performance of i o such as whether writes to the file system occur synchronously or asynchronously. synchronous writes occur in the order in which the disk subsystem receives them and the writes are not buffered. thus the calling routine must wait for the data to reach the disk drive before it can proceed. asynchronous writes are done the majority of the time. in an asynchronous write the data are stored in the cache and control returns to the caller. metadata writes among others can be synchronous. operating systems frequently include a flag in the open system call to allow a process to request that writes be performed synchronously. for example databases use this feature for atomic transactions to assure that data reach stable storage in the required order. some systems optimize their page cache by using different replacement algorithms depending on the access type of the file. a file being read or written sequentially should not have its pages replaced in lru order because the most
 recently used page will be used last or perhaps never again. instead sequential access can be optimized by techniques known as free behind and read ahead. free behind removes a page from the buffer as soon as the next page is requested. the previous pages are not likely to be used again and waste buffer space. with read ahead a requested page and several subsequent pages are read and cached. these pages are likely to be requested after the current page is processed. retrieving these data from the disk in one transfer and caching them saves a considerable amount of time. one might think a track cache on the controller eliminates the need for read ahead on a multiprogrammed system. however because of the high latency and overhead involved in making many small transfers from the track cache to main memory performing a read ahead remains beneficial. the page cache the file system and the disk drivers have some interesting interactions. when data are written to a disk file the pages are buffered in the cache and the disk driver sorts its output queue according to disk address. these two actions allow the disk driver to minimize disk head seeks and to write data at times optimized for disk rotation. unless synchronous writes are required a process writing to disk simply writes into the cache and the system asynchronously writes the data to disk when convenient. the user process sees very fast writes. when data are read from a disk file the block i o system does some read ahead however writes are much more nearly asynchronous than are reads. thus output to the disk through the file system is often faster than is input for large transfers counter to intuition. . recovery files and directories are kept both in main memory and on disk and care must taken to ensure that system failure does not result in loss of data or in data inconsistency. we deal with these issues in the following sections. . . consistency checking as discussed in section . some directory information is kept in main memory or cache to speed up access. the directory information in main memory is generally more up to date than is the corresponding information on the disk because cached directory information is not necessarily written to disk as soon as the update takes place. consider then the possible effect of a computer crash. cache and buffetcontents as well as i o operations in progress can be lost and with them any changes in the directories of opened files. such an event can leave the file system in an inconsistent state the actual state of some files is not as described in the directory structure. frequently a special program is run at reboot time to check for and correct disk inconsistencies. the consistency checker a systems program such as f sck in unix or chkdsk in ms dos compares the data in the directory structure with the data blocks on disk and tries to fix any inconsistencies it finds. the allocation and free space management algorithms dictate what types of problems the checker can find and how successful it will be in fixing them. for instance if linked allocation is used and there is a link from any block to its next block chapter file system implementation then the entire file can be reconstructed from the data blocks and the directory structure can be recreated. in contrast the loss of a directory entry on an indexed allocation system can be disastrous because the data blocks have no knowledge of one another. for this reason unix caches directory entries for reads but any data write that results in space allocation or other metadata changes is done synchronously before the corresponding data blocks are written. of course problems can still occur if a synchronous write is interrupted by a crash. . . backup and restore magnetic disks sometimes fail and care must be taken to ensure that the data lost in such a failure are not lost forever. to this end system programs can be used to back up data from disk to another storage device such as a floppy disk magnetic tape optical disk or other hard disk. recovery from the loss of an individual file or of an entire disk may then be a matter of restoring the data from backup. to minimize the copying needed we can use information from each file's directory entry. for instance if the backup program knows when the last backup of a file was done and the file's last write date in the directory indicates that the file has not changed since that date then the file does not need to be copied again. a typical backup schedule may then be as follows day . copy to a backup medium all files from the disk. this is called a full backup. day . copy to another medium all files changed since day . this is an incremental backup. day . copy to another medium all files changed since day . day n. copy to another medium all files changed since day n . then go back to day . the new cycle can have its backup written over the previous set or onto a new set of backup media. in this manner we can restore an entire disk by starting restores with the full backup and continuing through each of the incremental backups. of course the larger the value of n the greater the number of tapes or disks that must be read for a complete restore. an added advantage of this backup cycle is that we can restore any file accidentally deleted during the cycle by retrieving the deleted file from the backup of the previous day. the length of the cycle is a compromise between the amount of backup medium needed and the number of days back from which a restore can be done. to decrease the number of tapes that must be read to do a restore an option is to perform a full backup and then each day back up all files that have changed since the full backup. in this way a restore can be done via the most recent incremental backup and. the full backup with no other incremental backups needed. the trade off is that more files will be modified
 each day so each successive incremental backup involves more files and more backup media. a user may notice that a particular file is missing or corrupted long after the damage was done. for this reason we usually plan to take a full backup from time to time that will be saved forever. it is a good idea to store these permanent backups far away from the regular backups to protect against hazard such as a fire that destroys the computer and all the backups too. and if the backup cycle reuses media we must take care not to reuse the media too many times if the media wear out it might not be possible to restore any data from the backups. . log structured file systems computer scientists often find that algorithms and technologies originally used in one area are equally useful in other areas. such is the case with the database log based recovery algorithms described in section . . . these logging algorithms have been applied successfully to the problem of consistency checking. the resulting implementations are known as log based transaction oriented or journaling file systems. recall that a system crash can cause inconsistencies among on disk filesystem data structures such as directory structures free block pointers and free fcb pointers. before the use of log based techniques in operating systems changes were usually applied to these structures in place. a typical operation such as file create can involve many structural changes within the file system on the disk. directory structures are modified fcbs are allocated data blocks are allocated and the free counts for all of these blocks are decreased. these changes can be interrupted by a crash and inconsistencies among the structures can result. for example the free fcb count might indicate that an fcb had been allocated but the directory structure might not point to the fcb. the fcb would be lost were it not for the consistency check phase. although we can allow the structures to break and repair them on recovery there are several problems with this approach. one is that the inconsistency may be irreparable. the consistency check may not be able to recover the structures resulting in loss of files and even entire directories. consistency checking can require human intervention to resolve conflicts and that is inconvenient if no human is available. the system can remain unavailable until the human tells it how to proceed. consistency checking also takes system and clock time. terabytes of data can take hours of clock time to check. the solution to this problem is to apply log based recovery techniques to file system metadata updates. both ntfs and the veritas file system use this method and it is an optional addition to lfs on solaris and beyond. in fact it is becoming common on many operating systems. fundamentally all metadata changes are written sequentially to a log. each set of operations for performing a specific task is a transaction. once the changes are written to this log they are considered to be committed and the system call can return to the user process allowing it to continue execution. meanwhile these log entries are replayed across the actual filesystem structures. as the changes are made a pointer is updated to indicate which actions have completed and which are still incomplete. when an entire chapter file system implementation committed transaction is completed it is removed from the log file which is actually a circular buffer. a circular buffer writes to the end of its space and then continues at the beginning overwriting older values as it goes. we would not want the buffer to write over data that has not yet been saved so that scenario is avoided. the log may be in a separate section of the file system or even on a separate disk spindle. it is more efficient but more complex to have it under separate read and write heads thereby decreasing head contention and seek times. if the system crashes the log file will contain zero or more transactions. any transactions it contains were not completed to the file system even though they were committed by the operating system so they must now be completed. the transactions can be executed from the pointer until the work is complete so that the file system structures remain consistent. the only problem occurs when a transaction was aborted that is was not committed before the system crashed. any changes from such a transaction that were applied to the file system must be undone again preserving the consistency of the file system. this recovery is all that is needed after a crash eliminating any problems with consistency checking. a side benefit of using logging on disk metadata updates is that those updates proceed much faster than when they are applied directly to the on disk data structures. the reason for this improvement is found in the performance advantage of sequential i o over random i o. the costly synchronous random metadata writes are turned into much less costly synchronous sequential writes to the log structured file system's logging area. those changes in turn are replayed asynchronously via random writes to the appropriate structures. the overall result is a significant gain in performance of metadata oriented operations such as file creation and deletion
 network file systems are commonplace. they are typically integrated with the overall directory structure and interface of the client system. nfs is a good example of a widely used well implemented client server network file system. here we use it as an example to explore the implementation details of network file systems. nfs is both an implementation and a specification of a software system for accessing remote files across lans or even wans . nfs is part of onjc which most unix vendors and some pc operating systems support. the implementation described here is part of the solaris operating system which is a modified version of unix svr running on sun workstations and other hardware. it uses either the tcp or udp ip protocol depending on the interconnecting network . the specification and the implementation are intertwined in our description of nfs. whenever detail is needed we refer to the sun implementation whenever the description is general it applies to the specification also. . . overview n fs v iews a set of interconnected worksta tions as a set of independent machines with independent file systems. the goal is to allow some degree of sharing among these file systems on explicit request in a transparent manner. sharing s usr shared diri figure . three independent file systems. is based on a client server relationship. a machine may be and often is both a client and a server. sharing is allowed between any pair of machines. to ensure machine independence sharing of a remote file system affects only the client machine and no other machine. so that a remote directory will be accessible in a transparent manner from a particular machine say from ml a client of that machine must first carry out a mount operation. the semantics of the operation involve .mounting a remote directory over a directory of a local file system. once the mount operation is completed the mounted directory looks like an integral subtree of the local file system replacing the subtree descending from the local directory. the local directory becomes the name of the root of the newly mounted directory. specification of the remote directory as an argument for the mount operation is not done transparently the location or host name of the remote directory has to be provided. however from then on users on machine ml can access files in the remote directory in a totally transparent manner. to illustrate file mounting consider the file system depicted in figure . where the triangles represent subtrees of directories that are of interest. the figure shows three independent file systems of machines named u si and s . at this point at each machine only the local files can be accessed. in figure . a the effects of mounting si u s r s h a r e d over u u s r l o c a l are shown. this figure depicts the view users on u have of their file system. notice that after the mount is complete they can access any file within the dirl directory using the prefix usr local dirl. the original directory u s r l o c a l on that machine is no longer visible. subject to access rights accreditation any file system or any directory within a file system can be mounted remotely on top of any local directory. diskless workstations can even mount their own roots from servers. cascading mounts are also permitted in some nfs implementations. that is a file system can be mounted over another file system that is remotely mounted not local. a machine is affected by only those mounts that it has itself invoked. mounting a remote file system does not give the client access to other file systems that were by chance mounted over the former file system. thus the mount mechanism does not exhibit a transitivity property. chapter file system implementation u u usr ' c usr local o local dir l n din a b figure . mounting in nfs. a mounts b cascading mounts. in figure . b we illustrate cascading mounts by continuing our previous example. the figure shows the result of mounting s u s r d i r over u u s r l o c a l d i r l which is already remotely mounted from si. users can access files within dir on u using the prefix u s r l o c a l d i r l . if a shared file system is mounted over a user's home directories on all machines in a network the user can log into any workstation and get his home environment. this property permits user mobility. one of the design goals of nfs was to operate in a heterogeneous environment of different machines operating systems and network architectures. the nfs specification is independent of these media and thus encourages other implementations. this independence is achieved through the use of rpc primitives built on top of an external data representation xdk protocol used between two implementation independent interfaces. hence if the system consists of heterogeneous machines and file systems that are properly interfaced to nfs file systems of different types can be mounted both locally and remotely. the nfs specification distinguishes between the services provided by a mount mechanism and the actual remote file access services. accordingly two separate protocols are specified for these services a mount protocol and a protocol for remote file accesses the nfs protocol. the protocols are specified as sets of rpcs. these rfcs are the building blocks used to implement transparent remote file access. . . the mount protocol the mount protocol establishes the initial logical connection between a server and a client. in sun's implementation each machine has a server process outside the kernel performing the protocol functions. a mount operation includes the name of the remote directory to be mounted and the name of the server machine storing it. the mount request is mapped to the corresponding rpc and is forwarded to the mount server running on the specific server machine. the server maintains an export list . nfs that specifies local file systems that it exports for mounting along with names of machines that are permitted to mount them. in solaris this list is the e t c d f s df stab which can be edited only by a superuser. the specification can also include access rights such as read only. to simplify the maintenance of export lists and mount tables a distributed naming scheme can be used to hold this information and make it available to appropriate clients. recall that any directory within an exported file system can be mounted remotely by an accredited machine. a component unit is such a directory. when the server receives a mount request that conforms to its export list it returns to the client a file handle that serves as the key for further accesses to files within the mounted file system. the file handle contains all the information that the server needs to distinguish an individual file it stores. in unix terms the file handle consists of a file system identifier and an inode number to identify the exact mounted directory within the exported file system. the server also maintains a list of the client machines and the corresponding currently mounted directories. this list is used mainly for administrative purposes for instance for notifying all clients that the server is going down. only through addition and deletion of entries in this list can the server state be affected by the mount protocol. usually a system has a static mounting preconfiguration that is established at boot time etc vf s t a b in solaris howrever this layout can be .modified m addition to the actual mount procedure the mount protocol includes several other procedures such as unmount and return export list. . . the n fs protocol the nfs protocol provides a set of rpcs for remote file operations. the procedures support the following operations searching for a file within a directory reading a set of directory entries manipulating links and directories accessing file attributes reading and writing files these procedures can be invoked only after a file handle for the remotely mounted directory has been established. the omission of openo and close operations is intentional. a prominent feature of nfs servers is that they are stateless. servers do not maintain information about their clients from one access to another. no parallels to unix's open files table or file structures exist on the server side. consequently each request has to provide a full set of arguments including a unique file identifier and an absolute offset inside the file for the appropriate operations. the resulting design is robust no special measures need be taken to recover a server after a crash. file operations must be idempotent for this purpose. every nfs request has a sequence number allowing the server to determine if a request is duplicated or if any are missing. chapter file system implementation maintaining the list of clients that we mentioned seems to violate the statelessness of the server. however this list is not essential for the correct operation of the client or the server and hence it does not need to be restored after a server crash. consequently it might include inconsistent data and is treated as only a hint. a further implication of the stateless server philosophy and a result of the synchrony of an rpc is that modified data including indirection and status blocks must be committed to the server's disk before results are returned to the client. that is a client can cache write blocks but wiien it flushes them to the server it assumes that they have reached the server's disks. the server must write all nfs data synchronously. thus a server crash and recovery will be invisible to a client all blocks that the server is managing for the client will be intact. the consequent performance penalty can be large because the advantages of caching are lost. performance can be increased by using storage with its own nonvolatile cache usually battery backed up memory . the disk controller acknowledges the disk write when the write is stored in the nonvolatile cache. in essence the host sees a very fast synchronous write. these blocks remain intact even after system crash and are written from this stable storage to disk periodically. a single nfs write procedure call is guaranteed to be atomic and is not intermixed with other write calls to the same file. the nfs protocol however does not provide concurrency control mechanisms. a write system call maybe broken down into several rfc writes because each nfs write or read call can contain up to kb of data and udp packets are limited to bytes. as a result two users writing to the same remote file may get their data intermixed. the claim is that because lock management is inherently stateful a service outside the nfs should provide locking and solaris does . users are advised to coordinate access to shared files using mechanisms outside the scope of nfs. nfs is integrated into the operating system via a vfs. as an illustration of the architecture let's trace how an operation on an already open remote file is handled follow the example in figure . . the client initiates the operation with a regular system call. the operating system layer maps this call to a vfs operation on the appropriate vnode. the vfs layer identifies the file as a remote one and invokes the appropriate nfs procedure. an rpc call is made to the nfs service layer at the remote server. this call is reinjected to the vfs layer on the remote system which finds that it is local and invokes the appropriate file system operation. this path is retraced to return the result. an advantage of this architecture is that the client and the server are identical thus a machine may be a client or a server or both. the actual service on each server is performed by kernel threads. . . path name translation path name translation in nfs involves the parsing of a path name such as u s r l o c a l d i r i f i l e . t x t into separate directory entries or components usr l o c a l and d i r l . path name translation is done by breaking the path into component names and performing a separate nfs lookup c a l l for every pair of component name and directory vnode. once a mount point is crossed every component lookup causes a separate rfc to the server. this expensive path name traversal scheme is needed since the layout of each . nfs figure . schematic view of the nfs architecture. client's logical name space is unique dictated by the mounts the client has performed. it would be much more efficient to hand a server a path name and receive a target vnode once a mount point is encountered. at any point however there can be another mount point for the particular client of which the stateless server is unaware. so that lookup is fast a directory name lookup cache on the client side holds the vnodes for remote directory names. this cache speeds up references to files with the same initial path name. the directory cache is discarded when attributes returned from the server do not match the attributes of the cached vnode. recall that mounting a remote file system on top of another already mounted remote file system a cascading mount is allowed in some implementations of nfs. however a server cannot act as an intermediary between a client and another server. instead a client must establish a direct client server connection with the second server by directly mounting the desired directory. when a client has a cascading mount more than one server can be involved in a path name traversal. however each component lookup is performed between the original client and some server. therefore when a client does a lookup on a directory on which the server has mounted a file system the client sees the underlying directory instead of the mounted directory. . . remote operations with the exception of opening and closing files there is almost a one to one correspondence between the regular unix system calls for file operations and the nfs protocol rpcs. thus a remote file operation can be translated directly to the corresponding rfc. conceptually nfs adheres to the remote service chapter file system implementation paradigm but in practice buffering and caching techniques are employed for the sake of performance. i fo direct correspondence exists between a remote operation and an rfc. instead file blocks and file attributes are fetched by the rpcs and are cached locally. future remote operations use the cached data subject to consistency constraints. there are two caches the file attribute inode information cache and the file blocks cache. when a file is opened the kernel checks with the remote server to determine whether to fetch or re validate the cached attributes. the cached file blocks are used only if the corresponding cached attributes are up to date. the attribute cache is updated whenever new attributes arrive from the server. cached attributes are by default discarded after seconds. both read ahead and delayed write techniques are used between the server and the client. clients do not free delayed write blocks until the server confirms that the data have been written to disk. in contrast to the system used in sprite distributed file system delayed write is retained even when a file is opened concurrently in conflicting modes. hence unix semantics section . . . are not preserved. tuning the system for performance makes it difficult to characterize the consistency semantics of nfs. new files created on a machine may not be visible elsewhere for seconds. furthermore writes to a file at one site may or may not be visible at other sites that have this file open for reading. new opens of a file observe only the changes that have already been flushed to the server. thus nfs provides neither strict emulation of unix semantics nor the session semantics of andrew section . . . . in spite of these drawbacks the utility and good performance of the mechanism make it the most widely used multi vendor distributed system in operation. . example the wafl file system disk i o has a huge impact on system performance. as a result file system design and implementation command quite a lot of attention from system designers. some file systems are general purpose in that they can provide reasonable performance and functionality for a wide variety of file sizes file types and i o loads. others are optimized for specific tasks in an attempt to provide better performance in those areas than general purpose file systems. the wafl file system from network appliance is an example of this sort of optimization. wafl the ivrite nin wherc file layout is a powerful elegant file system optimized for random writes. wafl is used exclusively on network file servers produced by network appliance and so is meant for use as a distributed file system. it can provide files to clients via the nfs cifs ftp and http protocols although it was designed just for nfs and cifs. when many clients use these protocols to talk to a file server the server may see a very large demand for random reads and an even larger demand for random writes. the nfs and cifs protocols cache data from read operations so writes are of the greatest concern to file server creators. wafl is used on file servers that include an nvram cache for writes. the wafl designers took advantage of running on a specific architecture to optimize the file system for random i o with a stable storage cache in front. . example the wafl file system root inode figure . the wafl file layout. ease of use is one of the guiding principles of wafl because it is designed to be used in an appliance. its creators also designed it to include a new snapshot functionality that creates multiple read only copies of the file system at different points in time as we shall see. the file system is similar to the berkeley fast file system with many modifications. it is block based and uses inodes to describe files. each inode contains pointers to blocks or indirect blocks belonging to the file described by the inode. each file system has a root inode. all of the metadata lives in files all inodes are in one file the free block map in another and the free inode map in a third as shown in figure . . because these are standard files the data blocks are not limited in location and can be placed anywhere. if a file system is expanded by addition of disks the lengths of these metadata files are automatically expanded by the file system. thus a wafl file system is a tree of blocks rooted by the root inode. to take a snapshot wafl creates a duplicate root inode. any file or metadata updates after that go to new blocks rather than overwriting their existing blocks. the new root inode points to metadata and data changed as a result of these writes. meanwhile the old root inode still points to the old blocks which have not been updated. it therefore provides access to the file system just as it was at the instant the snapshot was made and takes very little disk space to do so! in essence the extra disk space occupied by a snapshot consists of just the blocks that have been modified since the snapshot was taken. an important change from more standard file systems is that the free block map has more than one bit per block. it is a bitmap with a bit set for each snapshot that is using the block. when all snapshots that have been using the block are deleted the bit map for that block is all zeros and the block is free to be reused. used blocks are never overwritten so writes are very fast because a write can occur at the free block nearest the current head location. there are many other performance optimizations in wafl as well. many snapshots can exist simultaneously so one can be taken each hour of the day and. each day of the month. a user with access to these snapshots can access files as they were at any of the times the snapshots were taken. the snapshot facility is also useful for backups testing versioning and so on. wafl's snapshot facility is very efficient in that it does not even require that copy on write copies of each data block be taken before the block is modified. other file systems provide snapshots but frequently with less efficiency. wafl snapshots are depicted in figure . . chapter file system implementation root snoda block a b ic id e a before a snapshot. ni! rsot natte b i l rfnspswotc block a d e b after a snapshot before any blocks change. irnbtlriibfiie . . . . . . . . . . so a. block a b c d i ' c after block d has changed to d'. figure . snapshots in wafl
 structure in this section we present a general overview of the physical structure of secondary and tertiary storage devices. . . magnetic disks magnetic disks provide the bulk of secondary storage for modern computer systems. conceptually disks are relatively simple figure . . each disk platter has a flat circular shape like a cd. common platter diameters range from . to . inches. the two surfaces of a platter are covered with a magnetic material. we store information by recording it magnetically on the platters. chapter mass storage structure track arm assembly sector s . i cylinder c platter rotation figure . moving head disk mechanism. a read write head flies just above each surface of every platter. the heads are attached to a disk arm that moves all the heads as a unit. the surface of a platter is logically divided into circular tracks which are subdivided into sectors. the set of tracks that are at one arm position makes up a cylinder. there may be thousands of concentric cylinders in a disk drive and each track may contain hundreds of sectors. the storage capacity of common disk drives is measured in gigabytes. when the disk is in use a drive motor spins it at high speed. most drives rotate to times per second. disk speed has two parts. the transfer rate is the rate at which data flow between the drive and the computer. the positioning time sometimes called the random access time consists of the time to move the disk arm to the desired cylinder called the seek time and the time for the desired sector to rotate to the disk head called the rotational latency. typical disks can transfer several megabytes of data per second and they have seek times and rotational latencies of several milliseconds. because the disk head flies on an extremely thin cushion of air measured in microns there is a danger that the head will make contact with the disk surface. although the disk platters are coated with a thin protective layer sometimes the head will damage the magnetic surface. this accident is called a head crash. a head crash normally cannot be repaired the entire disk must be replaced. a disk can be removable allowing different disks to be mounted as needed. removable magnetic disks generally consist of one platter held in a plastic case to prevent damage while not in the disk drive. floppy disks are inexpensive removable magnetic disks that have a soft plastic case containing a flexible platter. the head of a floppy disk drive generally sits directly on the disk surface so the drive is designed to rotate more slowly than a hard disk drive . overview of mass storage structure to reduce the wear on the disk surface. the storage capacity of a floppy disk is typically only . mb or so. removable disks are available that work much like normal hard disks and have capacities measured in gigabytes. a disk drive is attached to a computer by a set of wires called an i o bus. several kinds of buses are available including enhanced integrated drive electronics eide advanced technology attachment ata serial ata sata universal serial bus usb fiber channel fc and scsi buses. the data transfers on a bus are carried out by special electronic processors called controllers. the host controller is the controller at the computer end of the bus. a disk controller is built into each disk drive. to perform a disk i o operation the computer places a command into the host controller typically using memory mapped i o ports as described in section . . . the host controller then sends the command via messages to the disk controller and the disk controller operates the disk drive hardware to carry out the command. disk controllers usually have a built in cache. data transfer at the disk drive happens between the cache and the disk surface and data transfer to the host at fast electronic speeds occurs betwreen the cache and the host controller. . . magnetic tapes magnetic tape was used as an early secondary storage medium. although it is relatively permanent and can hold large quantities of data its access time is slow compared with that of main memory and magnetic disk. in addition random access to magnetic tape is about a thousand times slower than random access to magnetic disk so tapes are not very useful for secondary storage. tapes are used mainly for backup for storage of infrequently used information and as a medium for transferring information from one system to another. a tape is kept in a spool and is wound or rewound past a read write head. moving to the correct spot on a tape can take minutes but once positioned tape drives can write data at speeds comparable to disk drives. tape capacities vary greatly depending on the particular kind of tape drive. typically they store from gb to gb. some have built in compression that can more than double the effective storage. tapes and their drivers are usually categorized by width including and millimeters and and inch. some are named according to technology such as lto and sdlt. tape storage is further described in section . . chapter mass storage structure l i k i u fco aiiijitiierftiee siesagiiyd fyr . the ee.e . a i a d d s j d i i i f f i i g p itilwimik up fe sflo hi ega i s j per. geccinp. . cently a new sfa ii.f arc! i fe mel i ! i a m i t e i i i i
 modern disk drives are addressed as large one dimensional arrays of logical blocks where the logical block is the smallest unit of transfer. the size of a logical block is usually bytes although some disks can be low level formatted to have a different logical block size such as bytes. this option is described in section . . . the one dimensional array of logical blocks is mapped onto the sectors of the disk sequentially. sector is the first sector of the first track on the outermost cylinder. the mapping proceeds in order through that track then through the rest of the tracks in that cylinder and then through the rest of the cylinders from outermost to innermost. by using this mapping we can at least in theory convert a logical block number into an old style disk address that consists of a cylinder number a track number within that cylinder and a sector number within that track. in practice it is difficult to perform this translation for two reasons. first most disks have some defective sectors but the mapping hides this by substituting spare sectors from elsewhere on the disk. second the number of sectors per track is not a constant on some drives. let's look more closely at the second reason. on media that use constant linear velocity clv the density of bits per track is uniform. the farther a track is from the center of the disk the greater its length so the more sectors it can hold. as we move from outer zones to inner zones the number of sectors per track decreases. tracks in the outermost zone typically hold percent more sectors than do tracks in the innermost zone. the drive increases its rotation speed as the head moves from the outer to the inner tracks to keep the same rate of data moving under the head. this method is used in cd rom and dvd rom drives. alternatively the disk rotation speed can stay constant and the density of bits decreases from inner tracks to outer tracks to keep the data rate constant. this method is used in hard disks and is known as constant angular velocity cav . the number of sectors per track has been increasing as disk technology improves and the outer zone of a disk usually has several hundred sectors per track. similarly the number of cylinders per disk has been increasing large disks have tens of thousands of cylinders
 s . disk attachment computers access disk storage in two ways. one way is via i o ports or host attached storage this is common on small systems. the other way is via a remote host in a distributed file system this is referred to as network attached storage. . . host attached storage host attached storage is storage accessed through local i o ports. these ports use several technologies. the typical desktop pc uses an i o bus architecture called ide or ata. this architecture supports a maximum of two drives per i o bus. a newer similar protocol that has simplified cabling is sata. high end workstations and servers generally use more sophisticated i o architectures such as scsi and fiber channel fc . scsi is a bus architecture. its physical medium is usually a ribbon cable having a large number of conductors typically or . the scsi protocol supports a maximum of devices on the bus. generally the devices include one controller card in the host the scsi initiator and up to storage devices the scsi targets . a scsi disk is a common scsi target but the protocol provides the ability to address up to logical units in each scsi target. a typical use of logical unit addressing is to direct commands to components of a ratd array or components of a removable media library such as a cd jukebox sending commands to the media changer mechanism or to one of the drives . fc is a high speed serial architecture that can operate over optical fiber or over a four conductor copper cable. it has two variants. one is a large switched fabric having a bit address space. this variant is expected to dominate in the future and is the basis of storage area networks sans discussed in section . . . because of the large address space and the switched nature of the communication multiple hosts and storage devices can attach to the fabric allowing great flexibility in i o communication. the other pc variant is an arbitrated loop fc al that can address devices drives and controllers . a wide variety of storage devices are suitable for use as host attached storage. among these are hard disk drives raid arrays and cd dvd and tape drives. the i o commands that initiate data transfers to a host attached storage device are reads and writes of logical data blocks directed to specifically identified storage units such as bus id scsi id and target logical unit . . . network attached storage a network attached storage nas device is a special purpose storage system that is accessed remotely over a data network figure . . clients access network attached storage via a remote procedure call interface such as nfs for unix systems or cifs for windows machines. the remote procedure calls rpcs are carried via tcp or udp over an ip network usually the same local area network lan that carries all data traffic to the clients. the networkattached storage unit is usua lly implemented as a raid array with software that implements the rpc interface. it is easiest to think of nas as simply another storage access protocol. for example rather than using a scsi device driver and scsi protocols to access storage a system using nas would use rpc over tcp ip. chapter mass storage structure figure . network attached storage. network attached storage provides a convenient way for all the computers on a lan to share a pool of storage with the same ease of naming and access enjoyed with local host attached storage. however it tends to be less efficient and have lower performance than some direct attached storage options. iscsi is the latest network attached storage protocol. in essence it uses the ip network protocol to carry the scsi protocol. thus networks rather than scsi cables can be used as the interconnects between hosts and their storage. as a result hosts can treat their storage as if it were directly attached but the storage can be distant from the host. . . storage area network one drawback of network attached storage systems is that the storage i o operations consume bandwidth on the data network thereby increasing the latency of network communication. this problem can be particularly acute in large client server installations the communication between servers and clients competes for bandwidth with the communication among servers and storage devices. a storage area network san is a private network using storage protocols rather than networking protocols connecting servers and storage units as shown in figure . . the power of a san lies in its flexibility. multiple hosts and multiple storage arrays can attach to the same san and storage can be dynamically allocated to hosts. a san switch allows or prohibits access between the hosts and the storage. as one example if a host is running lowon disk space the san can be configured to allocate more storage to that host. sans make it possible for clusters of servers to share the same storage and for storage arrays to include multiple direct host connections. sans typically have more ports and less expensive ports than storage arrays. fc is the most common. san interconnect. an emerging alternative is a special purpose bus architecture named infiniband which provides hardware and software support for high speed interconnection networks for servers and storage units
 one of the responsibilities of the operating system is to use the hardware efficiently. for the disk drives meeting this responsibility entails having . disk scheduling figure . storage area network. fast access time and large disk bandwidth. the access time has two major components also see section . . . the seek time is the time for the disk arm to move the heads to the cylinder containing the desired sector. the rotational latency is the additional time for the disk to rotate the desired sector to the disk head. the disk bandwidth is the total number of bytes transferred divided by the total time between the first request for service and the completion of the last transfer. we can improve both the access time and the bandwidth by scheduling the servicing of disk i o requests in a good order. whenever a process needs i o to or from the disk it issues a system call to the operating system. the request specifies several pieces of information whether this operation is input or output what the disk address for the transfer is what the memory address for the transfer is what the number of sectors to be transferred is if the desired disk drive and controller are available the request can be serviced immediately. if the drive or controller is busy any new requests for service will be placed in the queue of pending requests for that drive. for a multiprogramming system with many processes the disk queue may often have several pending requests. thus when one request is completed the operating system chooses which pending request to service next. how does the operating system make this choice? any one of several disk scheduling algorithms can be used and we discuss them next. . . fcfs scheduling the simplest form of disk scheduling is of course the first come first served fcfs algorithm. this algorithm is intrinsically fair but it generally does not provide the fastest service. consider for example a disk queue with requests for i o to blocks on cylinders chapter mass storage structure queue head starts at ' . . . . . . i.i. .i i! i. . j figure . fcfs disk scheduling. in that order. if the disk head is initially at cylinder it will first move from to then to and finally to for a total head movement of cylinders. this schedule is diagrammed in figure . . the wild swing from to and then back to illustrates the problem with this schedule. if the requests for cylinders and could be serviced together before or after the requests at and the total head movement could be decreased substantially and performance could be thereby improved. . . sstf scheduling it seems reasonable to service all the requests close to the current head position before moving the head far away to service other requests. this assumption is the basis for the shortest seek time first sstf algorithm. the sstf algorithm selects the request with the minimum seek time from the current head position. since seek time increases with the number of cylinders traversed by the head sstf chooses the pending request closest to the current head position. for our example request queue the closest request to the initial head position is at cylinder . once we are at cylinder the next closest request is at cylinder . from there the request at cylinder is closer than the one at so is served next. continuing we service the request at cylinder then and finally figure . . this scheduling method results in a total head movement of only cylinders little more than one third of the distance needed for fcfs scheduling of this request queue. this algorithm gives a substantial improvement in performance. sstf scheduling is essentially a form of shortest job first sjf scheduling and like sjf scheduling it may cause starvation of some requests. remember that requests may arrive at any time. suppose that we have two requests in the queue for cylinders and and while servicing the request from a new request near arrives. this new request will be serviced next making the request at wait. while this request is being serviced another request close to could arrive. in theory a continual stream of requests near one another could arrive causing the request for cylinder to wait indefinitely. . disk scheduling queue . head starts at l figure . sstf disk scheduling. this scenario becomes increasingly likely if the pending request queue grows long. although the sstf algorithm is a substantial improvement over the fcfs algorithm it is not optimal. in the example we can do better by moving the head from to even though the latter is not closest and then to before turning around to service and . this strategy reduces the total head movement to cylinders. . . scan scheduling in the scan algorithm the disk arm starts at one end of the disk and moves toward the other end servicing requests as it reaches each cylinder until it gets to the other end of the disk. at the other end the direction of head movement is reversed and servicing continues. the head continuously scans back and forth across the disk. the scan algorithm is sometimes called the elevator algorithm since the disk arm behaves just like an elevator in a building first servicing all the requests going up and then reversing to service requests the other way. let's return to our example to illustrate. before applying scan to schedule the requests on cylinders and we need to know the direction of head movement in addition to the head's current position . if the disk arm is moving toward the head will service and then . at cylinder the arm will reverse and will move toward the other end of the disk servicing the requests at and figure . . if a request arrives in the queue just in front of the head it will be serviced almost immediately a request arriving just behind the head will have to wait until the arm moves to the end of the disk reverses direction and comes back. assuming a uniform distribution of requests for cylinders consider the density of requests when the head reaches one end and reverses direction. at this point relatively few requests are immediately in front of the head since these cylinders have recently been serviced. the heaviest density of requests is at the other end of the disk. these requests have also waited the longest so why not go there first? that is the idea of the next algorithm. chapter mass storage structure queue . head starts at figure . scan disk scheduling. . . c scan scheduling circular scan c scan scheduling is a variant of scan designed to provide a more uniform wait time. like scan c scan moves the head from one end of the disk to the other servicing requests along the way. when the head reaches the other end however it immediately returns to the beginning of the disk without servicing any requests on the return trip figure . . the c scan scheduling algorithm essentially treats the cylinders as a circular list that wraps around from the final cylinder to the first one. . . look scheduling as we described them both scan and c scak move the disk arm across the full width of the disk. in practice neither algorithm is often implemented this way. more commonly the arm goes only as far as the final request in each queue head starts at i j ljj j lj i i h figure . c scan disk scheduling. . disk scheduling queue head starts at figure . c look disk scheduling. direction. then it reverses direction immediately without going all the way to the end of the disk. versions of scan and c scan that follow this pattern are called look and c look scheduling because they look for a request before continuing to move in a given direction figure . . . . selection of a disk scheduling algorithm given so many disk scheduling algorithms how do we choose the best one? sstf is common and has a natural appeal because it increases performance over fcfs. scam and c scan perform better for systems that place a heavy load on the disk because they are less likely to cause a starvation problem.. for any particular list of requests we can define an optimal order of retrieval but the computation needed to find an optimal schedule may not justify the savings over sstf or scan. with any scheduling algorithm however performance depends heavily on the number and types of requests. for instance suppose that the queue usually has just one outstanding request. then all scheduling algorithms behave the same because they have only one choice for where to move the disk head they all behave like fcfs scheduling. requests for disk service can be greatly influenced by the file allocation method. a program reading a contiguously allocated file will generate several requests that are close together on the disk resulting in limited head movement. a linked or indexed file in contrast may include blocks that are widely scattered on the disk resulting in greater head movement. the location of directories and index blocks is also important. since every file must be opened to be used and opening a file requires searching the directory structure the directories will be accessed frequently. suppose that a directory entry is on the first cylinder and a file's data are on the final cylinder. in this case the disk head has to move the entire width of the disk. if the directory entry were on the middle cylinder the head would have to move at most one half the width. caching the directories and index blocks in main memory can also help to reduce the disk arm movement particularly for read requests. chapter mass storage structure because of these complexities the disk scheduling algorithm should be written as a separate module of the operating system so that it can be replaced with a different algorithm if necessary. either sstf or look is a reasonable choice for the default algorithm. the scheduling algorithms described here consider only the seek distances. for modern disks the rotational latency can be nearly as large as the average seek time. it is difficult for the operating system to schedule for improved rotational latency though because modern disks do not disclose the physical location of logical blocks. disk manufacturers have been alleviating this problem by implementing disk scheduling algorithms in the controller hardware built into the disk drive. if the operating system sends a batch of requests to the controller the controller can queue them and then schedule them to improve both the seek time and the rotational latency. if i o performance were the only consideration the operating system would gladly turn over the responsibility of disk scheduling to the disk hardware. in practice however the operating system may have other constraints on the service order for requests. for instance demand paging may take priority over application i o and writes are more urgent than reads if the cache is running out of free pages. also it may be desirable to guarantee the order of a set of disk writes to make the file system robust in the face of system crashes. consider what could happen if the operating system allocated a disk page to a file and the application wrote data into that page before the operating system had a chance to flush the modified inode and free space list back to disk. to accommodate such requirements an operating system may choose to do its own disk scheduling and to spoon feed the requests to the disk controller one by one for some types of f o
 the operating system is responsible for several other aspects of disk management too. here we discuss disk initialization booting from disk and bad block recovery. . . disk formatting a new magnetic disk is a blank slate it is just a platter of a magnetic recording material. before a disk can store data it must be divided into sectors that the disk controller can read and write. this process is called low level formatting or physical formatting. low level formatting fills the disk with a special data structure for each sector. the data structure for a sector typically consists of a header a data area usually bytes in size and a trailer. the header and trailer contain information used by the disk controller such as a sector number and an error correcting code ecc . when the controller writes a sector of data during normal i o the ecc is updated with a value calculated from all the bytes in the data area. when the sector is read the ecc is recalculated and is compared with the stored value. if the stored and calculated numbers are different this mismatch indicates that the data area of the sector has become corrupted and that the disk sector may be bad section . . . the ecc is an error correcting code because it contains enough information that if only a few . disk management bits or data have been corrupted the controller can identify which bits have changed and can calculate what their correct values should be. it then reports a recoverable soft error. the controller automatically does the ecc processing whenever a sector is read or written. most hard disks are low level forniatted at the factory as a part of the manufacturing process. this formatting enables the manufacturer to test the disk and to initialize the mapping from logical block numbers to defect free sectors on the disk. for many hard disks when the disk controller is instructed to low level format the disk it can also be told how many bytes of data space to leave between the header and trailer of all sectors. it is usually possible to choose among a few sizes such as and bytes. formatting a disk with a larger sector size means that fewer sectors can fit on each track but it also means that fewer headers and trailers are written on each track and more space is available for user data. some operating systems can handle only a sector size of bytes. to use a disk to hold files the operating system still needs to record its own data structures on the disk. it does so in two steps. the first step is to partition the disk into one or more groups of cylinders. the operating system can treat each partition as though it were a separate disk. for instance one partition can hold a copy of the operating system's executable code while another holds user files. after partitioning the second step is logical formatting or creation of a file system . in this step the operating system stores the initial file system data structures onto the disk. these data structures may include maps of free and allocated space a fat or modes and an initial empty directory. to increase efficiency most file systems group blocks together into larger chunks frequently called clusters. disk i o is done via blocks but file system i o is done via clusters effectively assuring that i o has more sequential access and fewer random access characteristics. some operating systems give special programs the ability to use a disk partition as a large sequential array of logical blocks without any file system data structures. this array is sometimes called the raw disk and o to this array is termed raw i o. for example some database systems prefer raw i o because it enables them to control the exact disk location where each database record is stored. raw i o bypasses all the file system services such as the buffer cache file locking prefetching space allocation file names and directories. we can make certain applications more efficient by allowing them to implement their own special purpose storage services on a raw partition but most applications perform better when they use the regular file system services. . . boot block for a computer to start running for instance when it is powered up or rebooted it must have an initial program to run. this initial bootstrap program tends to be simple. it initializes all aspects of the system from cpu registers to device controllers and the contents of main memory and then starts the operating system. to do its job the bootstrap program finds the operatingsystem kernel on disk loads that kernel into memory and jumps to an initial address to begin the operating system execution. for most computers the bootstrap is stored in read only memory rom . this location is convenient because rom needs no initialization and is at a fixed chapter mass storage structure boo' code partition part ten ia.d'e partition partition boot partition partition figure . booting from disk in windows . location that the processor can start executing when powered up or reset. and since rom is read only it cannot be infected by a computer virus. the problem is that changing this bootstrap code requires changing the rom hardware chips. for this reason most systems store a tiny bootstrap loader program in the boot rom whose only job is to bring in a full bootstrap program from disk. the full bootstrap program can be changed easily a new version is simply written onto the disk. the full bootstrap program is stored in ''the boot blocks at a fixed location on the disk. a disk that has a boot partition is called a boot disk or system disk. the code in the boot rom instructs the disk controller to read the boot blocks into memory no device drivers are loaded at this point and then starts executing that code. the full bootstrap program is more sophisticated than the bootstrap loader in the boot rom it is able to load the entire operating system from a non fixed location on disk and to start the operating system running. even so the full bootstrap code may be small. let's consider as an example the boot process in windows . the windows system places its boot code in the first sector on the hard disk which it terms the master boot record or mbr . furthermore windows allows a hard disk to be divided into one or more partitions one partition identified as the boot partition contains the operating system and device drivers. booting begins in a windows system by running code that is resident in the system's rom memory. this code directs the system to read the boot code from the mbr. in addition to containing boot code the mbr contains a table listing the partitions for the hard disk and a flag indicating which partition the system is to be booted from. this is illustrated in figure . . once the system identifies the boot partition it reads the first sector from that partition which is called the boot sector and continues with the remainder of the boot process which includes loading the various subsystems and system services. . . bad blocks because disks have moving parts and small tolerances recall that the disk head flies just above the disk surface they are prone to failure. sometimes the failure is complete in this case the disk needs to be replaced and its contents restored from backup media to the new disk. more frequently one or more . disk management sectors become defective. most disks even come from the factory with bad blocks. depending on the disk and controller in use these blocks are handled in a variety of ways. on simple disks such as some disks with de controllers bad blocks are handled manually. for instance the ms dos format command performs logical formatting and as a part of the process scans the disk to find bad blocks. if format finds a bad block it writes a special value into the corresponding fat entry to tell the allocation routines not to use that block. if blocks go bad during normal operation a special program such as chkdsk must be run manually to search for the bad blocks and to lock them away as before. data that resided on the bad blocks usually are lost. more sophisticated disks such as the scsi disks used in high end pcs and most workstations and servers are smarter about bad block recovery. the controller maintains a list of bad blocks on the disk. the list is initialized during the low level formatting at the factory and is updated over the life of the disk. low level formatting also sets aside spare sectors not visible to the operating system. the controller can be told to replace each bad sector logically with one of the spare sectors. this scheme is known as sector sparing or forwarding. a typical bad sector transaction might be as follows the operating system tries to read logical block . the controller calculates the ecc and finds that the sector is bad. it reports this finding to the operating system. the next time the system is rebooted a special command is run to tell the scsi controller to replace the bad sector with a spare. after that whenever the system requests logical block the request is translated into the replacement sector's address by the controller. such a redirection by the controller could invalidate any optimization by the operating system's disk scheduling algorithm! for this reason most disks are formatted to provide a few spare sectors in each cylinder and a spare cylinder as well. when a bad block is remapped the controller uses a spare sector from the same cylinder if possible. as an alternative to sector sparing some controllers can be instructed to replace a bad block by sector slipping. here is an example suppose that logical block becomes defective and the first available spare follows sector . then sector slipping remaps all the sectors from to moving them all down one spot. that is sector is copied into the spare then sector into and then into and so on until sector is copied into sector . slipping the sectors in this way frees up the space of sector so sector can be mapped to it. the replacement of a bad block generally is not totally automatic because the data in the bad block are usually lost. several soft errors could trigger a process in which a copy of the block data is made and the block is spared or slipped. an unrecoverable hard error however results in lost data. whatever file was using that block must be repaired for instance by restoration from a backup tape and that requires manual intervention. chapter mass storage structure 
 swapping was first presented in section . where wre discussed moving entire processes between disk and main memory. swapping in that setting occurs when the amount of physical memory reaches a critically low point and processes which are usually selected because they are the least active are moved from memory to swap space to free available memory. in practice very few modern operating systems implement swapping in this fashion. rather systems now combine swapping with virtual memory techniques chapter and swap pages not necessarily entire processes. in fact some systems now use the terms swapping and paging interchangeably reflecting the merging of these two concepts. swap space management is another low level task of the operating system. virtual memory uses disk space as an extension of main memory. since disk access is much slower than memory access using swap space significantly decreases system performance. the main goal for the design and implementation of swap space is to provide the best throughput for the virtual memory system. in this section we discuss how swap space is used where swap space is located on disk and how swap space is managed. . . swap space use swap space is used in various ways by different operating systems depending on the memory management algorithms in use. for instance systems that implement swapping may use swap space to hold an entire process image including the code and data segments. paging systems may simply store pages that have been pushed out of main memory. the amount of swap space needed on a system can therefore vary depending on the amount of physical memory the amount of virtual memory it is backing and the way in which the virtual memory is used. it can range from a few megabytes of disk space to gigabytes. note that it may be safer to overestimate than to underestimate the amount of swap space required because if a system runs out of swap space it may be forced to abort processes or may crash entirely. overestimation wastes disk space that could otherwise be used for files but it does no other harm. some systems recommend the amount to be set aside for swap space. solaris for example sviggests setting swap space equal to the amount by which virtual memory exceeds pageable physical memory. historically linux suggests setting swap space to double the amount of physical memory although most linux systems now use considerably less swap space. in fact there is currently much debate in the linux community about whether to set aside swap space at all! some operating systems including linux allow the use of multiple swap spaces. these swap spaces are usually put on separate disks so the load placed on the i o system by paging and swapping can be spread over the system's i o devices. . . swap space location a swap space can reside in one of two places it can be carved out of the normal file system or it can be in a separate disk partition. if the swap space is simply a large file within the file system normal file system routines . swap space management can be used to create it name it and allocate its space. this approach though easy to implement is inefficient. navigating the directory structure and the disk allocation data structures takes time and potentially extra disk accesses. external fragmentation can greatly increase swapping times by forcing multiple seeks during reading or writing of a process image. we can improve performance by caching the block location information in physical memory and by using special tools to allocate physically contiguous blocks for the swap file but the cost of traversing the file system data structures still remains. alternatively swap space can be created in a separate raw partition as no file system or directory structure is placed in this space. rather a separate swap space storage manager is used to allocate and deallocate the blocks from the raw partition. this manager uses algorithms optimized for speed rather than for storage efficiency because swap space is accessed much more frequently than file systems when it is used . internal fragmentation may increase but this trade off is acceptable because the life of data in the swap space generally is much shorter than that of files in the file system. swap space is reinitialized at boot time so any fragmentation is short lived. this approach creates a fixed amount of swap space during disk partitioning. adding more swap space requires repartitioning the disk which involves moving the other file system partitions or destroying them and restoring them from backup or adding another swap space elsewhere. some operating systems are flexible and can swap both in raw partitions and in file system space. linux is an example the policy and. implementation are separate allowing the machine's administrator to decide which type of swapping to use. the trade off is between the convenience of allocation and management in the file system and the performance of swapping in raw partitions. . . swap space management an example we can illustrate how swap space is used by following the evolution of swapping and paging in various unix systems. the traditional unix kernel started with an implementation of swapping that copied entire processes between contiguous disk regions and memory. unix later evolved to a combination of swapping and paging as paging hardware became available. in solaris sunos the designers changed standard unix methods to improve efficiency and reflect technological changes. when a process executes text segment pages containing code are brought in from the file system accessed in main memory and thrown away if selected for pageout. it is more efficient to reread a page from the file system than to write it to swap space and then reread it from there. swap space is only used as a backing store for pages of anonymous memory which includes memory allocated for the stack heap and uninitialized data of a process. more changes were made in later versions of solaris. the biggest change is that solaris now allocates swap space only when a page is forced out of physical memory rather than when the virtual memory page is first created. this scheme gives better performance on modern computers which have more physical memory than older systems and tend to page less. chapter mass storage structure swap area page slot swap partition ! ill ! m hi !m or swap file j j j . ' ' . ' . . m'. . ' ' iilil. swap map f figure . the data structures for swapping on linux systems. linux is similar to solaris in that swap space is only used for anonymous memory or for regions of memory shared by several processes. linux allows one or more swap areas to be established. a swap area may be in either a swap file on a regular file system or a raw swap partition. each swap area consists of a series of kb page slots which are used to hold swapped pages. associated with each swap area is a swap map an array of integer counters each corresponding to a page slot in the swap area. tf the value of a counter is the corresponding page slot is available. values greater than indicate that the page slot is occupied by a swapped page. the value of the counter indicates the number of mappings to the swapped page for example a value of indicates that the swapped page is mapped to three different processes which can occur if the swapped page is storing a region of memory shared by three processes . the data structures for swapping on linux systems are shown in figure . . . raid structure disk drives have continued to get smaller and cheaper so it is now economically feasible to attach .many disks to a computer system. having a large number of disks in a system presents opportunities for improving the rate at which data can be read or written if the disks are operated in parallel. furthermore this setup offers the potential for improving the reliability of data storage because redundant information can be stored on multiple disks. thus failure of one disk does not lead to loss of data. a variety of disk organization techniques collectively called redundant arrays of inexpensive disks raids are commonly used to address the performance and reliability issues. in the past raids composed of small cheap disks were viewed as a cost effective alternative to large expensive disks today raids are used for their higher reliability and higher data transfer rate rather than for economic reasons. hence the i in raid now stands for independent instead of inexpensive. . . improvement of reliability via redundancy let us first consider the reliability of raids. the chance that some disk out of a set of n disks will fail is much higher than the chance that a specific single disk will fail. suppose that the mean time to failure of a single disk is hours. then the mean time to failure of some disk in an array of disks . raid structure ptpgg j f idi? xaitt fe a s slejii can. fes e ilisftsmrect mtycfeti t itg.bases .'lit ih'ft ca e tfit epgiattftg 'scte usuallyl s i r t d l s k t . f t h a fh c f l e t ! f s ih ecgf vfa's h a r h i i 'tfea will be hours or . days which is not long at all! if we store only one copy of the data then each disk failure will result in loss of a significant amount of data and such a high rate of data loss is unacceptable. the solution to the problem of reliability is to introduce redundancy we store extra information that is not normally needed but that can be used in the event of failure of a disk to rebuild the lost information. thus even if a disk fails data are not lost. the simplest but most expensive approach to introducing redundancy is to duplicate every disk. this technique is called mirroring. a logical disk then consists of two physical disks and every write is carried out on both disks. if one of the disks fails the data can be read from the other. data will be lost only if the second disk fails before the first failed disk is replaced. the mean time to failure where failure is the loss of data of a mirrored volume made up of two disks mirrored depends on two factors. one is the mean time to failure of the individual disks. the other is the mean time to repair which is the time it takes on average to replace a failed disk and to restore the data on it. suppose that the failures of the two disks are independent that is the failure of one disk is not connected to the failure of the other. then if the mean time to failure of a single disk is hours and the mean time to repair is hours the mean time to data loss of a mirrored disk system is hours or years! you should be aware that the assumption of independence of disk failures is not valid. power failures and natural disasters such as earthquakes fires and floods may result in damage to both disks at the same time. also manufacturing defects in a batch of disks can cause correlated failures. as disks age the probability of failure grows increasing the chance that a second disk will fail while the first is being repaired. in spite of all these considerations however mirrored disk systems offer much higher reliability than do singledisk systems. power failures are a particular source of concern since they occur far more frequently than do natural disasters. even with mirroring of disks if writes are in progress to the same block in both disks and power fails before both blocks are fully written the two blocks can be in an inconsistent state. one solution to this problem is to write one copy first then the next so that one chapter mass storage structure of the two copies is always consistent. another is to add a nonvolatile' ram nvram cache to the raid array. this write back cache is protected from data loss during power failures so the write can be considered complete at that point assuming the nvram has some kind of error protection and correction. such as ecc or mirroring. . . improvement in performance via parallelism now let's consider how parallel access to multiple disks improves performance. with disk mirroring the rate at which read requests can be handled is doubled since read requests can be sent to either disk as long as both disks in a pair are functional as is almost always the case . the transfer rate of each read is the same as in a single disk system but the number of reads per unit time has doubled. with multiple disks we can improve the transfer rate as well or instead by striping data across the disks. in its simplest form data striping consists of splitting the bits of each byte across multiple disks such striping is called bit level striping. for example if we have an array of eight disks we write bit ' of each byte to disk . the array of eight disks can be treated as a single disk with sectors that are eight times the normal size and more important that have eight times the access rate. in such an organization every disk participates in every access read or write so the number of accesses that can be processed per second is about the same as on a single disk but each access can read eight times as many data in the same time as on a single disk. bit level striping can be generalized to include a number of disks that either is a multiple of or divides . for example if we use an array of four disks bits and i of each byte go to disk . further striping need not be at the bit level. for example in block level striping blocks of a file are striped across multiple disks with n disks block of a file goes to disk mod n . other levels of striping such as bytes of a sector or sectors of a block also are possible. block level striping is the most common. parallelism in a disk system as achieved through striping has two main goals . increase the throughput of multiple small accesses that is page accesses by load balancing. . reduce the response time of large accesses. . . raid levels mirroring provides high reliability but it is expensive. striping provides high data transfer rates but it does not improve reliability. numerous schemes to provide redundancy at lower cost by using the idea of disk striping combined with parity bits which we describe next have been proposed. these schemes have different cost performance trade offs and are classified according to levels called raid levels. we describe the various levels here figure . shows them pictorially in the figure p indicates error correcting bits and c indicates a second copy of the data . in all cases depicted in the figure four disks' worth of data are stored and the extra disks are used to store redundant information for failure recovery. . raid structure a raid non redundant striping. b raid mirrored disks. c raid memory style error correcting codes. d raid bit interleaved parity. e raid block interleaved parity. f raid block interleaved distributed parity. g raid p q redundancy. figure . raid levels. raid level . raid level refers to disk arrays with striping at the level of blocks but without any redundancy such as mirroring or parity bits as shown in figure . a . raid level . raid level refers to disk mirroring. figure . b shows a mirrored organization. raid level . raid level is also known as memory style error correctingcode ecc organization. memory systems have long detected certain errors by using parity bits. each byte in a memory system may have a parity bit associated with it that records whether the number of bits in the byte set to is even parity or odd parity . if one of the bits in the byte is damaged either a becomes a or a becomes a the parity of the byte changes and thus will not match the stored parity. similarly if the stored parity bit is damaged it will not match the computed parity. thus all single bit errors are detected by the memory system. error correcting chapter mass storage structure schemes store two or more extra bits and can reconstruct the data if a single bit is damaged. the idea of ecc can be used directly in disk arrays via striping of bytes across disks. for example the first bit of each byte can be stored in disk the second bit in disk and so on until the eighth bit is stored in disk the error correction bits are stored in further disks. this scheme is shown pictorially in figure . c where the disks labeled p store the error correction bits. if one of the disks fails the remaining bits of the byte and the associated error correction bits can be read from other disks and used to reconstruct the damaged data. note that raid level requires only three disks' overhead for four disks of data unlike raid level which requires four disks' overhead. raid level . raid level or bit interleaved parity organization improves on level by taking into account the fact that unlike memory systems disk controllers can detect whether a sector has been read correctly so a single parity bit can be used for error correction as well as for detection. the idea is as follows if one of the sectors is damaged we know exactly which sector it is and we can figure out whether any bit in the sector is a or a by computing the parity of the corresponding bits from sectors in the other disks. if the parity of the remaining bits is equal to the stored parity the missing bit is otherwise it is . raid level is as good as level but is less expensive in the number of extra disks required it has only a one disk overhead so level is not used in practice. this scheme is shown pictorially in figure . d . raid level has two advantages over level . first the storage overhead is reduced because only one parity disk is needed for several regular disks whereas one mirror disk is needed for every disk in level . second since reads and writes of a byte are spread out over multiple disks with a way striping of data the transfer rate for reading or writing a single block is n times as fast as with raid level . on the negative side raid level supports fewer i os per second since every disk has to participate in every i o request. a further performance problem with raid and with all paritybased raid levels is the expense of computing and writing the parity. this overhead results in significantly slower writes than with non parity raid arrays. to moderate this performance penalty many raid storage arrays include a hardware controller with dedicated parity hardware. this controller offloads the parity computation from the cpu to the array. the array has an nvram cache as well to store the blocks while the parity is computed and to buffer the writes from the controller to the spindles. this combination can make parity raid almost as fast as non parity. in fact a caching array doing parity raid can outperform a non caching non parity raid. raid level . raid level or block interleaved parity organization uses block level striping as in raid and in addition keeps a parity block on a separate disk for corresponding blocks from a! other disks. this scheme is diagramed in figure . e . if one of the disks fails the parity block can be used with the corresponding blocks from the other disks to restore the blocks of the failed disk. . raid structure a block read accesses only one disk allowing other requests to be processed by the other disks thus the data transfer rate for each access is slower but multiple read accesses can proceed in parallel leading to a higher overall i o rate. the transfer rates for large reads are high since all the disks can be read in parallel large writes also have high transfer rates since the data and parity can be written in parallel small independent writes cannot be performed in parallel. an operating system write of data smaller than a block requires that the block be read modified with the new data and written back. the parity block has to be updated as well. this is known as the read modify write cycle. thus a single write requires four disk accesses two to read the two old blocks and two to write the two new blocks. wafl chapter uses raid level because this raid level allows disks to be added to a raid set seamlessly. if the added ciisks are initialized with blocks containing all zeros then the parity value does not change and the raid set is still correct. raid level . raid level or block interleaved distributed parity differs from level by spreading data and parity among all n disks rather than storing data in n disks and parity in one disk. for each block one of the disks stores the parity and the others store data. for example with an array of five disks the parity for the nth block is stored in disk n mod the nth blocks of the other four disks store actual data for that block. this setup is shown in figure . l f where the ps are distributed across all the disks. a parity block cannot store parity for blocks in the same disk because a disk failure would result in loss of data as well as of parity and hence the loss would not be recoverable. by spreading the parity across all the disks in the set raid avoids the potential overuse of a single paritydisk that can occur with raid . raid is the most common parity raid system. raid level . raid level also called the p q redundancy scheme is much like raid level but stores extra redundant information to guard against multiple disk failures. instead of parity error correcting codes such as the reed solomon codes are used. in the scheme shown in figure . g bits of redundant data are stored for every bits of data compared with parity bit in level and the system can tolerate two disk failures. raid level . raid level refers to a combination of raid levels and . raid provides the performance while raid provides the reliability. generally this level provides better performance than raid . it is common in environments where both performance and. reliability are important. unfortunately it doubles the number of disks needed for storage as does raid so it is also more expensive in raid a set of disks are striped and then the stripe is mirrored to another equivalent stripe. another raid option that is becoming available commercially is raid level in which disks are mirrored in pairs and then the resulting mirror pairs are striped. this raid has some theoretical advantages over raid . for example if a single disk fails in raid the entire chapter mass storage structure stripe mirror stripe a raid with a single disk failure. stripe mirror mirror mirror mirror b raid with a single disk failure. figure . raid and . stripe is inaccessible leaving only the other stripe available. with a failure in raid the single disk is unavailable but its mirrored pair is still available as are all the rest of the disks figure . . numerous variations have been proposed to the basic raid schemes described here. as a result some confusion may exist about the exact definitions of the different raid levels. the implementation of raid is another area of variation. consider the following layers at which raid can be implemented. volume management software can implement raid within the kernel or at the system software layer. in this case the storage hardware can provide a minimum of features and still be part of a full raid solution. parity raid is fairly slow when implemented in software so typically raid or is used. raid can be implemented in the host bus adapter hba hardware. only the disks directly connected to the hba can be part of a given raid set. this solution is low in cost but not very flexible. raid can be implemented in the hardware of the storage array. the storage array can create raid sets of various levels and can even slice these sets into smaller volumes which are then presented to the operating system. . raid structure the operating system need only implement the file system on each f the volumes. arrays can have multiple connections available or can be part of a san allowing multiple hosts to take advantage of the array's features. raid can be implemented in the san interconnect layer by disk virtualization devices. in this case a device sits between the hosts and the storage. it accepts commands from the servers and manages access to the storage. it could provide mirroring for example by writing each block to two separate storage devices. other features such as snapshots and replication can be implemented at each of these levels as well. replication involves the automatic duplication of writes between separate sites for redimdancy and disaster recovery. replication can be synchronous or asynchronous. in synchronous replication each block must be written locally and remotely before the write is considered complete whereas in asynchronous replication the writes are grouped together and written periodically. asynchronous replication can result in data loss if the primary site fails but is faster and has no distance limitations. the implementation of these features differs depending on the layer at which raid is implemented. for example if raid is implemented in software then each host may need to implement and manage its own replication. if replication is implemented in the storage array or in the san interconnect however then whatever the host operating system or features the hosts data can be replicated. one other aspect of most raid implementations is a hot spare disk or disks. a hot spare is not used for data but is configured to be used as a replacement should any other disk fail. for instance a hot spare can be used to rebuild a mirrored pair should one of the disks in the pair fail. in this way the raid level can be reestablished automatically without waiting for the failed disk to be replaced. allocating more than one hot spare allows more than one failure to be repaired without human intervention. . . selecting a rasd level given the many choices they have how do system designers choose a raid level? one consideration is rebuild performance. if a disk fails the time needed to rebuild its data can be significant and will vary with the raid level used. rebuilding is easiest for raid level since data can be copied from another disk for the other levels we need to access all the other disks in the arrayto rebuild data in a failed disk. the rebuild performance of a raid system may be an important factor if a continuous supply of data is required as it is in high performance or interactive database systems. furthermore rebuild performance influences the mean time to failure. rebuild times can be hours for raid rebuilds of large disk sets. raid level is used in high performance applications where data loss is not critical. raid level is popular for applications that require high reliability with fast recovery. raid and are used where both performance and reliability are important for example for small databases. due to raid l's high space overhead raid level is often preferred for storing large volumes of data. level is not supported currently by many raid implementations but it should offer better reliability than level . chapter mass storage structure raid system designers and administrators of storage have to make several other decisions as well. for example how many disks should be in a given raid set? how many bits should be protected by each parity bit? if more disks are in an array data transfer rates are higher but the system is more expensive. if more bits are protected by a parity bit. the space overhead due to parity bits is lower but the chance that a second disk will fail before the first failed disk is repaired is greater and that wall result in data loss. . . extensions the concepts of raid have been generalized to other storage devices including arrays of tapes and even to the broadcast of data over wireless systems. when applied to arrays of tapes raid structures are able to recover data even if one of the tapes in an array is damaged. when applied to broadcast of data a block of data is split into short units and is broadcast along with a parity unit if one of the units is not received for any reason it can be reconstructed from the other units. commonly tape drive robots containing multiple tape drives will stripe data across all the drives to increase throughput and decrease backup time. . . the insarv titicin in an effort to provide betfer fasfei and less expeifisiye ohitions ge arr y ffobn pftr. uln ifce mqst other storage array thb jnsei v does not require that a set nf disks be' coh igua ed a t a specific rmd level jptfier a e h d i k iisrokeh i iiloi a mb iciaunklie l rllp isaheniapplied at the chu hklgt lev i l a disk can thus piiftic ipated n.miiiiiiple and variou s raid teyfefajas ferhiirnklefis afe usedfar multiple vaiumes. . v ! . i s ipserv al d pmiddes snapsha toy the vy pl lliowiing hpiti pledis s ts tc iii unt nc pdgs idf a giygii fits gvstlark i ai e ed i big theiiriidwnikbpiies mi. the jrt ti rei fflc systbnfi mny changes a ther goplesj ' ' . ' ? v' sh rink! fti these file systems ttieioriginal sizeisthedniy size and an y changes ceciudre copying data niadrninistiratcitvcan canfigure imserv toip'i'ovide a attiiount p phygical storage. s the htsi si ar t a afig ln ti gt ffage uinhsed disk area llpeatefltb he hml iip fe bggjhii llipinlleve! . jnithisimanneiva vgs can l t lteve that i! li asi a targe .fixt d sta .rage space ereaite'lts file systerfis there ajtd so on disks gan h .added q.f fenk ved froin th.e file system by tse re wifhbut the le systeens noticing the change t jis feature can reduce the number of drives needed by hosts or at least delay tbe purchase of disks
 . . problems with raid unfortunately raid does not always assure that data are available for the operating system and its users. a pointer to a file could be wrong for example or pointers within the file structure could be wrong. incomplete writes if not properly recovered could result in corrupt data. some other process could accidentally write over a file system's structures too. raid protects against physical rnedia errors but not other hardware and software errors. as large as the landscape of software and hardware bugs is that is how numerous are the potential perils for data on a system. the solaris zfs file system takes an innovative approach to solving these problems. it maintains internal checksums of all blocks including data and metadata. added functionality comes in the placement of the checksums. they are not kept with the block that is being checksummed. rather they are stored with the pointer to that block. consider an inode with pointers to its data. within the inode is the checksum of each block of data. if there is a problem with the data the checksum will be incorrect and the file system will knowabout it. if the data are mirrored and there is a block with a correct checksum and one with an incorrect checksum zfs will automatically update the bad block with the good one. likewise the directory entry that points to the inode has a checksum for the inode. any problem in the mode is detected when the directory is accessed. this checksumming takes places throughout all zfs structures providing a much higher level of consistency error detection and error correction than is found in raid disk sets or standard file systems. the extra overhead that is created by the checksum calculation and extra block read modify write cycles is not noticeable because the overall performance of zfs is very fast. . stable storage implementation in chapter we introduced the write ahead log which requires the availability of stable storage. by definition information residing in stable storage is never lost. to implement such storage we need to replicate the needed information on multiple storage devices usually disks with independent failure modes. we need to coordinate the writing of updates in a way that guarantees that a failure during an update will not leave all the copies in a damaged state and that when we are recovering from a failure we can force all copies to a consistent and correct value even if another failure occurs during the recovery. in this section we discuss how to meet these needs. a disk write results in one of three outcomes . successful completion. the data were written correctly on disk. . partial failure. a failure occurred in the midst of transfer so only some of the sectors were written with the new data and the sector being written during the failure may have been corrupted. . total failure. the failure occurred before the disk write started so the previous data values on the disk remain intact. whenever a failure occurs during writing of a block the system needs to detect it and invoke a recovery procedure to restore the block to a consistent chapter mass storage structure state. to do that the system must maintain two physical blocks for each logical block. an output operation is executed as follows . write the information onto the first physical block. . when the first write completes successfully write the same information onto the second physical block . declare the operation complete only after the second write completes successfully. during recovery from a failure each pair of physical blocks is examined. if both are the same and no detectable error exists then no further action is necessary. if one block contains a detectable error then we replace its contents with the value of the other block. if neither block contains a detectable error but the blocks differ in content then wre replace the content of the first block with that of the second. this recovery procedure ensures that a write to stable storage either succeeds completely or results in no change. we can extend this procedure easily to allow the use of an arbitrarily large number of copies of each block of stable storage. although having a large number of copies further reduces the probability of a failure it is usually reasonable to simulate stable storage with only two copies. the data in stable storage are guaranteed to be safe unless a failure destroys all the copies. because waiting for disk writes to complete synchronous i o is time consuming many storage arrays add nvram as a cache. since the memory is nonvolatile usually it has battery power as a backup to the unit's power it can be trusted to store the data en route to the disks. it is thus considered part of the stable storage. writes to it are much faster than to disk so performance is greatly improved
 would you buy a vcr that had inside it only one tape that you could not take out or replace? or a dvd or cd player that had one disk sealed inside? of course not. you expect to use a vcr or cd player with many relatively inexpensive tapes or disks. on a computer as well using many inexpensive cartridges with one drive lowers the overall cost. low cost is the defining characteristic of tertiary storage which we discuss in this section. . . tertiary storage devices because costis so important in practice tertiary storage is built with removable media. the most common examples are floppy disks tapes and read only write once and rewritable cds and dvds. many any other kinds of tertiarystorage devices are available as well including removable devices that store data in flash memory and interact with the computer system via a usb interface. . . . removable disks removable disks are one kind of tertiary storage. floppy disks are an example of removable magnetic disks. they are made from a thin flexible disk coated . tertiary storage structure with magnetic material and enclosed in a protective plastic case. although common floppy disks can hold only about mb similar technology is used for removable magnetic disks that hold more than gb. removable magnetic disks can be nearly as fast as hard disks although the recording surface is at greater risk of damage from scratches. a magneto optic disk is another kind of removable disk. it records data on a rigid platter coated with magnetic material but the recording technology is quite different from that for a magnetic disk. the magneto optic head flies much farther from the disk surface than a magnetic disk head does and the magnetic material is covered with a thick protective layer of plastic or glass. this arrangement makes the disk much more resistant to head crashes. the drive has a coil that produces a magnetic field at room temperature the field is too large and too weak to magnetize a bit on the disk. to write a bit the disk head flashes a laser beam at the disk surface. the laser is aimed at a tiny spot where a bit is to be written. the laser heats this spot which makes the spot susceptible to the magnetic field. now the large weak magnetic field can record a tiny bit. the magneto optic head is too far from the disk surface to read the data bydetecting the tiny magnetic fields in the way that the head of a hard disk does. instead the drive reads a bit using a property of laser light called the kerr effect. when a laser beam is bounced off of a magnetic spot the polarization of the laser beam is rotated clockwise or counterclockwise depending on the orientation of the magnetic field. this rotation is what the head detects to read a bit. another category of removable disk is the optical disk. optical disks do not use magnetism at all. instead they use special materials that can be altered by laser light to have relatively dark or bright spots. one example of optical disk technology is the phase change disk which is is coated with a material that can freeze into either a crystalline or an amorphous state. the crystalline state is more transparent and hence a laser beam is brighter when it passes through the material and bounces off the reflective layer. the phase change drive uses laser light at three different powers low power to read data medium power to erase the disk by melting and refreezing the recording medium into the crystalline state and high power to melt the medium into the amorphous state to write to the disk. the most common examples of this technology are the re recordable cd rw and dvd rw. the kinds of disks just described can be used over and over. they are called read write disks. in contrast write once read many times worm disks can be written only once. an old way to make a worm disk is to manufacture a thin aluminum film sandwiched between two glass or plastic platters. to write a bit the drive uses a laser light to burn a small hole through the aluminum . this burning cannot be reversed. although it is possible to destroy the information on a worm disk by burning holes everywhere it is virtually impossible to alter data on the disk because holes can only be added and the ecc code associated with each sector is likely to detect such additions. wortvl disks are considered durable and reliable because the metal layer is safely encapsulated between the protective glass or plastic platters and magnetic fields cannot damage the recording. a newer write once technology records on an organic polymer dye instead of an aluminum layer the dye absorbs laser light to form marks. this technology is used in the recordable cd r and dvd r. chapter mass storage structure read only disks such as cd rom and dvd rom come from the factory with the data prerecorded. they use technology similar to that of worm disks although the bits are pressed not burned and they are very durable. most removable disks are slower than their nonremovable counterparts. the writing process is slower as are rotation and sometimes seek time. . . . tapes magnetic tape is another type of removable medium. as a general rule a tape holds more data than an optical or magnetic disk cartridge. tape drives and . disk drives have similar transfer rates. but random access to tape is much slower than a disk seek because it requires a fast forward or rewind operation that takes tens of seconds or even minutes. although a typical tape drive is more expensive than a typical disk drive the price of a tape cartridge is lower than the price of the equivalent capacity of magnetic disks. so tape is an economical medium for purposes that do not require fast random access. tapes are commonly used to hold backup copies of disk data. they are also used in large supercomputer centers to hold the enormous volumes of data used in scientific research and by large commercial enterprises. large tape installations typically use robotic tape changers that move tapes between tape drives and storage slots in a tape library. these mechanisms give the computer automated access to many tape cartridges. a robotic tape library can lower the overall cost of data storage. a diskresident file that will not be neecied for a while can be archived to tape where the cost per gigabyte is lower if the file is needed in the future the computer can stage it back into disk storage for active use. a robotic tape library is sometimes called near line storage since it is between the high performance of on line magnetic disks and the low cost of off line tapes sitting on shelves in a storage room. . . . future technology in the future other storage technologies may become important. one promising storage technology holographic storage uses laser light to record holographic photographs on special media. we can think of a hologram as a three dimensional array of pixels. each pixel represents one bit for black or for white. and all the pixels in a hologram are transferred in one flash of laser light so the data transfer rate is extremely high. with continued development holographic storage may become commercially viable. another storage technology under active research is based on microelectronic mechanical systems mems . the idea is to apply the fabrication technologies that produce electronic chips to the manufacture of small datastorage machines. one proposal calls for the fabrication of an array of tiny disk heads with a square centimeter of magnetic storage material suspended above the array. when the storage material is moved lengthwise over the heads each head accesses its own linear track of data on the material. the storage material can be shifted sideways slightly to enable all the heads to access their next track. although it remains to be seen whether this technology can be successful it may provide a nonvolatile data storage technology that is faster than magnetic disk and cheaper than semiconductor dram. . tertiary storage structure whether the storage medium is a removable magnetic disk a dvd or a magnetic tape the operating system needs to provide several capabilities to use removable media for data storage. these capabilities are discussed in section . . . . . operating system support two major jobs of an operating system are to manage physical devices and to present a virtual machine abstraction to applications. in this chapter we have seen that for hard disks the operating system provides two abstractions. one is the raw device which is just an array of data blocks. the other is a file system. for a file system on a magnetic disk the operating system queues and schedules the interleaved requests from several applications. now we shall see how the operating system does its job when the storage media are removable. . . . application interface most operating systems can handle removable disks almost exactly as they do fixed disks. when a blank cartridge is inserted into the drive or mounted the cartridge must be formatted and then an empty file system is generated on the disk. this file system is used just like a file system on a hard disk. tapes are often handled differently. the operating system usually presents a tape as a raw storage medium. an application does not open a file on the tape it opens the whole tape drive as a raw device. usually the tape drive then is reserved for the exclusive use of that application until the application exits or closes the tape device. this exclusivity makes sense because random access on a tape can take tens of seconds or even a few minutes so interleaving random accesses to tapes from more than one application would be likely to cause thrashing. when the tape drive is presented as a raw device the operating system does not provide file system services. the application must decide how to use the array of blocks. for instance a program that backs up a hard disk to tape might store a list of file names and sizes at the beginning of the tape and then copy the data of the files to the tape in that order. it is easy to see the problems that can arise from this wray of using tape. since every application makes up its own. rules for how to organize a tape a tape full of data can generally be used by only the program that created it. for instance even if we know that a backup tape contains a list of file names and file sizes followed by the file data in that order we still would find it difficult to use the tape. how exactly are the file names stored? are the file sizes in binary or in ascii? are the files written one per block or are they all concatenated together in one tremendously long string of bytes? we do not even knowr the block size on the tape because this variable is generally one that can be chosen separately for each block written. for a disk drive the basic operations are r e a d o w r i t e o and seek . tape drives have a different set of basic operations. instead of seekq a tape drive uses the locate operation. the tape locate operation is more precise than the disk seek operation because it positions the tape to a specific logical block rather than an entire track. locating to block is the same as rewinding the tape. chapter mass storage structure for most kinds of tape drives it is possible to locate to any block that has been written on a tape. in a partly filled tape however it is not possible to locate into the empty space beyond the written area because most tape drives do not manage their physical space in the same way disk drives do. for a disk drive the sectors have a fixed size and the formatting process must be used to place empty sectors in their final positions before any data can be written. most tape drives have a variable block size and the size of each block is determined on the fly when that block is written. if an area of defective tape is encountered during writing the bad area is skipped and the block is written again. this operation explains why it is not possible to locate into the empty space beyond the written area the positions and numbers of the logical blocks have not yet been determined. most tape drives have a read position operation that returns the logical block number where the tape head is. many tape drives also support a space operation for relative motion. so for example the operation space would locate backward over two logical blocks. for most kinds of tape drives writing a block has the side effect of logically erasing everything beyond the position of the write. in practice this side effect means that most tape drives are append only devices because updating a block in the middle of the tape also effectively erases everything beyond that block. the tape drive implements this appending by placing an end of tape eot mark after a block that is written. the drive refuses to locate past the eot mark but it is possible to locate to the eot and then start writing. doing so overwrites the old eot mark and places a new one at the end of the new blocks just written. in principle a file system can be implemented on a tape. but many of the file system data structures and algorithms would be different from those used for disks because of the append only property of tape. . . . file naming another question that the operating system needs to handle is how to name files on removable media. for a fixed disk naming is not difficult. on a pc the file name consists of a drive letter followed by a path name. in unix the file name does not contain a drive letter but the mount table enables the operating system to discover on what drive the file is located. if the disk is removable however knowing what drive contained the cartridge at some time in the past does not mean knowing how to find the file. if every removable cartridge in the world had a different serial number the name of a file on a removable device could be prefixed with the serial number but to ensure that no two serial numbers are the same would require each one to be about digits in length. who could remember the names of her files if she had to memorize a digit serial number for each one? the problem becomes even more difficult when we want to write data on a removable cartridge on one computer and then use the cartridge in another computer. if both machines are of the same type and have the same kind of removable drive the only difficulty is knowing the contents and data layout on the cartridge. but if the machines or drives are different many additional problems can arise. even if the drives are compatible different . tertiary storage structure computers may store bytes in different orders and may use different encodings for binary numbers and even for letters such as ascii on pcs versus ebcdic on mainframes . today's operating systems generally leave the name space problem unsolved for removable media and depend on applications and users to figure out how to access and interpret the data. fortunately a few kinds of removable .media are so well standardized that all computers use them the same way. one example is the cd. music cds use a universal format that is understood by any cd drive. data cds are available in only a few different formats so it is usual for a cd drive and the operating system device driver to be programmed to handle all the common formats. dvd formats are also well standardized. . . . hierarchical storage management a robotic jukebox enables the computer to change the removable cartridge in a tape or disk drive without human assistance. two major uses of this technology are for backups and hierarchical storage systems. the use of a jukebox for backups is simple when one cartridge becomes full the computer instructs the jukebox to switch to the next cartridge. some jukeboxes hold tens of drives and thousands of cartridges with robotic arms managing the movement of tapes to the drives. a hierarchical storage system extends the storage hierarchy beyond primary memory and secondary storage that is magnetic disk to incorporate tertiary storage. tertiary storage is usually implemented as a jukebox of tapes or removable disks. this level of the storage hierarchy is larger cheaper and slower. although the virtual memory system can be extended in a straightforward manner to tertiary storage this extension is rarely carried out in practice. the reason is that a retrieval from a jukebox can take tens of seconds or even minutes and such a long delay is intolerable for demand paging and for other forms of virtual memory use. the usual way to incorporate tertiary storage is to extend the file system. small and frequently used files remain on magnetic disk while large and old files that are not actively used are archived to the jukebox. in some file archiving systems the directory entry for the file continues to exist but the contents of the file no longer occupy space in secondary storage. if an application tries to open the file the openc system call is suspended until the file contents can be staged in from tertiary storage. when the contents are again available from magnetic disk the open operation returns control to the application which proceeds to use the disk resident copy of the data. today hierarchical storage management hsm is usually found in installations that have large volumes of data that are used seldom sporadically or periodically. current work in hsm includes extending it to provide full information life cycle management ilm . here data move from disk to tape and back to disk as needed but are deleted on a schedule or according to policy. for example some sites save e mail for seven years but want to be sure that at the end oi seven years it is destroyed. at that point the data could be on disk hsm tape and backup tape. ilm centralizes knowledge of where the data are so that policies can be applied across all these locations. chapter mass storage structure . . performance issues as with any component of the operating system the three most important aspects of tertiary storage performance are speed reliability and cost. . . . speed the speed of tertiary storage has two aspects bandwidth and latency. we measure the bandwidth in bytes per second. the sustained bandwidth is the average data rate during a large transfer that is the number of bytes divided by the transfer time. the effective bandwidth calculates the average over the entire i o time including the time for seekq or locate and any cartridgeswitching time in a jukebox. in essence the sustained bandwidth is the data rate when the data stream is actually flowing and the effective bandwidth is the overall data rate provided by the drive. the bandwidth ofa drive is generally understood to mean the sustained bandwidth. for removable disks the bandwidth ranges from a few megabytes per second for the slowest to over mb per second for the fastest. tapes have a similar range of bandwidths from a few megabytes per second to over mb per second. the second aspect of speed is the access latency. by this performance measure disks are much faster than tapes disk storage is essentially twodimensional all the bits are out in the open. a disk access simply moves the arm to the selected cylinder and waits for the rotational latency which may take less than milliseconds. by contrast tape storage is three dimensional. at any time a small portion of the tape is accessible to the head whereas most of the bits are buried below hundreds or thousands of layers of tape wound on the reel. a random access on tape requires winding the tape reels until the selected block reaches the tape head which can take tens or hundreds of seconds. so we can generally say that random access within a tape cartridge is more than a thousand times slower than random access on disk. if a jukebox is involved the access latency can be significantly higher. for a removable disk to be changed the drive must stop spinning then the robotic arm must switch the disk cartridges and then the drive must spin up the new cartridge. this operation takes several seconds about a hundred times longer than the random access time within one disk. so switching disks in a jukebox incurs a relatively high performance penalty. for tapes the robotic arm time is about the same as for disk. but for tapes to be switched the old tape generally must rewind before it can be ejected and that operation can take as long as minutes. and after a new tape is loaded into the drive many seconds can be required for the drive to calibrate itself to the tape and to prepare for i o. although a slow tape jukebox can have a tape switch time of or minutes this time is not enormously greater than the random access time within one tape. so to generalize we say that random access in a disk jukebox has a latency of tens of seconds whereas random access in a tape jukebox has a latency of hundreds of seconds switching tapes is expensive but switching disks is not. be careful not to overgeneralize though some expensive tape jukeboxes can rewind eject load a new tape and fast forward to a random item of data all in less than seconds. . tertiary storage structure if we pay attention to only the performance of the drives in a jukebox the bandwidth and latency seem reasonable. but if we focus our attention on the cartridges instead we find a terrible bottleneck. consider first the bandwidth. the bandwidth to storage capacity ratio of a robotic library is much less favorable than that of a fixed disk. to read all the data stored on a large hard disk could take about an hour. to read all the data stored in a large tape library could take years. the situation with respect to access latency is nearly as bad. to illustrate this if requests are queued for a disk drive the average waiting time will be about a second. if requests are queued for a tape library the average waiting time could be over an hour. the lowcost of tertiary storage results from having many cheap cartridges share a few expensive drives. but a removable library is best devoted to the storage of infrequently used data because the library can satisfy only a relatively small number of i o requests per hour. . . . reliability although we often think good performance means high speed another important aspect of performance is reliability. if we try to read some data and are unable to do so because of a drive or media failure for all practical purposes the access time is infinitely long and the bandwidth is infinitely small. so it is important to understand the reliability of removable media. removable magnetic disks are somewhat less reliable than are fixed hard disks because the cartridge is more likely to be exposed to harmful environmental conditions such as dust large changes in temperature and humidity and mechanical forces such as shock and bending. optical disks are considered very reliable because the layer that stores the bits is protected by a transparent plastic or glass layer. the reliability of magnetic tape varies widely depending on the kind of drive. some inexpensive drives wear out tapes after a few dozen uses other kinds are gentle enough to allow millions of reuses. by comparison with a magnetic disk head the head in a magnetic tape drive is a weak spot. a disk head flies above the media but a tape head is in close contact with the tape. the scrubbing action of the tape can wear out the head after a few thousands or tens of thousands of hours. in summary we say that a fixed disk drive is likely to be more reliable than a removable disk or tape drive and an optical disk is likely to be more reliable than a magnetic disk or tape. but a fixed magnetic disk has one weakness. a head crash in a hard disk generally destroys the data whereas the failure of a tape drive or optical disk drive often leaves the data cartridge unharmed. . . . cost storage cost is another important factor. here is a concrete example of how removable media may lower the overall storage cost. suppose that a hard disk that holds x gb has a price of of this amount is for the housing motor and controller and is for the magnetic platters. the storage cost for this disk is x per gigabyte. now suppose that we can manufacture the platters in a removable cartridge. for one drive and cartridges the total price is and the capacity is x gb so the storage cost is x per gigabyte. even if it is a little more expensive to make a removable cartridge chapter mass storage structure mb s s year figure . price per megabyte of dram from to . the cost per gigabyte of removable storage may well be lower than the cost per gigabyte of a hard disk because the expense of one drive is averaged with the low price of many removable cartridges. figures . . and . show the cost trends per megabyte for dram memory magnetic hard disks and tape drives. the prices in the graphs are the lowest prices found in advertisements in various computer magazines and on the world wide web at the end of each year. these prices reflect the smallcomputer marketplace of the readership of these magazines where prices are low by comparison with the mainframe and minicomputer markets. in the case of tape the price is for a drive with one tape. the overall cost of tape storage becomes much lower as more tapes are purchased for use with the drive because the price of a tape is a small fraction of the price of the drive. however in a huge tape library containing thousands of cartridges the storage year figure . price per megabyte of magnetic hard disk from to . . tertiary storage structure . gb year figure . price per megabyte of a tape drive from to . cost is dominated by the cost of the tape cartridges. as of this writing in the cost per gb of tape cartridges can be approximated as somewhat less than . the cost of dram fluctuates widely. in the period from to we can see three price crashes around and as excess production caused a glut in the marketplace. we can also see two periods around and where shortages in the marketplace caused significant price increases. in the case of hard disks the price decline has been much steadier although it appears to have accelerated since . tape drive prices also fell steadily up to . since the price per gigabyte of inexpensive tape drives has ceased its dramatic fall although the price of mid range tape technology such as dat dds has continued to fall and is now approaching that of the inexpensive drives. tape drive prices are not shown prior to because as mentioned the magazines used in tracking prices are targeted to the small computer marketplace and tape drives were not widely used with small computers prior to . we can see from these graphs that the cost of storage has fallen dramatically over the past twenty years or so. by comparing the graphs we can also see that the price of disk storage has plummeted relative to the price of dram and tape. the price per megabyte of magnetic disk has improved by more than four orders of magnitude during the past two decades whereas the corresponding improvement for main memory has been only three orders of magnitude. main memory today is more expensive than disk storage by a factor of . the price per megabyte has dropped much more rapidly for disk drives than for tape drives as well. in fact the price per megabyte of a magnetic disk drive is approaching that of a tape cartridge without the tape drive. consequently small and medium sized tape libraries have a higher storage cost than disk systems with equivalent capacity. the dramatic fall in disk prices has largely rendered tertiary storage obsolete we no longer have any tertiary storage technology that is orders of magnitude less expensive than magnetic disk. it appears that the revival chapter mass storage structure of tertiary storage must await a revolutionary technology breakthrough. meanwhile tape storage will find its use mostly limited to purposes such as backups of disk drives and archival storage in enormous tape libraries that greatly exceed the practical storage capacity of large disk farms
 the control of devices connected to the computer is a major concern of operating system designers. because i o devices vary so widely in their function and speed consider a mouse a hard disk and a cd rom jukebox varied methods are needed to control them. these methods form the i o subsystem of the kernel which separates the rest of the kernel from the complexities of managing i o devices. chapter i o systems i o device technology exhibits two conflicting trends. on one hand we see increasing standardization of software and hardware interfaces. this trend helps us to incorporate improved device generations into existing computers and operating systems. on the other hand we see an increasingly broad variety of i o devices. some new devices are so unlike previous devices that it is a challenge to incorporate them into our computers and operating systems. this challenge is met by a combination of hardware and software techniques. the basic i o hardware elements such as ports buses and device controllers accommodate a wide variety of i o devices. to encapsulate the details and oddities of different devices the kernel of an operating system is structured to use device driver modules. the device drivers present a uniform deviceaccess interface to the i o subsystem much as system calls provide a standard interface between the application and the operating system. . i o hardware computers operate a great many kinds of devices. most fit into the general categories of storage devices disks tapes transmission devices network cards modems and human interface devices screen keyboard mouse . other devices are more specialized such as the steering of a military fighter jet or a space shuttle. in these aircraft a human gives input to the flight computer via a joystick and foot pedals and the computer sends output commands that cause motors to move rudders flaps and thrusters. despite the incredible variety of i o devices though we need only a few concepts to understand how the devices are attached and how the software can control the hardware. a device communicates with a computer system by sending signals over a cable or even through the air. the device communicates with the machine via a connection point or port for example a serial port. if devices use a common set of wires the connection is called a bus. a bus is a set of wires and a rigidly defined protocol that specifies a set of messages that can be sent on the wires. in terms of the electronics the messages are conveyed by patterns of electrical voltages applied to the wires with defined timings. when device a has a cable that plugs into device b and device b has a cable that plugs into device c and device c plugs into a port on the computer this arrangement is called a daisy chain. a daisy chain usually operates as a bus. buses are used widely in computer architecture. a typical pc bus structure appears in figure . . this figure shows a pci bus the common pc system bus that connects the processor memory subsystem to the fast devices and an expansion bus that connects relatively slow devices such as the keyboard and serial and parallel ports. in the upper right portion of the figure four disks are connected together on a scsi bus plugged into a scsi controller. a controller is a collection of electronics that can operate a port a bus or a device. a serial port controller is a simple device controller. it is a single chip or portion of a chip in the computer that controls the signals on the wires of a serial port. by contrast a scsi bus controller is not simple. because the scsi protocol is complex the scsi bus controller is often implemented as a separate circuit board or a host adapter that plugs into the computer. it typically contains a processor microcode and some private memory to enable it to process the scsi protocol messages. some devices have their own built in . i o hardware monitor process '! ' cache grapriscs 'h nernory scsi cont oller controller pc! bus ide disk control'er expansion bus keyboard interlace expansion bus parallel serial port port figure . a typical pc bus structure. controllers. if you look at a disk drive you will see a circuit board attached to one side. this board is the disk controller. it implements the disk side of the protocol for some kind of connection scsi or ata for instance. tt has microcode and a processor to do many tasks such as bad sector mapping prefetching buffering a n c caching. how can the processor give commands and data to a controller to accomplish an i o transfer? the short answer is that the controller has one or more registers for data and control signals. the processor communicates with the controller by reading and writing bit patterns in these registers. one way in which this communication can occur is through the use of special i o instructions that specify the transfer of a byte or word to an i o port address. the i o instruction triggers bus lines to select the proper device and to move bits into or out of a device register. alternatively the device controller can support memory mapped i o. in this case the device control registers are mapped into the address space of the processor. the cpu executes i o requests using the standard data transfer instructions to read and write the device control registers. some systems use both techniques. for instance pcs use i o instructions to control some devices and memory mapped i o to control others. figure . shows the usual t o port addresses for pcs. the graphics controller has i o ports for basic control operations but the controller has a large memorymapped region to hold screen contents. the process sends output to the screen by writing data into the memory mapped region. the controller generates the screen image based on the contents of this memory this technique is simple to use. moreover writing millions of bytes to the graphics memory is faster than issuing millions of i o instructions. but the ease of writing chapter i o systems issrange fr !i! iii !i! iii !i! i! iii i i pft iii.ili ii i!i t u i i . i .. ! . . '.. itt i j. . r i i i ''j ' ' ' ' ' ' ' ' ' . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . f . . . . ... . . . . . . .. . . . .. . ! ! . gf f . . j ji . tiillill l.i l l .li . lllss!illil f. mi lii !i! iii iii iii i ?s f i i i i i hi. i lalffdff if . lui l iiti f ! i i f f f f i ''! ' ! . '. ' . . . . . . . . . . . . . . . . ii! ! . !ih . !i serial p o tft eftrwy mn ' ' figure . device i o port locations on pcs partial . to a memory mapped i o controller is offset by a disadvantage. because a common type of software fault is a write through an incorrect pointer to an unintended region of memory a memory mapped device register is vulnerable to accidental modification. of course protected memory helps to reduce this risk. an i o port typically consists of four registers called the status control data in and data out registers. the data in register is read by the host to get input. the data out register is written by the host to send output. the status register contains bits that can be read by the host. these bits indicate states such as whether the current command has completed whether a byte is available to be read from the data in register and whether a device error has occurred. the control register can be written by the host to start a command or to change the mode of a device. for instance a certain bit in the control register of a serial port chooses between full duplex and half duplex communication another bit enables parity checking a third bit sets the word length to or bits and other bits select one of the speeds supported by the serial port. the data registers are typically to bytes in size. some controllers have fifo chips that can hold several bytes of input or output data to expand the capacity of the controller beyond the size of the data register. a fifo chip can hold a small burst of data until the device or host is able to receive those data. . . polling the complete protocol for interaction between the host and a controller can be intricate but the basic handshaking notion is simple. we explain handshaking . i o hardware with an example. we assume that bits are used to coordinate the producer consumer relationship between the controller and the host. the controller indicates its state through the busy bit in the status register. recall that to set a bit means to write a into the bit and to clear a bit means to write a into it. the controller sets the busy bit when it is busy working and clears the busy bit when it is ready to accept the next command. the host signals its wishes via the command ready bit in the command register. the host sets the command ready bit when a command is available for the controller to execute. for this example the host writes output through a port coordinating with the controller by handshaking as follows. . the host repeatedly reads the busy bit until that bit becomes clear. . the host sets the write bit in the command register and writes a byte into the data out register. . the host sets the command ready bit. . when the controller notices that the command ready bit is set it sets the busy bit. . the controller reads the command register and sees the write command. it reads the data out register to get the byte and does the i o to the device. . the controller clears the command ready bit clears the error bit in the status register to indicate that the device i o succeeded and clears the busy bit to indicate that it is finished. this loop is repeated for each byte. tn step the host is busy waiting or polling it is in a loop reading the status register over and over until the busy bit becomes clear f the controller and device are fast this method is a reasonable one. but if the wait may be long the host should probably swritch to another task. how then does the host know when the controller has become idle? for some devices the host must service the device quickly or data will be lost. for instance when data are streaming in on a serial port or from a keyboard the small buffer on the controller will overflow and data will be lost if the host waits too long before returning to read the bytes. in many computer architectures three cpu instruction cycles are sufficient to poll a device read a device register logical arid to extract a status bit and branch if not zero. clearly the basic polling operation is efficient. but polling becomes inefficient when it is attempted repeatedly yet rarely finds a device to be ready for service while other useful cpu processing remains undone. in such instances it may be more efficient to arrange for the hardware controller to notify the cpu when the device becomes ready for service rather than to require the cpu to poll repeatedly for an i o completion. the hardware mechanism that enables a device to notify the cpu is called an interrupt. . . interrupts the basic interrupt mechanism works as follows. the cpu hardware has a wire called the interrupt request line that the cpu senses after executing every instruction. when the cpu detects that a controller has asserted a signal on the chapter i o systems cpu i o controller device driver initiates i o cpu executing checks for interrupts between instructions mm i i transfers aorttrotm i tmm.. ! gemrates m . .! . .. .. .j.j l . inferruptihariaitfr . . i u prioi ess idatg ii it v ! i . . ' . cpu resumes processing of interrupted task figure . interrupt driven i o cycle. interrupt request line the cpu performs a state save and jumps to the interrupthandler routine at a fixed address in memory. the interrupt handler determines the cause of the interrupt performs the necessary processing performs a state restore and executes a return from interrupt instruction to return the cpu to the execution state prior to the interrupt. we say that the device controller raises an interrupt by asserting a signal on the interrupt request line the cpu catches the interrupt and dispatches it to the interrupt handler and the handler clears the interrupt by servicing the device. figure summarizes the interrupt driven i o cycle. this basic interrupt mechanism enables the cpu to respond to an asynchronous event as when a device controller becomes ready for service. in a modern operating system however we need more sophisticated interrupthandling features. . we need the ability to defer interrupt handling during critical processing. . we need an efficient way to dispatch to the proper interrupt handler for a device without first polling all the devices to see which one raised the interrupt. . i o hardware . we need multilevel interrupts so that the operating system can.distinguish between high and low priority interrupts and can respond with the appropriate degree of urgency. in modern computer hardware these three features are provided by the cpu and by the interrupt controller hardware. most cpus have two interrupt request lines. one is the nonmaskable interrupt which is reserved for events such as unrecoverable memory errors. the second interrupt line is maskable it can be turned off by the cpu before the execution of critical instruction sequences that must not be interrupted. the maskable interrupt is used by device controllers to request service. the interrupt mechanism accepts an address a number that selects a specific interrupt handling routine from a small set. in most architectures this address is an offset in a table called the interrupt vector. this vector contains the memory addresses of specialized interrupt handlers. the purpose of a vectored interrupt mechanism is to reduce the need for a single interrupt handler to search all possible sources of interrupts to determine which one needs service. in practice however computers have more devices and hence interrupt handlers than they have address elements in the interrupt vector. a common way to solve this problem is to use the technique of interrupt chaining in which each element in the interrupt vector points to the head of a list of interrupt handlers. when an interrupt is raised the handlers on the corresponding list are called one by one until one is found that can service the request. this structure is a compromise between the overhead of a huge interrupt table and the inefficiency of dispatching to a single interrupt handler. figure . illustrates the design of the interrupt vector for the intel pentium processor. the events from to which are nonmaskable are used to signal various error conditions. the events from to which are maskable are used for purposes such as device generated interrupts. the interrupt mechanism also implements a system of interrupt priority levels. this mechanism enables the cpu to defer the handling of low priority interrupts without masking off all interrupts and makes it possible for a high priority interrupt to preempt the execution of a low priority interrupt. a modern operating system interacts with the interrupt mechanism in several ways. at boot time the operating system probes the hardware buses to determine what devices are present and installs the corresponding interrupt handlers into the interrupt vector. during i o the various device controllers raise interrupts when they are ready for service. these interrupts signify that output has completed or that input data are available or that a failure has been detected. the interrupt mechanism is also used to handle a wide variety of exceptions such as dividing by zero accessing a protected or nonexistent memory address or attempting to execute a privileged instruction from user mode. the events that trigger interrupts have a common property they are occurrences that induce the cpu to execute an urgent self contained routine. an operating system has other good uses for an efficient hardware and software mechanism that saves a small amount of processor state and then calls a privileged routine in the kernel. for example many operating systems use the interrupt mechanism for virtual memory paging. a page fault is an exception that raises an interrupt. the interrupt suspends the current process and jumps to the page fault handler in the kernel. this handler saves the state chapter i o systems vector number . ... . . descspiwi . j q v . ciivide error. . . . . ' . . . . . . . . . . rti'ii ih'fj'i'fii' . . i i ib l c . f ' ' .j i . . . . . . . . . . . . . . ' . . . . . . . . . . ! . . r . ' ' ' ' ' ' ' fergakpoigt . i . . i i ' 'il ' i ! ilsi t cieteq!e qverlfaw i i ' i . v i . ' .'. i. i i . ' i boprid iraingf bxeepfiort ! . . i i i 'i i . v it i i i i i . elsweelnqt gvltladle i i ! i . . i i '. ' i cnprocbssgr segraefitlpvenrun eresgruee r mi ii iwafid task st ts!segment i ' ' ' ' . aegrne ht r iqt gras?nt ' v ' . ' ' . '. . . . . . . . j j.. . .. .... stapfcfault.. .'. . . . ....... . . i . .. . gb ara pfojeetim . . e . . . . e e e . e ' page fault ... ' injejiressryeci.dqnot.usb iloa'irigrppintbrror . ' i . . giignment check . . machine check infefteserved do not use maskable interrupts figure . intel pentium processor event vector table. of the process moves the process to the wait queue performs page cache management schedules an i o operation to fetch the page schedules another process to resume execution and then returns from the interrupt. another example is found in the implementation of system calls. usually a program uses library calls to issue system calls. the library routines check the arguments given by the application build a data structure to convey the arguments to the kernel and then execute a special instruction called a software interrupt or a trap . this instruction has an operand that identifies the desired kernel service. when a process executes the trap instruction the interrupt hardware saves the state of the user code switches to supervisor mode and dispatches to the kernel routine that implements the requested service. the trap is given a relatively low interrupt priority compared with those assigned to device interrupts executing a system call on behalf of an application is less urgent than servicing a device controller before its fifo queue overflows and loses data. interrupts can also be used to manage the flow of control within the kernel. for example consider the processing required to complete a disk read. one step is to copy data from kernel space to the user buffer. this copying is time consuming but not urgent it should not block other high priority interrupt handling. another step is to start the next pending i o for that disk drive. this step has higher priority if the disks are to be used efficiently we need to start the next i o as soon as the previous one completes. consequently a pair of interrupt handlers implements the kernel code that completes a disk read. the . i o hardware high priority handler records the i o status clears the device interrupt.starts the next pending i o and raises a low priority interrupt to complete the work. later when the cpu is not occupied with high priority work the low priority interrupt will be dispatched. the corresponding handler completes the userlevel i o by copying data from kernel buffers to the application space and then calling the scheduler to place the application on the ready queue. a threaded kernel architecture is well suited to implement multiple interrupt priorities and to enforce the precedence of interrupt handling over background processing in kernel and application routines. we illustrate this point with the solaris kernel in solaris interrupt handlers are executed as kernel threads. a range of high priorities is reserved for these threads. these priorities give interrupt handlers precedence over application code and kernel housekeeping and implement the priority relationships among interrupt handlers. the priorities cause the solaris thread scheduler to preempt lowpriority interrupt handlers in favor of higher priority ones and the threaded implementation enables multiprocessor hardware to run several interrupt handlers concurrently. we describe the interrupt architecture of unix and windows xp in appendices a and respectively. in summary interrupts are used throughout modern operating systems to handle asynchronous events and to trap to supervisor mode routines in the kernel. to enable the most urgent work to be done first modern computers use a system of interrupt priorities. device controllers hardware faults and system calls all raise interrupts to trigger kernel routines. because interrupts are used so heavily for time sensitive processing efficient interrupt handling is required for good system performance. . . direct memory access for a device that does large transfers such as a disk drive it seems wasteful to use an expensive general purpose processor to watch status bits and to feed data into a controller register one byte at a time a process termed programmed i o pio . many computers avoid burdening the main cpu with pio by offloading some of this work to a special purpose processor called a direct memory access dma controller. to initiate a dma transfer the host writes a dma command block into memory. this block contains a pointer to the source of a transfer a pointer to the destination of the transfer and a count of the number of bytes to be transferred. the cpu writes the address of this command block to the dma controller then goes on with other work. the dma controller proceeds to operate the memory bus directly placing addresses on the bus to perform transfers without the help of the main cpu. a simple dma controller is a standard component in pcs and bus mastering i o boards for the pc usually contain their own high speed dma hardware. handshaking between the dma controller and the device controller is performed via a pair of wires called dma request and dma acknowledge. the device controller places a signal on the dma request wire when a word of data is available for transfer. this signal causes the dma controller to seize the memory bus to place the desired address on the memory address wires and to place a signal on the dma acknowledge wire. when the device controller receives the dma acknowledge signal it transfers the w ord of data to memory and removes the dma request signal. chapter i o systems . device driver is told to transfer disk data to buffer at address x . dma controller . device driver teiis transfers bytes to disk controller to buffer x increasing transfer c bytes memory address from disk to buffer and decreasing c at address x until c . when c dma i cp . tsemofv 'jo interrupts cpu to signal d transfer completion pci ens . disk controller initiates dma transfer . disk controller sends each byte to dma controller figure . steps in a dma transfer. when the entire transfer is finished the dma controller interrupts the cpu. this process is depicted in figure . . when the dma controller seizes the memory bus the cpu is momentarily prevented from accessing main memory although it can still access data items in its primary and secondary caches. although this cycle stealing can slow down the cpu computation offloading the data transfer work to a. dma controller generally improves the total system performance. some computer architectures use physical memory addresses for dma but others perform direct virtual memory access dvma using virtual addresses that undergo translation to physical addresses. dvma can perform a transfer between two memory mapped devices without the intervention of the cpu or the use of main memory. on protected mode kernels the operating system generally prevents processes from issuing device commands directly. this discipline protects data from access control violations and also protects the system from erroneous use of device controllers that could cause a system crash. instead the operating system exports functions that a sufficiently privileged process can use to access low level operations on the underlying hardware. on kernels without memory protection processes can access device controllers directly. this direct access can be used to obtain high performance since it can avoid kernel communication context switches and layers of kernel software. unfortunately it interferes with system security and stability. the trend in general purpose operating systems is to protect memory and devices so that the system can try to guard against erroneous or malicious applications. . . i o hardware summary although the hardware aspects of i o are complex when considered at the level of detail of electronics hardware design the concepts that we have . application i o interface just described are sufficient to enable us to understand many i o features of operating systems. let's review the main concepts a bus a controller an i o port and its registers the handshaking relationship between the host and a device controller the execution of this handshaking in a polling loop or via interrupts the offloading of this work to a dma controller for large transfers we gave a basic example of the handshaking that takes place between a device controller and the host earlier in this section. in reality the wide variety of available devices poses a problem for operating system implementers. each kind of device has its own set of capabilities control bit definitions and protocols for interacting with the host and they are all different. how can the operating system be designed so that we can attach new devices to the computer without rewriting the operating system? and when the devices vary so widely how can the operating system give a convenient uniform i o interface to applications? we address those questions next. . application s o interface in this section we discuss structuring techniques and interfaces for the operating system that enable i o devices to be treated in a standard uniform way. we explain for instance how an application can open a file on a disk without knowing what kind of disk it is and how new disks and other devices can be added to a computer without disruption of the operating system. like other complex software engineering problems the approach here involves abstraction encapsulation and software layering. specifically we can abstract away the detailed differences in i o devices by identifying a fewgeneral kinds. each general kind is accessed through a standardized set of functions an interface. the differences are encapsulated in kernel modules called device drivers that internally are custom tailored to each device but that export one of the standard interfaces. figure . illustrates how the i o related portions of the kernel are structured in software layers. the purpose of the device driver layer is to hide the differences among device controllers from the i o subsystem of the kernel much as the i o system calls encapsulate the behavior of devices in a few generic classes that hide hardware differences from applications. making the i o subsystem independent of the hardware simplifies the job of the operating system developer. it also benefits the hardware manufacturers. they either design new devices to be compatible with an existing host controller interface such as scsi or they write device drivers to interface the new hardware to popular operating systems. thus we can attach new peripherals to a computer without waiting for the operating system vendor to develop support code. unfortunately for device hardware manufacturers each type of operating system has its own standards for the device driver interface. a given device chapter i o systems ibriver .silver co o jbdmcbsi ipjslbiisi iiiclrises figure . a kernel i o structure. may ship with multiple device drivers for instance drivers for ms dos windows windows nt and solaris. devices vary on many dimensions as illustrated in figure . . character stream or block. a character stream device transfers bytes one by one whereas a block device transfers a block of bytes as a unit. sequential or random access. a sequential device transfers data in a fixed order determined by the device whereas the user of a random access device can instruct the device to seek to any of the available data storage locations. synchronous or asynchronous. a synchronous device performs data transfers with predictable response times. an asynchronous device exhibits irregular or unpredictable response times. sharable or dedicated. a sharable device can be used concurrently by several processes or threads a dedicated device cannot. speed of operation. device speeds range from a few bytes per second to a few gigabytes per second. read write read only or write only. some devices perform both input and output but others support only one data direction. for the purpose of application access many of these differences are hidden by the operating system and the devices are grouped into a few conventional . application i o interface f ff m m m lpm sm. d ial i n g ! x v . . . . . . . . . . . . i i lal ngy i n i i i . l l w l l s jhi ' . m. !ij ' ' ' m tela teteeein g eratons n u . . ' o . gfaphics eo mtoiter . . . . figure . characteristics of i o devices. types. the resulting styles of device access have been found to be useful and broadly applicable. although the exact system calls may differ across operating systems the device categories are fairly standard. the major access conventions include block i o character stream i o memory mapped file access and network sockets. operating systems also provide special system calls to access a few additional devices such as a time of day clock and a timer. some operating systems provide a set of system calls for graphical display video and audio devices. most operating systems also have an escape or back door that transparently passes arbitrary commands from an application to a device driver. tn unix this system call is i o c t l o for i o control . the i o c t l o system call enables an application to access any functionality that can be implemented by any device driver without the need to invent a new system call. the i o c t l o system call has three arguments. the first is a file descriptor that connects the application to the driver by referring to a hardware device managed by that driver. the second is an integer that selects one of the commands implemented in the driver. the third is a pointer to an arbitrary data structure in memory that enables the application and driver to communicate any necessary control information or data. . . block and character devices the block device interface captures all the aspects necessary for accessing disk drives and other block oriented devices. the device is expected to understand commands such as read and wr i t e if it is a random access device it is also expected to have a seek command to specify which block to transfer next. applications normally access such a device through a file system interface. we can see that r e a d o write and seeko capture the essential behaviors chapter i o systems of block storage devices so that applications are insulated from the low level differences among those devices. the operating system itself as well as special applications such as databasemanagement systems may prefer to access a block device as a simple linear array of blocks. this mode of access is sometimes called raw i o. if the application performs its own buffering then using a file system would cause extra unneeded buffering. likewise if an application provides its own locking of file blocks or regions then any operating system locking services would be redundant at the least and contradictory at the worst. to avoid these conflicts raw device access passes control of the device directly to the application letting the operating system step out of the way. unfortunately no operating system services are then performed on this device. a compromise that is becoming common is for the operating system to allow a mode of operation on a file that disables buffering and locking. in the unix world this is called direct i o. memory mapped file access can be layered on top of block device drivers. rather than offering read and write operations a memory mapped interface provides access to disk storage via an array of bytes in main memory. the system call that maps a file into memory returns the virtual memory address that contains a copy of the file. the actual data transfers are performed only when needed to satisfy access to the memory image. because the transfers are handled by the same mechanism as that used for demand paged virtual memory access memory mapped i o is efficient. memory mapping is also convenient for programmers access to a memory mapped file is as simple as reading from and writing to memory. operating systems that offer virtual memory commonly use the mapping interface for kernel services. for instance to execute a program the operating system maps the executable into memory and then transfers control to the entry address of the executable. the mapping interface is also commonly used for kernel access to swap space on disk. a keyboard is an example of a device that is accessed through a characterstream interface. the basic system calls in this interface enable an application to get or puto one character. on top of this interface libraries can be built that offer line at a time access with buffering and editing services for example when a user types a backspace the preceding character is removed from the input stream . this style of access is convenient for input devices such as keyboards mice and modems that produce data for input spontaneously that is at times that cannot necessarily be predicted by the application. this access style is also good for output devices such as printers and audio boards which naturally fit the concept of a linear stream of bytes. . . network devices because the performance and addressing characteristics of network i o differ significantly from those of disk i o most operating systems provide a network i o interface that is different from the read w r i t e s e e k o interface used for disks. one interface available in many operating systems including unix and windows nt is the network socket interface. think of a wall socket for electricity any electrical appliance can be plugged in. by analogy the system calls in the socket interface enable an application to create a socket to connect a local socket to a remote address which plugs this application into a socket created by another application to . application i o interface listen for any remote application to plug into the local socket and to send and receive packets over the connection. to support the implementation of servers the socket interface also provides a function called s e l e c t that manages a set of sockets. a call to s e l e c t returns information about which sockets have a packet waiting to be received and which sockets have room to accept a packet to be sent. the use of s e l e c t eliminates the polling and busy waiting that would otherwise be necessary for network i o. these functions encapsulate the essential behaviors of networks greatly facilitating the creation of distributed applications that can use any underlying network hardware and protocol stack. many other approaches to interprocess communication and network communication have been implemented. for instance windows nt provides one interface to the network interface card and a second interface to the network protocols section c. . in unix which has a long history as a proving ground for network technology we find half duplex pipes full duplex fifos full duplex
 unix system v has an interesting mechanism called streams that enables an application to assemble pipelines of driver code dynamically. a stream is a full duplex connection between a device driver and a user level process. it consists of a stream head that interfaces with the user process a driver end that controls the device and zero or more stream modules between them. the stream head the driver end and each module contain a pair of queues a read queue and a write queue. message passing is used to transfer data between queues. the streams structure is shown in figure . . modules provide the functionality of streams processing they are pushed onto a stream by use of the i o c t l q system call. for example a process can. . streams modules iidrivmertdli ideviee figure . the streams structure. open a serial port device via a stream and can push on a module to handle input editing. because messages are exchanged between queues in adjacent modules a queue in one module may overflow an adjacent queue. to prevent this from occurring a queue may support flow control. without flow control a queue accepts all messages and immediately sends them on to the queue in the adjacent module without buffering them. a queue supporting flow control buffers messages and does not accept messages without sufficient buffer space this process involves exchanges of control messages between queues in adjacent modules. a user process writes data to a device using either the write or putmsgo system call. the w r i t e system call writes raw data to the stream whereas putmsgo allows the user process to specify a message. regardless of the system call used by the user process the stream head copies the data into a message and delivers it to the queue for the next module in line. this copying of messages continues until the message is copied to the driver end and hence the device. similarly the user process reads data from the stream head using either the readq or getmsgo system call. if read is used the stream head gets a message from its adjacent queue and returns ordinary data an unstructured byte stream to the process. if getmsgo is used a message is returned to the process. streams i o is asynchronous or nonblocking except when the user process communicates with the stream head. when writing to the stream the user process will block assuming the next queue uses flow control until there is room to copy the message. likewise the user process will block when reading from the stream until data are available. chapter i o systems the driver end is similar to a stream head or a module in that it has'a read and write queue. however the driver end must respond to interrupts such as one triggered when a frame is ready to be read from a network. unlike the stream head which may block if it is unable to copy a message to the next queue in line the driver end must handle all incoming data. drivers must support flow control as well. however if a device's buffer is full the device typically resorts to dropping incoming messages. consider a network card whose input buffer is full. the network card must simply drop further messages until there is ample buffer space to store incoming messages. the benefit of using streams is that it provides a framework for a modular and incremental approach to writing device drivers and network protocols. modules may be used by different streams and hence by different devices. for example a networking module may be used by both an ethernet network card and a token ring network card. furthermore rather than treating character device i o as an unstructured byte stream streams allows support for message boundaries and control information between modules. support for streams is widespread among most unix variants and it is the preferred method for writing protocols and device drivers. for example system v unix and solaris implement the socket mechanism using streams. 
 i o is a major factor in system performance. it places heavy demands on the cpu to execute device driver code and to schedule processes fairly and efficiently as they block and unblock. the resulting context switches stress the cpu and its hardware caches. i o also exposes any inefficiencies in the interrupt handling mechanisms in the kernel. in addition i o loads down the memory bus during data copy between controllers and physical memory and again during copies between kernel buffers and application data space. coping gracefully with all these demands is one of the major concerns of a computer architect. although modern computers can handle many thousands of interrupts per second interrupt handling is a relatively expensive task each interrupt causes the system to perform a state change to execute the interrupt handler and then to restore state. programmed i o can be more efficient than interrupt driven j o if the number of cycles spent in busy waiting is not excessive. an i o completion typically unblocks a process leading to the full overhead of a context switch. network traffic can also cause a high context switch rate. consider for instance a remote login from one machine to another. each character typed on the local machine must be transported to the remote machine. on the local machine the character is typed a keyboard interrupt is generated and the character is passed through the interrupt handler to the device driver to the kernel and then to the user process. the user process issues a network i o system call to send the character to the remote machine. the character then flows into the local kernel through the network layers that construct a network packet and into the network device driver. the network device driver transfers the packet to the network controller which sends the character and generates an interrupt. the interrupt is passed back up through the kernel to cause the network i o system call to complete. . performance now the remote system's network hardware receives the packet and an interrupt is generated. the character is unpacked from the network protocols and is given to the appropriate network daemon. the network daemon. identifies which remote login session is involved and passes the packet to the appropriate subdaemon for that session. throughout this flow there are context switches and state switches figure . . usually the receiver echoes the character back to the sender that approach doubles the work. to eliminate the context switches involved in moving each character between daemons and the kernel the solaris developers reimplemented the telnet daemon using in kernel threads. sun estimates that this improvement increased the maximum number of network logins from a few hundred to a few thousand on a large server. other systems use separate front end processors for terminal i o to reduce the interrupt burden on the main cpu. for instance a terminal concentrator can multiplex the traffic from hundreds of remote terminals into one port on a large computer. an i o channel is a dedicated special purpose cpu found in v fyped system all packei 'contplstbs s f ! ' i interrupt iijiterrl!jp t ' generated' har 'djbd adapef . . jjj.. . . . r . v.. td! ! ijl . . !. b i! a v if? interrupt . ihteirrtipt! j ! handled generated qenefated network '. device tietifiark v drby'ef . sdspisr. j. kei ' e . o j ill . i user imnlem ketnm nrhpp ' ' sendingsystem figure . intercomputer communications. chapter i o systems mainframes and in other high end systems. the job of a channel is to offload i o work from the main cpu. the idea is that the channels keep the data flowing smoothly while the main cpu remains free to process the data. like the device controllers and dma controllers found in smaller computers a channel can process more general and sophisticated programs so channels can be tuned for particular workloads. we can employ several principles to improve the efficiency of i o reduce the number of context switches. reduce the number of times that data must be copied in memory while passing between device and application. reduce the frequency of interrupts by using large transfers smart controllers and polling if busy waiting can be minimized . increase concurrency by using dma knowledgeable controllers or channels to offload simple data copying from the cpu. move processing primitives into hardware to allow their operation in device controllers to be concurrent with cpu and bus operation. balance cpu memory subsystem bus and r o performance because an overload in any one area will cause idleness in others. devices vary greatly in complexity. for instance a mouse is simple. the mouse movements and button clicks are converted into numeric values that are passed from hardware through the mouse device driver to the application. by contrast the functionality provided by the windows nt disk device driver is complex. it not only manages individual disks but also implements raid arrays section . . to do so it converts an application's read or write request into a coordinated set of disk i o operations. moreover it implements sophisticated error handling and data recovery algorithms and takes many steps to optimize disk performance. where should the i o functionality be implemented in the device hardware in the device driver or in application software? sometimes we observe the progression depicted in figure . . initially we implement experimental i o algorithms at the application level because application code is flexible and application bugs are unlikely to cause system crashes. furthermore by developing code at the application level we avoid the need to reboot or reload device drivers after every change to the code. an application level implementation can be inefficient however because of the overhead of context switches and because the application cannot take advantage of internal kernel data structures and kernel functionality such as efficient in kerne! messaging threading and locking . when an application level algorithm has demonstrated its worth we may reimplement it in the kernel. this can improve the performance but the development effort is more challenging because an operatingsystem kernel is a large complex software system. moreover an in kernel
 j si c a. s si i i yo a de i c eofitfaller cqde hardware ! si z figure . device functionality progression implementation must be thoroughly debugged to avoid data corruption and system crashes. the highest performance may be obtained by a specialized implementation in hardware either in the device or in the controller. the disadvantages of a hardware implementation include the difficulty and expense of making further improvements or of fixing bugs the increased development time months rather than days and the decreased flexibility. for instance a hardware raid controller may not provide any means for the kernel to influence the order or location of individual block reads and writes even if the kernel has special information about the workload that would enable the kernel to improve the i o performance. . summary the basic hardware elements involved in i o are buses device controllers and the devices themselves. the work of moving data between devices and main memory is performed by the cpu as programmed i o or is offloaded to a dma controller. the kernel module that controls a device is a device driver. the system call interface provided to applications is designed to handle several basic categories of hardware including block devices character devices memory mapped files network sockets and programmed interval timers. the system calls usually block the process that issues them but nonblocking and asynchronous calls are used by the kernel itself and by applications that must not sleep while waiting for an t o operation to complete. the kernel's i o subsystem provides numerous services. among these are i o scheduling buffering caching spooling device reservation and error handling. another service name translation makes the connection between hardware devices and the symbolic file names used by applications. it involves several levels of mapping that translate from character string names to specific chapter i o systems device drivers and device addresses and then to physical addresses of l oports or bus controllers. this mapping may occur within the file system name space. as it does in unix or in a separate device name space as it does in ms dos. streams is an implementation and methodology for making drivers reusable and easy to use. through them drivers can be stacked with data passed through them sequentially and bidirectionally for processing. i o system calls are costly in terms of cpu consumption because of the many layers of software between a physical device and the application. these layers imply the overheads of context switching to cross the kernel's protection boundary of signal and interrupt handling to service the i o devices and of the load on the cpu and memory system to copy data between kernel buffers and application space. exercises . when multiple interrupts from different devices appear at about the same time a priority scheme could be used to determine the order in which the interrupts would be serviced. discuss what issues need to be considered in assigning priorities to different interrupts. . what are the advantages and disadvantages of supporting memorymapped i o to device control registers? . consider the following i o scenarios on a single user pc a. a mouse used with a graphical user interface b. a tape drive on a multitasking operating system with no device preallocation available c. a disk drive containing user files d. a graphics card with direct bus connection accessible through memory mapped i o for each of these scenarios would you design the operating system to use buffering spooling caching or a combination? would you use polled i o or interrupt driven i o? give reasons for your choices. . in most multiprogrammed systems user programs access memory through virtual addresses while the operating system uses raw physical addresses to access memory. what are the implications of this design on the initiation of i o operations by the user program and their execution by the operating system? . what are the various kinds of performance overheads associated with servicing an interrupt? . describe three circumstances under which blocking i o should be used. describe three circumstances under which nonblocking i o should be used. why not just implement nonblocking i o and have processes busv wait until their device is readv? bibliographical notes . typically at the completion of a device i o a single interrupt is raised and appropriately handled by the host processor. in certain settings however the code that is to be executed at the completion of the i o can be broken into two separate pieces one of which executes immediately after the i o completes and schedules a second interrupt for the remaining piece of code to be executed at a later time. what is the purpose of using this strategy in the design of interrupt handlers? . some dma controllers support direct virtual memory access where the targets of i o operations are specified as virtual addresses and a translation from virtual to physical address is performed during the dma. how does this design complicate the design of the dma controller? what are the advantages of providing such a functionality? . unix coordinates the activities of the kernel i o components by manipulating shared in kernel data structures whereas windows nt uses object oriented message passing between kernel i o components. discuss three pros and three cons of each approach. . write in pseudocode an implementation of virtual clocks including the queueing and management of timer requests for the kernel and applications. assume that the hardware provides three timer channels. . discuss the advantages and disadvantages of guaranteeing reliable transfer of data between modules in the streams abstraction. bibliographical notes vahalia provides a good overview of i o and networking in unix. leffler et al. detail the i o structures and methods employed in bsd unix. milenkovic discusses the complexity of i o methods and implementation. the use and programming of the various interprocesscommunication and network protocols in unix are explored in stevens . brain documents the windows t application interface. the i o implementation in the sample mln x operating system is described in tanenbaum and woodhull . custer includes detailed information on the nt message passing implementation of i o. for details of hardware level i o handling and memory mapping functionality processor reference manuals motorola and intel are among the best sources. hennessy and patterson describe multiprocessor systems and cache consistency issues. tanenbaum describes hardware i o design at a low level and sargent and shoemaker provide a programmer's guide to low level pc hardware and software. the ibm pc device i o address map is given in ibm . the march issue of ieee computer is devoted to advanced i o hardware and software. rago provides a good discussion of streams. part five
 refers to a mechanism for controlling the access of programs processes or users to the resources defined by a computer system. this mechanism must provide a means for specifying the controls to be imposed together with a means of enforcement. we distinguish between protection and security which is a measure of confidence that the integrity of a system and its data will be preserved. security assurance is a much broader topic than is protection and we address it in chapter . objectives discuss the goals and principles of protection in a modern computer system. explain how protection domains combined with an access matrix are used to specify the resources a process may access. examine capability and language based protection systems. 
 as computer systems have become more sophisticated and pervasive in their applications the need to protect their integrity has also grown. protection was originally conceived as an adjunct to multiprogramming operating systems so that untrustworthy users might safely share a common logical name space such as a directory of files or share a common physical name space such as memory. modern protection concepts have evolved to increase the reliability of any complex system that makes use of shared resources. we need to provide protection for several reasons. the most obvious is the need to prevent mischievous intentional violation of an access restriction chapter protection by a user. of more general importance however is the need to ensure that each program component active in a system uses system resources only in ways consistent with stated policies. this requirement is an absolute one for a reliable system. protection can improve reliability by detecting latent errors at the interfaces between component subsystems. early detection of interface errors can often prevent contamination of a healthy subsystem by a malfunctioning subsystem. an unprotected resource cannot defend against use or misuse by an unauthorized or incompetent user. a protection oriented system provicies means to distinguish between authorized and unauthorized usage. the role of protection in a computer system is to provide a mechanism for the enforcement of the policies governing resource use. these policies can be established in a variety of ways. some are fixed in the design of the system while others are formulated by the management of a system. still others are defined by the individual users to protect their own files and programs. a protection system must have the flexibility to enforce a variety of policies. policies for resource use may vary by application and they may change over time. for these reasons protection is no longer the concern solely of the designer of an operating system. the application programmer needs to use protection mechanisms as well to guard resources created and supported by an application subsystem against misuse. in this chapter we describe the protection m.echanisms the operating system should provide so that application designers can use them in designing their own protection software. note that mechanisms are distinct horn policies. mechanisms determine how something will be done policies decide what will be done. the separation of policy and mechanism is important for flexibility. policies are likely to change from place to place or time to time. in the worst case every change in policy would require a change in the underlying mechanism. using general mechanisms enables us to avoid such a situation. 
 frequently a guiding principle can be used throughout a project such as the design of an operating system. following this principle simplifies design decisions and keeps the system consistent and easy to understand. a key time tested guiding principle for protection is the principle of least privilege. it dictates that programs users and even systems be given just enough privileges to perform their tasks. consider the analogy of a security guard with a passkey. if this key allows the guard into just the public areas that she guards then misuse of the key will result in minimal damage. if however the passkey allows access to all areas then damage from its being lost stolen misused copied or otherwise compromised will be much greater. an operating system following the principle of least privilege implements its features programs system calls and data structures so that failure or compromise of a component does the minimum damage and allows the minimum damage to be done. the overflow of a buffer in a system daemon might cause the daemon to fail for example but should not allow the execution of code from the process's stack that would enable a remote user to gain
 maximum privileges and access to the entire system as happens too often today . such an operating system also provides system calls and services that allow applications to be written with fine grained access controls. it provides mechanisms to enable privileges when they are needed and to disable them when they are not needed. also beneficial is the creation of audit trails for all privileged function access. the audit trail allows the programmer systems administrator or law enforcement officer to trace all protection and security activities on the system. managing users with the principle of least privilege entails creating a separate account for each user with just the privileges that the user needs. an operator who needs to mount tapes and backup files on the system has access to just those commands and files needed to accomplish the job. some systems implement role based access control rbac to provide this functionality. computers implemented in a computing facility under the principle of least privilege can be limited to running specific services accessing specific remote hosts via specific services and doing so during specific times. typically these restrictions are implemented through enabling or disabling each service and through access control lists as described in section . . and . . the principle of least privilege can help produce a more secure computing environment. unfortunately it frequently does not. for example windows has a complex protection scheme at its core and yet has many security holes. by comparison solaris is considered relatively secure even though it is a variant of unix which historically was designed with little protection in mind. one reason for the difference may be that windows has more lines of code and more services than solaris and thus has more to secure and protect. another reason could be that the protection scheme in windows is incomplete or protects the wrong aspects of the operating system leaving other areas vulnerable. . domain of protection a computer system is a collection of processes and objects. by objects we mean both hardware objects such as the cpu memory segments printers disks and tape drives and software objects such as files programs and semaphores . each object has a unique name that differentiates it from all other objects in the system and each can be accessed only through well defined and meaningful operations. objects are essentially abstract data types. the operations that are possible may depend on the object. for example a cpu can only be executed on. memory segments can be read and written whereas a cd rom or dvd rom can only be read. tape drives can be read written and rewound. data files can be created opened read written closed and deleted program files can be read written executed and deleted. a process should be allowed to access only those resources for which it has authorization. furthermore at any time a process should be able to access only those resources that it currently requires to complete its task. this second requirement commonly referred to as the need to knozv principle is useful in limiting the amount of damage a faulty process can cause in the system. for example when process p invokes procedure a the procedure should be chapter protection allowed to access only its own variables and the formal parameters passed to it it should not be able to access all the variables of process p. similarly consider the case where process p invokes a compiler to compile a particular file. the compiler should not be able to access files arbitrarily but should have access only to a well defined subset of files such as the source file listing file and so on related to the file to be compiled. conversely the compiler may have private files used for accounting or optimization purposes that process p should not be able to access. the need to know principle is similar to the principle of least privilege discussed in section . in that the goals of protection are to minimize the risks of possible security violations. . . domain structure to facilitate this scheme a process operates within a protection domain which specifies the resources that the process may access. each domain defines a set of objects and the types of operations that may be invoked on each object. the ability to execute an operation on an object is an access right. a domain is a collection of access rights each of which is an ordered pair object iiame rights set . for example if domain d has the access right file f read write then a process executing in domain d can both read and write file f it cannot however perform any other operation on that object. domains do not need to be disjoint they may share access rights. for example in figure . we have three domains dir d and d . the access right oi print is shared by d? and d implying that a process executing in either of these two domains can print object o . note that a process must be executing in domain d to read and write object o while only processes in domain d may execute object o . the association between a process and a domain may be either static if the set of resources available to the process is fixed throughout the process's lifetime or dynamic. as might be expected establishing dynamic protection domains is more complicated than establishing static protection domains. if the association between processes and domains is fixed and we want to adhere to the need to know principle then a mechanism must be available to change the content of a domain. the reason stems from the fact that a process may execute in two different phases and may for example need read access in one phase and write access in another. if a domain is static. we must define the domain to include both read and write access. however this arrangement provides more rights than are needed in each of the two phases since we have read access in the phase where we need only write access and vice versa. thus d figure . system with three protection domains. . domain of protection the need to know principle is violated. we must allow the contents of a domain to be modified so that it always reflects the minimum necessary access rights. if the association is dynamic a mechanism is available to allow domain switching enabling the process to switch from one domain to another. we may also want to allow the content of a domain to be changed. if we cannot change the content of a domain we can provide the same effect by creating a new domain with the changed content and switching to that new domain when we want to change the domain content. a domain can be realized in a variety of ways each user may be a domain. in this case the set of objects that can be accessed depends on the identity of the user. domain switching occurs when the user is changed generally when one user logs out and another user logs in. each process may be a domain. in this case the set of objects that can be accessed depends on the identity of the process. domain switching occurs when one process sends a message to another process and then waits for a response. each procedure may be a domain. in this case the set of objects that can be accessed corresponds to the local variables defined within the procedure. domain switching occurs when a procedure call is made. we discuss domain switching in greater detail in section . . consider the standard dual mode monitor user mode model of operating system execution. when a process executes in monitor mode it can execute privileged instructions and thus gain complete control of the computer system. in contrast when a process executes in user mode it can invoke only nonprivileged instructions. consequently it can execute only within its predefined memory space. these two modes protect the operating system executing in monitor domain from the user processes executing in user domain . in a multiprogrammed operating system two protection domains are insufficient since users also want to be protected from one another. therefore a more elaborate scheme is needed. we illustrate such a scheme by examining two influential operating systems unix and mult cs to see how these concepts have been implemented there. . . an example unix in the unix operating system a domain is associated with the user. switching the domain corresponds to changing the user identification temporarily. this change is accomplished through the file system as follows. an owner identification and a domain bit known as the setuid bit are associated with each file. when the setuid bit is on and a user executes that file the user id is set to that of the owner of the file when the bit is off however the user id does not change. for example when a user a that is a user with userld a starts executing a file owned by b whose associated domain bit is off the uscrld of the process is set to a. when the setuid bit is on the userld is set to that of the owner of the file b. when the process exits this temporary userld change ends. chapter protection other methods are used to change domains in operating systems in which user ids are used for domain definition because almost all systems need to provide such a mechanism. this mechanism is used when an otherwise privileged facility needs to be made available to the general user population. for instance it might be desirable to allow users to access a network without letting them write their own networking programs. in such a case on a unix system the setuid bit on a networking program would be set causing the user id to change when the program was run. the user id would change to that of a user with network access privilege such as root the most powerful user id . one problem with this method is that if a user manages to create a file with user id root and with its setuid bit on that user can become root and do anything and everything on the system. the setuid mechanism is discussed further in appendix a. an alternative to this method used in other operating systems is to place privileged programs in a special directory. the operating system would be designed to change the user id of any program run from this directory either to the equivalent of root or to the user id of the owner of the directory. this eliminates one security problem with setuid programs in which crackers create and hide using obscure file or directory names them for later use. this method is less flexible than that used in unix however. even more restrictive and thus more protective are systems that simply do not allow a change of user id. in these instances special techniques must be used to allow users access to privileged facilities. for instance a daemon process may be started at boot time and run as a special user id. users then run a separate program which sends requests to this process whenever they need to use the facility this method is used by the tops operating system. in any of these systems great care must be taken in writing privileged programs. any oversight can result in a total lack of protection on the system. generally these programs are the first to be attacked by people trying to break into a system unfortunately the attackers are frequently successful. for example security has been breached on many unix systems because of the setuid feature. we discuss security in chapter . . . an example multics in the multics system the protection domains are organized hierarchically into a ring structure. each ring corresponds to a single domain figure . . the rings are numbered from to . let d and d be any two domain rings. if then d is a subset of d . that is a process executing in domain d has more privileges than does a process executing in domain d a process executing in domain do has the most privileges. if only two rings exist this scheme is equivalent to the monitor user mode of execution where monitor mode corresponds to do and user mode corresponds to d . multics has a segmented address space each segment is a file and each segment is associated with one of the rings. a segment description includes an entry that identifies the ring number. in addition it includes three access bits to control reading writing and execution. the association between segments and rings is a policy decision with which we are not concerned here. a cuirent ring mtmber counter is associated with each process identifying the ring in which the process is executing currently. when a process is executing . domain of protection s ring ring n figure . multics ring structure. in ring ' it cannot access a segment associated with ring i . it can access a segment associated with ring k k . the type of access however is restricted according to the access bits associated with that segment. domain switching in multics occurs when a process crosses from one ring to another by calling a procedure in a different ring. obviously this switch must be done in a controlled manner otherwise a process could start executing in ring and no protection would be provided. to allow controlled domain switching we modify the ring field of the segment descriptor to include the following access bracket. a pair of integers bl and bl such that bl bl. limit. an integer b such that b bl. list of gates. identifies the entry points or gates at which the segments may be called. if a process executing in ring ' calls a procedure or segment with access bracket bl bl then the call is allowed if bl s ' bl and the current ring number of the process remains '. otherwise a trap to the operating system occurs and the situation is handled as follows if bl then the call is allowed to occur because we have a transfer to a ring or domain with fewer privileges. however if parameters are passed that refer to segments in a lower ring that is segments not accessible to the called procedure then these segments must be copied into an area that can be accessed by the called procedure. if bl then the call is allowed to occur only if b is greater than or equal to and the call has been directed to one of the designated entry points in the list of gates. this scheme allows processes with limited access rights to call procedures in lower rings that have more access rights but only in a carefully controlled manner. chapter protection the main disadvantage of the ring or hierarchical structure is that it ctoes not allow us to enforce the need to know principle. in particular if an object must be accessible in domain d but not accessible in domain du then we must have i. but this requirement means that every segment accessible in d is also accessible in d . the mult cs protection system is generally more complex and less efficient than are those used in current operating systems. if protection interferes with the ease of use of the system or significantly decreases system performance then its use must be weighed carefully against the purpose of the system. for instance we would want to have a complex protection system on a computer used by a university to process students' grades and also used by students for classwork. a similar protection system would notbe suited to a computer being used for number crunching in which performance is of utmost importance. we would prefer to separate the mechanism from the protection policy allowing the same system to have complex or simple protection depending on the needs of its users. to separate mechanism from policy we require a more general model of protection
 our model of protection can be viewed abstractly as a matrix called an access matrix. the rows of the access matrix represent domains and the columns represent objects. each entry in the matrix consists of a set of access rights. because the column defines objects explicitly we can omit the object name from the access right. the entry access defines the set of operations that a process executing in domain dj can invoke on object or to illustrate these concepts we consider the access matrix shown in figure . . there are four domains and four objects three files f f f and one laser printer. a process executing in domain d can read files fj and f . a process executing in domain d has the same privileges as one executing in domain d but in addition it can also write onto files f and f?. note that the laser printer can be accessed only by a process executing in domain dofigure . access matrix. . access matrix the access matrix scheme provides us with the mechanism for specifying a variety of policies. the mechanism consists of implementing the access matrix and ensuring that the semantic properties we have outlined indeed hold. more specifically we must ensure that a process executing in domain d can access only those objects specified in row and then only as allowed by the access matrix entries. the access matrix can implement policy decisions concerning protection. the policy decisions involve which rights should be included in the z' ' th entry. we must also decide the domain in which each process executes. this last policy is usually decided by the operating system. the users normally decide the contents of the access matrix entries. when a user creates a new object o the column is added to the access matrix with the appropriate initialization entries as dictated by the creator. the user may decide to enter some rights in some entries in column and other rights in other entries as needed. the access matrix provides an appropriate mechanism for defining and implementing strict control for both the static and dynamic association between processes and domains. wthen we switch a process from one domain to another we are executing an operation switch on an object the domain . we can control domain switching by including domains among the objects of the access matrix. similarly when we change the content of the access matrix we are performing an operation on an object the access matrix. again we can control these changes by including the access matrix itself as an object. actually since each entry in the access matrix may be modified individually we must consider each entry in the access matrix as an object to be protected. now we need to consider only the operations possible on these new objects domains and the access matrix and decide how we want processes to be able to execute these operations. processes should be able to switch from one domain to another. domain switching from domain d to domain d is allowed if and only if the access right switch e access ' . thus in figure . a process executing in domain d can switch to domain d or to domain d . a process in domain d can switch to d and one in domain d can switch to domain d . object f i laser domain ' printer read rti swifcfi l pf n ! swiich react swiiah vyfilf yfjte figure . access matrix of figure . with domains as objects. chapter protection iobject a n l . . . c pjegt ! . . . . ... . i . . . . . k. . x ctaftiai n i i i i i xl a i... illwrites jilii ' ' ' f' si ' ' ' ' ' ' ' ' ' ' .jlrbab . j f '' ''' ''' ''' '' ... rseuil.i. b figure . access matrix with copy rights. allowing controlled change in the contents of the access matrix entries requires three additional operations copy owner and control. we examine these operations next. the ability to copy an access right from one domain or row of the access matrix to another is denoted by an asterisk appended to the access right. the copy right allows the copying of the access right only within the column that is for the object for which the right is defined. for example in figure . a a process executing in domain d can copy the read operation into any entry associated with file f . hence the access matrix of figure . a can be modified to the access matrix shown in figure . b . this scheme has two variants . a right is copied from access to access c it is then removed from access . this action is a transfer of a right rather than a copy. . propagation of the copy right may be limited. that is when the right r is copied from access y to access t only the right r not r is created. a process executing in domain dk cannot further copy the right r. a system may select only one of these three copy rights or it may provide all three by identifying them as separate rights copy transfer and limited copy. we also need a mechanism to allow addition of new rights and removal of some rights. the owner right controls these operations. if access includes the oivncr right then a process executing in domain d can add and remove any right in any entry in column '. for example in figure . a domain d is the owner of f and thus can add and delete any valid right in column f . . access matrix s . . . ! . . . p . . . . j . . ' . . . . .... . . . i ..m. z . ...lit? .. i..hi . .. rs.. . . .... domain n lfllllijif!fill!' r ii i i i i. i ! i i ! i i i i i i !mi i tieacl n ii write i imi ii. jii wrjte l l b figure . access matrix with owner rights. similarly domain d is the owner of f and f and thus can add and remove any valid right within these two columns. thus the access matrix of figure . a can be modified to the access matrix shown in figure . b . the copy and owner rights allow a process to change the entries in a column. a mechanism is also needed to change the entries in a row. the control right is applicable only to domain objects. if access includes the control right then a process executing in domain d. can remove any access right from row '. for example suppose that in figure . we include the control right in access d d . then a process executing in domain dt could modify domain d as shown in figure . . the copy and owner rights provide us with a mechanism to limit the propagation of access rights. however they do not give us the appropriate tools for preventing the propagation or disclosure of information. the problem of guaranteeing that no information initially held in an object can migrate outside of its execution environment is called the confinement problem. this problem is in general unsolvable see bibliographical notes for references . these operations on the domains and the access matrix are not in themselves important but they illustrate the ability of the access matrix model to allow the implementation and control of dynamic protection requirements. new objects and new domains can be created dynamically and included in the access matrix model. however we have shown only that the basic mechanism chapter protection figure . modified access matrix of figure . . is here system designers and users must make the policy decisions concerning which domains are to have access to which objects in which ways
 how can the access matrix be implemented effectively? in general the matrix will be sparse that is most of the entries will be empty. although datastructure techniques are available for representing sparse matrices they are not particularly useful for this application because of the way in which the protection facility is used. here we first describe several methods of implementing the access matrix and then compare the methods. . . global table the simplest implementation of the access matrix is a global table consisting of a set of ordered triples domain object rights set . whenever an operation m is executed on an object o within domain d the global table is searched for a triple d o rk with m e r . if this triple is found the operation is allowed to continue otherwise an exception or error condition is raised. this implementation suffers from several drawbacks. the table is usually large and thus cannot be kept in main memory so additional i o is needed. virtual memory techniques are often used for managing this table. in addition it is difficult to take advantage of special groupings of objects or domains. for example if everyone can read a particular object it must have a separate entry in every domain. . . access lists for objects each column in the access matrix can be implemented as an access list for one object as described in section . . . obviously the empty entries can be discarded. the resulting list for each object consists of ordered pairs rfomnin rights set which define all domains with a nonempty set of access rights for that object. this approach can be extended easily to define a list plus a default set of access rights. when an operation m on an object is attempted in domain . implementation of access matrix dj we search the access list for object o. looking for an entry d r with m e kj. if the entry is found we allow the operation if it is not we check the default set. if m is in the default set we allow the access. otherwise access is denied and an exception condition occurs. for efficiency we may check the default set first and then search the access list. . . capability lists for domains rather than associating the columns of the access matrix with the objects as access lists we can associate each row with its domain. a capability list for a domain is a list of objects together with the operations allowed on those objects. an object is often represented by its physical name or address called a capability. to execute operation m on object the process executes the operation m specifying the capability or pointer for object o as a parameter. simple possession of the capability means that access is allowed. the capability list is associated with a domain but it is never directly accessible to a process executing in that domain. rather the capability list is itself a protected object maintained by the operating system and accessed by the user only indirectly. capability based protection relies on the fact that the capabilities are never allowed to migrate into any address space directly accessible by a user process where they could be modified . if all capabilities are secure the object they protect is also secure against unauthorized access. capabilities were originally proposed as a kind of secure pointer to meet the need for resource protection that was foreseen as multiprogrammed computer systems came of age. the idea of an inherently protected pointer provides a foundation for protection that canbe extended up to the applications level. to provide inherent protection we must distinguish capabilities from other kinds of objects and they must be interpreted by an abstract machine on which higher level programs run. capabilities are usually distinguished from other data in one of two ways each object has a tag to denote its type either as a capability or as accessible data. the tags themselves must not be directly accessible by an application program. hardware or firmware support may be used to enforce this restriction. although only bit is necessary to distinguish between capabilities and other objects more bits are often used. this extension allows all objects to be tagged with their types by the hardware. thus the hardware can distinguish integers floating point numbers pointers booleans characters instructions capabilities and uninitialized values by their tags. alternatively the address space associated with a program can be split into two parts. one part is accessible to the program and contains the program's normal data and instructions. the other part containing the capability list is accessible only by the operating system. a segmented memory space section . is useful to support this approach. several capability based protection systems have been developed we describe them briefly in section . . the mach operating system also uses a version of capability based protection it is described in appendix b. chapter protection . . a lock key mechanism the lock key scheme is a compromise between access lists and capability lists. each object has a list of unique bit patterns called locks. similarly each domain has a list of unique bit patterns called keys. a process executing in a domain can access an object only if that domain has a key that matches one of the locks of the object. as with capability lists the list of keys for a domain must be managed by the operating system on behalf of the domain. users are not allowed to examine or modify the list of keys or locks directly. . . comparison we now compare the various techniques for implementing an access matrix. using a global table is simple however the table can be quite large and often cannot take advantage of special groupings of objects or domains. access lists correspond directly to the needs of users. when a user creates an object he can specify which domains can access the object as well as the operations allowed. however because access rights information for a particular domain is not localized determining the set of access rights for each domain is difficult. in addition every access to the object must be checked requiring a search of the access list. in a large system with long access lists this search can be time consuming. capability lists do not correspond directly to the needs of users they are useful however for localizing information for a given process. the process attempting access must present a capability for that access. then the protection system needs only to verify that the capability is valid. revocation of capabilities however may be inefficient section . . the lock key mechanism as mentioned is a compromise between access lists and capability lists. the mechanism can be both effective and flexible depending on the length of the keys. the keys can be passed freely from domain to domain. in addition access privileges can be effectively revoked by the simple technique of changing some of the locks associated with the object section . . most systems use a combination of access lists and capabilities. when a process first tries to access an object the access list is searched. if access is denied an exception condition occurs. otherwise a capability is created and attached to the process. additional references use the capability to demonstrate swiftly that access is allowed. after the last access the capability is destroyed. this strategy is used in the m.ultics system and in the cal system. as an example of how such a strategy works consider a file system in which each file has an associated access list. when a process opens a file the directory structure is searched to find the file access permission is checked and buffers are allocated. all this information is recorded in a new entry in a file table associated with the process. the operation returns an index into this table for the newly opened file. all operations on the file are made by specification of the index into the file table. the entry in the file table then points to the file and its buffers. when the file is closed the file table entry is deleted. since the file table is maintained by the operating system the user cannot accidentally corrupt it. thus the user can access only those files that have been opened
 since access is checked when the file is opened protection is ensured this strategy is used in the unix system. the right to access must still be checked on each access and the file table entry has a capability only for the allowed operations. if a file is opened for reading then a capability for read access is placed in the file table entry. if an attempt is made to write onto the file the system identifies this protection violation by comparing the requested operation with the capability in the file table entrv. . access in section . . we described how access controls can be used on files within a file system. each file and directory are assigned an owner a group or possibly a list of users and for each of those entities access control information is assigned. a similar function can be added to other aspects of a computer system. a good example of this is found in solaris . solaris advances the protection available in the sun microsystems operating system by explicitly adding the principle of least privilege via role based access control rbac . this facility revolves around privileges. a privilege is the right to execute a system call or to use an option within that system call such as opening a file with write access . privileges can be assigned to processes limiting them to exactly the access they need to perform their work. privileges and programs can also be assigned to roles. users are assigned roles or can take roles based on passwords to the roles. in this way a user can take a role that enables a privilege allowing the user to run a program to accomplish a specific task as depicted in figure . . this implementation of privileges decreases the security risk associated with superusers and setuid programs. executes with role privileges figure . rote based access control in solaris . chapter protection notice that this facility is similar to the access matrix described in section . . this relationship will be further explored in the exercises at the end of the chapter
 in a dynamic protection system we may sometimes need to revoke access rights to objects shared by different users. various questions about revocation may arise immediate versus delayed. does revocation occur immediately or is it delayed? if revocation is delayed can we find out when it will take place? selective versus general. when an access right to an object is revoked does it affect all the users who have an access right to that object or can we specify a select group of users whose access rights should be revoked? partial versus total. can a subset of the rights associated with an object be revoked or must we revoke all access rights for this object? temporary versus permanent. can access be revoked permanently that is the revoked access right will never again be available or can access be revoked and later be obtained again? with an access list scheme revocation is easy. the access list is searched for any access rights to be revoked and they are deleted from the list. revocation is immediate and can be general or selective total or partial and permanent or temporary. capabilities however present a much more difficult revocation problem. since the capabilities are distributed throughout the system we must find them before we can revoke them. schemes that implement revocation for capabilities include the following reacquisition. periodically capabilities are deleted from each domain. if a process wants to use a capability it may find that that capability has been deleted. the process may then try to reacquire the capability. if access has been revoked the process will not be able to reacquire the capability. back pointers. a list of pointers is maintained with each object pointing to all capabilities associated with that object. when revocation is required we can follow these pointers changing the capabilities as necessary. this scheme was adopted in the multics system. it is quite general but its implementation is costly. indirection. the capabilities point indirectly not directly to the objects. each capability points to a unique entry in a global table which in turn points to the object. we implement revocation by searching the global table for the desired entry and deleting it. then when an access is attempted the capability is found to point to an illegal table entry. table entries can be reused for other capabilities without difficulty since both the capability and the table entry contain the unique name of the object. the object for a
 capability and its table entry must match. this scheme was adopted in the cal system. it does not allow selective revocation. keys. a key is a unique bit pattern that can be associated with a capability. tliis key is defined when the capability is created and it can be neither modified nor inspected by the process owning the capability. a master key is associated with each object it can be defined or replaced with the set key operation. when a capability is created the current value of the master key is associated with the capability. when the capability is exercised its key is compared with the master key. if the keys match the operation is allowed to continue otherwise an exception condition is raised. revocation replaces the master key with a new value via the set key operation invalidating all previous capabilities for this object. this scheme does not allowr selective revocation since only one master key is associated with each object. if we associate a list of keys with each object then selective revocation can be implemented. finally we can group all keys into one global table of keys. a capability is valid only if its key matches some key in the global table. we implement revocation by removing the matching key from the table. with this scheme a key can be associated with several objects and several keys can be associated with each object providing maximum flexibility. in key based schemes the operations of defining keys inserting them into lists and deleting them from lists should not be available to all users. in particular it would be reasonable to allow only the owner of an object to set the keys for that object. this choice however is a policy decision that the protection system can implement but should not define. . capability based systems in this section we survey two capability based protection systems. these systems vary in their complexity and in the types of policies that can be implemented on them. neither system is widely used but they are interesting proving grounds for protection theories. . . an example hydra hydra is a capability based protection system that provides considerable flexibility. a fixed set of possible access rights is known to and interpreted by the system. these rights include such basic forms of access as the right to read write or execute a memory segment. in addition a user of the protection system can declare other rights. the interpretation of user defined rights is performed solely by the user's program but the system provides access protection for the use of these rights as well as for the use of system defined rights. these facilities constitute a significant development in protection technology. operations on objects are defined procedurally. the procedures that implement such operations are themselves a form of object and they are accessed indirectly by capabilities. the names of user defined procedures must be identified to the protection system if it is to deal with objects of the userdefined type. when the definition of an object is made known to hydra the chapter protection names of operations on the type become auxiliary rights. auxiliary rights can be described in a capability for an instance of the type. for a process to perform an operation on a typed object the capability it holds for that object must contain the name of the operation being invoked among its auxiliary rights. this restriction enables discrimination of access rights to be made on an instance by instance and process by process basis. hydra also provides rights amplification. this scheme allows a procedure to be certified as trustworthy to act on a formal parameter of a specified type on behalf of any process that holds a right to execute the procedure. the rights held by a trustworthy procedure are independent of and may exceed the rights held by the calling process. however such a procedure must not be regarded as universally trustworthy the procedure is not allowed to act on other types for instance and the trustworthiness must not be extended to any other procedures or program segments that might be executed by a process. amplification allows implementation procedures access to the representation variables of an abstract data type. if a process holds a capability to a typed object a for instance this capability may include an auxiliary right to invoke some operation p but would not include any of the so called kernel rights such as read write or execute on the segment that represents a. such a capability gives a process a means of indirect access through the operation p to the representation of a but only for specific purposes. when a process invokes the operation p on an object a however the capability for access to a may be amplified as control passes to the code body of p. this amplification may be necessary to allow p the right to access the storage segment representing a so as to implement the operation that p defines on the abstract data type. the code body of p may be allowed to read or to write to the segment of a directly even though the calling process cannot. on return from p the capability for a is restored to its original unamplified state. this case is a typical one in which the rights held by a process for access to a protected segment must change dynamically depending on the task to be performed. the dynamic adjustment of rights is performed to guarantee consistency of a programmer defined abstraction. amplification of rights can be stated explicitly in the declaration of an abstract type to the hydra operating system. when a user passes an object as an argument to a procedure we may need to ensure that the procedure cannot modify the abject. we can implement this restriction readily by passing an access right that does not have the modification write right. however if amplification may occur the right to modify may be reinstated. thus the user protection requirement can be circumvented. in general of course a user may trust that a procedure performs its task correctly. this assumption is not always correct however because of hardware or software errors. hydra solves this problem by restricting amplifications. the procedure call mechanism of hydra was designed as a direct solution to the problem of mutually suspicious subsystems. this problem is defined as follows. suppose that a program is provided that can be invoked as a service by a number of different users for example a sort routine a compiler a game . when users invoke this service program they take the risk that the program will malfunction and will either damage the given data or retain some access right to the data to be used without authority later. similarly the service program may have some private files for accounting purposes . capability based systems for example that should not be accessed directly by the calling user program. hydra provides mechanisms for directly dealing with this problem. a hydra subsystem is built on top of its protection kernel and may require protection of its own components. a subsystem interacts with the kernel through calls on a set of kernel defined primitives that define access rights to resources defined by the subsystem. the subsystem designer can define policies for use of these resources by user processes but the policies are enforceable by use of the standard access protection afforded by the capability system. a programmer can make direct use of the protection system after acquainting herself with its features in the appropriate reference manual. hydra provides a large library of system defined procedures that can be called by user programs. a user of the hydra system would explicitly incorporate calls on these system procedures into the code of her programs or would use a program translator that had been interfaced to hydra. . . an example cambridge cap system a different approach to capability based protection has been taken in the design of the cambridge cap system. cap's capability system is simpler and superficially less powerful than that of hydra. however closer examination shows that it too can be used to provide secure protection of user defined objects. cap has two kinds of capabilities. the ordinary kind is called a data capability. it can be used to provide access to objects but the only rights provided are the standard read write and execute of the individual storage segments associated with the object. data capabilities are interpreted by microcode in the cap machine. the second kind of capability is the so called software capability which is protected but not interpreted by the cap microcode. it is interpreted by a protected that is a privileged procedure which may be written by an application programmer as part of a subsystem. a particular kind of rights amplification is associated with a protected procedure. when executing the code body of such a procedure a process temporarily acquires the right to read or write the contents of a software capability itself. this specific kind of rights amplification corresponds to an implementation of the seal and unseal primitives on capabilities. of course this privilege is still subject to type verification to ensure that only software capabilities for a specified abstract type are passed to any such procedure. universal trust is not placed in any code other than the cap machine's microcode. see bibliographical notes for references. the interpretation of a software capability is left completely to the subsystem. through the protected procedures it contains. this scheme allows a variety of protection policies to be implemented. although a programmer can define her own protected procedures any of which might be incorrect the security of the overall system cannot be compromised. the basic protection system will not allow an unverified user defined protected procedure access to any storage segments or capabilities that do not belong to the protection environment in which it resides. the most serious consequence of an insecure protected procedure is a protection breakdown of the subsystem for which that procedure has responsibility. . chapter protection the designers of the cap system have noted that the use of software capabilities allowed them to realize considerable economies in formulating and implementing protection policies commensurate with the requirements of abstract resources. however a subsystem designer who wants to make use of this facility cannot simply study a reference manual as is the case with hydra. instead she must learn the principles and techniques of protection since the system provides her with no library of procedures
 to the degree that protection is provided in existing computer systems it is usually achieved through an operating system kernel which acts as a security agent to inspect and validate each attempt to access a protected resource. since comprehensive access validation is potentially a source of considerable overhead either we must give it hardware support to reduce the cost of each validation or we must accept that the system designer may compromise the goals of protection. satisfying all these goals is difficult if the flexibility to implement protection policies is restricted by the support mechanisms provided or if protection environments are made larger than necessary to secure greater operational efficiency. as operating systems have become more complex and particularly as they have attempted to provide higher level user interfaces the goals of protection have become much more refined. the designers of protection systems have drawn heavily on ideas that originated in programming languages and especially on the concepts of abstract data types and objects. protection systems are now concerned not only with the identity of a resource to which access is attempted but also with the functional nature of that access in the newest protection systems concern for the function to be invoked extends beyond a set of system defined functions such as standard file access methods to include functions that may be user defined as well. policies for resource use may also vary depending on the application and they may be subject to change over time. for these reasons protection can no longer be considered a matter of concern to only the designer of an operating system. it should also be available as a tool for use by the application designer so that resources of an applications subsystem can be guarded against tampering or the influence of an error. . . compiler based enforcement at this point programming languages enter the picture. specifying the desired control of access to a shared resource in a system is making a declarative statement about the resource. this kind of statement can be integrated into a language by an extension of its typing facility. when protection is declared along with data typing the designer of each subsystem can specify its requirements for protection as well as its need for use of other resources in a system. such a specification should be given directly as a program is composed and in the language in which the program itself is stated.. this approach has several significant advantages . language based protection . protection needs are simply declared rather than programmed as a sequence of calls on procedures of an operating system. . protection requirements can be stated independently of the facilities provided by a particular operating system. . the means for enforcement need not be provided by the designer of a subsystem. . a declarative notation is natural because access privileges are closely related to the linguistic concept of data type. a variety of techniques can be provided by a programming language implementation to enforce protection but any of these must depend on some degree of support from an underlying machine and its operating system. for example suppose a language is used to generate code to run on the cambridge cap system. on this system every storage reference made on the underlying hardware occurs indirectly through a capability. this restriction prevents any process from accessing a resource outside of its protection environment at any time. however a program may impose arbitrary restrictions on how a resource can be used during execution of a particular code segment. we can implement such restrictions most readily by using the software capabilities provided by cap. a language implementation might provide standard protected procedures to interpret software capabilities that would realize the protection policies that could be specified in the language. this scheme puts policy specification at the disposal of the programmers while freeing them from implementing its enforcement. even if a system does not provide a protection kernel as powerful as those of hydra or cap mechanisms are still available for implementing protection specifications given in a programming language. the principal distinction is that the security of this protection will not be as great as that supported by a protection kernel because the mechanism must rely on more assumptions about the operational state of the system. a compiler can separate references for which it can certify that no protection violation could occur from those for which a violation might be possible and it can treat them differently. the security provided by this form of protection rests on the assumption that the code generated by the compiler will not be modified prior to or during its execution. what then are the relative merits of enforcement based solely on a kernel as opposed to enforcement provided largely by a compiler? security. enforcement by a kernel provides a greater degree of security of the protection system itself than does the generation of protectionchecking code by a compiler. in a compiler supported scheme security rests on correctness of the translator on some underlying mechanism of storage management that protects the segments from which compiled code is executed and ultimately on'the security of files from which a program is loaded. some of these considerations also apply to a softwaresupported protection kernel but to a lesser degree since the kernel may reside in fixed physical storage segments and may be loaded from only a designated file. with a tagged capability system in which all address . chapter protection computation is performed either by hardware or by a fixed microprogram even greater security is possible. hardware supported protection is also relatively immune to protection violations that might occur as a result of either hardware or system software malfunction. flexibility. there are limits to the flexibility of a protection kernel in implementing a user defined policy although it may supply adequate facilities for the system to provide enforcement of its own policies. with a programming language protection policy can be declared and enforcement provided as needed by an implementation. if a language does not provide sufficient flexibility it can be extended or replaced with less disturbance of a system in service than would be caused by the modification of an operating system kernel. efficiency. the greatest efficiency is obtained wrhen enforcement of protection is supported directly by hardware or microcode . insofar as software support is required language based enforcement has the advantage that static access enforcement can be verified off line at compile time. also since an intelligent compiler can tailor the enforcement mechanism to meet the specified need the fixed overhead of kernel calls can often be avoided. in summary the specification of protection in a programming language allows the high level description of policies for the allocation and use of resources. a language implementation can provide software for protection enforcement when automatic hardware supported checking is unavailable. in addition it can interpret protection specifications to generate calls on whatever protection system is provided by the hardware and the operating system. one way of making protection available to the application program is through the use of a software capability that could be used as an object of computation. inherent in this concept is the idea that certain program components might have the privilege of creating or examining these software capabilities. a capability creating program would be able to execute a primitive operation that would seal a data structure rendering the latter's contents inaccessible to any program components that did not hold either the seal or the unseal privilege. they might copy the data structure or pass its address to other program components but they could not gain access to its contents. the reason for introducing such software capabilities is to bring a protection mechanism into the programming language. the only problem with the concept as proposed is that the use of the seal and unseal operations takes a procedural approach to specifying protection. a nonprocedural or declarative notation seems a preferable way to make protection available to the application programmer. what is needed is a safe dynamic access control mechanism for distributing capabilities to system resources among user processes. to contribute to the overall reliability of a system the access control mechanism should be safe to use. to be useful in practice it should also be reasonably efficient. this requirement has led to the development of a number of language constructs that allow the programmer to declare various restrictions on the use of a specific managed resource. see the bibliographical notes for appropriate references. these constructs provide mechanisms for three functions . language based protection . distributing capabilities safely and efficiently among customer processes in particular mechanisms ensure that a user process will use the managed resource only if it was granted a capability to that resource . specifying the type of operations that a particular process may invoke on an allocated resource for example a reader of a file should be allowed only to read the file whereas a writer should be able both to read and to write it should not be necessary to grant the same set of rights to every user process and it should be impossible for a process to enlarge its set of access rights except with the authorization of the access control mechanism. . specifying the order in which a particular process may invoke the various operations of a resource for example a file must be opened before it can be read it should be possible to give two processes different restrictions on the order in which they can invoke the operations of the allocated resource. the incorporation of protection concepts into programming languages as a practical tool for system design is in its infancy. protection will likely become a matter of greater concern to the designers of new systems with distributed architectures and increasingly stringent requirements on data security. then the importance of suitable language notations in which to express protection requirements will be recognized more widely. . . protection in java because java was designed to run in a distributed environment the java virtual machine or jvm has many built in protecion mechanisms. java programs are composed of classes each of which is a collection of data fields and functions called methods that operate on those fields. the jvm loads a class in response to a request to create instances or objects of that class. one of the most novel and useful features of java is its support for dynamically loading untrusted classes over a network and for executing mutually distrusting classes within the same vm. because of these capabilities of java protection is a paramount concern. classes running in the same jvm may be from different sources and may not be equally trusted. as a result enforcing protection at the granularity of the jvm process is insufficient. intuitively whether a request to open a file should be allowed will generally depend on which class has requested the open. the operating system lacks this knowledge. thus such protection decisions are handled within the jvm. when the jvm loads a class it assigns the class to a protection domain that gives the permissions of that class. the protection domain to which the class is assigned depends on the url from which the class was loaded and any digital signatures on the class file. digital signatures are covered in section . . . . a configurable policy file determines the permissions granted to the domain and its classes . for example classes loaded from a trusted server might be placed in a protection domain that allows them to access files in the user's home directory whereas classes loaded from an untrusted server might have no file access permissions at all. s chapter protection it can be complicated for the jvm to determine what class is responsible for a request to access a protected resource. accesses are often performed indirectly through system libraries or other classes. for example consider a class that is not allowed to open network connections. it could call a system library to request the load of the contents of a url. the jvm must decide whether or not to open a network connection for this request. but which class should be used to determine if the connection should be allowed the application or the system library? the philosophy adopted in java is to require the library class to explicitly permit the network connection to load the requested url. more generally in order to access a protected resource some method in the calling sequence that resulted in the request must explicitly assert the privilege to access the resource. by doing so this method takes responsibility for the request presumably it will also perform whatever checks are necessary to ensure the safety of the request. of course not every method is allowed to assert a privilege a method can assert a privilege only if its class is in a protection domain that is itself allowed to exercise the privilege. this implementation approach is called stack inspection. every thread in the jvm has an associated stack of its ongoing method invocations. when its caller may not be trusted a method executes an access request within a doprivileged block to perform the access to a protected resource directly or indirectly. doprivileged is a static method in the accesscontroller class that is passed a class with a run method to invoke. when the doprivileged block is entered the stack frame for this method is annotated to indicate this fact. then the contents of the block are executed. when an access to a protected resource is subsequently requested either by this method or a method it calls a call to checkpermissionso is used to invoke stack inspection to determine if the request should be allowed. the inspection examines stack frames on the calling thread's stack starting from the most recently added frame and working toward the oldest. if a stack frame is first found that has the doprivileged annotation then checkpermissionso returns immediately and silently allowing the access. if a stack frame is first found for which access is disallowed based on the protection domain of the method's class then checkpermissionso throws an accesscontrolexception. if the stack inspection exhausts the stack without finding either type of frame then whether access is allowed depends on the implementation for example some implementations of the jvm may allow access other implementations may disallow it . stack inspection is illustrated in figure . . here the gui method of a class in the tmtrusted applet protection domain performs two operations first a get o and then an open . the former is an invocation of the get method of a class in the url loader protection domain which is permitted to openo sessions to sites in the l u c e n t . com domain in particular a proxy server proxy.lucent.com for retrieving urls. for this reason the untrusted applet's get invocation will succeed the checkpermissionso call in the networking library encounters the stack frame of the get method which performed its openo in a doprivileged block. however the untrusted applet's openo invocation will result in an exception because the checkpermissionso call finds no doprivileged annotation before encountering the stack frame of the gui method
 drotection . . i ! ! domain apie! t iii ii i ' ' ' ' ' ' ' ' ' socket rs s .? ! h i i permission f ? ? .l' t .i t . . . class i rfy.w v'a ' ' ' ' ' ' ' i 'm r ' ' r r . r. r r ' ' ' ' .' '.' . .' . . ' ' .' .i l fff . ! ' ' ' i ' . ' ' . . ' v r i !i h ! ! ! ! h n hi ! i .. ! ! . figure . stack inspection. of course for stack inspection to work a program must be unable to modify the annotations on its own stack frame or to do other manipulations of stack inspection. this is one of the most important differences between java and many other languages including c . a java program cannot directly access memory. rather it can manipulate only an object for which it has a reference. references cannot be forged and the manipulations are made only through well defined interfaces. compliance is enforced through a sophisticated collection of load time and run time checks. as a result an object cannot manipulate its run time stack because it cannot get a reference to the stack or other components of the protection system. more generally java's load time and run time checks enforce type safety of java classes. type safety ensures that classes cannot treat integers as pointers write past the end of an array or otherwise access memory in arbitrary ways. rather a program can access an object only via the methods defined on that object by its class. this is the foundation of java protection since it enables a class to effectively encapsulate and protect its data and methods from other classes loaded in the same jvm. for example a variable can be defined as p r i v a t e so that only the class that contains it can access it or p r o t e c t e d so that it can be accessed only by the class that contains it subclasses of that class or classes in the same package. type safety' ensures that these restrictions can be enforced. summary computer systems contain many objects and they need to be protected from misuse. objects may be hardware such as memory cpu time and i o devices or software such as files programs and semaphores . an access right is permission to perform an operation on an object. a domain is a set of access rights. processes execute in domains and may use any of the access rights in the domain to access and manipulate objects. during its lifetime a process may be either bound to a protection domain or allowed to switch from one domain to another. chapter protection the access matrix is a general model of protection that provides a mechanism for protection without imposing a particular protection policy on the system or its users. the separation of policy and mechanism is an important design property. the access matrix is sparse. it is normally implemented either as access lists associated with each object or as capability lists associated with each domain. we can include dynamic protection in the access matrix model by considering domains and the access matrix itself as objects. revocation of access rights in a dynamic protection model is typically easier to implement with an access list scheme than with a capability list. real systems are much more limited than the general model and tend to provide protection only for files. unix is representative providing read write and execution protection separately for the owner group and general public for each file. multjcs uses a ring structure in addition to file access. hydra the cambridge cap system and mach are capability systems that extend protection to user defined software objects. solaris implements the principle of least privilege via role based access control a form of the access matrix. language based protection provides finer grained arbitration of requests and privileges than the operating system is able to provide. for example a single java jvm can run several threads each in a different protection class. it enforces the resource requests tlirough sophisticated stack inspection and via the type safety of the language. exercises . consider the ring protection scheme in multics. if we were to implement the system calls of a typical operating system and store them in a segment associated with ring what should be the values stored in the ring field of the segment descriptor? what happens during a system call when a process executing in a higher numbered ring invokes a procedure in ring ? . the access control matrix could be used to determine whether a process can switch from say domain a to domain b and enjoy the access privileges of domain b. is this approach equivalent to including the access privileges of domain b in those of domain a? . consider a computer system in which ''computer games can be played by students only between p.m. and a.m. by faculty members between p.m. and a.m. and by the computer center staff at all times. suggest a scheme for implementing this policy efficiently. . what hardware features are needed in a computer system for efficient capability manipulation? can these be used for memory protection? . discuss the strengths and weaknesses of implementing an access matrix using access lists that are associated with objects. . discuss the strengths and weaknesses of implementing an access matrix using capabilities that are associated with domains. bibliographical notes . explain why a capability based system such as hydra provides greater flexibility than the ring protection scheme in enforcing protection policies. . discuss the need for rights amplification in hydra. how does this practice compare with the cross ring calls in a ring protection scheme? . what is the need to know principle? why is it important for a protection system to adhere to this principle? . discuss which of the following systems allow module designers to enforce the need to know principle. a. the multics ring protection scheme b. hydra's capabilities c. jvm's stack inspection scheme . describe how the java protection model would be sacrificed if a java program were allowed to directly alter the annotations of its stack frame. . how are the access matrix facility and the role based access control facility similar? how do they differ? . how does the principle of least privilege aid in the creation of protection systems? . how can systems that implement the principle of least privilege still have protection failures that lead to security violations? bibliographical notes the access matrix model of protection between domains and objects was developed by lampson and lampson . popek and saltzer and schroeder provided excellent surveys on the subject of protection. harrison et al. used a formal version of this model to enable them to prove properties of a protection system mathematically. the concept of a capability evolved from iliffe's and jodeit's codewords which were implemented in the rice university computer iliffe and jodeit . the term capability was introduced by dennis and horn . the hydra system was described by wulf et al. . the cap system was described by needham and walker . organick discussed the multics ring protection system. revocation was discussed by redell and fabry cohen and jefferson and ekanadham and bernstein . the principle of separation of policy and mechanism was advocated by the designer of hydra levin et al. . the confinement problem was first discussed by lampson and was further examined by lipner . the use of higher level languages for specifying access control was suggested first by morris who proposed the use of the s e a l and unseal operations discussed in section . . kieburtz and silberschatz kieburtz and silberschatz and mcgraw and andrews proposed various chapter protection language constructs for dealing with general dynamic resource nianagi ment schemes. jones and liskov considered how a static access control scheme can be incorporated in a programming language that supports abstract data types. the use of minimal operating system support to enforce protection was advocated by the exokernel project ganger et al. kaashoek et al. . extensibility of system code through language based protection mechanisms was discussed in bershad et al. b . other techniques for enforcing protection include sandboxing goldberg et al. and software fault isolation wahbe et al. b . the issues of lowering the overhead associated with protection costs and enabling user level access to networking devices were discussed in mccanne and jacobson and basu et al. . more detailed analyses of stack inspection including comparisons with other approaches to java security can be found in wallach et al. and gong etal. 
 in many applications ensuring the security of the computer system is worth considerable effort. large commercial systems containing payroll or other financial data are inviting targets to thieves. systems that contain data pertaining to corporate operations may be of interest to unscrupulous competitors. furthermore loss of such data whether by accident or fraud can seriously impair the ability of the corporation to function. in chapter we discussed mechanisms that the operating system can provide with appropriate aid from the hardware that allow users to protect chapter security their resources including programs and data. these mechanisms work well only as long as the users conform to the intended use of and access to these resources. we say that a system is secure if its resources are used and accessed as intended under all circumstances. unfortunately total security cannot be achieved. nonetheless we must have mechanisms to make security breaches a rare occurrence rather than the norm. security violations or misuse of the system can be categorized as intentional malicious or accidental. it is easier to protect against accidental misuse than against malicious misuse. for the most part protection mechanisms are the core of protection from accidents. the following list includes forms of accidental and malicious security violations. we should note that in our discussion of security we vise the terms intruder and cracker for those attempting to breach security. in addition a threat is the potential for a security violation stich as the discovery of a vulnerability whereas an attack is the attempt to break secvirity. breach of confidentiality. this type of violation involves unauthorized reading of data or theft of information . typically a breach of confidentiality is the goal of an intruder. capturing secret data from a system or a data stream such as credit card information or identity information for identity theft can result directly in money for the intruder. breach of integrity. this violation involves unauthorized modification of data. such attacks can for example result in passing of liability to an innocent party or modification of the source code of an important commercial application. breach of availability. this violation involves unauthorized destruction of data. some crackers would rather wreak havoc and gain status or bragging rights than gain financially. web site defacement is a common example of this type of security breach. theft of service. this violation involves unauthorized use of resources. for example an intruder or intrusion program may install a daemon on a system that acts as a file server. denial of service. this violation involves preventing legitimate use of the system. denial of service or dos attacks are sometimes accidental. the original internet worm turned into a dos attack when a bug failed to delay its rapid spread. we discuss dos attacks further in section . . . attackers use several standard methods in their attempts to breach security. the most common is masquerading in which one participant in a communication pretends to be someone else another host or another person . by masquerading attackers breach authentication the correctness of identification they can then can gain access that they would not normally be allowed or escalate their privileges obtain privileges to which they would not normally be entitled. another common attack is to replay a captured exchange of data. a replay attack consists of the malicious or fraudulent repeat of a valid data transmission. sometimes the replay comprises the entire attack for example in a repeat of a request to transfer money. but frequently it is done along with message modification again to escalate privileges. consider the damage that could be done if a request for authentication had a legitimate . the security problem user's information replaced with an unauthorized user's. yet another kind of attack is the man in the middle attack in which an attacker sits in the data flow of a communication masquerading as the sender to the receiver and vice versa. in a network communication a man in the middle attack may be preceded by a session hijacking in which an active communication session is intercepted. several attack methods are depicted in figure . . as we have already suggested absolute protection of the system from malicious abuse is not possible but the cost to the perpetrator can be made sufficiently high to deter most intruders. in some cases such as a denial ofservice attack it is preferable to prevent the attack but sufficient to detect the attack so that countermeasures can be taken. normal communication sender receiver attacker masquerading sender .f.o'ii receiver attacker man in the middle attacker figure . standard security attacks. chapter security to protect a system we must take security measures at four levels . physical. the site or sites containing the computer systems must be physically secured against armed or surreptitious entry by intruders. both the machine rooms and the terminals or workstations that have access to the machines must be secured. . human. authorizing users must be done carefully to assure that only appropriate users have access to the system. even authorized users however may be encouraged to let others use their access in exchange for a bribe for example . they may also be tricked into allowing access via social engineering. one type of social engineering attack is phishing. here a legitimate looking e mail or web page misleads a user into entering confidential information. another technique is dumpster diving a general term for attempting to gather information in order to gain unauthorized access to the computer by looking through trash finding phone books or finding notes containing passwords for example . these security problems are management and personnel issues not problems pertaining to operating systems. . operating system. the system must protect itself from accidental or purposeful security breaches. a runaway process could constitute an accidental denial of service attack. a query to a service could reveal passwords. a stack overflow could allow the launching of an unauthorized process. the list of possible breaches is almost endless. . network. much computer data in modern systems travels over private leased lines shared lines like the internet wireless connections or dial up lines. intercepting these data could be just as harmful as breaking into a computer and interruption of communications could constitute a remote denial of service attack diminishing users' use of and trust in the system. security at the first two levels must be maintained if operating system security is to be ensured. a weakness at a high level of security physical or human allows circumvention of strict low level operating system security measures. thus the old adage that a chain is as weak as its weakest link is especially true of system security. all of these aspects must be addressed for security to be maintained. furthermore the system must provide protection chapter to allow the implementation of security features. without the ability to authorize users and processes to control their access and to log their activities it would be impossible for an operating system to implement security measures or to run securely. hardware protection features are needed to support an overall protection scheme. for example a system without memory protection cannot be secure. new hardware features are allowing systems to be made more secure as we shall discuss. unfortunately little in security is straightforward. as intruders exploit security vulnerabilities security countermeasures are created and deployed. this causes intruders to become more sophisticated in their attacks. for example recent security incidents include the use of spyware to provide a conduit for spam through innocent systems we discuss this practice in . program threats section . . this cat and mouse game is likely to continue with more security tools needed to block the escalating intruder techniques and activities. in the remainder of this chapter we address security at the network and operating system levels. security at the physical and human levels although important is for the most part beyond the scope of this text. security within the operating system and between operating systems is implemented in several ways ranging from passwords for authentication through guarding against viruses to detecting intrusions. we start with an exploration of security threats. . program threats processes along with the kernel are the only means of accomplishing work on a computer. therefore writing a program that creates a breach of security or causing a normal process to change its behavior and create a breach is a common goal of crackers. in fact even most nonprogram security events have as their goal causing a program threat. for example while it is useful to log in to a system without authorization it is quite a lot more useful to leave behind a back door daemon that provides information or allows easy access even if the original exploit is blocked. in this section we describe common methods by which programs cause security breaches. note that there is considerable variation in the naming conventions of security holes and that we use the most common or descriptive terms. . . trojan horse many systems have mechanisms for allowing programs written by users to be executed by other users. if these programs are executed in a domain that provides the access rights of the executing user the other users may misuse these rights. a text editor program for example may include code to search the file to be edited for certain keywords. if any are found the entire file may be copied to a special area accessible to the creator of the text editor. a code segment that misuses its environment is called a trojan horse. long search paths such as are common on unix systems exacerbate the trojanhorse problem. the search path lists the set of directories to search when an ambiguous program name is given. the path is searched for a file of that name and the file is executed. all the directories in such a search path must be secure or a trojan horse could be slipped into the user's path and executed accidentally. for instance consider the use of the . character in a search path. the . tells the shell to include the current directory in the search. thus if a user has . in her search path has set her current directory to a friend's directory and enters the name of a normal system command the command may be executed from the friend's directory instead. the program would run within the user's domain allowing the program to do anything that the user is allowed to do including deleting the user's files for instance. a variation of the trojan horse is a program that emulates a login program. an unsuspecting user starts to log in at a terminal and notices that he has apparently mistyped his password. he tries again and is successful. what has happened is that his authentication key and password have been stolen by the login emulator which was left running on the terminal by the thief. chapter security the emulator stored away the password printed out a login error message and exited the user was then provided with a genuine login prompt. this type of attack can be defeated by having the operating system print a usage message at the end of an interactive session or by a non trappable key sequence such as the c o n t r o l a l t d e l e t e combination used by all modern windows operating systems. another variation on the trojan horse is spyware. spyware sometimes accompanies a program that the user has chosen to install. most frequently it comes along with freeware or shareware programs but sometimes it is included with commercial software. the goal of spyware is to download ads to display on the user's system create pop up browser windows when certain sites are visited or capture information from the user's system and return it to a central site. this latter mode is an example of a general category of attacks known as covert channels in which surreptitious communication occurs. as a current example the installation of an innocuous seeming program on a windows system could result in the loading of a spyware daemon. the spyware could contact a central site be given a message and a list of recipient addresses and deliver the spam message to those users from the windows machine. this process continues until the user discovers the spyware. frequently the spyware is not discovered. in it was estimated that percent of spam was being delivered by this method. this theft of service is not even considered a crime in most countries! spyware is a micro example of a macro problem violation of the principle of least privilege. under most circumstances a user of an operating system does not need to install network daemons. such daemons are installed via two mistakes. first a user may run with more privileges than necessary for example as the administrator allowing programs that she runs to have more access to the system than is necessary. this is a case of human error a common security weakness. second an operating system may allow by default more privileges than a normal user needs. this is a case of poor operating system design decisions. an operating system and indeed software in general should allow fine grained control of access and security but it must also be easy to manage and understand. inconvenient or inadequate security measures are bound to be circumvented causing an overall weakening of the security they were designed to implement. . . trap door the designer of a program or system might leave a hole in the software that only she is capable of using. this type of security breach or trap door was shown in the movie war games. for instance the code might check for a specific user id or password and it might circumvent normal security procedures. programmers have been arrested for embezzling from banks by including rounding errors in their code and having the occasional half cent credited to their accounts. this account crediting can add up to a large amount of money considering the number of transactions that a large bank executes. a clever trap door could be included in a compiler. the compiler could generate standard object code as well as a trap door regardless of the source code being compiled. this activity is particularly nefarious since a search of the source code of the program will not reveal any problems. only the source code of the compiler would contain the information. . program threats trap doors pose a difficult problem because to detect them we have to analyze all the source code for all components of a system. given that software systems may consist of millions of lines of code this analysis is not done frequently and frequently it is not done at all! . . logic bomb consider a program that initiates a security incident only under certain circumstances. it would be hard to detect because under normal operations there would be no security hole. however when a predefined set of parameters were met the security hole would be created. this scenario is known as a logic bomb. a programmer for example might write code to detect if she is still employed if that check failed a daemon could be spawned to allow remote access or code could be launched to cause damage to the site. . . stack and buffer overflow the stack or buffer overflow attack is the most common way for an attacker outside the system on a network or dial up connection to gain unauthorized access to the target system. an authorized user of the system may also use this exploit for privilege escalation. essentially the attack exploits a bug in a program. the bug can be a simple case of poor programming in which the programmer neglected to code bounds checking on an input field hi this case the attacker sends more data than the program was expecting. using trial and error or by examining the source code of the attacked program if it is available the attacker determines the vulnerability and writes a program to do the following . overflow an input field command line argument or input buffer for example on a network daemon until it writes into the stack. . overwrite the current return address on the stack with the address of the exploit code loaded in step . . write a simple set of code for the next space in the stack that includes the commands that the attacker wishes to execute for instance spawn a shell. the result of this attack program's execution will be a root shell or other privileged command execution. for instance if a web page form expects a user name to be entered into a field the attacker could send the user name plus extra characters to overflow the buffer and reach the stack plus a new return address to load onto the stack plus the code the attacker wants to run. when the buffer reading subroutine returns from execution the return address is the exploit code and the code is run. let's look at a buffer overflow exploit in more detail. consider the simple c program shown in figure . . this program creates a character array of size buffer size and copies the contents of the parameter provided on the command line argv l . as long as the size of this parameter is less than buffer size we need one byte to store the null terminator this program works properly. but consider what happens if the parameter provided on the chapter security include stdio.h define buffer size int main int argc char argv char buffer buffer size if argc return else strcpy buffer argv return figure . c program with buffer overflow condition. command line is longer than buffer size. in this scenario the strcpy function will begin copying from argv until it encounters a null terminator or until the program crashes. thus this program suffers from a potential buffer overflow problem in which copied data overflow the buffer array. note that a careful programmer could have performed bounds checking on the size of argv by using the strncpy function rather than strcpy replacing the line strcpy buffer argv l with strncpy buffer argv l sizeof buf f e r l . unfortunately good bounds checking is the exception rather than the norm. furthermore lack of bounds checking is not the only possible cause of the behavior of the program in figure . . the program could instead have been carefully designed to compromise the integrity of the system. we now consider the possible security vulnerabilities of a buffer overflow. when a function is invoked in a typical computer architecture the variables defined locally to the function sometimes known as automatic variables the parameters passed to the function and the address to which control returns once the function exits are stored in a stack frame. the layout for a typical stack bottom frame pointer return address saved frame pointer grows automatic variables parameter s top figure . the layout for a typical stack frame. . program threats frame is shown in figure . . examining the stack frame from top to bottom we first see the parameters passed to the function followed by any automatic variables declared in the function. we next see the frame pointer which is the address of the beginning of the stack frame. finally we have the return address which specifies where to return control once the function exits. the frame pointer must be saved on the stack as the value of the stack pointer can vary during the function call the saved frame pointer allows relative access to parameters and automatic variables. given this standard memory layout a cracker could execute a bufferoverflow attack. her goal is to replace the return address in the stack frame so that it now points to the code segment containing the attacking program. the programmer first writes a short code segment such as the following include stdio.h int mainfint argc char argv execvpt'' bin sh'' 'v bin sh'' null return using the execvpo system call this code segment creates a shell process. if the program being attacked runs with system wide permissions this newly created shell will gain complete access to the system. of course the code segment could do anything allowed by the privileges of the attacked process. this code segment is then compiled so that the assembly language instructions can be modified. the primary modification is to remove unnecessary features in the code thereby reducing the code size so that it can fit into a stack frame. this assembled code fragment is now a binary sequence that will be at the heart of the attack. refer again to the program shown in figure . . let's asstime that when the maino function is called in that program the stack frame appears as shown in figure . a . using a debugger the programmer then finds the address of buffer in the stack. that address is the location of the code the attacker wants executed so the binary sequence is appended with the necessary amount of no op instructions for no operation to fill the stack frame up to the location of the return address and the location of buffer the new return address is added. the attack is complete when the attacker gives this constructed binary sequence as input to the process. the process then copies the binary sequence from argv to position buffer in the stack frame. now when control returns from maino instead of returning to the location specified by the old value of the return address we return to the modified shell code which runs with the access rights of the attacked process! figure . b contains the modified shell code. there are many ways to exploit potential buffer overflow problems. in this example we considered the possibility that the program being attacked the code shown in figure . ran with system wide permissions. however the code segment that runs once the value of the return address has been modified might perform any type of malicious act such as deleting files opening network ports for further exploitation and so on. chapter security return address address of mo li jed shell code ii no op copied a b figure . hypothetical stack frame for figure . a before and b after. this example buffer overflow attack reveals that considerable knowledge and programming skill are needed to recognize exploitable code and then to exploit it. unfortunately it does not take great programmers to launch security attacks. rather one cracker can determine the bug and then write an exploit. anyone with rudimentary computer skills and access to the exploit a so called script kiddie can then try to launch the attack at target systems. the buffer overflow attack is especially pernicious because it can be run between systems and can travel over allowed communication channels. such attacks can occur within protocols that are expected to be used to communicate with the target machine and they can therefore be hard to detect and prevent. they can even bypass the security added by firewalls section . . one solution to this problem is for the cpu to have a feature that disallows execution of code in a stack section of memory. recent versions of sun's sparc chip include this setting and recent versions of solaris enable it. the return address of the overflowed routine can still be modified but when the return address is within the stack and the code there attempts to execute an exception is generated and the program is halted with an error. recent versions of amd and intel x chips include the nx feature to prevent this type of attack. the use of the feature is supported in several x operating systems including linux and windows xp sp . the hardware implementation involves the use of a new bit in the page tables of the cpus. this bit marks the associated page as nonexecutable disallowing instructions to be read from it and executed. as this feature becomes prevalent buffer overflow attacks should greatly dimmish. . . viruses another form of program threat is a virus. viruses are self replicating and are designed to infect other programs. they can wreak havoc in a system by modifying or destroying files and causing system crashes and program . program threats malfunctions. a virus is a fragment of code embedded in a legitimate program. as with most penetration attacks viruses are very specific to architectures operating systems and applications. viruses are a particular problem for users of pcs. unix and other multiuser operating systems generally are not susceptible to viruses because the executable programs are protected from writing by the operating system. even if a virus does infect such a program its powers usually are limited because other aspects of the system are protected. viruses are usually borne via email with spam the most common vector. they can also spread when users download viral programs from internet file sharing services or exchange infected disks. another common form of virus transmission uses microsoft office files such as microsoft word documents. these documents can contain macros or visual basic programs that programs in the office suite word powerpoint and excel will execute automatically. because these programs run under the user's own account the macros can run largely unconstrained for example deleting user files at will . commonly the virus will also e mail itself to others in the user's contact list. here is a code sample that shows the simplicity of writing a visual basic macro that a virus could use to format the hard drive of a windows computer as soon as the file containing the macro was opened sub autoopen dim ofs set ofs createobject ''scripting.filesystemobject'' vs shell ''c command.com k format c '' vbhide end sub how do viruses work? once a virus reaches a target machine a program known as a virus dropper inserts the virus onto the system. the virus dropper is usually a trojan horse executed for other reasons but installing the virus as its core activity. once installed the virus may do any one of a number of things. there are literally thousands of viruses but they fall into several main categories. note that many viruses belong to more than one category. file. a standard file virus infects a system by appending itself to a file. it changes the start of the program so that execution jumps to its code. after it executes it returns control to the program so that its execution is not noticed. file viruses are sometimes known as parasitic viruses as they leave no full files behind and leave the host program still functional. boot. a boot virus infects the boot sector of the system executing every time the system is booted and before the operating system is loaded. it watches for other bootable media that is floppy disks and infects them. these viruses are also known as memory viruses because they do not appear in the file system. figure . shows how a boot virus works. macro. most viruses are written in a low level language such as assembly or c. macro viruses are written in a high level language such as visual basic. these viruses are triggered when a program capable of executing the macro is run. for example a macro virus could be contained in a spreadsheet file. chapter security virus copies buo' j sector to unusprt location x virus replaces original boot block with itself whenever new it btocks ariy aftenfi dt df thisategic b rrtt to removable r w d sk other pifdgrams o yi rite the is installed it infects u p boot sector n n certain bate that as well figure . a boot sector computer virus. source code. a source code virus looks for source code and modifies it to include the virus and to help spread the virus. polymorphic. this virus changes each time it is installed to avoid detection by antivirus software. the changes do not affect the virus's functionality but rather change the virus's signature. a virus signature is a pattern that can be used to identify a virus typically a series of bytes that make up the virus code. encrypted. an encrypted virus includes decryption code along with the encrypted virus again to avoid detection. the virus first decrypts and then executes. stealth. this tricky virus attempts to avoid detection by modifying parts of the system that could be used to detect it. for example it could modify the read system call so that if the file it has modified is read the original form of the code is returned rather than the infected code
 tunneling. this virus attempts to bypass detection by an antivirus scanner by installing itself in the interrupt handler chain. similar viruses install themselves in device drivers. multipartite. a virus of this type is able to infect multiple parts of a system including boot sectors memory and files. this makes it difficult to detect and contain. armored. an armored virus is coded to make itself hard for antivirus researchers to unravel and understand. it can also be compressed to avoid detection and disinfection. in addition virus droppers and other full files that are part of a virus infestation are frequently hidden via file attributes or unviewable file names. this vast variety of viruses is likely to continue to grow. in fact in a new and widespread virus was detected. it exploited three separate bugs for its operation. this virus started by infecting hundreds of windows servers including many trusted sites running microsoft internet information server iis . any vulnerable microsoft explorer web browser visiting those sites received a browser virus with any download. the browser virus installed several back door programs including a keystroke logger which records all things entered on the keyboard including passwords and credit card numbers . it also installed a daemon to allow unlimited remote access by an intruder and another that allowed an intruder to route spam through the infected desktop computer. generally viruses are the most disruptive security attack and because they are effective they will continue to be written and to spread. among the active debates within the computing community is whether a monoculture in which many systems run the same hardware operating system and or application software is increasing the threat of and damage caused by security intrusions. within the debate is the issue of whether or not there even exists a monoculture today consisting of microsoft products . . system and network threats program threats typically use a breakdown in the protection mechanisms of a system to attack programs. in contrast system and network threats involve the abuse of services and network connections. sometimes a system and network attack is used to launch a program attack and vice versa. system and network threats create a situation in which operating system resources and user files are misused. here we discuss some examples of these threats including worms port scanning and denial of service attacks. it is important to note that masquerading and replay attacks are also common over networks between systems. in fact these attacks are more effective and harder to counter when multiple systems are involved. for example within a computer the operating system usually can determine the sender and receiver of a message. even if the sender changes to the id of someone else there might be a record of that id change. when multiple systems are involved especially systems controlled by attackers then such tracing is much harder. chapter security the generalization is that sharing secrets to prove identity and as keys to encryption is required for authentication and encryption and that is easier in environments such as a single operating system in which secure sharing methods exist. these methods include shared memory and interprocess communications. creating secure communication and authentication is discussed in sections . and . . . . worms a worm is a process that uses the spawn mechanism to ravage system performance. the worm spawns copies of itself using up system resources and perhaps locking out all other processes. on computer networks worms are particularly potent since they may reproduce themselves among systems and thus shut down an entire network. such an event occurred in to unix systems on the internet causing millions of dollars of lost system and system administrator time. at the close of the workday on november robert tappan morris jr. a first year cornell graduate student unleashed a worm program on one or more hosts connected to the internet. targeting sun microsystems' sun workstations and vax computers running variants of version bsd unix the worm quickly spread over great distances within a few hours of its release it had consumed system resources to the point of bringing down the infected machines. although robert morris designed the self replicating program for rapid reproduction and distribution some of the features of the unix networking environment provided the means to propagate the worm throughout the system. it is likely that morris chose for initial infection an internet host left open for and accessible to outside users. from there the worm program exploited flaws in the unix operating system's security routines and took advantage of unix utilities that simplify resource sharing in local area networks to gain unauthorized access to thousands of other connected sites. morris's methods of attack are outlined next. rsh attack finger attack grappling y sendmail attack hook . r e q u e s t for worm wqrrti worm sent worm target system infected system figure . the morris internet worm. . system and network threats the worm was made up of two programs a grappling hook also called a bootstrap or vector program and the main program. named .c the grappling hook consisted of lines of c code compiled and run on each machine it accessed. once established on the computer system under attack the grappling hook connected to the machine where it originated and uploaded a copy of the main worm onto the hooked system figure . . the main program proceeded to search for other machines to which the newly infected system could connect easily. in these actions morris exploited the unix networking utility rsh for easy remote task execution. by setting up special files that list host login name pairs users can omit entering a password each time they access a remote account on the paired list. the worm searched these special files for site names that would allow remote execution without a password. where remote shells were established the worm program was uploaded and began executing anew. the attack via remote access was one of three infection methods built into the worm. the other two methods involved operating system bugs in the unix finger and sendmail programs. the finger utility functions as an electronic telephone directory the command finger user name hostname returns a person's real and login names along with other information that the user may have provided such as office and home address and telephone number research plan or clever quotation. finger runs as a background process or daemon at each bsd site and responds to queries throughout the internet. the worm executed a buffer overflow attack on f inger. the program queried finger with a byte string crafted to exceed the buffer allocated for input and to overwrite the stack frame. instead of returning to the main routine it was in before morris's call the finger daemon was routed to a procedure within the invading byte string now residing on the stack. the new procedure executed bin sh which if successful gave the worm a remote shell on the machine under attack. the bug exploited in sendmail also involved using a daemon process for malicious entry sendmail sends receives and routes electronic mail. debugging code in the utility permits testers to verify and display the state of the mail system. the debugging option was useful to system administrators and was often left on. morris included in his attack arsenal a call to debug that instead of specifying a user address as would be normal in testing issued a set of commands that mailed and executed a copy of the grappling hook program. once in place the main worm undertook systematic attempts to discover user passwords. it began by trying simple cases of no password or of passwords constructed of account user name combinations then used comparisons with an internal dictionary of favorite password choices and then went to the final stage of trying each word in the standard unix on line dictionary as a possible password. this elaborate and efficient three stage password cracking algorithm enabled the worm to gain access to other user accounts on the infected system. the worm then searched for rsh data files in these newly broken accounts and used them as described previously to gain access to user accounts on remote systems. chapter security with each new access the worm program searched for already active copies of itself. if it found one the new copy exited except in every seventh instance. had the worm exited on all duplicate sightings it might have remained undetected. allowing every seventh duplicate to proceed possibly to confound efforts to stop its spread by baiting with fake worms created a wholesale infestation of sun and vax systems on the internet. the very features of the unix network environment that assisted the worm's propagation also helped to stop its advance. ease of electronic communication mechanisms to copy source and binary files to remote machines and access to both source code and human expertise allowed cooperative efforts to develop solutions quickly. by the evening of the next day november methods of halting the invading program were circulated to system administrators via the internet. within days specific software patches for the exploited security flaws were available. why did morris unleash the worm? the action has been characterized as both a harmless prank gone awry and a serious criminal offense. based on the complexity of starting the attack it is unlikely that the worm's release or the scope of its spread was unintentional. the worm program took elaborate steps to cover its tracks and to repel efforts to stop its spread. yet the program contained no code aimed at damaging or destroying the systems on which it ran. the author clearly had the expertise to include such commands in fact data structures were present in the bootstrap code that could have been used to transfer trojan horse or virus programs. the behavior of the program may lead to interesting observations but it does not provide a sound basis for inferring motive. what is not open to speculation however is the legal outcome a federal court convicted morris and handed down a sentence of three years' probation hours of community service and a fine. morris's legal costs probably exceeded . security experts continue to evaluate methods to decrease or eliminate worms. a more recent event though shows that worms are still a fact of life on the internet. it also shows that as the internet grows the damage that even harmless worms can do also grows and can be significant. this example occurred during august . the fifth version of the sobig worm more properly known as 'iw .sobig.f mm was released by persons at this time unknown. it was the fastest spreading worm released to date at its peak infecting hundreds of thousands of computers and one in seventeen e mail messages on the internet. it clogged e mail inboxes slowed networks and took a huge number of hours to clean up. sobig.f was launched by being uploaded to a pornography newsgroup via an account created with a stolen credit card. it was disguised as a photo. the virus targeted microsoft windows systems and used its own smtp engine to e mail itself to all the addresses found on an infected system. it used a variety of subject lines to help avoid detection including thank you! ''your details and re approved. it also used a random address on the host as the from address making it difficult to determine from the message which machine was the infected source. sobig.f included an attachment for the target e mail reader to click on again with a variety of names. if this payload was executed it stored a program called w nppr .exe in the default windows directory along with a text file. it also modified the windows registry. . system and network threats the code included in the attachment was also programmed to periodically attempt to connect to one of twenty servers and download and execute a program from them. fortunately the servers were disabled before the code could be downloaded. the content of the program from these servers has not yet been determined. if the code was malevolent untold damage to a vast number of machines could have resulted. . . port scanning port scanning is not an attack but rather is a means for a cracker to detect a system's vulnerabilities to attack. port scanning typically is automated involving a tool that attempts to create a tcp ip connection to a specific port or a range of ports. for example suppose there is a known vulnerability or bug in sendmail. a cracker could launch a port seamier to try to connect to say port of a particular system or a range of systems. if the connection was successful the cracker or tool could attempt to communicate with the answering service to determine if it was indeed sendmail and if so if it was the version with the bug. now imagine a tool in which each bug of every service of every operating system was encoded. the tool could attempt to connect to every port of one or more systems. for every service that answered it could try to use each known bug. frequently the bugs are buffer overflows allowing the creation of a privileged command shell on the system. from there of course the cracker could install trojan horses back door programs and so on. there is no such tool but there are tools that perform subsets of that functionality. for example nmap from http www.insecure.org nmap is a very versatile open source utility for network exploration and security auditing. when pointed at a target it will determine what services are running including application names and versions. it can determine the host operating system. it can also provide information about defenses such as what firewalls are defending the target. it does not exploit any known bugs. nessus from http www.nessus.org performs a similar function but it has a database of bugs and their exploits. it can scan a range of systems determine the services running on those systems and attempt to attack all appropriate bugs. it generates reports about the results. it does not perform the final step of exploiting the found bugs but a knowledgeable cracker or a script kiddie could. because port scans are detectable see . . they frequently are launched from zombie systems. such systems are previously compromised independent systems that are serving their owners while being used for nefarious purposes including denial of service attacks and spam relay. zombies make crackers particularly difficult to prosecute because determining the source of the attack and the person that launched it is challenging. this is one of many reasons that inconsequential systems should also be secured not just systems containing valuable information or services. . . denial of service as mentioned earlier dos attacks are aimed not at gaining information or stealing resources but rather at disrupting legitimate use of a system or facility. most denial of service attacks involve systems that the attacker has chapter security not penetrated. indeed launching an attack that prevents legitimate use is frequently easier than breaking into a machine or facility. denial of service attacks are generally network based. they fall into two categories. the first case is an attack that uses so many facility resources that in essence no useful work can be done. for example a web site click could download a java applet that proceeds to vise all available cpu time or to infinitely pop up windows. the second case involves disrupting the network of the facility. there have been several successful denial of service attacks of this kind against major web sites. they result from abuse of some of the fundamental functionality of tcp ip. for instance if the attacker sends the part of the protocol that says i want to start a tcp connection ' but never follows with the standard the connection is now complete the result can be partially started tcp sessions. enough of these sessions can eat up all the network resources of the system disabling any further legitimate tcp connections. such attacks which can last hours or days have caused partial or full failure of attempts to use the target facility these attacks are usually stopped at the network level until the operating systems can be updated to reduce their vulnerability. generally it is impossible to prevent denial of service attacks. the attacks use the same mechanisms as normal operation. even more difficult to prevent and resolve are distributed denial of service attacks ddos . these attacks are launched from multiple sites at once toward a common target typically by zombies. sometimes a site does not even know it is under attack. it can be difficult to determine whether a system slowdown is just a surge in system use or an attack. consider that a successful advertising campaign that greatly increases traffic to a site could be considered a ddos. there are other interesting aspects of dos attacks. for example programmers and systems managers need to fully understand the algorithms and technologies they are deploying. if an authentication algorithm locks an account for a period of time after several incorrect attempts then an attacker could cause all authentication to be blocked by purposefully causing incorrect attempts to all accounts. similarly a firewall that automatically blocks certain kinds of traffic could be induced to block that traffic when it should not. finally computer science classes are notorious sources of accidental system dos attacks. consider the first programming exercises in which students learn to create subprocesses or threads. a common bug involves spawning subprocesses infinitely. the system's free memory and cpu resources don't stand a chance
 there are many defenses against computer attacks running the gamut from methodology to technology. the broadest tool available to system designers and users is cryptography. in this section we discuss the details of crypography and its use in computer security. in an isolated computer the operating system can reliably determine the sender and recipient of all interprocess communication since it controls all communication channels in the computer. in a network of computers the . cryptography as a security tool situation is quite different. a networked computer receives bits fivm the wire with no immediate and reliable way of determining what machine or application sent those bits. similarly the computer sends bits onto the network with no way of knowing who might eventually receive them. commonly network addresses are used to infer the potential senders and receivers of network messages. network packets arrive with a source address such as an ip address. and when a computer sends a message it names the intended receiver by specifying a destination address. however for applications where security matters we are asking for trouble if we assume that the source or destination address of a packet reliably determines who sent or received that packet. a rogue computer can send a message with a falsified source address and numerous computers other than the one specified by the destination address can and typically do receive a packet. for example all of the routers on the way to the destination will receive the packet too. how then is an operating system to decide whether to grant a request when it cannot trust the named source of the request? and how is it supposed to provide protection for a request or data when it cannot determine who will receive the response or message contents it sends over the network? it is generally considered infeasible to build a network of any scale in which the source and destination addresses of packets can be trusted in this sense. therefore the only alternative is somehow to eliminate the need to trust the network. this is the job of cryptography. abstractly cryptography is used to constrain the potential senders and or receivers of a message. modern cryptography is based on secrets called keys that are selectively distributed to computers in a network and used to process messages. cryptography enables a recipient of a message to verify that the message was created by some computer possessing a certain key the key is the source of the message. similarly a sender can encode its message so that only a computer with a certain key can decode the message so that the key becomes the destination. unlike network addresses however keys are designed so that it is not computationally feasible to derive them from the messages they were used to generate or from any other public information. thus they provide a much more trustworthy means of constraining senders and receivers of messages. note that cryptography is a field of study unto itself with large and small complexities and subtleties. here we explore the most important aspects of the parts of cryptography that pertain to operating systems. . . encryption because it solves a wide variety of communication security problems encryption is used frequently in many aspects of modern computing. encryption is a means for constraining the possible receivers of a message. an encryption algorithm enables the sender of a message to ensure that only a computer possessing a certain key can read the message. encryption of messages is an ancient practice of course and there have been many encryption algorithms dating back to before caesar. in this section we describe important modern encryption principles and algorithms. figure . shows an example of two users communicating securely over an insecure channel. we refer to this figure throughout the section. note that the chapter security write message m attacker figure . a secure communication over an insecure medium. key exchange can take place directly between the two parties or via a trusted third party that is a certificate authority as discussed in section . . . . an encryption algorithm consists of the following components a set k of keys. a set m of messages. a set c of ciphertexts. a function e k m c . that is for each k e k e k is a function for generating ciphertexts from messages. both e and e k for any k should be efficiently computable functions. a function d k c m . that is for each k e k d k is a function for generating messages from ciphertexts. both d and d k for any k should be efficiently computable functions. an encryption algorithm must provide this essential property given a ciphertext c e c a computer can compute m such that e k m c only if it possesses d k . thus a computer holding d k can decrypt ciphertexts to the plaintexts used to produce them but a computer not holding d k cannot decrypt ciphertexts. since ciphertexts are generally exposed for example sent . cryptography as a security tool on the network it is important that it be infeasible to derive d k from the ciphertexts. there are two main types of encryption algorithms symmetric and asymmetric. we discuss both types in the following sections. . . . symmetric encryption in a symmetric encryption algorithm the same key is used to encrypt and to decrypt. that is e k can be derived from d k and vice versa. therefore the secrecy of e k must be protected to the same extent as that of d k . for the past years or so the most commonly used symmetric encryption algorithm in the united states for civilian applications has been the dataencryption standard des adopted by the national institute of standards and technology nist . des works by taking a bit value and a bit key and performing a series of transformations. these transformations are based on substitution and permutation operations as is generally the case for symmetric encryption transformations. some of the transformations are black box transformations in that their algorithms are hidden. in fact these so called s boxes are classified by the united states government. messages longer than bits are broken into bit chunks and a shorter block is padded to fill out the block. because des works on a chunk of bits at a time is a known as a block cipher. if the same key is used for encrypting an extended amount of data it becomes vulnerable to attack. consider for example that the same source block would result in the same ciphertext if the same key and encryption algorithm were used. therefore the chunks are not just encrypted but also xored with the previous ciphertext block before encryption. this is known as cipher block chaining. des is now considered insecure for many applications because its keys can be exhaustively searched with moderate computing resources. rather than giving up on des though nist created a modification called triple des in which the des algorithm is repeated three times two encryptions and one decryption on the same plaintext using two or three keys for example c e k d k e ki m . when three keys are used the effective key length is bits. triple des is in widespread use today. in nist adopted a new encryption algorithm called the advanced encryption standard aes to replace des. aes is another symmetric block cipher. it can use key lengths of and bits and works on bit blocks. it works by performing to rounds of transformations on a matrix formed from a block. generally the algorithm is compact and efficient. there are several other symmetric block encryption algorithms in use today that bear mentioning. the twofish algorithm is fast compact and easy to implement. it can use a variable key length of up to bits and works on bit blocks. rc can vary in key length number of transformations and block size. because it uses only basic computational operations it can run on a wide variety of cpus. rc is perhaps the most common stream cipher. a stream cipher is designed to encrypt and decrypt a stream of bytes or bits rather than a block. this is useful when the length of a communication would make a block cipher too slow. the key is input into a pseudo random bit generator which is an algorithm that attempts to produce random bits. the output of the generator chapter security when fed a key is a keystream. a keystream is an infinite set of keys that can be vised for the input plaintext stream. rc is used in encrypting steams of data such as in wep the wireless lan protocol. it is also used in communications between web browsers and web servers as we discuss below. unfortunately rc as used in wep ieee standard . has been found to be breakable in a reasonable amount of computer time. in fact rc itself has vulnerabilities. . . . asymmetric encryption in an asymmetric encryption algorithm there are different encryption and decryption keys. here we describe one such algorithm known as rsa after the names of its inventors rivest shamir and adleman. the rsa cipher is a block cipher public key algorithm and is the most widely used asymmetrical algorithm. asymmetrical algorithms based on elliptical curves are gaining ground however because the key length of such an algorithm can be shorter for the same amount of cryptographic strength. it is computationally infeasible to derive d q n from e kc a and so e kc iv need not be kept secret and can be widely disseminated thus e ke n or just kt. is the public key and d kli n or just kj is the private key. a is the product of two large randomly chosen prime numbers p and q for example p andtj are bits each . the encryption algorithm is e kc n m mke mod jv where kl. satisfies kl.kj mod p q . the decryption algorithm is then d kd n c ck modn. an example using small values is shown in figure . . in this example we makep andq . we then calculate n and p l j l . we next select ke relatively prime to and yielding . finally we calculate kd such that kekd mod yielding . we how have our keys the public key kt n and the private key kj n . encrypting the message with the public key results in the message which is then decoded by the receiver via the private key. the use of asymmetric encryption begins with the publication of the public key of the destination. for bidirectional communication the source also must publish its public key. publication can be as simple as handing over an electronic copy of the key or it can be more complex. the private key or secret key must be jealously guarded as anyone holding that key can decrypt any message created by the matching public key. we should note that the seemingly small difference in key use between asymmetric and symmetric cryptography is quite large in practice. asymmetric cryptography is based on mathematical functions rather than transformations making it much more computationally expensive to execute. it is much faster for a computer to encode and decode ciphertext by using the usual symmetric algorithms than by using asymmetric algorithms. why then use an asymmetric algorithm? in truth these algorithms are not used for generalpurpose encryption of large amounts of data. however they are used not only for encryption of small amounts of data but also for authentication confidentiality and key distribution as wre show in the following sections. . . . authentication we have seen that encryption offers a way of constraining the set of possible receivers of a message. constraining the set of potential senders of a message is . cryptography as a security tool write message x encryption key k decryption key k i read figure . encryption and decryption using rsa asymmetric cryptography. called authentication. authentication is thus complementary to encryption. in fact sometimes their functions overlap. consider that an encrypted message can also prove the identity of the sender. for example if d kd n e ke n m produces a valid message then we know that the creator of the message must hold kc. authentication is also useful for proving that a message has not been modified. in this section we discuss authentication as a constraint on possible receivers of a message. note that this sort of authentication is similar to but distinct from user authentication which we discuss in section . . an authentication algorithm consists of the following components a set k of keys. a set m of messages. a set a of authenticators. a function s k m a . that is for each k e k s k is a function for generating authenticators from messages. both s and s k for any k should be efficiently computable functions. chapter security a function v x mxyl true false . that is for each k e k v k is a function for verifying authenticators on messages. both v and v k for any k should be efficiently computable functions. the critical property that an authentication algorithm must possess is this for a message m a computer can generate an authenticator a e a such that v k ni.a true only if it possesses s k . thus a computer holding s k can generate authenticators on messages so that any other computer possessing v k can verify them. however a computer not holding s k cannot generate authenticators on messages that can be verified using v k . since authenticators are generally exposed for example they are sent on the network with the messages themselves it must not be feasible to derive s k from the authenticators. just as there are two types of encryption algorithms there are two main varieties of authentication algorithms. the first step in understanding these algorithms is to explore hash functions. a hash function creates a small fixedsized block of data known as a message digest or hash value from a message. hash functions work by taking a message in n bit blocks and processing the blocks to produce an n bit hash. h must be collision resistant on m that is it must be infeasible to find an m' m such that h m h m' . now if h m h m' we know that ni m i that is we know that the message has not been modified. common message digest functions include md which produces a bit hash and sha l which outputs a bit hash. message digests are useful for detecting changed messages but are not useful as authenticators. for example h m can be sent along with a message but if h is known then someone could modify m and recompute h m and the message modification would not be detected. therefore an authentication algorithm takes the message digest and encrypts it. the first type of authentication algorithm uses symmetric encryption. in a message authentication code mac a cryptographic checksum is generated from the message using a secret key. knowledge of v k and knowledge of s k are equivalent one can be derived from the other so k must be kept secret. a simple example of a mac defines s k m f k h m where is a function that is one way on its first argument that is k cannot be derived from f k h m . because of the collision resistance in the hash function we are reasonably assured that no other message could create the same mac. a suitable verification algorithm is then v k m a f k m a . note that k is needed to compute both s k and v k so anyone able to compute one can compute the other. the second main type of authentication algorithm is a digital signature algorithm and the authenticators thus produced are called digital signatures. in a digital signature algorithm it is computationally infeasible to derive s rs from v kv in particular v is a one way function. thus kv is the public key and ks is the private key. consider as an example the rsa digital signature algorithm. it is similar to the rsa encryption algorithm but the key use is reversed. the digital signature of a message is derived by computing s ks m h m k mod n. the key ks again is a pair d n where n is the product of two large randomlychosen prime numbers p and q. the verification algorithm is then v kv m a ak mod n h m where kv satisfies kvks mod p l q . . cryptography as a security tool if encryption can prove the identity of the sender of a message then why do we need separate authentication algorithms? there are three primary reasons. authentication algorithms generally require fewer computations with the notable exception of rsa digital signatures . over large amounts of plaintext this efficiency can make a huge difference in resource use and the time needed to authenticate a message. an authenticator of a message is almost always shorter than the message and its ciphertext. this improves space use and transmission time efficiency. sometimes we want authentication but not confidentiality. for example a company could provide a software patch and could sign that patch to prove that it came from the company and that it hasn't been modified. authentication is a component of many aspects of security for example it is the core of nonrepudiation which supplies proof that an entity performed an action. a typical example of nonrepudiation involves the filling out of electronic forms as an alternative to the signing of paper contracts. nonrepudiation assures that a person filling out an electronic form cannot deny that he did so. . . . key distribution certainly a good part of the battle between cryptographers those inventing ciphers and cryptanalysts those trying to break them involves keys. with symmetric algorithms both parties need the key and no one else should have it. the delivery of the symmetric key is a huge challenge. sometimes it is performed out of band say via a paper document or a conversation. these methods do not scale well however. also consider the key management challenge. suppose a user wanted to communicate with n other users privately. that user would need jv keys and for more security would need to change those keys frequently. these are the very reasons for efforts to create asymmetric key algorithms. k ot only can the keys be exchanged in public but a given user needs only one private key no matter how many other people she wants to communicate with. there is still the matter of managing a public key per party to be communicated with but since public keys need not be secured simple storage can be used for that key ring. unfortunately even the distribution of public keys requires some care. consider the man in the middle attack shown in figure . . here the person who wants to receive an encrypted message sends out his public key but an attacker also sends her bad public key which matches her private key . the person who wants to send the encrypted message knows no better and so uses the bad key to encrypt the message. the attacker then happily decrypts it. the problem is one of authentication what we need is proof of who or what owns a public key. one way to solve that problem involves the use of digital certificates. a digital certificate is a public key digitally signed by a trusted party. the trusted party receives proof of identification from some entity and certifies that the public key belongs to that entity. but how do we chapter security write message m encryption key kbad decryption i decryption key kbad j algorithm attacker read messagemdecryption keykd figure . a man in the middle attack on asymmetric cryptography. know we can trust the certifier? these certificate authorities have their public keys included within web browsers and other consumers of certificates before they are distributed. these certificate authorities can then vouch for other authorities digitally signing the public keys of these other authorities and so on creating a web of trust. the certificates can be distributed in a standard x. digital certificate format that can be parsed by computer. this scheme is used for secure web communication as we discuss in section . . . . . implementation of cryptography network protocols are typically organized in layers each layer acting as a client to the one below it. that is when one protocol generates a message to send to its protocol peer on another machine it hands its message to the protocol below it in the network protocol stack for delivery to its peer on that machine. for example in an ip network tcp a transport layer protocol acts as a client of ip a network layer protocol tcp packets are passed down to ip for delivery to the tcp peer at the other end of the tcp connection. ip encapsulates the tcp . cryptography as a security tool packet in an ip packet which it similarly passes down to the data link layer t be transmitted across the network to its ip peer on the destination computer. this ip peer then delivers the tcp packet up to the tcp peer on that machine. all in all the iso reference model which has been almost universally adopted as a model for data networking defines seven such protocol layers. you will read more about the iso model of networking in chapter figure . shows a diagram of the model. cryptography can be inserted at almost any layer in the iso model. ssl section . . for example provides security at the transport layer. networklayer security generally has been standardized on ipsec which defines ip packet formats that allow the insertion of authenticators and the encryption of packet contents. it uses symmetric encryption and uses the ike protocol for key exchange. ipsec is becoming widely used as the basis for virtual private networks vpns in which all traffic between two ipsec endpoints is encrypted to make a private network out of one that may otherwise be public. numerous protocols also have been developed for use by applications but then the applications themselves must be coded to implement security. where is cryptographic protection best placed in a protocol stack? in general there is no definitive answer. on the one hand more protocols benefit from protections placed lower in the stack. for example since ip packets encapsulate tcp packets encryption of ip packets using ipsec for example also hides the contents of the encapsulated tcp packets. similarly authenticators on ip packets detect the modification of contained tcp header information. on the other hand protection at lower layers in the protocol stack may give insufficient protection to higher layer protocols. for example an application server that runs over ipsec might be able to authenticate the client computers from which requests are received. however to authenticate a user at a client computer the server may need to use an application level protocol for example the user may be required to type a password. also consider the problem of e mail. e mail delivered via the industry standard smtp protocol is stored and forwarded frequently multiple times before it is delivered. each of these hops could go over a secure or insecure network. for e mail to be secure the e mail message needs to be encrypted so that its security is independent of the transports that carry it. . . an example ssl ssl . is a cryptographic protocol that enables two computers to communicate securely that is so that each can limit the sender and receiver of messages to the other. it is perhaps the most commonly used cryptographic protocol on the internet today since it is the standard protocol by which web browsers communicate securely with web servers. for completeness we should note that ssl was designed by netscape and that it evolved into the industry standard tls protocol. in this discussion we use ssl to mean both ssl and tls. ssl is a complex protocol with many options. here we present only a single variation of it and even then in a very simplified and abstract form so as to maintain focus on its use of cryptographic primitives. what we are about to see is a complex dance in which asymmetric cryptography is used so that a client and server can establish a secure session key that can be used chapter security for symmetric encryption of the session between the two all of this while avoiding man in the middle and replay attacks. for added cryptographic strength the session keys are forgotten once a session is completed. another communication between the two would require generation of new session keys. the ssl protocol is initiated by a client c to communicate securely with a server. prior to the protocol's use the server s is assumed to have obtained a certificate denoted cert from certification authority ca. this certificate is a structure containing the following various attributes attrs of the server such as its unique distinguished name and its common dns name the identity of a public encryption algorithm e for the server the public key kc of this server a validity interval interval during which the certificate should be considered valid a digital signature a on the above information by the ca that is a s kca attrs e ke interval in addition prior to the protocol's use the client is presumed to have obtained the public verification algorithm v ca for ca. in the case of the web the user's browser is shipped from its vendor containing the verification algorithms and public keys of certain certification authorities. the user can add or delete these for certification authorities as she chooses. when c connects to s it sends a byte random value nc to the server which responds with a random value ns of its own plus its certificate cert . the client verifies that v kca attrs e ke interval a true and that the current time is in the validity interval interval. if both of these tests are satisfied the server has proved its identity. then the client generates a random byte premaster secret pms and sends cpms e fcs pms to the server. the server recovers pms d crf cpms . now both the client and the server are in possession of ns and pms and each can compute a shared byte master secret ms f nc itg pms where f is a one way and collision resistant function. only the server and client can compute ms since only they know pms. moreover the dependence of ms on nc and ns ensures that ms is a fresh value that is a session key that has not been used in a previous communication. at this point the client and the server both compute the following keys from the ms a symmetric encryption key kf p for encrypting messages from the client to the server a symmetric encryption key k?p p for encrypting messages from the server to the client a mac generation key ktmac for generating authenticators on messages from the client to the server a mac generation key ktmac for generating authenticators on messages from the server to the client
 to send a message m to the server the client sends c upon receiving c the server recovers and accepts m if v ktmac m a true. similarly to send a message m to the client the server sends c e kfp m s ktmc m and the client recovers and accepts m if v ktmac m a true. this protocol enables the server to limit the recipients of its messages to the client that generated pms and to limit the senders of the messages it accepts to that same client. similarly the client can limit the recipients of the messages it sends and the sender of the messages it accepts to the party that knows s kd that is the party that can decrypt cpms . in many applications such as web transactions the client needs to verify the identity of the party that knows s kti . this is one purpose of the certificate certs in particular the attrs field contains information that the client can vise to determine the identity for example the domain name of the server with which it is communicating. for applications in which the server also needs information about the client ssl supports an option by which a client can send a certificate to the server. in addition to its use on the internet ssl is being used for a wide variety of tasks. for example ipsec vpns now have a competitor in ssl vpns. ipsec is good for point to point encryption of traffic say between two company offices. ssl vpns are more flexible but not as efficient so they might be used between an individual employee working remotely and the corporate office. . user authentication the discussion of authentication above involves messages and sessions. but what of users? if a system cannot authenticate a user then authenticating that a message came from that user is pointless. thus a major security problem for operating systems is user authentication. the protection system depends on the ability to identify the programs and processes currently executing which in turn depends on the ability to identify each user of the system. a user normally identifies herself. how do we determine whether a user's identity is authentic? generally user authentication is based on one or more of three things the user's possession of something a key or card the user's knowledge of something a user identifier and password and or an attribute of the user fingerprint retina pattern or signature . chapter security . . passwords ? the most common approach to authenticating a user identity is the use of passwords. when the user identifies herself by user id or account name she is asked for a password. if the user supplied password matches the password stored in the system the system assumes that the account is being accessed by the owner of that account. passwords are often used to protect objects in the computer system in the absence of more complete protection schemes. they can be considered a special case of either keys or capabilities. for instance a password could be associated with each resource such as a file . whenever a request is made to use the resource the password must be given. if the password is correct access is granted. different passwords may be associated with different access rights. for example different passwords may be used for reading files appending files and updating files. in practice most systems require only one password for a user to gain full rights. although more passwords theoretically would be more secure such systems tend not to be implemented due to the classic trade off between security and convenience. if security makes something inconvenient then the security is frequently bypassed or otherwise circumvented. . . password vulnerabilities passwords are extremely common because they are easy to understand and use. unfortunately passwords can often be guessed accidentally exposed sniffed or illegally transferred from an authorized user to an unauthorized one as we show next. there are two common ways to guess a password. one way is for the intruder either human or program to know the user or to have information about the user. all too frequently people use obvious information such as the names of their cats or spouses as their passwords. the other way is to use brute force trying enumeration or all possible combinations of valid password characters letters numbers and punctuation on some systems until the password is found. short passwords are especially vulnerable to this method. for example a four decimal password provides only variations. on average guessing times would produce a correct hit. a program that could try a password every millisecond would take only about seconds to guess a four digit password. enumeration is less successful where systems allow longer passwords that include both uppercase and lowercase letters along with numbers and all punctuation characters. of course users must take advantage of the large password space and must not for example use only lowercase letters. in addition to being guessed passwords can be exposed as a result of visual or electronic monitoring. an intruder can look over the shoulder of a user shoulder surfing when the user is logging in and can learn the password easily by watching the keyboard. alternatively anyone with access to the network on which a computer resides can seamlessly add a network monitor allowing her to watch all data being transferred on the network sniffing including user ids and passwords. encrypting the data stream containing the password solves this problem. even such a system could have passwords stolen however. for example if a file is used to contain the passwords it . user authentication could be copied for off system analysis. or consider a trojan horse prpgram installed on the system that captures every keystroke before sending it on to the application. exposure is a particularly severe problem if the password is written down where it can be read or lost. as we shall see some systems force users to select hard to remember or long passwords which may cause a user to record the password or to reuse it. as a result such systems provide much less security than systems that allow users to select easy passwords! the final type of password compromise illegal transfer is the result of human nature. most computer installations have a rule that forbids users to share accounts. this rule is sometimes implemented for accounting reasons but is often aimed at improving security. for instance suppose one user id is shared by several users and a security breach occurs from that user id. it is impossible to know who was using the id at the time the break occurred or even whether the user was an authorized one. with one user per user id any user can be questioned directly about use of the account in addition the user might notice something different about the account and detect the break in. sometimes users break account sharing rules to help friends or to circumvent accounting and this behavior can result in a system's being accessed by unauthorized users possibly harmful ones. passwords can be either generated by the system or selected by a user. system generated passwords may be difficult to remember and thus users may write them down. as mentioned however user selected passwords are often easy to guess the user's name or favorite car for example . some systems will check a proposed password for ease of guessing or cracking before accepting it. at some sites administrators occasionally check user passwords and notify a user if his password is easy to guess. some systems also age passwords forcing users to change their passwords at regular intervals every three months for instance . this method is not foolproof either because users can easily toggle between two passwords. the solution as implemented on some systems is to record a password history for each user. for instance the system could record the last n passwords and not allow their reuse. several variants on these simple password schemes can be used. for example the password can be changed more frequently. in the extreme the password is changed from session to session. a new password is selected either by the system or by the user at the end of each session and that password must be used for the next session. in such a case even if a password is misused it can be used only once. when the legitimate user tries to use a now invalid password at the next session he discovers the security violation. steps can then be taken to repair the breached security. . . encrypted passwords one problem with all these approaches is the difficulty of keeping the password secret within the computer. how can the system store a password securely yet allow its use for authentication when the user presents her password? the unix system uses encryption to avoid the necessity of keeping its password list secret. each user has a password. the system contains a function that is extremely difficult the designers hope impossible to invert but is simple to compute. that is given a value x it is easy to compute the function value chapter security f x . given a function value f x however it is impossible to compute x this function is used to encode all passwords. only encoded passwords are stored. when a user presents a password it is encoded and compared against the stored encoded password. even if the stored encoded password is seen it cannot be decoded so the password cannot be determined. thus the password file does not need to be kept secret. the function is typically an encryption algorithm that has been designed and tested rigorously. the flaw in this method is that the system no longer has control over the passwords. although the passwords are encrypted anyone with a copy of the password file can run fast encryption routines against it encrypting each word in a dictionary for instance and comparing the results against the passwords. if the user has selected a password that is also a word in the dictionary the password is cracked. on sufficiently fast computers or even on clusters of slow computers stich a comparison may take only a few hours. furthermore because unix systems use a well known encryption algorithm a cracker might keep a cache of passwords that have been cracked previously. for these reason new versions of unix store the encrypted password entries in a file readable only by the superuser. the programs that compare a presented password to the stored password run s e t u i d to root so they can read this file but other users cannot. they also include a salt or recorded random number in the encryption algorithm. the salt is added to the password to ensure that if two plaintext passwords are the same they result in different ciphertexts. another weakness in the unix password methods is that many unix systems treat only the first eight characters as significant. it is therefore extremely important for users to take advantage of the available password space. to avoid the dictionary encryption method some systems disallow the use of dictionary words as passwords. a good technique is to generate your password by using the first letter of each word of an easily remembered phrase using both upper and lower characters with a number or punctuation mark thrown in for good measure. for example the phrase my mother's name is katherine might yield the password mmn.isk!' . the password is hard to crack but easy for the user to remember. . . one time passwords to avoid the problems of password sniffing and shoulder surfing a system could use a set of paired passwords. when a session begins the system randomly selects and presents one part of a password pair the user must supply the other part. in this system the user is challenged and must respond with the correct answer to that challenge. this approach can be generalized to the use of an algorithm as a password. the algorithm might be an integer function for example. the system selects a random integer and presents it to the user. the user applies the function and replies with the correct result. the system also applies the function. if the two results match access is allowed. such algorithmic passwords are not susceptible to reuse that is a user can type in a password and no entity intercepting that password will be able to reuse it. in this variation the system and the user share a secret. the secret is never transmitted over a medium that allows exposure. rather the secret is used as input to the function along with a shared seed. a seed is a random . user authentication number or alphanumeric sequence. the seed is the authentication challenge from the computer. the secret and the seed are used as input to the function secret seed . the result of this function is transmitted as the password to the computer. because the computer also knows the secret and the seed it can perform the same computation. if the results match the user is authenticated. the next time the user needs to be authenticated another seed is generated and the same steps ensue. this time the password is different. in this one time password system the password is different in each instance. anyone capturing the password from one session and trying to reuse it in another session will fail. one time passwords are among the only ways to prevent improper authentication due to password exposure. one time password systems are implemented in various ways. commercial implementations such as securld use hardware calculators. most of these calculators are shaped like a credit card a key chain dangle or a usb device they include a display and may or may not also have a keypad. some use the current time as the random seed. others require that the user enters the shared secret also known as a personal identification number or pin on the keypad. the display then shows the one time password. the use of both a one time password generator and a pin is one form of two factor authentication. two different types of components are needed in this case. two factor authentication offers far better authentication protection than single factor authentication. another variation on one time passwords is the use of a code book or one time pad which is a list of single use passwords. in this method each password on the list is used in order once and then is crossed out or erased. the commonly used s key system uses either a software calculator or a code book based on these calculations as a source of one time passwords. of course the user must protect his code book. . . biometrics another variation on the use of passwords for authentication involves the use of biometric measures. palm or hand readers are commonly used to secure physical access for example access to a data center. these readers match stored parameters against what is being read from hand reader pads. the parameters can include a temperature map as well as finger length finger width and line patterns. these devices are currently too large and expensive to be used for normal computer authentication. fingerprint readers have become accurate and cost effective and should become more common in the future. these devices read your finger's ridge patterns and convert them into a sequence of numbers. over time they can store a set of sequences to adjust for the location of the finger on the reading pad and other factors. software can then scan a finger on the pad and compare its features with these stored sequences to determine if the finger on the pad is the same as the stored one. of course multiple users can have profiles stored and the scanner can differentiate among them. a very accurate two factor authentication scheme can result from requiring a password as well as a user name and fingerprint scan. if this information is encrypted in transit the system can be very resistant to spoofing or replay attack. chapter security multi factor authentication is better still. consider how strong authentication can be with a usb device that must be plugged into the system a pin and a fingerprint scan. except for the user's having to place her finger on a pad and plug the usb into the system this authentication method is no less convenient that using normal passwords. recall though that strong authentication by itself is not sufficient to guarantee the id of the user. an authenticated session can still be hijacked if it is not encrypted
 just as there are myriad threats to system and network security there are many security solutions. the solutions run the gamut from improved user education through technology to writing bug free software. most security professionals subscribe to the theory of defense in depth which states that more layers of defense are better than fewer layers. of course this theory applies to any kind of security. consider the security of a house without a door lock with a door lock and with a lock and an alarm. in this section we look at the major methods tools and techniques that can be used to improve resistance to threats. . . security policy the first step toward improving the security of any aspect of computing is to have a security policy. policies vary widely but generally include a statement of what is being secured. for example a policy might state that all outsideaccessible applications must have a code review before being deployed or that users should not share their passwords or that all connection points between a company and the outside must have port scans run every six months. without a policy in place it is impossible for users and administrators to know what is permissible what is required and what is not allowed. the policy is a road map to security and if a site is trying to move from less secure to more secure it needs a map to know how to get there. once the security policy is in place the people it affects should know it well. it should be their guide. the policy should also be a living document that is reviewed and updated periodically to ensure that it is still pertinent and still followed. . . vulnerability assessment how can we determine whether a security policy has been correctly implemented? the best way is to execute a vulnerability assessment. such assessments can cover broad ground from social engineering through risk assessment to port scans. for example risk assessment endeavors to value the assets of the entity in question a program a management team a system or a facility and determine the odds that a security incident will affect the entity and decrease its value. when the odds of suffering a loss and the amount of the potential loss are known a value can be placed on trying to secure the entity. the core activity of most vulnerability assessments is a penetration test in which the entity is scanned for known vulnerabilities. because this book is . implementing security defenses concerned with operating systems and the software that runs on them we will concentrate on those aspects. vulnerability scans typically are done at times when computer use is relatively low to minimize their impact. when appropriate they are done on test systems rather than production systems because they can induce unhappy behavior from the target systems or network devices. a scan within an individual system can check a variety of aspects of the system short or easy to guess passwords unauthorized privileged programs such as setuid programs unauthorized programs in system directories unexpectedly long running processes improper directory protections on user and system directories improper protections on system data files such as the password file device drivers or the operating system kernel itself dangerous entries in the program search path for example the trojan horse discussed in section . . changes to system programs detected with checksum values unexpected or hidden network daemons any problems found by a security scan can be either fixed automatically or reported to the managers of the system. networked computers are much more susceptible to security attacks than are standalone systems. rather than attacks from a known set of access points such as directly connected terminals we face attacks from an unknown and large set of access points a potentially severe security problem. to a lesser extent systems connected to telephone lines via modems are also more exposed. in fact the u.s. government considers a system to be only as secure as its most far reaching connection. for instance a top secret system may be accessed only from within a building also considered top secret. the system loses its topsecret rating if any form of communication can occur outside that environment. some government facilities take extreme security precautions. the connectors that plug a terminal into the secure computer are locked in a safe in the office when the terminal is not in use. a person must have proper id to gain access to the building and her office must know a physical lock combination and must know authentication information for the computer itself to gain access to the computer an example of multi factor authentication. unfortunately for systems administrators and computer security professionals it is frequently impossible to lock a machine in a room and disallow all remote access. for instance the internet network currently connects millions of computers. it is becoming a mission critical indispensable resource for many companies and individuals. if you consider the internet a club then as in any club with millions of members there are many good members and some bad chapter security members. the bad members have many tools they can use to attempt to gain access to the interconnected computers just as morris did with his worm. vulnerability scans can be applied to networks to address some of the problems with network security. the scans search a network for ports that respond to a request. if services are enabled that should not be access to them can be blocked or they can be disabled. the scans then determine the details of the application listening on that port and try to determine if each has any known vulnerabilities. testing those vulnerabilities can determine if the system is misconfigured or is lacking needed patches. finally though consider the use of port scanners in the hands of a cracker rather than someone trying to improve security. these tools could help crackers find vulnerabilities to attack. fortunately it is possible to detect port scans through anomaly detection as we discuss next. it is a general challenge to security that the same tools can be used for good and for harm. in fact some people advocate security through obscurity stating that tools should not be written to test security so that security holes will be harder to find and exploit . others believe that this approach to security is not a valid one pointing out for example that crackers could write their own tools. it seems reasonable that security through obscurity be considered one of the layers of security only so long as it is not the only layer. for example a company could publish its entire network configuration information but keeping that information secret makes it harder for intruders to know what to attack or to determine what might be detected. even here though a company assuming that such information will remain a secret has a false sense of security. . . intrusion detection securing systems and facilities is intimately linked to intrusion detection. intrusion detection as its name suggests strives to detect attempted or successful intrusions into computer systems and to initiate appropriate responses to the intrusions. intrusion detection encompasses a wide array of techniques that vary on a number of axes. these axes include the time that detection occurs. detection can occur in real time while the intrusion is occurring or after the fact. the types of inputs examined to detect intrusive activity. these may include user shell commands process system calls and network packet headers or contents. some forms of intrusion might be detected only by correlating information from several such sources. the range of response capabilities. simple forms of response include alerting an administrator to the potential intrusion or somehow halting the potentially intrusive activity for example killing a process engaged in apparently intrusive activity. in a sophisticated form of response a system might transparently divert an intruder's activity to a honeypot a false resource exposed to the attacker. the resource appears real to the attacker and enables the system to monitor and gain information about the attack. these degrees of freedom in the design space for detecting intrusions have yielded a wide range of solutions known as intrusion detection systems . implementing security defenses idss and intrusion prevention systems idps . ids systems raise an alarm when an intrusion is detected while idp systems act as routers passing traffic unless an intrusion is detected at which point that traffic is blocked . but just what constitutes an intrusion? defining a suitable specification of intrusion turns out to be quite difficult and thus automatic idss and idps today typically settle for one of two less ambitious approaches. in the first called signature based detection system input or network traffic is examined for specific behavior patterns or signatures known to indicate attacks. a simple example of signature based detection is scanning network packets for the string etc passwd targeted for a unix system. another example is virus detection software which scans binaries or network packets for known viruses. the second approach typically called anomaly detection attempts through various techniques to detect anomalous behavior within computer systems. of course not all anomalous system activity indicates an intrusion but the presumption is that intrusions often induce anomalous behavior. an example of anomaly detection is monitoring system calls of a daemon process to detect whether the system call behavior deviates from normal patterns possibly indicating that a buffer overflow has been exploited in the daemon to corrupt its behavior. another example is monitoring shell commands to detect anomalous commands for a given user or detecting an anomalous login time for a user either of which may indicate that an attacker has succeeded in gaining access to that user's account. signature based detection and anomaly detection can be viewed as two sides of the same coin signature based detection attempts to characterize dangerous behaviors and detects when one of these behaviors occurs whereas anomaly detection attempts to characterize normal or non dangerous behaviors and detects when something other than these behaviors occurs. these different approaches yield idss and idps with very different properties however. in particular anomaly detection can detect previously unknown methods of intrusion so called zero day attacks . signature based detection in contrast will identify only known attacks that can be codified in a recognizable pattern. thus new attacks that were not contemplated when the signatures were generated will evade signature based detection. this problem is well known to vendors of virus detection software who must release new signatures with great frequency as new viruses are detected manually. anomaly detection is not necessarily superior to signature based detection however. indeed a significant challenge for systems that attempt anomaly detection is to benchmark normal system behavior accurately. if the system is already penetrated when it is benchmarked then the intrusive activity may be included in the normal benchmark. even if the system is benchmarked cleanly without influence from intrusive behavior the benchmark must give a fairly complete picture of normal behavior. otherwise the number of false positives false alarms or worse false negatives missed intrusions will be excessive. to illustrate the impact of even a marginally high rate of false alarms consider an installation consisting of a hundred unix workstations from which records of security relevant events are recorded for purposes of intrusion detection. a small installation such as this could easily generate a million audit records per day. only one or two might be worthy of an administrator's investigation. if we suppose optimistically that each such attack is reflected in chapter security ten audit records we can then roughly compute the rate of occurrence of audit records reflecting truly intrusive activity as o intrusions . n records dav intrusion i . . q records day interpreting this as a probability of occurrence of intrusive records ' we denote it as p i that is event i is the occurrence of a record reflecting truly intrusive behavior. since p . we also know that p i l p i . . now let a denote the raising of an alarm by an ids. an accurate ids should maximize both p l a and p .j a that is the probabilities that an alarm indicates an intrusion and that no alarm indicates no intrusion. focusing on p i a for the moment we can compute it using bayes' theorem . p a i . p a i . p a i now consider the impact of the false alarm rate p a j on p i a . even with a very good true alarm rate of p a l . a seemingly good falsealarm rate of p a i . yields p i a . . that is fewer than one in every seven alarms indicates a real intrusion! in systems where a security administrator investigates each alarm a high rate of false alarms called a christmas tree effect is exceedingly wasteful and will quickly teach the administrator to ignore alarms. this example illustrates a general principle for idss and idps for usability they must offer an extremely low false alarm rate. achieving a sufficiently low false alarm rate is an especially serious challenge for anomaly detection systems as mentioned because of the difficulties of adequately benchmarking normal system behavior. however research continues to improve anomalydetection techniques. intrusion detection software is evolving to implement signatures anomaly algorithms and other algorithms and to combine the results to arrive at a more accurate anomaly detection rate. . . virus protection as we have seen viruses can and do wreak havoc on systems. protection from viruses thus is an important security concern. antivirus programs are often used to provide this protection. some of these programs are effective against only particular known viruses. they work by searching all the programs on a system for the specific pattern of instructions known to make up the virus. when they find a known pattern they remove the instructions disinfecting the program. antivirus programs may have catalogs of thousands of viruses for which they search. . implementing security defenses the tripwire file system an example of an anomaly detection tool is the tripwire file system integritychecking tool for unix developed at purdue university. ivipwire operates on the premise that many intrusions result in modification of system directories and files. for example an attacker might modify the system programs perhaps inserting copies with trojan horses or might insert new programs into directories commonly found in user shell search paths or an intruder might remove system log'files to cover his tracks. tripwire is a tool to monitor file systems for added deleted or changed files and to alert system administrators to these modifications. the operation of tripwire is controlled by a configuration file tv.conf ig that enumerates the directories and files to be monitored for changes deletions or additions. each entry in this configuration file includes a selection mask to specify the file attributes inode attributes that will be monitored for changes. for example the selection mask might specify that a file's permissions be monitored but its access time be ignored. in addition the selection mask can instruct that the file be monitored for changes. monitoring the hash of a file for changes is as good as monitoring the file itself but storing hashes of files requires far less room than copying the files themselves. when run initially tripwire takes as input the tw.config file and computes a signature for each file or directory consisting of its monitored attributes inode attributes and hash values . these signatures are stored in a. database. when run subsequently tripwire inputs both tw.config and the previously stored database recomputes the signature for each file or directory named in tw.cprif ig and compares this signature with the signature if any in the previously computed database. events reported to an administrator include any monitored file or directory whose signature differs from that in the database a changed file any file or directory in a monitored directory for which a signature does hot exist in the database an added file and any signature in .the.database.for. which the corresponding file or directory no longer exists a deleted file . although effective for a wide class of attacks tripwire does have limitations. perhaps the most obvious is the need to protect the tripwire program and its associated files especially the database file from unauthorized modification. for this reason tripwire and its associated files should be stored on some tamper proof medium such as a write protected disk or a secure server where logins can be tightly controlled. unfortunately this makes it less convenient to update the database after authorized updates to monitored directories and files. a second limitation is that some security relevant files for example system log files are supposed to change over time and tripwire does not provide a way to distinguish between an authorized and an unauthorized change. so for example an attack that modifies without deleting a system log that would normally change anyway would escape tripwire's detection capabilities. the best tripwire can do in this case is to detect certain obvious inconsistencies for example if the log file shrinks . free and commercial versions of tripwire are available from http tripwire.org and http tripvvire.com. chapter security both viruses and antivirus software continue to become more sophisticated. some viruses modify themselves as they infect other software to avoid the basic pattern match approach of antivirus programs. antivirus programs in turn now look for families of patterns rather than a single pattern to identify a virus. in fact some anti virus programs implement a variety of detection algorithms. they can decompress compressed viruses before checking for a signature. some also look for process anomalies. a process opening an executable file for writing is suspicious for example unless it is a compiler. another popular technique is to run a program in a sandbox which is a controlled or emulated section of the system. the antivirus software analyzes the behavior of the code in the sandbox before letting it run unmonitored. some antivirus programs also put up a complete shield rather than just scanning files within a file system. they search boot sectors memory inbound and outbound e mail files as they are downloaded files on removable devices or media and so on. the best protection against computer viruses is prevention or the practice of safe computing. purchasing unopened software from vendors and avoiding free or pirated copies from public sources or disk exchange offer the safest route to preventing infection. however even new copies of legitimate software applications are not immune to virus infection there have been cases where disgruntled employees of a software company have infected the master copies of software programs to do economic harm to the company selling the software. for macro viruses one defense is to exchange word documents in an alternative file format called rich text format rtf . unlike the native word format rtf does not include the capability to attach macros. another defense is to avoid opening any e mail attachments from unknown users. unfortunately history has shown that e mail vulnerabilities appear as fast as they are fixed. for example in the love bug virus became very widespread by appearing to be a love note sent by a friend of the receiver. once the attached visual basic script was opened the virus propagated by sending itself to the first users in the user's e mail contact list. fortunately except for clogging e mail systems and users' inboxes it was relatively harmless. it did however effectively negate the defensive strategy of opening attachments only from people known to the receiver. a more effective defense method is to avoid opening any e mail attachment that contains executable code. some companies now enforce this as policy by removing all incoming attachments to e mail messages. another safeguard although it does not prevent infection does permit early detection. a user must begin by completely reformatting the hard disk especially the boot sector which is often targeted for viral attack. only secure software is uploaded and a signature of each program is taken via a secure message digest computation. the resulting filename and associated messagedigest list must then be kept free from unauthorized access. periodically or each time a program is run the operating system recomputes the signature and compares it with the signature on the original list any differences serve as a warning of possible infection. this technique can be combined with others. for example a high overhead antivirus scan such as a sandbox can be used and if a program passes the test a signature can be created for it. if the signatures match the next time the program is run it does not need to be virus scanned again. . firewalling to protect systems and networks . . auditing accounting and logging . auditing accounting and logging can decrease system performance but they are useful in several areas including security. logging can be general or specific. all system call executions can be logged for analysis of program behavior or misbehavior . more typically suspicious events are logged. authentication failures and authorization failures can tell us quite a lot about break in attempts. accounting is another potential tool in a security administrator's kit. it can be used to find performance changes which in turn can reveal security problems. one of the early unix computer break ins was detected by cliff stoll when he was examining accounting logs and spotted an anomaly. . firewalling to protect systems and networks we turn next to the question of how a trusted computer can be connected safely to an untrustworthy network. one solution is the use of a firewall to separate trusted and untrusted systems. a firewall is a computer appliance or router that sits between the trusted and the untrusted. a network firewall limits network access between the two security domains and monitors and logs all connections. it can also limit connections based on source or destination address source or destination port or direction of the connection. for instance web servers use http to communicate with web browsers. a firewall therefore may allow only http to pass from all hosts outside the firewall to the web server within the firewall. the morris internet worm used the f inger protocol to break into computers so f inger would not be allowed to pass for example. in fact a network firewall can separate a network into multiple domains. a common implementation has the internet as the untrusted domain a semitrusted and semi secure network called the demilitarized zone dmz as another domain and a company's computers as a third domain figure . . connections are allowed from the internet to the dmz computers and from the company computers to the internet but are not allowed from the internet or dmz computers to the company computers. optionally controlled communications may be allowed between the dmz and one company computer or more. for instance a web server on the dmz may need to query a database server on the corporate network. with a firewall however access is contained and any dmz systems that are broken into still are unable to access the company computers. of course a firewall itself must be secure and attack proof otherwise its ability to secure connections can be compromised. furthermore firewalls do not prevent attacks that tunnel or travel within protocols or connections that the firewall allows. a buffer overflow attack to a web server will not be stopped by the firewall for example because the http connection is allowed it is the contents of the http connection that house the attack. likewise denial ofservice attacks can affect firewalls as much as any other machines. another vulnerability of firewalls is spoofing in which an unauthorized host pretends to be an authorized host by meeting some authorization criterion. for example if a firewall rule allows a connection from a host and identifies that host by its ip address then another host could send packets using that same address and be allowed through the firewall. chapter security internet access from company's computers dmz access from internet access between dmz and company's computers figure . domain separation via firewall. in addition to the most common network firewalls there are other newer kinds of firewalls each with its pros and cons. a personal firewall is a software layer either included with the operating system or added as an application. rather than limiting communication between security domains it limits communication to and possibly from a given host. a user could add a personal firewall to her pc so that a trojan horse would be denied access to the network to which the pc is connected. an application proxy firewall understands the protocols that applications speak across the network. for example smtp is used for mail transfer. an application proxy accepts a connection just as an smtp server would and then initiates a connection to the original destination smtp server. it can monitor the traffic as it forwards the message watching for and disabling illegal commands attempts to exploit bugs and so on. some firewalls are designed for one specific protocol. an xml firewall for example has the specific purpose of analyzing xml traffic and blocking disallowed or malformed xml. system call firewalls sit between applications and the kernel monitoring system call execution. for example in solaris the least privilege feature implements a list of more than fifty system calls that processes may or may not be allowed to make. a process that does not need to spawn other processes can have that ability taken away for instance. . computer security classifications the u.s. department of defense trusted computer system evaluation criteria specify four security classifications in systems a b c and d. this specification is widely used to determine the security of a facility and to model security solutions so we explore it here. the lowest level classification is division d or minimal protection. division d includes only one class and is used for systems . computer security classifications that have failed to meet the requirements of any of the other security classes. for instance ms dos and windows . are in division d. division c the next level of security provides discretionary protection and accountability of users and their actions through the use of audit capabilities. division c has two levels cl and c . a cl class system incorporates some form of controls that allow users to protect private information and to keep other users from accidentally reading or destroying their data. a cl environment is one in which cooperating users access data at the same levels of sensitivity. most versions of unix are cl class. the sum total of all protection systems within a computer system hardware software firmware that correctly enforce a security policy is known as a trusted computer base tcb . the tcb of a cl system controls access between users and files by allowing the user to specify and control sharing of objects by named individuals or defined groups. in addition the tcb requires that the users identify themselves before they start any activities that the tcb is expected to mediate. this identification is accomplished via a protected mechanism or password the tcb protects the authentication data so that they are inaccessible to unauthorized users. a c class system adds an individual level access control to the requirements of a cl system. for example access rights of a file can be specified to the level of a single individual. in addition the system administrator can selectively audit the actions of any one or more users based on individual identity. the tcb also protects itself from modification of its code or data structures. in addition no information produced by a prior user is available to another user who accesses a storage object that has been released back to the system. some special secure versions of unix have been certified at the c level. division b mandatory protection systems have all the properties of a classc system in addition they attach a sensitivity label to each object. the bl class tcb maintains the security label of each object in the system the label is used for decisions pertaining to mandatory access control. for example a user at the confidential level could not access a file at the more sensitive secret level. the tcb also denotes the sensitivity level at the top and bottom of each page of any human readable output. in addition to the normal user namepassword authentication information the tcb also maintains the clearance and authorizations of individual users and will support at least two levels of security. these levels are hierarchical so that a user may access any objects that carry sensitivity labels equal to or lower than his security clearance. for example a secret level user could access a file at the confidential level in the absence of other access controls. processes are also isolated through the use of distinct address spaces. a b class system extends the sensitivity labels to each system resource such as storage objects. physical devices are assigned minimum and maximum security levels that the system uses to enforce constraints imposed by the physical environments in which the devices are located. in addition a b system supports covert channels and the auditing of events that could lead to the exploitation of a covert channel. a b class system allows the creation of access control lists that denote users or groups not granted access to a given named object. the tcb also contains a mechanism to monitor events that may indicate a violation of chapter security security policy. the mechanism notifies the security administrator a id if necessary terminates the event in the least disruptive manner. the highest level classification is division a. architecturally a class al system is functionally equivalent to a b system but it uses formal design specifications and verification techniques granting a high degree of assurance that the tcb has been implemented correctly. a system beyond class al might be designed and developed in a trusted facility by trusted personnel. the use of a tcb merely ensures that the system can enforce aspects of a security policy the tcb does not specify what the policy should be. typically a given computing environment develops a security policy for certification and has the plan accredited by a security agency such as the national computer security center. certain computing environments may require other certification such as that supplied by tempest which guards against electronic eavesdropping. for example a tempest certified system has terminals that are shielded to prevent electromagnetic fields from escaping. this shielding ensures that equipment outside the room or building where the terminal is housed cannot detect what information is being displayed by the terminal. . an example windows xp microsoft windows xp is a general purpose operating system designed to support a variety of security features and methods. in this section we examine features that windows xp uses to perform security functions. for more information and background on windows xp see chapter . the windows xp security model is based on the notion of user accounts. windows xp allows the creation of any number of user accounts which can be grouped in any manner. access to system objects can then be permitted or denied as desired. users are identified to the system by a unique security id. when a user logs on windows xp creates a security access token that includes the security id for the user security ids for any groups of which the user is a member and a list of any special privileges that the user has. examples of special privileges include backing up files and directories shutting down the computer logging on interactively and changing the system clock. every process that windows xp runs on behalf of a user will receive a copy of the access token. the system uses the security ids in the access token to permit or deny access to system objects whenever the user or a process on behalf of the user attempts to access the object. authentication of a user account is typically accomplished via a user name and password although the modular design of windows xp allows the development of custom authentication packages. for example a retinal or eye scanner might be used to verify that the user is who she says she is. windows xp uses the idea of a subject to ensure that programs run by a user do not get greater access to the system than the user is authorized to have. a subject is used to track and manage permissions for each program that a user runs it is composed of the user's access token and the program acting on behalf of the user. since windows xp operates with a client server model two classes of subjects are used to control access simple subjects and server subjects. an example of a simple subject is the typical application program that a user executes after she logs on. the simple subject is assigned a security . an example windows xp context based on the security access token of the user. a server subject is a process implemented as a protected server that uses the security context of the client when acting on the client's behalf. as mentioned in section . auditing is a useful security technique. windows xp has built in auditing that allows many common security threats to be monitored. examples include failure auditing for login and logoff events to detect random password break ins success auditing for login and logoff events to detect login activity at strange hours success and failure write access auditing for executable files to track a virus outbreak and success and failure auditing for file access to detect access to sensitive files. security attributes of an object in windows xp are described by a security descriptor. the security descriptor contains the security id of the owner of the object who can change the access permissions a group security id used only by the posix subsystem a discretionary access control list that identifies which users or groups are allowed and which are not allowed access and a system access control list that controls which atiditing messages the system will generate. for example the security descriptor of the file foo.bar might have owner avi and this discretionary access control list avi all access group cs read write access user cliff no access in addition it might have a system access control list of audit writes by everyone. an access control list is composed of access control entries that contain the security id of the individual and an access mask that defines all possible actions on the object with a value of accessauowed or accessdenied for each action. files in windows xp may have the following access types readdata writedata appenddata execute readextendedattribute writeextendedattribute readattributes and w r i t e a t t r i b u t e s . we can see how this allows a fine degree of control over access to objects. windows xp classifies objects as either container objects or noncontainer objects. container objects such as directories can logically contain other objects. by default when an object is created within a container object the new object inherits permissions from the parent object. similarly if the user copies a file from one directory to a new directory the file will inherit the permissions of the destination directory. noncontainer objects inherit no other permissions. furthermore if a permission is changed on a directory the new permissions do not automatically apply to existing files and subdirectories the user may explicitly apply them if she so desires. the system administrator can prohibit printing to a printer on the system for all or part of a day and can use the windows xp performance monitor to help her spot approaching problems. in general windows xp does a good job of providing features to help ensure a secure computing environment. many of these features are not enabled by default however which may be one reason for the myriad security breaches on windows xp systems. another reason is the vast number of services windows xp starts at system boot time and the number of applications that typically are installed on a windows xp system. chapter security for a real multiuser environment the system administrator should forrnulate a security plan and implement it using the features that windows xp provides and other security tools
 a distributed system is a collection of loosely coupled processors interconnected by a communication network. from the point of view of a specific processor in a distributed system the rest of the processors and their respective resources are remote whereas its own resources are local. the processors in a distributed system may vary in size and function. they may include small microprocessors workstations minicomputers and large general purpose computer systems. these processors are referred to by a number of names such as sites nodes computers machines and hosts depending on the context in which they are mentioned. we mainly use site to indicate the location of a machine and host to refer to a specific system at a site. generally one host at one site the server has a resource that another host at another site the client or user would like to use. a general structure of a distributed system is shown in figure . . chapter distributed system structures site a site c communication client site b figure . a distributed system. there are four major reasons for building distributed systems resource sharing computation speedup reliability and communication. in this section we briefly discuss each of them. . . resource sharing if a number of different sites with different capabilities are connected to one another then a user at one site may be able to use the resources available at another. for example a user at site a may be using a laser printer located at site b. meanwhile a user at b may access a file that resides at a. in general resource sharing in a distributed system provides mechanisms for sharing files at remote sites processing information in a distributed database printing files at remote sites using remote specialized hardware devices such as a high speed array processor and performing other operations. . . computation speedup if a particular computation can be partitioned into subcomputations that can run concurrently then a distributed system allows us to distribute the subcomputations among the various sites the subcomputations can be run concurrently and thus provide computation speedup. in addition if a particular site is currently overloaded with jobs some of them may be moved to other lightly loaded sites. this movement of jobs is called load sharing. automated load sharing in which the distributed operating system automatically moves jobs is not yet common in commercial systems. . . reliability if one site fails in a distributed system the remaining sites can continue operating giving the system better reliability if the system is composed of multiple large autonomous installations that is general purpose computers the failure of one of them should not affect the rest. if however the system . types of distributed operating systems is composed of small machines each of which is responsible for some crucial system function such as terminal character i o or the file system then a single failure may halt the operation of the whole system. in general with enough redundancy in both hardware and data the system can continue operation even if some of its sites have failed. the failure of a site must be detected by the system and appropriate action may be needed to recover from the failure. the system must no longer use the services of that site. in addition if the function of the failed site can be taken over by another site the system must ensure that the transfer of function occurs correctly. finally when the failed site recovers or is repaired mechanisms must be available to integrate it back into the system smoothly. as we shall see in chapters and these actions present difficult problems that have many possible solutions. . . communication when several sites are connected to one another by a communication network the users at different sites have the opportunity to exchange information. at a low level messages are passed between systems much as messages are passed between processes in the single computer message system discussed in section . . given message passing all the higher level functionality found in standalone systems can be expanded to encompass the distributed system. such functions include file transfer login mail and remote procedure calls rpcs . the advantage of a distributed system is that these functions can be carried out over great distances. two people at geographically distant sites can collaborate on a project for example. by transferring the files of the project logging in to each other's remote systems to run programs and exchanging mail to coordinate the work users minimize the limitations inherent in longdistance work. we wrote this book by collaborating in such a manner. the advantages of distributed systems have resulted in an industry wide trend toward downsizing. many companies are replacing their mainframes with networks of workstations or personal computers. companies get a bigger bang for the buck that is better functionality for the cost more flexibility in locating resources and expanding facilities better user interfaces and easier maintenance. . types of distributed operating systems in this section we describe the two general categories of network oriented operating systems network operating systems and distributed operating systems. network operating systems are simpler to implement but generally more difficult for users to access and utilize than are distributed operating systems which provide more features. . . network operating systems a network operating system provides an environment in which users who are aware of the multiplicity of machines can access remote resources by either chapter distributed system structures logging in to the appropriate remote machine or transferring data from the remote machine to their own machines. . . . remote login an important function of a network operating system is to allow users to log in remotely. the internet provides the telnet facility for this purpose. to illustrate this facility lets suppose that a user at westminster college wishes to compute on cs.yale.edu a computer that is located at yale university. to do so the user must have a valid account on that machine. to log in remotely the user issues the command telnet cs.yale.edu this command results in the formation of a socket connection between the local machine at westminster college and the cs.yale.edu computer. after this connection has been established the networking software creates a transparent bidirectional link so that all characters entered by the user are sent to a process on cs.yale.edu and all the output from that process is sent back to the user. the process on the remote machine asks the user for a login name and a password. once the correct information has been received the process acts as a proxy for the user who can compute on the remote machine just as any local user can. . . . remote file transfer another major function of a network operating system is to provide a mechanism for remote file transfer from one machine to another. in such an environment each computer maintains its own local file system. if a user at one site say cs.uvm.edu wants to access a file located on another computer say cs.yale.edu then the file must be copied explicitly from the computer at yale to the computer at the university of vermont. the internet provides a mechanism for such a transfer with the file transfer protocol ftp program. suppose that a user on cs.uvm.edu wants to copy a java program server. j ava that resides on cs.yale.edu. the user must first invoke the ftp program by executing ftp cs.yale.edu the program then asks the user for a login name and a password. once the correct information has been received the user must connect to the subdirectory where the file server. j ava resides and then copy the file by executing get server.java in this scheme the file location is not transparent to the user users must knowexactly where each file is. moreover there is no real file sharing because a user can only copy a file from one site to another. thus several copies of the same file may exist resulting in a waste of space. in addition if these copies are modified the various copies will be inconsistent. notice that in our example the user at the university of vermont must have login permission on cs.yale.edu. ftp also provides a way to allow a user . types of distributed operating systems who does not have an account on the yale computer to copy files remotely. this remote copying is accomplished through the anonymous ftp method which works as follows. the file to be copied that is server .java rmist be placed in a special subdirectory say ftp with the protection set to allow the public to read the file. a user who wishes to copy the file uses the f t p command as before. when the user is asked for the login name the user supplies the name anonymous and an arbitrary password. once anonymous login is accomplished care must be taken by the system to ensure that this partially authorized user does not access inappropriate files. generally the user is allowed to access only those files that are in the directory tree of user anonymous. any files placed here are accessible to any anonymous users subject to the usual file protection scheme used on that machine. anonymous users however cannot access files outside of this directory tree. the ftp mechanism is implemented in a manner similar to telnet implementation. there is a daemon on the remote site that watches for connection requests to the system's ftp port. login authentication is accomplished and the user is allowed to execute commands remotely. unlike the telnet daemon which executes any command for the user the ftp daemon responds only to a predefined set of file related commands. these include the following get transfer a file from the remote machine to the local machine. put transfer from the local machine to the remote machine. i s or d i r list files in the current directory on the remote machine. cd change the current directory on the remote machine. there are also various commands to change transfer modes for binary or ascii files and to determine connection status. an important point about telnet and ftp is that they require the user to change paradigms. ftp requires the user to know a command set entirely different from the normal operating system commands. telnet requires a smaller shift the user must know appropriate commands on the remote system. for instance a viser on a windows machine who telnets to a unix machine must switch to unix commands for the duration of the telnet session. facilities are more convenient for users if they do not require the use of a different set of commands. distributed operating systems are designed to address this problem. . . distributed operating systems in a distributed operating system the users access remote resources in the same way they access local resources. data and process migration from one site to another is under the control of the distributed operating system. . . . data migration suppose a user on site a wants to access data such as a file that reside at site b. the system can transfer the data by one of two basic methods. one approach to data migration is to transfer the entire file to site a. from that point on all chapter distributed system structures access to the file is local. when the user no longer needs access to the file a copy of the file if it has been modified is sent back to site b. even if only a modest change has been made to a large file all the data must be transferred. this mechanism can be thought of as an automated ftp system. this approach was used in the andrew file system as we discuss in chapter but it was found to be too inefficient. the other approach is to transfer to site a only those portions of the file that are actually necessary for the immediate task. if another portion is required later another transfer will take place. when the user no longer wants to access the file any part of it that has been modified must be sent back to site b. note the similarity to demand paging. the sun microsystems network file system nfs protocol uses this method chapter as do newer versions of andrew. the microsoft smb protocol running on top of either tcp ip or the microsoft netbeui protocol also allows file sharing over a network. smb is described in appendix c. . . clearly if only a small part of a large file is being accessed the latter approach is preferable. if significant portions of the file are being accessed however it is more efficient to copy the entire file. in both methods data migration includes more than the mere transfer of data from one site to another. the system must also perform various data translations if the two sites involved are not directly compatible for instance if they use different character code representations or represent integers with a different number or order of bits . . . . computation migration in some circumstances we may want to transfer the computation rather than the data across the system this approach is called computation migration. for example consider a job that needs to access various large files that reside at different sites to obtain a summary of those files. it would be more efficient to access the files at the sites where they reside and return the desired results to the site that initiated the computation. generally if the time to transfer the data is longer than the time to execute the remote command the remote command should be used. such a computation can be carried out in different ways. suppose that process p wants to access a file at site a. access to the file is carried out at site a and could be initiated by an rpc. an rpc uses a datagram protocol udp on the internet to execute a routine on a remote system section . . . process p invokes a predefined procedure at site a. the procedure executes appropriately and then returns the results to p. alternatively process p can send a message to site a. the operating system at site a then creates a new process q whose function is to carry out the designated task. when process q completes its execution it sends the needed result back to p via the message system. in this scheme process p may execute concurrently with process q and in fact may have several processes running concurrently on several sites. both methods could be used to access several files residing at various sites. one rpc might result in the invocation of another rpc or even in the transfer of messages to another site. similarly process q could during the course of its execution send a message to another site which in turn would create another process. this process might either send a message back to q or repeat the cycle
 . . . process migration a logical extension of computation migration is process migration. when a process is submitted for execution it is not always executed at the site at which it is initiated. the entire process or parts of it may be executed at different sites. this scheme may be used for several reasons load balancing. the processes or subprocesses may be distributed across the network to even the workload. computation speedup. if a single process can be divided into a number of subprocesses that can run concurrently on different sites then the total process turnaround time can be reduced. hardware preference. the process may have characteristics that make it more suitable for execution on some specialized processor such as matrix inversion on an array processor rather than on a microprocessor . software preference. the process may require software that is available at only a particular site and either the software cannot be moved or it is less expensive to move the process. data access. just as in computation migration if the data being used in the computation are numerous it may be more efficient to have a process run remotely than to transfer all the data. we use two complementary techniques to move processes in a computer network. in the first the system can attempt to hide the fact that the process has migrated from the client. this scheme has the advantage that the user does not need to code her program explicitly to accomplish the migration. this method is usually employed for achieving load balancing and computation speedup among homogeneous systems as they do not need user input to help them execute programs remotely. the other approach is to allow or require the user to specify explicitly how the process should migrate. this method is usually employed when the process must be moved to satisfy a hardware or software preference. you have probably realized that the web has many aspects of a distributedcomputing environment. certainly it provides data migration between a web server and a web client . it also provides computation migration. for instance a web client could trigger a database operation on a web server. finally with java it provides a form of process migration java applets are sent from the server to the client where they are executed. a network operating system provides most of these features but a distributed operating system makes them seamless and easily accessible. the result is a powerful and easy to use facility one of the reasons for the huge growth of the world wide web. . network structure there are basically two types of networks local area networks lan and wide area networks wan . the main difference between the two is the way in which they are geographically distributed. local area networks are composed chapter distributed system structures of processors distributed over small areas such as a single building? or a number of adjacent buildings whereas wide area networks are composed of a number of autonomous processors distributed over a large area such as the united states . these differences imply major variations in the speed and reliability of the communications network and they are reflected in the distributed operating system design. . . local area networks local area networks emerged in the early s as a substitute for large mainframe computer systems. for many enterprises it is more economical to have a number of small computers each with its own self contained applications than to have a single large system. because each small computer is likely to need a full complement of peripheral devices such as disks and printers and because some form of data sharing is likely to occur in a single enterprise it was a natural step to connect these small systems into a network. lans as mentioned are usually designed to cover a small geographical area such as a single building or a few adjacent buildings and are generally used in an office environment. all the sites in such systems are close to one another so the communication links tend to have a higher speed and lower error rate than do their counterparts in wide area networks. high quality expensive cables are needed to attain this higher speed and reliability. it is also possible to use the cable exclusively for data network traffic. over longer distances the cost of using high quality cable is enormous and the exclusive use of the cable tends to be prohibitive. r jr application server workstation workstation workstation gateway printer laptop file server figure . local area network. ' . network structure the most common links in a local area network are twisted pair and fiberoptic cabling. the most common configurations are multiaccess bus ring and star networks. communication speeds range from megabit per second for networks such as appletalk infrared and the new bluetooth local radio network to gigabit per second for gigabit ethernet. ten megabits per second is most common and is the speed of lobaset ethernet. baset ethernet requires a higher quality cable but runs at megabits per second and is becoming common. also growing is the use of optical fiber based fddi networking. the fddi network is token based and runs at over megabits per second. a typical lan may consist of a number of different computers from mainframes to laptops or pdas various shared peripheral devices such as laser printers and magnetic tape drives and one or more gateways specialized processors that provide access to other networks figure . . an ethernet scheme is commonly vised to construct lans. an ethernet network has no central controller because it is a multiaccess bus so new hosts can be added easily to the network. the ethernet protocol is defined by the ieee . standard. . . wide area networks wide area networks emerged in the late s mainly as an academic research project to provide efficient communication among sites allowing hardware and software to be shared conveniently and economically by a wide community of visers. the first wan to be designed and developed was the arpanet. begun in the arpanet has grown from a four site experimental network to a worldwide network of networks the internet comprising millions of computer systems. because the sites in a wan are physically distributed over a large geographical area the communication links are by default relatively slow and unreliable. typical links are telephone lines leased dedicated data lines microwave links and satellite channels. these commvmication links are controlled by special communication processors figure . which are responsible for defining the interface through which the sites communicate over the network as well as for transferring information among the various sites. for example the internet wan provides the ability for hosts at geographj ically separated sites to communicate with one another. the host computers typically differ from one another in type speed word length operating system i and so on. hosts are generally on lans which are in turn connected to j the internet via regional networks. the regional networks such as nsfnet in the northeast united states are interlinked with routers section . . to form the worldwide network. connections between networks frequently j use a telephone system service called tl which provides a transfer rate of . megabits per second over a leased line. for sites requiring faster internet access tls are collected into multiple tl units that work in parallel to provide more throughput. for instance a t is composed of tl connections and has a transfer rate of megabits per second. the routers control the path each message takes through the net. this routing may be either dynamic to increase communication efficiency or static to reduce security risks or to allow communication charges to be computed. chapter distributed system structures usef processes network host i l i t i . v.. .. .risf .rit .l ..r f . . t . . j ' ' j communication host operating system . ' 'subsystem communication processor figure . communication processors in a wide area network. other wans use standard telephone lines as their primary means of communication. modems are devices that accept digital data from the computer side and convert it to the analog signals that the telephone system uses. a modem at the destination site converts the analog signal back to digital form and the destination receives the data. the unix news network uucp allows systems to communicate with each other at predetermined times via modems to exchange messages. the messages are then routed to other nearby systems and in this way either are propagated to all hosts on the network public messages or are transferred to their destination private messages . wans are generally slower than lans their transmission rates range from bits per second to over megabit per second. uucp has been superseded by ppp the point to point protocol. ppp functions over modem connections allowing home computers to be fully connected to the internet
 the sites in a distributed system can be connected physically in a variety of ways. each configuration has advantages and disadvantages. we can compare the configurations by using the following criteria installation cost. the cost of physically linking the sites in the system communication cost. the cost in time and money to send a message from site a to site b . network topology availability. the extent to which data can be accessed despite the failure of some links or sites the various topologies are depicted in figure . as graphs whose nodes correspond to sites. an edge from node a to node b corresponds to a direct communication link between the two sites. in a fully connected network each site is directly connected to every other site. however the number of links grows as the square of the number of sites resvilting in a huge installation cost. therefore fully connected networks are impractical in any large system. in a partially connected network direct links exist between some but not all pairs of sites. hence the installation cost of such a configuration is lower than that of the fully connected network. however if two sites a and b are not directly connected messages from one to the other must be routed through a sequence of communication links. this requirement results in a higher communication cost. fully connected network partially connected network tree structured network star network figure . network topology. chapter distributed system structures if a communication link fails messages that would have been transmitted across the link must be rerouted. in some cases another route through the network may be found so that the messages are able to reach their destination. in other cases a failure may mean that no connection exists between some pairs of sites. when a system is split into two or more subsystems that lack any connection between them it is partitioned. under this definition a subsystem or partition may consist of a single node. the various partially connected network types include tree structured networks ring networks and star networks as shown in figure . . they have different failure characteristics and installation and communication costs. installation and communication costs are relatively low for a tree structured network. however the failure of a single link in such a network can result in the network's becoming partitioned. in a ring network at least two links must fail for partition to occur. thus the ring network has a higher degree of availability than does a tree structured network. however the communication cost is high since a message may have to cross a large number of links. in a star network the failure of a single link results in a network partition but one of the partitions has only a single site. such a partition can be treated as a single site failure. the star network also has a low communication cost since each site is at most two links away from every other site. however if the central site fails every site in the system becomes disconnected
 now that we have discussed the physical aspects of networking we turn to the internal workings. the designer of a communication network must address five basic issues naming and name resolution. how do two processes locate each other to communicate? routing strategies. how are messages sent through the network? packet strategies. are packets sent individually or as a sequence? connection strategies. how do two processes send a sequence of messages? contention. how do we resolve conflicting demands for the network's use given that it is a shared resource? in the following sections we elaborate on each of these issues. . . naming and name resolution the first component of network communication is the naming of the systems in the network. for a process at site a to exchange information with a process at site b each must be able to specify the other. within a computer system each process has a process identifier and messages may be addressed with the process identifier. because networked systems share no memory a host within the system initially has no knowledge about the processes on other hosts. . communication structure to solve this problem processes on remote systems are generally identified by the pair host name identifiers where iwst name is a name unique within the network and identifier may be a process identifier or other unique number within that host. a host name is usually an alphanumeric identifier rather than a number to make it easier for users to specify. for instance site a might have hosts named homer marge bart and lisa. bart is certainly easier to remember than is . names are convenient for humans to use but computers prefer numbers for speed and simplicity. for this reason there must be a mechanism to resolve the host name into a host id that describes the destination system to the networking hardware. this resolve mechanism is similar to the nameto address binding that occurs during program compilation linking loading and execution chapter . in the case of host names two possibilities exist. first every host may have a data file containing the names and addresses of all the other hosts reachable on the network similar to binding at compile time . the problem with this model is that adding or removing a host from the network requires updating the data files on all the hosts. the alternative is to distribute the information among systems on the network. the network must then use a protocol to distribute and retrieve the information. this scheme is like execution time binding. the first method was the original method vised on the internet as the internet grew however it became untenable so the second method the domain name system dns is now in use. dns specifies the naming structure of the hosts as well as name to address resolution. hosts on the internet are logically addressed with a multipart name. names progress from the most specific to the most general part of the address with periods separating the fields. for instance bob.cs.brown.edu refers to host bob in the department of computer science at brown university within the domain edit. other top level domains include com for commercial sites and org for organizations as well as a domain for each country connected to the network for systems specified by country rather than organization type. generally the system resolves addresses by examining the host name components in reverse order. each component has a name server simply a process on a system that accepts a name and returns the address of the name server responsible for that name. as the final step the name server for the host in question is contacted and a host id is returned. for our example system bob.cs.brown.edu the following steps would be taken as result of a request made by a process on system a to communicate with bob.cs.broion.edu . the kernel of system a issues a request to the name server for the edu domain asking for the address of the name server for broum.edu. the name server for the edu domain must be at a known address so that it can be queried. . the edit name server returns the address of the host on which the brown.edu name server resides. . the kernel on system a then queries the name server at this address and asks abovit cs.brown.edu . an address is returned and a request to that address for bob.cs.brozon.edu now finally returns an internet address host id for that host for example . . l . chapter distributed system structures this protocol may seem inefficient but local caches are usually kept at? each name server to speed the process. for example the edu name server would have brown.edu in its cache and would inform system a that it could resolve two portions of the name returning a pointer to the cs.broum.edu name server. of course the contents of these caches must be refreshed over time in case the name server is moved or its address changes. in fact this service is so important that many optimizations have occurred in the protocol as well as many safeguards. consider what would happen if the primary edu name server crashed. it is possible that no edu hosts would be able to have their addresses resolved making them all unreachable! the solution is to use secondary back up name servers that duplicate the contents of the primary servers. before the domain name service was introduced all hosts on the internet needed to have copies of a file that contained the names and addresses of each host on the network. all changes to this file had to be registered at one site host sri nic and periodically all hosts had to copy the updated file from sri nic to be able to contact new systems or find hosts whose addresses had changed. under the domain name service each name server site is responsible for updating the host information for that domain. for instance any host changes at brown university are the responsibility of the name server for brown.edu and do not have to be reported anywhere else. dns lookups will automatically retrieve the updated information because brotvn.edu is contacted directly. within domains there can be autonomous subdomains to distribute further the responsibility for host name and host id changes. java provides the necessary api to design a program that maps ip names to ip addresses. the program shown in figure . is passed an ip name such as bob.cs.brown.edu on the command line and either outputs the ip address of the host or returns a message indicating that the host name could not be resolved. an inetaddress is a java class representing an ip name or address. the static method getbynameo belonging to the inetaddress class usage java dnslookup ip name i.e. java dnslookup www.wiley.com public class dnslookup public static void main string args inetaddress hostaddress try hostaddress inetaddress.getbyname args system.out.printin hostaddress.gethostaddress catch unknownhostexception uhe system.err.println unknown host args figure . java program illustrating a dns lookup. . communication structure is passed a string representation of an ip name and it returns the corresponding inetaddress. the program then invokes the gethostaddressq method which internally uses divs to look up the ip address of the designated host. generally the operating system is responsible for accepting from its processes a message destined for host name identifier and for transferring that message to the appropriate host. the kernel on the destination host is then responsible for transferring the message to the process named by the identifier. this exchange is by no means trivial it is described in section . . . . . routing strategies when a process at site a wants to communicate with a process at site b how is the message sent? if there is only one physical path from a to b such as in a star or tree structured network the message must be sent through that path. however if there are multiple physical paths from a to b then several routing options exist. each site has a routing table indicating the alternative paths that can be used to send a message to other sites. the table may include information about the speed and cost of the various communication paths and it may be updated as necessary either manually or via programs that exchange routing information. the three most common routing schemes are fixed routing virtual routing and dynamic routing. fixed routing. a path from a to b is specified in advance and does not change unless a hardware failure disables it. usually the shortest path is chosen so that communication costs are minimized. virtual routing. a path from a to b is fixed for the duration of one session. different sessions involving messages from a to b may use different paths. a session could be as short as a file transfer or as long as a remote login period. dynamic routing. the path used to send a message from site a to site b is chosen only when a message is sent. because the decision is made dynamically separate messages may be assigned different paths. site a will make a decision to send the message to site c c in turn will decide to send it to site d and so on. eventually a site will deliver the message to b. usually a site sends a message to another site on whatever link is the least used at that particular time. there are tradeoffs among these three schemes. fixed routing cannot adapt to link failures or load changes. in other words if a path has been established between a and b the messages must be sent along this path even if the path is down or is used more heavily than another possible path. we can partially remedy this problem by using virtual routing and can avoid it completely by using dynamic routing. fixed routing and virtual routing ensure that messages from a to b will be delivered in the order in which they were sent. in dynamic routing messages may arrive out of order. we can remedy this problem by appending a sequence number to each message. dynamic routing is the most complicated to set up and run however it is the best way to manage routing in complicated environments. unix provides both fixed routing for use on hosts within simple networks and dynamic chapter distributed system structures routing for complicated network environments. it is also possible to mix the two. within a site the hosts may just need to know how to reach the system that connects the local network to other networks such as company wide networks or the internet . such a node is known as a gateway. each individual host has a static route to the gateway although the gateway itself uses dynamic routing to reach any host on the rest of the network. a router is the entity within the computer network responsible for routing messages. a router can be a host computer with routing software or a special purpose device. either way a router must have at least two network connections or else it would have nowhere to route messages. a router decides whether any given message needs to be passed from the network on which it is received to any other network connected to the router. it makes this determination by examining the destination internet address of the message. the router checks its tables to determine the location of the destination host or at least of the network to which it will send the message toward the destination host. in the case of static routing this table is changed only by manual update a new file is loaded onto the router . with dynamic routing a routing protocol is used between routers to inform them of network changes and to allow them to update their routing tables automatically gateways and routers typically are dedicated hardware devices that run code out of firmware. . . packet strategies messages are generally of variable length. to simplify the system design we commonly implement communication with fixed length messages called packets frames or datagrams. a communication implemented in one packet can be sent to its destination in a connectionless message. a connectionless message can be unreliable in which case the sender has no guarantee that and cannot tell whether the packet reached its destination. alternatively the packet can be reliable usually in this case a packet is returned from the destination indicating that the packet arrived. of course the return packet could be lost along the way. if a message is too long to fit within one packet or if the packets need to flow back and forth between the two communicators a connection is established to allow the reliable exchange of multiple packets. . . connection strategies once messages are able to reach their destinations processes can institute communications sessions to exchange information. pairs of processes that want to communicate over the network can be connected in a number of ways. the three most common schemes are circuit switching message switching and packet switching. circuit switching. if two processes want to communicate a permanent physical link is established between them. this link is allocated for the duration of the communication session and no other process can use that link during this period even if the two processes are not actively communicating for a while . this scheme is similar to that used in the telephone system. once a communication line has been opened between two parties that is party a calls party b no one else can use this circuit . communication structure until the communication is terminated explicitly for example when the parties hang up . message switching. if two processes want to communicate a temporary link is established for the duration of one message transfer. physical links are allocated dynamically among correspondents as needed and are allocated for only short periods. each message is a block of data with system information such as the source the destination and errorcorrection codes ecc that allows the communication network to deliver the message to the destination correctly. this scheme is similar to the post office mailing system. each letter is a message that contains both the destination address and source return address. many messages from different users can be shipped over the same link. packet switching. one logical message may have to be divided into a number of packets. each packet may be sent to its destination separately and each therefore must include a source and destination address with its data. furthermore the various packets may take different paths through the network. the packets must be reassembled into messages as they arrive. note that it is not harmful for data to be broken into packets possibly routed separately and reassembled at the destination. breaking up an audio signal say a telephone communication in contrast could cause great confusion if it was not done carefully. there are obvious tradeoffs among these schemes. circuit switching requires substantial set up time and may waste network bandwidth but it incurs less overhead for shipping each message. conversely message and packet switching require less set up time but incur more overhead per message. also in packet switching each message must be divided into packets and later reassembled. packet switching is the method most commonly used on data networks because it makes the best use of network bandwidth. . . contention depending on the network topology a link may connect more than two sites in the computer network and several of these sites may want to transmit information over a link simultaneously. this situation occurs mainly in a ring or multiaccess bus network. in this case the transmitted information may become scrambled. if it does it must be discarded and the sites must be notified about the problem so that they can retransmit the information. if no special provisions are made this situation may be repeated resulting in degraded performance. several techniques have been developed to avoid repeated collisions including collision detection and token passing. csma cd. before transmitting a message over a link a site must listen to determine whether another message is currently being transmitted over that link this technique is called carrier sense with multiple access csma . if the link is free the site can start transmitting. otherwise it must wait and continue to listen until the link is free. if two or more sites begin transmitting at exactly the same time each thinking that no other site is using the link then they will register a collision detection cd and will chapter distributed system structures stop transmitting. each site will try again after some random time interval. the main problem with this approach is that when the system is very busy many collisions may occur and thus performance may be degraded. nevertheless csma cd has been used successfully in the ethernet system the most common local area network system. one strategy for limiting the number of collisions is to limit the number of hosts per ethernet network. adding more hosts to a congested network could result in poor network throughput. as systems get faster they are able to send more packets per time segment. as a result the number of systems per ethernet network generally is decreasing so that networking performance is kept reasonable. token passing. a unique message type known as a token continuously circulates in the system usually a ring structure . a site that wants to transmit information must wait until the token arrives. it removes the token from the ring and begins to transmit its messages. when the site completes its round of message passing it retransmits the token. this action in turn allows another site to receive and remove the token and to start its message transmission. if the token gets lost the system must then detect the loss and generate a new token. it usually does that by declaring an election to choose a unique site where a new token will be generated. later in section . we present one election algorithm. a token passing scheme has been adopted by the ibm and hp apollo systems. the benefit of a token passing network is that performance is constant. adding new sites to a network may lengthen the waiting time for a token but it will not cause a large performance decrease as may happen on ethernet. on lightly loaded networks however ethernet is more efficient because systems can send messages at any time
 when we are designing a communication network we must deal with the inherent complexity of coordinating asynchronous operations communicating in a potentially slow and error prone environment. in addition the systems on the network must agree on a protocol or a set of protocols for determining host names locating hosts on the network establishing connections and so on. we can simplify the design problem and related implementation by partitioning the problem into multiple layers. each layer on one system communicates with the equivalent layer on other systems. typically each layer has its own protocols and communication takes place between peer layers using a specific protocol. the protocols may be implemented in hardware or software. for instance figure . shows the logical communications between two computers with the three lowest level layers implemented in hardware. following the international standards organization iso we refer to the layers as follows . physical layer. the physical layer is responsible for handling both the mechanical and the electrical details of the physical transmission of a bit stream. at the physical layer the communicating systems must agree on the electrical representation of a binary and so that when data are . communication protocols computer a computer b application layer a l ? presentation layer p l session layer s m transport layer t l network layer m l link layer t l physical layer data network network environment iso environment real systems environment figure . two computers communicating via the iso network model. sent as a stream of electrical signals the receiver is able to interpret the data properly as binary data. this layer is implemented in the hardware of the networking device. . data link layer. the data link layer is responsible for handling ram ?s or fixed length parts of packets including any error detection and recovery that occurred in the physical layer. . network layer. the network layer is responsible for providing connections and for routing packets in the communication network including handling the addresses of outgoing packets decoding the addresses of incoming packets and maintaining routing information for proper response to changing load levels. routers work at this layer. . transport layer. the transport layer is responsible for low level access to the network and for transfer of messages between clients including partitioning messages into packets maintaining packet order controlling flow and generating physical addresses. . session layer. the session layer is responsible for implementing sessions or process to process communication protocols. typically these protocols are the actual communications for remote logins and for file and mail transfers. . presentation layer. the presentation layer is responsible for resolving the differences in formats among the various sites in the network including character conversions and half duplex full duplex modes character echoing . . application layer. the application layer is responsible for interacting directly with users. this layer deals with file transfer remote login protocols and electronic mail as well as with schemas for distributed databases. chapter distributed system structures figure . summarizes the iso protocol stack a set of cooperating protocols showing the physical flow of data. as mentioned logically each layer of a protocol stack communicates with the equivalent layer on other systems. but physically a message starts at or above the application layer and is passed through each lower level in turn. each layer may modify the message and include message header data for the equivalent layer on the receiving side. ultimately the message reaches the data network layer and is transferred as one or more packets figure . . the data link layer of the target system receives these data and the message is moved up through the protocol stack it is analyzed modified and stripped of headers as it progresses. it finally reaches the application layer for use by the receiving process. the iso model formalizes some of the earlier work done in network protocols but was developed in the late s and is currently not in widespread use. perhaps the most widely adopted protocol stack is the tcp ip model which end user application process distributed information services file transfer access and management document and message interchange application layer job transfer and manipulation syntax independent message interchange service i transfer syntax negotiation presentation layer data representation transformations dialog and synchronization session layer control for application entities network independent i message interchange service! end to end message transfer connection management error control transport layer fragmentation flow control network routing addressing network layer call set up and clearing data link control link layer framing data transparency error control mechanical and electrical physical layer network interface connections if physical connection to if network termination equipment!! data communication network figure . the iso protocol stack
 data link layer header network layer header transport layer header session layer header presentation layer application layer message data link layer trailer figure . an iso network message. has been adopted by virtually all internet sites. the tcp ip protocol stack has fewer layers than does the iso model. theoretically because it combines several functions in each layer it is more difficult to implement but more efficient than iso networking. the relationship between the iso and tcp ip models is shown in figure . . the tcp ip application layer identifies several protocols in widespread use in the internet including http ftp telnet dns and smtp. the transport layer identifies the unreliable connectionless user datagram protocol udp and the reliable connection oriented transmission control protocol tcp . the internet protocol ip is responsible for routing ip datagrams through the internet. the tcp ip model does not formally identify a link or physical layer allowing tcp ip traffic to run across any physical network. in section . we consider the tcp ip model running over an ethernet network. . robustness a distributed system may suffer from various types of hardware failure. the failure of a link the failure of a site and the loss of a message are the most common types. to ensure that the system is robust we must detect any of these failures reconfigure the system so that computation can continue and recover when a site or a link is repaired. . . failure detection in an environment with no shared memory we are generally unable to differentiate among link failure site failure and message loss. we can usually detect only that one of these failures has occurred. once a failure has been detected appropriate action must be taken. what action is appropriate depends on the particular application. chapter distributed system structures iso t cp ip http dns telnet smtp ftp not defined session not defined data lartk not defined physical not defined figure . the iso and tcp ip protocol stacks. to detect link and site failure we use a handshaking procedure. suppose that sites a and b have a direct physical link between them. at fixed intervals the sites send each other an l am up message. if site a does not receive this message within a predetermined time period it can assume that site b has failed that the link between a and b has failed or that the message from b has been lost. at this point site a has two choices. it can wait for another time period to receive an l am up message from b or it can send an are you up? message to b. if time goes by and site a still has not received an l am up message or if site a has sent an are you up? message and has not received a reply the procedure can be repeated. again the only conclusion that site a can draw safely is that some type of failure has occurred. site a can try to differentiate between link failure and site failure by sending an are you up? message to b by another route if one exists . if and when b receives this message it immediately replies positively. this positive reply tells a that b is up and that the failure is in the direct link between them. since we do not know in advance how long it will take the message to travel from a to b and back we must use a time out scheme. at the time a sends the are you up? message it specifies a time interval during which it is willing to wait for the reply from b. if a receives the reply message within that time interval then it can safely conclude that b is up. if not however that is if a time out occurs then a may conclude only that one or more of the following situations has occurred site b is down. the direct link if one exists from a to b is down. . design issues the alternative path from a to b is down. the message has been lostsite a cannot however determine which of these events has occurred. . . reconfiguration suppose that site a has discovered through the mechanism described in the previous section that a failure has occurred. it must then initiate a procedure that will allow the system to reconfigure and to continue its normal mode of operation. if a direct link from a to b has failed this information must be broadcast to every site in the system so that the various routing tables can be updated accordingly. if the system believes that a site has failed because that site can be reached no longer then all sites in the system must be so notified so that they will no longer attempt to use the services of the failed site. the failure of a site that serves as a central coordinator for some activity such as deadlock detection requires the election of a new coordinator. similarly if the failed site is part of a logical ring then a new logical ring must be constructed. note that if the site has not failed that is if it is up but cannot be reached then we may have the undesirable situation where two sites serve as the coordinator. when the network is partitioned the two coordinators each for its own partition may initiate conflicting actions. for example if the coordinators are responsible for implementing mutual exclusion we may have a situation where two processes are executing simultaneously in their critical sections. . . recovery from failure when a failed link or site is repaired it must be integrated into the system gracefully and smoothly. suppose that a link between a and b has failed. when it is repaired both a and b must be notified. we can accomplish this notification by continuously repeating the handshaking procedure described in section . . . suppose that site b has failed. when it recovers it must notify all other sites that it is up again. site b then may have to receive information from the other sites to update its local tables for example it may need routing table information a list of sites that are down or undelivered messages and mail. if the site has not failed but simply could not be reached then this information is still required. . design issues making the multiplicity of processors and storage devices transparent to the users has been a key challenge to many designers. ideally a distributed system chapter distributed system structures should look to its users like a conventional centralized system. the user interface of a transparent distributed system should not distinguish between local and remote resources. that is users should be able to access remote resources as though these resources were local and the distributed system should be responsible for locating the resources and for arranging for the appropriate interaction. another aspect of transparency is user mobility it would be convenient to allow users to log into any machine in the system rather than forcing them to use a specific machine. a transparent distributed system facilitates user mobility by bringing over the user's environment for example home directory to wherever she logs in. both the andrew file system from cmu and project athena from met provide this functionality on a large scale nfs can provide it on a smaller scale. another design issue involves fault tolerance. we use the termfault tolerance in a broad sense. communication faults machine failures of type fail stop storage device crashes and decays of storage media should all be tolerated to some extent. a fault tolerant system should continue to function perhaps in a degraded form when faced with these failures. the degradation can be in performance in functionality or in both. it should be proportional however to the failures that cause it. a system that grinds to a halt when only a few of its components fail is certainly not fault tolerant. unfortunately fault tolerance is difficult to implement. most commercial systems provide only limited fault tolerance. for instance the dec vax cluster allows multiple computers to share a set of disks. if a system crashes users can still access their information from another system. of course if a disk fails all systems will lose access. but in this case raid can ensure continued access to the data even in the event of a failure section . . still another issue is scalability the capability of a system to adapt to increased service load. systems have bounded resources and can become completely saturated under increased load. for example regarding a file system saturation occurs either when a server's cpu runs at a high utilization rate or when disks are almost full. scalability is a relative property but it can be measured accurately. a scalable system reacts more gracefully to increased load than does a nonscalable one. first its performance degrades more moderately and second its resources reach a saturated state later. even perfect design cannot accommodate an ever growing load. adding new resources might solve the problem but it might generate additional indirect load on other resources for example adding machines to a distributed system can clog the network and increase service loads . even worse expanding the system can call for expensive design modifications. a scalable system should have the potential to grow without these problems. in a distributed system the ability to scale up gracefully is of special importance since expanding the network by adding new machines or interconnecting two networks is commonplace. in short a scalable design should withstand high service load accommodate growth of the user community and enable simple integration of added resources. fault tolerance and scalability are related to each other. a heavily loaded component can become paralyzed and behave like a faulty component. also shifting the load from a faulty component to that component's backup can saturate the latter. generally having spare resources is essential for ensuring reliability as well as for handling peak loads gracefully an inherent advantage . design issues of a distributed system is a potential for fault tolerance and scalability because of the multiplicity of resources. however inappropriate design can obscure this potential. fault tolerance and scalability considerations call for a design demonstrating distribution of control and data. very large scale distributed systems to a great extent are still only theoretical. no magic guidelines ensure the scalability of a system. it is easier to point out why current designs are not scalable. we next discuss several designs that pose problems and propose possible solutions all in the context of scalability. one principle for designing very large scale systems is that the service demand from any component of the system should be bounded by a constant that is independent of the number of nodes in the system. any service mechanism whose load demand is proportional to the size of the system is destined to become clogged once the system grows beyond a certain size. adding more resources will not alleviate such a problem. the capacity of this mechanism simply limits the growth of the system. central control schemes and central resources should not be used to build scalable and fault tolerant systems. examples of centralized entities are central authentication servers central naming servers and central file servers. centralization is a form of functional asymmetry among machines constituting the system. the ideal alternative is a functionally symmetric configuration that is all the component machines have an equal role in the operation of the system and hence each machine has some degree of autonomy. practically it is virtually impossible to comply with such a principle. for instance incorporating diskless machines violates functional symmetry since the workstations depend on a central disk. however autonomy and symmetry are important goals to which we should aspire. the practical approximation of symmetric and autonomous configuration is clustering in which the system is partitioned into a collection of semiautonomous clusters. a cluster consists of a set of machines and a dedicated cluster server. so that cross cluster resource references are relatively infrequent each cluster server should satisfy requests of its own machines most of the time. of course this scheme depends on the ability to localize resource references and to place the component units appropriately. if the cluster is well balanced that is if the server in charge suffices to satisfy all the cluster demands it can be used as a modular building block to scale up the system. deciding on the process structure of the server is a major problem in the design of any service. servers are supposed to operate efficiently in peak periods when hundreds of active clients need to be served simultaneously. a single process server is certainly not a good choice since whenever a request necessitates disk i o the whole service will be blocked. assigning a process for each client is a better choice however the expense of frequent context switches between the processes must be considered. a related problem occurs because all the server processes need to share information. one of the best solutions for the server architecture is the use of lightweight processes or threads which we discussed in chapter . we can think of a group of lightweight processes as multiple threads of control associated with some shared resources. usually a lightweight process is not bound to a particular client. instead it serves single requests of different clients. scheduling of threads can be preemptive or nonpreemptive. if threads are allowed to run chapter distributed system structures to completion nonpreemptive then their shared data do not need to be protected explicitly. otherwise some explicit locking mechanism must be used. clearly some form of lightweight process scheme is essential if servers are to be scalable. . an example networking we now return to the name resolution issue raised in section . . and examine its operation with respect to the tcp ip protocol stack on the internet. we consider the processing needed to transfer a packet between hosts on different ethernet networks. in a tcp ip network every host has a name and an associated bit internet number or host id . both of these strings must be unique and so that the name space can be managed they are segmented. the name is hierarchical as explained in section . . describing the host name and then the organization with which the host is associated. the host id is split into a network number and a host number. the proportion of the split varies depending on the size of the network. once the internet administrators assign a network number the site with that number is free to assign host ids. the sending system checks its routing tables to locate a router to send the packet on its way. the routers use the network part of the host id to transfer the packet from its source network to the destination network. the destination system then receives the packet. the packet may be a complete message or it may just be a component of a message with more packets needed before the message can be reassembled and passed to the tcp udp layer for transmission to the destination process. now we know how a packet moves from its source network to its destination. within a network how does a packet move from sender host or router to receiver? every ethernet device has a unique byte number called the medium access control mac address assigned to it for addressing. two devices on a lan communicate with each other only with this number. if a system needs to send data to another system the kernel generates an address resolution protocol arp packet containing the ip address of the destination system. this packet is broadcast to all other systems on that ethernet network. a broadcast uses a special network address usually the maximum address to signal that all hosts should receive and process the packet. the broadcast is not re sent by gateways so only systems on the local network receive it. only the system whose ip address matches the ip address of the arp request responds and sends back its mac address to the system that initiated the query. for efficiency the host caches the ip mac address pair in an internal table. the cache entries are aged so that an entry is eventually removed from the cache if an access to that system is not required in a given time. in this way hosts that are removed from a network are eventually forgotten. for added performance arp entries for heavily used hosts may be hardwired in the arp cache. once an ethernet device has announced its host id and address communication can begin. a process may specify the name of a host with which to communicate. the kernel takes that name and determines the internet number of the target using a dks lookup. the message is passed from the application
 as we noted in the preceding chapter a distributed system is a collection of loosely coupled computers interconnected by a communication network. these computers can share physically dispersed files by using a distributed file system dfs . in this chapter we use the term dfs to mean distributed file systems in general not the commercial transarc dfs product. the latter is referenced as transarc dfs. also nfs refers to nfs version unless otherwise noted. chapter distributed file systems to explain the structure of a dfs we need to define the terms service seroer and client. a service is a software entity running on one or more machines and providing a particular type of function to clients. a server is the service software running on a single machine. a client is a process that can invoke a service using a set of operations that form its client interface. sometimes a lower level interface is defined for the actual cross machine interaction it is the intermachine interface. using this terminology we say that a file system provides file services to clients. a client interface for a file service is formed by a set of primitive file operations such as create a file delete a file read from a file and write to a file. the primary hardware component that a file server controls is a set of local secondary storage devices usually magnetic disks on which files are stored and from which they are retrieved according to the clients' requests. a dfs is a file system whose clients servers and storage devices are dispersed among the machines of a distributed system. accordingly service activity has to be carried out across the network. instead of a single centralized data repository the system frequently has multiple and independent storage devices. as you will see in this text the concrete configuration and implementation of a dfs may vary from system to system. in some configurations servers run on dedicated machines in others a machine can be both a server and a client. a dfs can be implemented as part of a distributed operating system or alternatively by a software layer whose task is to manage the communication between conventional operating systems and file systems. the distinctive features of a dfs are the multiplicity and autonomy of clients and servers in the system. ideally a dfs should appear to its clients to be a conventional centralized file system. the multiplicity and dispersion of its servers and storage devices should be made invisible. that is the client interface of a dfs should not distinguish between local and remote files. it is up to the dfs to locate the files and to arrange for the transport of the data. a transparent dfs facilitates user mobility by bringing the user's environment that is home directory to wherever a user logs in. the most important performance measurement of a dfs is the amount of time needed to satisfy service requests. in conventional systems this time consists of disk access time and a small amount of cpu processing time. in a dfs however a remote access has the additional overhead attributed to the distributed structure. this overhead includes the time to deliver the request to a server as well as the time to get the response across the network back to the client. for each direction in addition to the transfer of the information there is the cpu overhead of running the communication protocol software. the performance of a dfs can be viewed as another dimension of the dfs's transparency. that is the performance of an ideal dfs would be comparable to that of a conventional file system. the fact that a dfs manages a set of dispersed storage devices is the dfs's key distinguishing feature. the overall storage space managed by a dfs is composed of different and remotely located smaller storage spaces. usually these constituent storage spaces correspond to sets of files. a component unit is the smallest set of files that can be stored on a single machine independently from other units. all files belonging to the same component unit must reside in the same location
 . naming and transparency naming is a mapping between logical and physical objects. for instance users deal with logical data objects represented by file names whereas the system manipulates physical blocks of data stored on disk tracks. usually a user refers to a file by a textual name. the latter is mapped to a lower level numerical identifier that in turn is mapped to disk blocks. this multilevel mapping provides users with an abstraction of a file that hides the details of how and where on the disk the file is stored. in a transparent dfs a new dimension is added to the abstraction that of hiding where in the network the file is located. in a conventional file system the range of the naming mapping is an address within a disk. in a dfs this range is expanded to include the specific machine on whose disk the file is stored. going one step further with the concept of treating files as abstractions leads to the possibility of file replication. given a file name the mapping returns a set of the locations of this file's replicas. in this abstraction both the existence of multiple copies and their locations are hidden. . . naming structures we need to differentiate two related notions regarding name mappings in a dfs . location transparency. the name of a file does not reveal any hint of the file's physical storage location. . location independence. the name of a file does not need to be changed when the file's physical storage location changes. both definitions are relative to the level of naming discussed previously since files have different names at different levels that is user level textual names and system level numerical identifiers . a location independent naming scheme is a dynamic mapping since it can map the same file name to different locations at two different times. therefore location independence is a stronger property than is location transparency. in practice most of the current dfss provide a static location transparent mapping for user level names. these systems however do not support file migration that is changing the location of a file automatically is impossible. hence the notion of location independence is irrelevant for these systems. files are associated permanently with a specific set of disk blocks. files and disks can be moved between machines manually but file migration implies an automatic operating system initiated action. only afs and a few experimental file systems support location independence and file mobility. afs supports file mobility mainly for administrative purposes. a protocol provides migration of afs component units to satisfy high level user requests without changing either the user level names or the low level names of the corresponding files. a few aspects can further differentiate location independence and static location transparency divorce of data from location as exhibited by location independence provides a better abstraction for files. a file name should denote the file's chapter distributed file systems most significant attributes which are its contents rather than its location. location independent files can be viewed as logical data containers that are not attached to a specific storage location. if only static location transparency is supported the file name still denotes a specific although hidden set of physical disk blocks. static location transparency provides users with a convenient way to share data. users can share remote files by simply naming the files in a locationtransparent manner as though the files were local. nevertheless sharing the storage space is cumbersome because logical names are still statically attached to physical storage devices. location independence promotes sharing the storage space itself as well as the data objects. when files can be mobilized the overall system wide storage space looks like a single virtual resource. a possible benefit of such a view is the ability to balance the utilization of disks across the system. location independence separates the naming hierarchy from the storagedevices hierarchy and from the intercomputer structure. by contrast if static location transparency is used although names are transparent we can easily expose the correspondence between component units and machines. the machines are configured in a pattern similar to the naming structure. this configuration may restrict the architecture of the system unnecessarily and conflict with other considerations. a server in charge of a root directory is an example of a structure that is dictated by the naming hierarchy and contradicts decentralization guidelines. once the separation of name and location has been completed clients can access files residing on remote server systems. in fact these clients may be diskless and rely on servers to provide all files including the operatingsystem kernel. special protocols are needed for the boot sequence however. consider the problem of getting the kernel to a diskless workstation. the diskless workstation has no kernel so it cannot use the dfs code to retrieve the kernel. instead a special boot protocol stored in read only memory rom on the client is invoked. it enables networking and retrieves only one special file the kernel or boot code from a fixed location. once the kernel is copied over the network and loaded its dfs makes all the other operating system files available. the advantages of diskless clients are many including lower cost because the client machines require no disks and greater convenience when an operating system upgrade occurs only the server needs to be modified . the disadvantages are the added complexity of the boot protocols and the performance loss resulting from the use of a network rather than a local disk. the current trend is for clients to use both local disks and remote file servers. operating systems and networking software are stored locally file systems containing user data and possibly applications are stored on remote file systems. some client systems may store commonly used applications such as word processors and web browsers on the local file system as well. other less commonly used applications may be pushed from the remote file server to the client on demand. the main reason for providing clients with local file systems rather than pure diskless systems is that disk drives are rapidly increasing in capacity and decreasing in cost with new generations appearing every year or so. the same cannot be said for networks which evolve every few years. . naming and transparency overall systems are growing more quickly than are networks so extra work is needed to limit network access to improve system throughput. . . naming schemes there are three main approaches to naming schemes in a dfs. in the simplest approach a file is identified by some combination of its host name and local name which guarantees a unique system wide name. in ibis for instance a file is identified uniquely by the name host local name where local name is a umx like path. this naming scheme is neither location transparent nor location independent. nevertheless the same file operations can be used for both local and remote files. the dfs is structured as a collection of isolated component units each of which is an entire conventional file system. in this first approach component units remain isolated although means are provided to refer to a remote file. we do not consider this scheme any further in this text. the second approach was popularized by sun's network file system nfs . nfs is the file system component of onc a networking package supported by many unix vendors. nfs provides a means to attach remote directories to local directories thus giving the appearance of a coherent directory tree. early nfs versions allowed only previously mounted remote directories to be accessed transparently. with the advent of the automount feature mounts are done on demand based on a table of mount points and file structure names. components are integrated to support transparent sharing although this integration is limited and is not uniform because each machine may attach different remote directories to its tree. the resulting structure is versatile. we can achieve total integration of the component file systems by using the third approach. a single global name structure spans all the files in the system. ideally the composed file system structure is isomorphic to the structure of a conventional file system. in practice however the many special files for example unix device files and machine specific binary directories make this goal difficult to attain. to evaluate naming structures we look at their administrative complexity. the most complex and most difficult to maintain structure is the nfs structure. because any remote directory can be attached anywhere onto the local directory tree the resulting hierarchy can be highly unstructured. if a server becomes unavailable some arbitrary set of directories on different machines becomes unavailable. in addition a separate accreditation mechanism controls which machine is allowed to attach which directory to its tree. thus a user might be able to access a remote directory tree on one client but be denied access on another client. . . implementation techniques implementation of transparent naming requires a provision for the mapping of a file name to the associated location. to keep this mapping manageable we must aggregate sets of files into component units and provide the mapping on a component unit basis rather than on a single file basis. this aggregation serves administrative purposes as well. unix like systems use the hierarchical directory tree to provide name to location mapping and to aggregate files recursively into directories. chapter distributed file systems to enhance the availability of the crucial mapping information we ca n use replication local caching or both. as we noted location independence means that the mapping changes over time hence replicating the mapping makes a simple yet consistent update of this information impossible. a technique to overcome this obstacle is to introduce low level location independent file identifiers. textual file names are mapped to lower level file identifiers that indicate to which component unit the file belongs. these identifiers are still location independent. they can be replicated and cached freely without being invalidated by migration of component units. the inevitable price is the need for a second level of mapping which maps component units to locations and needs a simple yet consistent update mechanism. implementing unix like directory trees using these low level location independent identifiers makes the whole hierarchy invariant under component unit migration. the only aspect that does change is the component unit location mapping. a common way to implement low level identifiers is to use structured names. these names are bit strings that usually have two parts. the first part identifies the component unit to which the file belongs the second part identifies the particular file within the unit. variants with more parts are possible. the invariant of structured names however is that individual parts of the name are unique at all times only within the context of the rest of the parts. we can obtain uniqueness at all times by taking care not to reuse a name that is still used by adding sufficiently more bits this method is used in afs or by using a timestamp as one part of the name as done in apollo domain . another way to view this process is that we are taking a location transparent system such as ibis and adding another level of abstraction to produce a location independent naming scheme. aggregating files into component units and using lower level locationindependent file identifiers are techniques exemplified in afs
 consider a user who requests access to a remote file. the server storing the file has been located by the naming scheme and now the actual data transfer must take place. one way to achieve this transfer is through a remote service mechanism whereby requests for accesses are delivered to the server the server machine performs the accesses and their results are forwarded back to the user. one of the most common ways of implementing remote service is the remote procedure call rpc paradigm which we discussed in chapter . a direct analogy exists between disk access methods in conventional file systems and the remote service method in a dfs using the remote service method is analogous to performing a disk access for each access request. to ensure reasonable performance of a remote service mechanism we can use a form of caching. in conventional file systems the rationale for caching is to reduce disk i o thereby increasing performance whereas in dfss the goal is to reduce both network traffic and disk i o. in the following discussion we describe the implementation of caching in a dfs and contrast it with the basic remote service paradigm. . remote file access . . basic caching scheme f the concept of caching is simple. if the data needed to satisfy the access reqviest are not already cached then a copy of those data is brought from the server to the client system. accesses are performed on the cached copy. the idea is to retain recently accessed disk blocks in the cache so that repeated accesses to the same information can be handled locally without additional network traffic. a replacement policy for example least recently used keeps the cache size bounded. no direct correspondence exists between accesses and traffic to the server. files are still identified with one master copy residing at the server machine but copies or parts of the file are scattered in different caches. when a cached copy is modified the changes need to be reflected on the master copy to preserve the relevant consistency semantics. the problem of keeping the cached copies consistent with the master file is the cache consistency problem which we discuss in section . . . dfs caching could just as easily be called network virtual memory it acts similarly to demand paged virtual memory except that the backing store usually is not a local disk but rather a remote server. nfs allows the swap space to be mounted remotely so it actually can implement virtual memory over a network notwithstanding the resulting performance penalty. the granularity of the cached data in a dfs can vary from blocks of a file to an entire file. usually more data are cached than are needed to satisfy a single access so that many accesses can be served by the cached data. this procedure is much like disk read ahead section . . . afs caches files in large chunks kb . the other systems discussed in this chapter support caching of individual blocks driven by client demand. increasing the caching unit increases the hit ratio but it also increases the miss penalty because each miss requires more data to be transferred. it increases the potential for consistency problems as well. selecting the unit of caching involves considering parameters such as the network transfer unit and the rpc protocol service unit if an rpc protocol is used . the network transfer unit for ethernet a packet is about . kb so larger units of cached data need to be disassembled for delivery and reassembled on reception. block size and total cache size are obviously of importance for blockcaching schemes. in unix like systems common block sizes are kb and kb. for large caches over mb large block sizes over kb are beneficial. for smaller caches large block sizes are less beneficial because they result in fewer blocks in the cache and a lower hit ratio. . . cache location where should the cached data be stored on disk or in main memory? disk caches have one clear advantage over main memory caches they are reliable. modifications to cached data are lost in a crash if the cache is kept in volatile memory. moreover if the cached data are kept on disk they are still there during recovery and there is no need to fetch them again. main memory caches have several advantages of their own however main memory caches permit workstations to be diskless. data can be accessed more quickly from a cache in main memory than from one on a disk. chapter distributed file systems technology is moving toward larger and less expensive memory. the achieved performance speedup is predicted to outweigh the advantages of disk caches. the server caches used to speed up disk i o will be in main memory regardless of where user caches are located if we use main memory caches on the user machine too we can build a single caching mechanism for use by both servers and users. many remote access implementations can be thought of as hybrids of caching and remote service. in nfs for instance the implementation is based on remote service but is augmented with client and server side memory caching for performance. similarly sprite's implementation is based on caching but under certain circumstances a remote service method is adopted. thus to evaluate the two methods we must evaluate to what degree either method is emphasized. the nfs protocol and most implementations do not provide disk caching. recent solaris implementations of nfs solaris . and beyond include a clientside disk caching option the cachefs file system. once the nfs client reads blocks of a file from the server it caches them in memory as well as on disk. if the memory copy is flushed or even if the system reboots the disk cache is referenced. if a needed block is neither in memory nor in the cachefs disk cache an rpc is sent to the server to retrieve the block and the block is written into the disk cache as well as stored in the memory cache for client use. . . cache update policy the policy used to write modified data blocks back to the server's master copy has a critical effect on the system's performance and reliability. the simplest policy is to write data through to disk as soon as they are placed in any cache. the advantage of a write through policy is reliability little information is lost when a client system crashes. however this policy requires each write access to wait until the information is sent to the server so it causes poor write performance. caching with write through is equivalent to using remote service for write accesses and exploiting caching only for read accesses. an alternative is the delayed write policy also known as write back caching where we delay updates to the master copy. modifications are written to the cache and then are written through to the server at a later time. this policy has two advantages over write through. first because writes are made to the cache write accesses complete much more quickly. second data may be overwritten before they are written back in which case only the last update needs to be written at all. unfortunately delayed write schemes introduce reliability problems since unwritten data are lost whenever a user machine crashes. variations of the delayed write policy differ in when modified data blocks are flushed to the server. one alternative is to flush a block when it is about to be ejected from the client's cache. this option can result in good performance but some blocks can reside in the client's cache a long time before they are written back to the server. a compromise between this alternative and the write through policy is to scan the cache at regular intervals and to flush blocks that have been modified since the most recent scan just as unix scans . remote file access memory cache write through network hiserver disk storage memory cache disk object write back disk cache write through figure . cachets and its use of caching. its local cache. sprite uses this policy with a second interval. nfs uses the policy for file data but once a write is issued to the server during a cache flush the write must reach the server's disk before it is considered complete. nfs treats metadata directory data and file attribute data differently. any metadata changes are issued synchronously to the server. thus file structure loss and directory structure corruption are avoided when a client or the server crashes. for nfs with cachefs writes are also written to the local disk cache area when they are written to the server to keep all copies consistent. thus nfs with cachefs improves performance over standard nfs on a read request with a cachefs cache hit but decreases performance for read or write requests with a cache miss. as with all caches it is vital to have a high cache hit rate to gain performance. cachefs and its use of write through and write back caching is shown in figure . . yet another variation on delayed write is to write data back to the server when the file is closed. this write on close policy is used in afs. in the case of files that are open for short periods or are modified rarely this policy does not significantly reduce network traffic. in addition the write on close policy requires the closing process to delay while the file is written through which reduces the performance advantages of delayed writes. for files that are open for long periods and are modified frequently however the performance advantages of this policy over delayed write with more frequent flushing are apparent. . . consistency a client machine is faced with the problem of deciding whether or not a locally cached copy of the data is consistent with the master copy and hence can be chapter distributed file systems used . if the client machine determines that its cached data are out of date accesses can no longer be served by those cached data. an up to date copy of the data needs to be cached. there are two approaches to verifying the validity of cached data . client initiated approach. the client initiates a validity check in which it contacts the server and checks whether the local data are consistent with the master copy. the frequency of the validity checking is the crux of this approach and determines the resulting consistency semantics. it can range from a check before every access to a check only on first access to a file on file open basically . every access coupled with a validity check is delayed compared with an access served immediately by the cache. alternatively checks can be initiated at fixed time intervals. depending on its frequency the validity check can load both the network and the server. . server initiated approach. the server records for each client the files or parts of files that it caches. when the server detects a potential inconsistency it must react. a potential for inconsistency occurs when two different clients in conflicting modes cache a file. if unix semantics section . . is implemented we can resolve the potential inconsistency by having the server play an active role. the server must be notified whenever a file is opened and the intended mode read or write must be indicated for every open. the server can then act when it detects that file has been opened simultaneously in conflicting modes by disabling caching for that particular file. actually disabling caching results in switching to a remote service mode of operation. . . a comparison of caching and remote service essentially the choice between caching and remote service trades off potentially increased performance with decreased simplicity. we evaluate this tradeoff by listing the advantages and disadvantages of the two methods when caching is used the local cache can handle a substantial number of the remote accesses efficiently. capitalizing on locality in file access patterns makes caching even more attractive. thus most of the remote accesses will be served as fast as will local ones. moreover servers are contacted only occasionally rather than for each access. consequently server load and network traffic are reduced and the potential for scalability is enhanced. by contrast when the remote service method is used every remote access is handled across the network. the penalty in network traffic server load and performance is obvious. total network overhead is lower for transmitting big chunks of data as is done in caching than for transmitting series of responses to specific requests as in the remote service method . furthermore disk access routines on the server may be better optimized if it is known that requests will always be for large contiguous segments of data rather than for random disk blocks
 the cache consistency problem is the major drawback of caching. when access patterns exhibit infrequent writes caching is superior. however when writes are frequent the mechanisms employed to overcome the consistency problem incur substantial overhead in terms of performance network traffic and server load. so that caching will confer a benefit execution should be carried out on machines that have either local disks or large main memories. remote access on diskless small memory capacity machines should be done through the remote service method. in caching since data are transferred en masse between the server and the client rather than in response to the specific needs of a file operation the lower level intermachine interface is different from the upper level user interface. the remote service paradigm in contrast is just an extension of the local file system interface across the network. thus the intermachine interface mirrors the user interface. . stateful versus stateless service there are two approaches for storing server side information when a client accesses remote files either the server tracks each file being accessed byeach client or it simply provides blocks as they are requested by the client without knowledge of how those blocks are used. in the former case the service provided is stateful in the latter case it is stateless. the typical scenario of a stateful file service is as follows a client must perform an open operation on a file before accessing that file. the server fetches information about the file from its disk stores it in its memory and gives the client a connection identifier that is unique to the client and the open file. in umix terms the server fetches the mode and gives the client a file descriptor which serves as an index to an in core table of inodes. this identifier is used for subsequent accesses until the session ends. a stateful service is characterized as a connection between the client and the server during a session. either on closing the file or by a garbage collection mechanism the server must reclaim the main memory space used by clients that are no longer active. the key point regarding fault tolerance in a stateful service approach is that the server keeps main memory information about its clients. afs is a stateful file service. a stateless file service avoids state information by making each request self contained. that is each request identifies the file and the position in the file for read and write accesses in full. the server does not need to keep a table of open files in main memory although it usually does so for efficiencyreasons. moreover there is no need to establish and terminate a connection through open and close operations. they are totally redundant since each file operation stands on its own and is not considered part of a session. a client process would open a file and that open would not result in the sending of a remote message. reads and writes would take place as remote messages or cache lookups . the final close by the client would again result in only a local operation. nfs is a stateless file service. the advantage of a stateful over a stateless service is increased performance. file information is cached in main memory and can be accessed easily chapter distributed file systems via the connection identifier thereby saving disk accesses. in addition a s ateful server knows whether a file is open for sequential access and can therefore read ahead the next blocks. stateless servers cannot do so since they have no knowledge of the purpose of the client's requests. the distinction between stateful and stateless service becomes more evident when we consider the effects of a crash that occurs during a service activity. a stateful server loses all its volatile state in a crash. ensuring the graceful recovery of such a server involves restoring this state usually by a recovery protocol based on a dialog with clients. less graceful recovery requires that the operations that were underway when the crash occurred be aborted. a different problem is caused by client failures. the server needs to become aware of such failures so that it can reclaim space allocated to record the state of crashed client processes. this phenomenon is sometimes referred to as orphan detection and elimination. a stateless computer server avoids these problems since a newly reincarnated server can respond to a self contained request without any difficulty. therefore the effects of server failures and recovery are almost unnotkeable. there is no difference between a slow server and a recovering server from a client's point of view. the client keeps retransmitting its request if it receives no response. the penalty for using the robust stateless service is longer request messages and slower processing of requests since there is no in core information to speed the processing. in addition stateless service imposes additional constraints on the design of the dfs. first since each request identifies the target file a uniform system wide low level naming scheme should be used. translating remote to local names for each request would cause even slower processing of the requests. second since clients retransmit requests for file operations these operations must be idempotent that is each operation must have the same effect and return the same output if executed several times consecutively. self contained read and write accesses are idempotent as long as they use an absolute byte count to indicate the position within the file they access and do not rely on an incremental offset as done in unix read and write system calls . however we must be careful when implementing destructive operations such as deleting a file to make them idempotent too. in some environments a stateful service is a necessity. if the server employs the server initiated method for cache validation it cannot provide stateless service since it maintains a record of which files are cached by which clients. the way unix uses file descriptors and implicit offsets is inherently stateful. servers must maintain tables to map the file descriptors to inodes and must store the current offset within a file. this requirement is why nfs which employs a stateless service does not use file descriptors and does include an explicit offset in every access
 replication of files on different machines in a distributed file system is a useful redundancy for improving availability. multimachine replication can benefit performance too selecting a nearby replica to serve an access request results in shorter service time. . file replication nfs v our coverage of nfs thus far has only considered version or v nfs. the most recent nfs standard is version v and it differs fundamentally from previous versions. the most significant change is that the protocol is now statefid meaning that the server maintains the state of the client session from the time the remote file is opened until it is closed. thus the nfs protocol now provides openo and close operations previous versions of nfs which are stateless provide no such operations. furthermore previous versions specify separate protocols for mounting remote file systems and for locking remote files. v provides all of these features under a single protocol. in particular the mount protocol was eliminated allowing nfs to work with network firewalls. the mount protocol was a notorious security hole in nfs implementations. additionally v has enhanced the ability of clients to cache file data locally. this feature improves the performance of the distributed file system as clients are able to resolve more file accesses from the local cache rather than having to go through the server. v allows clients to request file locks from servers as well. if the server grants the request the client maintains the lock until it is released or its lease expires. clients are also permitted to renew existing leases. traditionally unix based systems provide advisory file locking whereas windows operating systems use mandatory locking. to allow nfs to work well with non unix systems v now provides mandatory locking as well. the new locking and caching mechanisms are based on the concept of delegation whereby the server delegates responsibilities for a file's lock and contents to the client that requested the lock. that delegated client maintains in cache the current version of the file and other clients can ask that delegated client for lock access and file contents until the delegated client relinquishes the lock and delegation. finally whereas previous versions of nfs are based on the udp network protocol v is based on tcp which allows it to better adjust to varying traffic loads on the network. delegating these responsibilities to clients reduces the load on the server and improves cache coherency. the basic requirement of a replication scheme is that different replicas of the same file reside on failure independent machines. that is the availability of one replica is not affected by the availability of the rest of the replicas. this obvious requirement implies that replication management is inherently a location opaque activity. provisions for placing a replica on a particular machine must be available. it is desirable to hide the details of replication from users. mapping a replicated file name to a particular replica is the task of the naming scheme. the existence of replicas should be invisible to higher levels. at lower levels however the replicas must be distinguished from one another by different lower level names. another transparency requirement is providing replication control at higher levels. replication control includes determination of the degree of replication and of the placement of replicas. under certain circumstances we may want to expose these details to users. locus for chapter distributed file systems instance provides users and system administrators with mechanisms to control the replication scheme. the main problem associated with replicas is updating. from a user's point of view replicas of a file denote the same logical entity and thus an update to any replica must be reflected on all other replicas. more precisely the relevant consistency semantics must be preserved when accesses to replicas are viewed as virtual accesses to the replicas' logical files. if consistency is not of primary importance it can be sacrificed for availability and performance. in this fundamental tradeoff in the area of fault tolerance the choice is between preserving consistency at all costs thereby creating a potential for indefinite blocking and sacrificing consistency under some we hope rare circumstances of catastrophic failures for the sake of guaranteed progress. locus for example employs replication extensively and sacrifices consistency in the case of network partition for the sake of availability of files for read and write accesses. ibis uses a variation of the primary copy approach. the domain of the name mapping is a pair primary replica identifier local replica identifier . ifno local replica exists a special value is used. thus the mapping is relative to a machine. if the local replica is the primary one the pair contains two identical identifiers. ibis supports demand replication an automatic replication control policy similar to whole file caching. under demand replication reading of a nonlocal replica causes it to be cached locally thereby generating a new nonprimary replica. updates are performed only on the primary copy and cause all other replicas to be invalidated through the sending of appropriate messages. atomic and serialized invalidation of all nonprimary replicas is not guaranteed. hence a stale replica may be considered valid. to satisfy remote write accesses we migrate the primary copy to the requesting machine. . an example afs andrew is a distributed computing environment designed and implemented at carnegie mellon university. the andrew file system afs constitutes the underlying information sharing mechanism among clients of the environment. the transarc corporation took over development of afs then was purchased by ibm. ibm has since produced several commercial implementations of afs. afs was subsequently chosen as the dfs for an industry coalition the result was transarc dfs part of the distributed computing environment dce from the osf organization. in ibm's transarc lab announced that afs would be an open source product termed openafs available under the ibm public license and transarc dfs was canceled as a commercial product. openafs is available under most commercial versions of unix as well as linux and microsoft windows systems. many unix vendors as well as microsoft support the dce system and its dfs which is based on afs and work is ongoing to make dce a cross platform universally accepted dfs. as afs and transarc dfs are very similar we describe afs throughout this section unless transarc dfs is named specifically. afs seeks to solve many of the problems of the simpler dfss such as nfs and is arguably the most feature rich nonexperimental dfs. it features a uniform name space location independent file sharing client side caching . an example afs with cache consistency and secure authentication via kerberos. it also includes server side caching in the form of replicas with high avail ability through automatic switchover to a replica if the source server is unavailable. one of the most formidable attributes of afs is scalability the andrew system is targeted to span over workstations. between afs and transarc dfs there are hundreds of implementations worldwide. . . overview afs distinguishes between client machines sometimes referred to as workstations and dedicated server machines. servers and clients originally ran only . bsd unix but afs has been ported to many operating systems. the clients and servers are interconnected by a network of lans or wans. clients are presented with a partitioned space of file names a local name space and a shared name space. dedicated servers collectively called vice after the name of the software they run present the shared name space to the clients as a homogeneous identical and location transparent file hierarchy. the local name space is the root file system of a workstation from which the shared name space descends. workstations run the virtue protocol to communicate with vice and each is required to have a local disk where it stores its local name space. servers collectively are responsible for the storage and management of the shared name space. the local name space is small is distinct for each workstation and contains system programs essential for autonomous operation and better performance. also local are temporary files and files that the workstation owner for privacy reasons explicitly wants to store locally. viewed at a finer granularity clients and servers are structured in clusters interconnected by a wan. each cluster consists of a collection of workstations on a lan and a representative of vice called a cluster server and each cluster is connected to the wan by a router. the decomposition into clusters is done primarily to address the problem of scale. for optimal performance workstations should use the server on their own cluster most of the time thereby making cross cluster file references relatively infrequent. the file system architecture is also based on considerations of scale. the basic heuristic is to offload work from the servers to the clients in light of experience indicating that server cpu speed is the system's bottleneck. following this heuristic the key mechanism selected for remote file operations is to cache files in large chunks kb . this feature reduces file open latency and allows reads and writes to be directed to the cached copy without frequently involving the servers. briefly here are a few additional issues in the design of afs client mobility. clients are able to access any file in the shared name space from any workstation. a client may notice some initial performance degradation due to the caching of files when accessing files from a workstation other than the usual one. security. the vice interface is considered the boundary of trustworthiness because no client programs are executed on vice machines. authentication and secure transmission functions are provided as part of a connectionbased communication package based on the rpc paradigm. after mutual chapter distributed file systems authentication a vice server and a client communicate via encrypted messages. encryption is performed by hardware devices or more slowly in software. information about clients and groups is stored in a protection database replicated at each server. protection. afs provides access lists for protecting directories and the regular unix bits for file protection. the access list may contain information about those users allowed to access a directory as well as information about those users not allowed to access it. thus it is simple to specify that everyone except say jim can access a directory. afs supports the access types read write lookup insert administer lock and delete. heterogeneity. defining a clear interface to vice is a key for integration of diverse workstation hardware and operating systems. so that heterogeneity is facilitated some files in the local bin directory are symbolic links pointing to machine specific executable files residing in vice. . . the shared name space afs's shared name space is made up of component units called volumes. the volumes are unusually small component units. typically they are associated with the files of a single client. few volumes reside within a single disk partition and they may grow up to a quota and shrink in size. conceptually volumes are glued together by a mechanism similar to the unix mount mechanism. however the granularity difference is significant since in unix only an entire disk partition containing a file system canbe mounted. volumes are a key administrative unit and play a vital role in identifying and locating an individual file. a vice file or directory is identified by a low level identifier called a fid. each afs directory entry maps a path name component to a fid. a fid is bits long and has three equal length components a volume number a vnode number and a iiniquifier. the vnode number is used as an index into an array containing the modes of files in a single volume. the uniquifier allows reuse of vnode numbers thereby keeping certain data structures compact. fids are location transparent therefore file movements from server to server do not invalidate cached directory contents. location information is kept on a volume basis in a volume location database replicated on each server. a client can identify the location of every volume in the system by querying this database. the aggregation of files into volumes makes it possible to keep the location database at a manageable size. to balance the available disk space and utilization of servers volumes need to be migrated among disk partitions and servers. when a volume is shipped to its new location its original server is left with temporary forwarding information so that the location database does not need to be updated synchronously. while the volume is being transferred the original server can still handle updates which are shipped later to the new server. at some point the volume is briefly disabled so that the recent modifications can be processed then the new volume becomes available again at the new site. the volume movement operation is atomic if either server crashes the operation is aborted. . an example afs read only replication at the granularity of an entire volume is supported for system executable files and for seldom updated files in the upper levels of the vice name space. the volume location database specifies the server containing the only read write copy of a volume and a list of read only replication sites. . . file operations and consistency semantics the fundamental architectural principle in afs is the caching of entire files from servers. accordingly a client workstation interacts with vice servers only during opening and closing of files and even this interaction is not always necessary. reading and writing files do not cause remote interaction in contrast to the remote service method . this key distinction has far reaching ramifications for performance as well as for semantics of file operations. the operating system on each workstation intercepts file system calls and forwards them to a client level process on that workstation. this process called venus caches files from vice when they are opened and stores modified copies of files back on the servers from which they came when they are closed. venus may contact vice only when a file is opened or closed reading and writing of individual bytes of a file are performed directly on the cached copy and bypass venus. as a result writes at some sites are not visible immediately at other sites. caching is further exploited for future opens of the cached file. venus assumes that cached entries files or directories are valid unless notified otherwise. therefore venus does not need to contact vice on a file open to validate the cached copy. the mechanism to support this policy called callback dramatically reduces the number of cache validation requests received by servers. it works as follows. when a client caches a file or a directory the server updates its state information to record this caching. we say that the client has a callback on that file. the server notifies the client before allowing another client to modify the file. in such a case we say that the server removes the callback on the file for the former client. a client can use a cached file for open purposes only when the file has a callback. if a client closes a file after modifying it all other clients caching this file lose their callbacks. therefore when these clients open the file later they have to get the new version from the server. reading and writing bytes of a file are done directly by the kernel without venus's intervention on the cached copy. venus regains control when the file is closed. if the file has been modified locally it updates the file on the appropriate server. thus the only occasions on which venus contacts vice servers are on opens of files that either are not in the cache or have had their callback revoked and on closes of locally modified files. basically afs implements session semantics. the only exceptions are file operations other than the primitive read and write such as protection changes at the directory level which are visible everywhere on the network immediately after the operation completes. in spite of the callback mechanism a small amount of cached validation traffic is still present usually to replace callbacks lost because of machine or network failures. when a workstation is rebooted venus considers all cached chapter distributed file systems files and directories suspect and it generates a cache validation request for the first use of each such entry. the callback mechanism forces each server to maintain callback information and each client to maintain validity information. if the amount of callback information maintained by a server is excessive the server can break callbacks and reclaim some storage by unilaterally notifying clients and revoking the validity of their cached files. if the callback state maintained by venus gets out of sync with the corresponding state maintained by the servers some inconsistency may result. venus also caches contents of directories and symbolic links for pathname translation. each component in the path name is fetched and a callback is established for it if it is not already cached or if the client does not have a callback on it. venus does lookups on the fetched directories locally using fids. no requests are forwarded from one server to another. at the end of a path name traversal all the intermediate directories and the target file are in the cache with callbacks on them. future open calls to this file will involve no network communication at all unless a callback is broken on a component of the path name. the only exception to the caching policy is a modification to a directory that is made directly on the server responsible for that directory for reasons of integrity. the vice interface has well defined operations for such purposes. venus reflects the changes in its cached copy to avoid re fetching the directory. . . implementation client processes are interfaced to a unix kernel with the usual set of system calls. the kernel is modified slightly to detect references to vice files in the relevant operations and to forward the requests to the client level venus process at the workstation. venus carries out path name translation component by component as described above. it has a mapping cache that associates volumes to server locations in order to avoid server interrogation for an already known volume location. if a volume is not present in this cache venus contacts any server to which it already has a connection requests the location information and enters that information into the mapping cache. unless venus already has a connection to the server it establishes a new connection. it then uses this connection to fetch the file or directory. connection establishment is needed for authentication and security purposes. when a target file is found and cached a copy is created on the local disk. venus then returns to the kernel which opens the cached copy and returns its handle to the client process. the unix file system is used as a low level storage system for both afs servers and clients. the client cache is a local directory on the workstation's disk. within this directory are files whose names are placeholders for cache entries. both venus and server processes access unix files directly by the latter's modes to avoid the expensive path name to inode translation routine namei . because the internal inode interface is not visible to client level processes both venus and server processes are client level processes an appropriate set of additional system calls was added. dfs uses its own journaling file system to improve performance and reliability over ufs
 venus manages two separate caches one for status and the other for .data. it uses a simple least recently used lru algorithm to keep each of them bounded in size. when a file is flushed from the cache venus notifies the appropriate server to remove the callback for this file. the status cache is kept in virtual memory to allow rapid servicing of stat file status returning system calls. the data cache is resident on the local disk but the unix i o buffering mechanism does some caching of disk blocks in memory that is transparent to venus. a single client level process on each file server services all file requests from clients. this process uses a lightweight process package with non preemptible scheduling to service many client requests concurrently. the rfc package is integrated with the lightweight process package thereby allowing the file server to concurrently make or service one rpc per lightweight process. the rpc package is built on top of a low level datagram abstraction. whole file transfer is implemented as a side effect of the rpc calls. one rpc connection exists per client but there is no a priori binding of lightweight processes to these connections. instead a pool of lightweight processes services client requests on all connections. the use of a single multithreaded server process allows the caching of data structures needed to service requests. on the negative side a crash of a single server process has the disastrous effect of paralyzing this particular server. . summary a dfs is a file service system whose clients servers and storage devices are dispersed among the sites of a distributed system. accordingly service activity has to be carried out across the network instead of a single centralized data repository there are multiple independent storage devices. ideally a dfs should look to its clients like a conventional centralized file system. the multiplicity and dispersion of its servers and storage devices should be made transparent. that is the client interface of a dfs should not distinguish between local and remote files. it is up to the dfs to locate the files and to arrange for the transport of the data. a transparent dfs facilitates client mobility by bringing the client's environment to the site where the client logs in. there are several approaches to naming schemes in a dfs. in the simplest approach files are named by some combination of their host name and local name which guarantees a unique system wide name. another approach popularized by nfs provides a means to attach remote directories to local directories thus giving the appearance of a coherent directory tree. requests to access a remote file are usually handled by two complementary methods. with remote service requests for accesses are delivered to the server. the server machine performs the accesses and their results are forwarded back to the client. with caching if the data needed to satisfy the access request are not already cached then a copy of the data is brought from the server to the client. accesses are performed on the cached copy. the idea is to retain recently accessed disk blocks in the cache so that repeated accesses to the same information can be handled locally without additional network traffic. a replacement policy is used to keep the cache size bounded. the chapter distributed file systems problem of keeping the cached copies consistent with the master file fe the cache consistency problem. there are two approaches to server side information. either the server tracks each file the client accesses or it simply provides blocks as the client requests them without knowledge of their use. these approaches are the stateful versus stateless sendee paradigms. replication of files on different machines is a useful redundancy for improving availability. multimachine replication can benefit performance too since selecting a nearby replica to serve an access request results in shorter service time. afs is a feature rich dfs characterized by location independence and location transparency. it also imposes significant consistency semantics. caching and replication are used to improve performance. exercises . what are the benefits of a dfs compared with a file system in a centralized system? . which of the example dfss discussed in this chapter would handle a large multiclient database application most efficiently? explain your answer. . discuss whether afs and nfs provide the following a location transparency and b location independence. . under what circumstances would a client prefer a locationtransparent dfs? under what circumstances would she prefer a location independent dfs? discuss the reasons for these preferences. . what aspects of a distributed system would you select for a system running on a totally reliable network? . consider afs which is a stateful distributed file system. what actions need to be performed to recover from a server crash in order to preserve the consistency guaranteed by the system? . compare and contrast the techniques of caching disk blocks locally on a client system and remotely on a server. . afs is designed to support a large number of clients. discuss three techniques used to make afs a scalable system. . discuss the advantages and disadvantages of performing path name translation by having the client ship the entire path to the server requesting a translation for the entire path name of the file. . what are the benefits of mapping objects into virtual memory as apollo domain does? what are the drawbacks? . describe some of the fundamental differences between afs and nfs see chapter . bibliographical notes . discuss whether clients in the following systems can obtain inconsistent or stale data from the file server and if so under what scenarios this could occur. a. afs b. sprite c.nfs bibliographical notes discussions concerning consistency and recovery control for replicated files were offered by davcev and burkhard . management of replicated files in a unix environment was covered by brereton and purdin et al. . wah discussed the issue of file placement on distributed computer systems. a detailed survey of mainly centralized file servers was given in svobodova . sun's network file system nfs was presented by callaghan and sandberg et al. . the afs system was discussed by morris et al. howard et al. and satyanarayanan . information about openafs is available from http www.openafs.org many different and interesting dfss were not covered in detail in this text including unix united sprite and locus. unix united was described by brownbridge et al. . the locus system was discussed by popek and walker . the sprite system was described by ousterhout et al. and nelson et al. . distributed file systems for mobile storage devices were discussed in kistler and satyanarayanan and sobti et al. . considerable research has also been performed on cluster based distributed file systems anderson et al. lee and thekkath thekkath et al. and anderson et al. . distributed storage systems for large scale wide area settings were presented in dabek et al. and kubiatowicz et al. 
 in chapter we described various mechanisms that allow processes to synchronize their actions. we also discussed a number of schemes to ensure the atomicity of a transaction that executes either in isolation or concurrently with other transactions. in chapter we described various methods that an operating system can use to deal with the deadlock problem. in this chapter we examine how centralized synchronization mechanisms can be extended to a distributed environment. we also discuss methods for handling deadlocks in a distributed system. objectives to describe various methods for achieving mutual exclusion in a distributed system. to explain how atomic transactions can be implemented in a distributed system. to show how some of the concurrency control schemes discussed in chapter can be modified for use in a distributed environment. to present schemes for handling deadlock prevention deadlock avoidance and deadlock detection in a distributed system
 in a centralized system we can always determine the order in which two events occurred since the system has a single common memory and clock. many applications may require us to determine order. for example in a resourceallocation scheme we specify that a resource can be used only after the resource has been granted. a distributed system however has no common memory and no common clock. therefore it is sometimes impossible to say which of two events occurred first. the liappened before relation is only a partial ordering of the events in distributed systems. since the ability to define a total ordering is chapter distributed coordination crucial in many applications we present a distributed algorithm for exterfding the happened before relation to a consistent total ordering of all the events in the system. . . the happened before relation since we are considering only sequential processes all events executed in a single process are totally ordered. also by the law of causality a message can be received only after it has been sent. therefore we can define the happenedbefore relation denoted by on a set of events as follows assuming that sending and receiving a message constitutes an event . if a and b are events in the same process and a was executed before b then a b. . if a is the event of sending a message by one process and b is the event of receiving that message by another process then a b. . if a b and b c then a c. since an event cannot happen before itself the relation is an irreflexive partial ordering. if two events a and b are not related by the relation that is a did not happen before b and b did not happen before a then we say that these two events were executed concurrently. in this case neither event can causally affect the other. if however a b then it is possible for event a to affect event b causally. a space time diagram such as that in figure . can best illustrate the definitions of concurrency and happened before. the horizontal direction represents space that is different processes and the vertical direction represents time. the labeled vertical lines denote processes or processors . the labeled dots denote events. a wavy line denotes a message sent from one process to another. events are concurrent if and only if no path exists between them. for example these are some of the events related by the happened before relation in figure . p ? since p c i and q i these are some of the concurrent events in the system q a n d p 'oandcj rq and p ? and p. we cannot know which of two concurrent events such as qo and pi happened first. however since neither event can affect the other there is no way for one of them to know whether the other has occurred yet it is not important which . event ordering figure . relative time for three concurrent processes. happened first. it is important only that any processes that care about the order of two concurrent events agree on some order. . . implementation to determine that an event a happened before an event b we need either a common clock or a set of perfectly synchronized clocks. since neither of these is available in a distributed system we must define the happened before relation without the use of physical clocks. we associate with each system event a timestamp. we can then define the global ordering requirement for every pair of events a and b if a b then the timestamp of a is less than the timestamp of b. below we will see that the converse need not be true. how do we enforce the global ordering requirement in a distributed environment? we define within each process p a logical clock lq. the logical clock can be implemented as a simple counter incremented between any two successive events executed within a process. since the logical clock has a monotonically increasing value it assigns a unique number to every event and if an event a occurs before event b in process p then lc a lc b . the timestamp for an event is the value of the logical clock for that event. this scheme enstires that for any two events in the same process the global ordering requirement is met. unfortunately this scheme does not ensure that the global ordering requirement is met across processes. to illustrate the problem consider two processes pi and p that communicate with each other. suppose that pi sends a message to pi event a with lci a and pi receives the message event b with lcjib because the processor for p is slower than the processor for p r its logical clock ticks more slowly . this situation violates our requirement since a b but the timestamp of a is greater than the timestamp ofb. to resolve this difficulty we require a process to advance its logical clock when it receives a message whose timestamp is greater than the current value of its logical clock. in particular if process p receives a message event b with timestamp f and lc b t then it should advance its clock so that lc b t . thus in our example when p receives the message from pi it will advance its logical clock so that lc b . chapter distributed coordination finally to realize a total ordering we need only observe that with ur timestamp ordering scheme if the timestamps of two events a and b are the same then the events are concurrent. in this case we may use process identity numbers to break ties and to create a total ordering. the use of timestamps is further discussed in section
 in this section we present a number of different algorithms for implementing mutual exclusion in a distributed environment. we assume that the system consists of n processes each of which resides at a different processor. to simplify our discussion we assume that processes are numbered uniquely from to n and that a one to one mapping exists between processes and processors that is each process has its own processor . . . centralized approach in a centralized approach to providing mutual exclusion one of the processes in the system is chosen to coordinate the entry to the critical section. each process that wants to invoke mutual exclusion sends a request message to the coordinator. when the process receives a reply message from the coordinator it can proceed to enter its critical section. after exiting its critical section the process sends a release message to the coordinator and proceeds with its execution. on receiving a request message the coordinator checks to see whether some other process is in its critical section. if no process is in its critical section the coordinator immediately sends back a reply message. otherwise the request is queued. when the coordinator receives a release message it removes one of the request messages from the queue in accordance with some scheduling algorithm and sends a reply message to the requesting process. it should be clear that this algorithm ensures mutual exclusion. in addition if the scheduling policy within the coordinator is fair such as first come firstserved fcfs scheduling no starvation can occur. this scheme requires three messages per critical section entry a request a reply and a release. if the coordinator process fails then a new process must take its place. in section . we describe some algorithms for electing a unique new coordinator. once a new coordinator has been elected it must poll all the processes in the system to reconstruct its request queue. once the queue has been constructed the computation can resume. . . fully distributed approach if we want to distribute the decision making across the entire system then the solution is far more complicated. one approach described next uses an algorithm based on the event ordering scheme described in section . . when a process p wants to enter its critical section it generates a new timestamp ts and sends the message request pj ts to all processes in the system including itself . on receiving a request message a process may reply immediately that is send a reply message back to p or it may defer sending a reply back because it is already in its critical section for example . a process . mutual exclusion that has received a reply message from all other processes in the system can enter its critical section queueing incoming requests and deferring them. after exiting its critical section the process sends reply messages to all its deferred requests. the decision whether process p replies immediately to a requcst pj ts message or defers its reply is based on three factors . if process p is in its critical section then it defers its reply to p . . if process p does not want to enter its critical section then it sends a reply immediately to pj. . if process p wants to enter its critical section but has not yet entered it then it compares its own request timestamp with the timestamp of the incoming request made by process pj. if its own request timestamp is greater than that of the incoming request then it sends a reply immediately to pj pj asked first . otherwise the reply is deferred. this algorithm exhibits the following desirable behavior mutual exclusion is obtained. freedom from deadlock is ensured. freedom from starvation is ensured since entry to the critical section is scheduled according to the timestamp ordering. the timestamp ordering ensures that processes are served in fcfs order. the number of messages per critical section entry is x n . this number is the minimum number of required messages per critical section entry when processes act independently and concurrently. to illustrate how the algorithm functions we consider a system consisting of processes pi pz and p . suppose that processes pi and p want to enter their critical sections. process pi then sends a message request pi timestamp to processes p? and p while process p sends a message request p timestamp to processes p and pi. the timestamps and were obtained from the logical clocks described in section . . when process p receives these request messages it replies immediately. when process pi receives the request from process p it replies immediately since the timestamp on its own request message is greater than the timestamp for process p . when process p receives the request message from process p it defers its reply since the timestamp on its request message is less than the timestamp for the message from process pi. on receiving replies from both process pi and process p? process p can enter its critical section. after exiting its critical section process p sends a reply to process pi which can then enter its critical section. because this scheme requires the participation of all the processes in the system however it has three undesirable consequences . the processes need to know the identity of all other processes in the system. when a new process joins the group of processes participating in the mutual exclusion algorithm the following actions need to be taken chapter distributed coordination a. the process must receive the names of all the other processes n the group. b. the name of the new process must be distributed to all the other processes in the group. this task is not as trivial as it may seem since some request and reply messages may be circulating in the system when the new process joins the group. the interested reader is referred to the bibliographical notes for more details. . if one process fails then the entire scheme collapses. we can resolve this difficulty by continuously monitoring the state of all processes in the system. if one process fails then all other processes are notified so that they will no longer send request messages to the failed process. when a process recovers it must initiate the procedure that allows it to rejoin the group. . processes that have not entered their critical section must pause frequently to assure other processes that they intend to enter the critical section. because of these difficulties this protocol is best suited for small stable sets of cooperating processes. . . token passing approach another method of providing mutual exclusion is to circulate a token among the processes in the system. a token is a special type of message that is passed around the system. possession of the token entitles the holder to enter the critical section. since there is only a single token only one process can be in its critical section at a time. we assume that the processes in the system are logically organized in a ring structure. the physical communication network need not be a ring. as long as the processes are connected to one another it is possible to implement a logical ring. to implement mutual exclusion we pass the token around the ring. when a process receives the token it may enter its critical section keeping the token. after the process exits its critical section the token is passed around again. if the process receiving the token does not want to enter its critical section it passes the token to its neighbor. this scheme is similar to algorithm in chapter but a token is substituted for a shared variable. if the ring is unidirectional freedom from starvation is ensured. the number of messages required to implement mutual exclusion may vary from one message per entry in the case of high contention that is every process wants to enter its critical section to an infinite number of messages in the case of low contention that is no process wants to enter its critical section . two types of failure must be considered. first if the token is lost an election must be called to generate a new token. second if a process fails a new logical ring must be established. in section . we present an election algorithm others are possible. the development of an algorithm for reconstructing the ring is left to you in exercise . 
 . atomicity ? in chapter we introduced the concept of an atomic transaction which is a program unit that must be executed atomically. that is either all the operations associated with it are executed to completion or none are performed. when we are dealing with a distributed system ensuring the atomicity of a transaction becomes much more complicated than in a centralized system. this difficulty occurs because several sites may be participating in the execution of a single transaction. the failure of one of these sites or the failure of a communication link connecting the sites may result in erroneous computations. ensuring that the execution of transactions in the distributed system preserves atomicity is the function of the transaction coordinator. each site has its own local transaction coordinator which is responsible for coordinating the execution of all the transactions initiated at that site. for each such transaction the coordinator is responsible for the following starting the execution of the transaction breaking the transaction into a number of subtransactions and distributing these subtransactions to the appropriate sites for execution coordinating the termination of the transaction which may result in the transactions being committed at all sites or aborted at all sites we assume that each local site maintains a log for recovery purposes. . . the two phase commit protocol for atomicity to be ensured all the sites in which a transaction t has executed must agree on the final outcome of the execution. t must either commit at all sites or it must abort at all sites. to ensure this property the transaction coordinator of t must execute a commit protocol. among the simplest and most widely used commit protocols is the two phase commit pc protocol which we discuss next. let tbe a transaction initiated at site s and let the transaction coordinator at si be c . when t completes its execution that is when all the sites at which t has executed inform c that t has completed then c starts the pc protocol. phase . c adds the record prepare t to the log and forces the record onto stable storage. it then sends a prepare t message to all the sites at which t has executed. on receiving the message the transaction manager at that site determines whether it is willing to commit its portion of t. if the answer is no it adds a record no t to the log and then it responds by sending an abort t message to c . if the answer is yes it adds a record ready t to the log and forces all the log records corresponding to t onto stable storage. the transaction manager then replies with a ready t message to c . phase . when c has received responses to the prepare t message from all the sites or when a pre specified interval of time has elapsed since the prepare t message was sent out c can determine whether the transaction chapter distributed coordination t can be committed or aborted. transaction t can be committed if has received a ready t message from all the participating sites. otherwise transaction t must be aborted. depending on the verdict either a record commit t or a record abort t is added to the log and is forced onto stable storage. at this point the fate of the transaction has been sealed. following this the coordinator sends either a commit t or an abort t message to all participating sites. when a site receives that message it records the message in the log. a site at which t has executed can unconditionally abort t at any time prior to its sending the message ready t to the coordinator. the ready t message is in effect a promise by a site to follow the coordinator's order to commit t or to abort t. a site can make such a promise only when the needed information is stored in stable storage. otherwise if the site crashes after sending ready t it may be unable to make good on its promise. since unanimity is required to commit a transaction the fate of t is sealed as soon as at least one site responds with abort t . note that the coordinator site s can decide unilaterally to abort t as it is one of the sites at which t has executed. the final verdict regarding t is determined at the time the coordinator writes that verdict commit or abort to the log and forces it to stable storage. in some implementations of the pc protocol a site sends an acknowledge t message to the coordinator at the end of the second phase of the protocol. when the coordinator has received the acknowledge t message from all the sites it adds the record complete t to the log. . . failure handling in pc we now examine in detail how pc responds to various types of failures. as we shall see one major disadvantage of the pc protocol is that coordinator failure may result in blocking and a decision either to commit or to abort t may have to be postponed until c recovers. . . . failure of a participating site when a participating site sjt recovers from a failure it must examine its log to determine the fate of those transactions that were in the midst of execution when the failure occurred. let tbe one such transaction. how will s deal with t? we consider each of the possible alternatives the log contains a commit t record. in this case the site executes redo t . the log contains an abort t record. in this case the site executes undo t . the log contains a ready t record. in this case the site must consult c to determine the fate of t. if c is up it notifies s regarding whether t committed or aborted. in the former case it executes redo t in the latter case it executes undo t . if c is down s must try to find out the fate of t from other sites. it does so by sending a query status t message to all . atomicity the sites in the system. on receiving such a message a site must censult its log to determine whether t has executed there and if so whether t committed or aborted. it then notifies s t about this outcome. if no site has the appropriate information that is whether t committed or aborted then s k can neither abort nor commit t. the decision concerning t is postponed until sk can obtain the needed information. thus sk must periodically resend the query status t message to the other sites. it does so until a site recovers that contains the needed information. the site at which c resides always has the needed information. the log contains no control records abort commit ready concerning t. the absence of control records implies that sk failed before responding to the prepare t message from c . since the failure of sk means that it could not have sent such a response by our algorithm c must have aborted t. hence sk must execute undo t . . . . failure of the coordinator if the coordinator fails in the midst of the execution of the commit protocol for transaction t then the participating sites must decide on the fate of t. we shall see that in certain cases the participating sites cannot decide whether to commit or abort t and therefore these sites must wait for the recovery of the failed coordinator. if an active site contains a commit t record in its log then t must be committed. if an active site contains an abort t record in its log then t must be aborted. if some active site does not contain a ready t record in its log then the failed coordinator c cannot have decided to commit t. we can draw this conclusion because a site that does not have a ready t record in its log cannot have sent a ready t message to q. however the coordinator may have decided to abort f. rather than wait for c to recover it is preferable to abort t in this case. if none of the preceding cases holds then all the active sites must have a ready t record in their logs but no additional control records such as abort t or commit t . since the coordinator has failed it is impossible to determine whether a decision has been made or if so what that decision is until the coordinator recovers. thus the active sites must wait for c to recover. as long as the fate of t remains in doubt t may continue to hold system resources. for example if locking is used t may hold locks on data at active sites. such a situation is undesirable because hours or days may pass before c is again active. during this time other transactions may be forced to wait for t. as a result data are unavailable not only on the failed site c but on active sites as well. the amount of unavailable data increases as the downtime of c grows. this situation is called the blocking problem because t is blocked pending the recovery of site c . chapter distributed coordination . . . failure of the network ? when a link fails the messages in the process of being routed through the link do not arrive at their destinations intact. from the viewpoint of the sites connected throughout that link the other sites appear to have failed. thus our previous schemes apply here as well. when a number of links fail the network may partition hi this case two possibilities exist. the coordinator and all its participants may remain in one partition in this case the failure has no effect on the commit protocol. alternatively the coordinator and its participants may belong to several partitions in this case messages between the participant and the coordinator are lost reducing the case to a link failure
 we move next to the issue of concurrency control. in this section we show how certain of the concurrency control schemes discussed in chapter can be modified for use in a distributed environment. the transaction manager of a distributed database system manages the execution of those transactions or subtransactions that access data stored in a local site. each such transaction may be either a local transaction that is a transaction that executes only at that site or part of a global transaction that is a transaction that executes at several sites . each transaction manager is responsible for maintaining a log for recovery purposes and for participating in an appropriate concurrency control scheme to coordinate the conciirrent execution of the transactions executing at that site. as we shall see the concurrency schemes described in chapter need to be modified to accommodate the distribution of transactions. . . locking protocols the two phase locking protocols described in chapter can be used in a distributed environment. the only change needed is in the way the lock manager is implemented. here we present several possible schemes. the first deals with the case where no data replication is allowed. the others apply to the more general case where data can be replicated in several sites. as in chapter we assume the existence of the shared and exclusive lock modes. . . . nonreplicated scheme if no data are replicated in the system then the locking schemes described in section . can be applied as follows each site maintains a local lock manager whose function is to administer the lock and unlock requests for those data items stored in that site. when a transaction wishes to lock data item q at site si it simply sends a message to the lock manager at site s requesting a lock in a particular lock mode . if data item q is locked in an incompatible mode then the request is delayed until that request can be granted. once it has been determined that the lock request can be granted the lock manager sends a message back to the initiator indicating that the lock request has been granted. . concurrency control this scheme has the advantage of simple implementation. it requires two message transfers for handling lock requests and one message transfer for handling unlock requests. however deadlock handling is more complex. since the lock and unlock requests are no longer made at a single site the various deadlock handling algorithms discussed in chapter must be modified these modifications are discussed in section . . . . . single coordinator approach several concurrency control schemes can be used in systems that allow data replication. under the single coordinator approach the system maintains a single lock manager that resides in a single chosen site say s all lock and unlock requests are made at site s . when a transaction needs to lock a data item it sends a lock request to s . the lock manager determines whether the lock can be granted immediately. if so it sends a message to that effect to the site at which the lock request was initiated. otherwise the request is delayed until it can be granted and at that time a message is sent to the site at which the lock request was initiated. the transaction can read the data item from any one of the sites at which a replica of the data item resides. in the case of a write operation all the sites where a replica of the data item resides must be involved in the writing. the scheme has the following advantages simple implementation. this scheme requires two messages for handling lock requests and one message for handling unlock requests. simple deadlock handling. since all lock and unlock requests are made at one site the deadlock handling algorithms discussed in chapter can be applied directly to this environment. the disadvantages of the scheme include the following bottleneck. the site s becomes a bottleneck since all requests must be processed there. vulnerability. if the site s fails the concurrency controller is lost. either processing must stop or a recovery scheme must be used. a compromise between these advantages and disadvantages can be achieved through a multiple coordinator approach in which the lockmanager function is distributed over several sites. each lock manager administers the lock and unlock requests for a subset of the data items and the lock managers reside in different sites. this distribution reduces the degree to which the coordinator is a bottleneck but it complicates deadlock handling since the lock and unlock requests are not made at a single site. . . . majority protocol the majority protocol is a modification of the nonreplicated data scheme presented earlier. the system maintains a lock manager at each site. each manager controls the locks for all the data or replicas of data stored at that site. when a transaction wishes to lock a data item q that is replicated in n different chapter distributed coordination sites it must send a lock request to more than one half of the n sites in which q is stored. each lock manager determines whether the lock can be granted immediately as far as it is concerned . as before the response is delayed until the request can be granted. the transaction does not operate on q until it has successfully obtained a lock on a majority of the replicas of chl . this scheme deals with replicated data in a decentralized manner thus avoiding the drawbacks of central control. however it suffers from its own disadvantages implementation. the majority protocol is more complicated to implement than the previous schemes. it requires n messages for handling lock requests and n messages for handling unlock requests. deadlock handling. since the lock and unlock requests are not made at one site the deadlock handling algorithms must be modified section . . in addition a deadlock can occur even if only one data item is being locked. to illustrate consider a system with four sites and full replication. suppose that transactions t and t wish to lock data item q in exclusive mode. transaction t may succeed in locking q at sites s and s while transaction t may succeed in locking q at sites sj and s . each then must wait to acquire the third lock and hence a deadlock has occurred. . . . biased protocol the biased protocol is similar to the majority protocol. the difference is that requests for shared locks are given more favorable treatment than are requests for exclusive locks. the system maintains a lock manager at each site. each manager manages the locks for all the data items stored at that site. shared and exclusive locks are handled differently. shared locks. when a transaction needs to lock data item q it simply requests a lock on q from the lock manager at one site containing a replica oichls . exclusive locks. when a transaction needs to lock data item q it requests a lock on q from the lock manager at each site containing a replica of chl . as before the response to the request is delayed until the request can be granted. the scheme has the advantage of imposing less overhead on read operations than does the majority protocol. this advantage is especially significant in common cases in which the frequency of reads is much greater than the frequency of writes. however the additional overhead on writes is a disadvantage. furthermore the biased protocol shares the majority protocol's disadvantage of complexity in handling deadlock. . . . primary copy yet another alternative is to choose one of the replicas as the primary copythus for each data item q the primary copy of q must reside in precisely one site which we call the primary site ofq. when a transaction needs to lock a data . concurrency control item q it requests a lock at the primary site of chl . as before the response to the request is delayed until the request can be granted. this scheme enables us to handle concurrency control for replicated data in much the same way as for unreplicated data. implementation of the method is simple. however if the primary site of q fails q is inaccessible even though other sites containing a replica may be accessible. . . timestamping the principal idea behind the timestamping scheme discussed in section . is that each transaction is given a unique timestamp which is used to decide the serialization order. our first task then in generalizing the centralized scheme to a distributed scheme is to develop a method for generating unique timestamps. our previous protocols can then be applied directly to the nonreplicated environment. . . . generation of unique timestamps two primary methods are used to generate unique timestamps one is centralized and one is distributed. in the centralized scheme a single site is chosen for distributing the timestamps. the site can use a logical counter or its own local clock for this purpose. in the distributed scheme each site generates a local unique timestamp using either a logical counter or the local clock. the global unique timestamp is obtained by concatenation of the local unique timestamp with the site identifier which must be unique figure . . the order of concatenation is important! we use the site identifier in the least significant position to ensure that the global timestamps generated in one site are not always greater than those generated in another site. compare this technique for generating unique timestamps with the one we presented in section . . for generating unique names. we may still have a problem if one site generates local timestamps at a faster rate than do other sites. in such a case the fast site's logical counter will be larger than those of other sites. therefore all timestamps generated by the fast site will be larger than those generated by other sites. a mechanism is needed to ensure that local timestamps are generated fairly across the system. to accomplish the fair generation of timestamps we define within each site s a logical clock lc which generates the local timestamp see section . . . to ensure that the various logical clocks are synchronized we require that a site s advance its logical clock whenever a transaction t with timestamp x y local unique timestamp site identifier global unique identifier figure . generation of unique timestamps. chapter distributed coordination visits that site and x is greater than the current value of ld. in this case ?site s advances its logical clock to the value x . if the system clock is used to generate timestamps then timestamps are assigned fairly provided that no site has a system clock that runs fast or slow. since clocks may not be perfectly accurate a technique similar to that used for logical clocks must be used to ensure that no clock gets far ahead or far behind another clock. . . . timestamp ordering scheme the basic timestamp scheme introduced in section . can be extended in a straightforward manner to a distributed system. as in the centralized case cascading rollbacks may result if no mechanism is used to prevent a transaction from reading a data item value that is not yet committed. to eliminate cascading rollbacks we can combine the basic timestamp scheme of section . with the pc protocol of section . to obtain a protocol that ensures serializability with no cascading rollbacks. we leave the development of such an algorithm to you. the basic timestamp scheme just described suffers from the undesirable property that conflicts between transactions are resolved through rollbacks rather than through waits. to alleviate this problem we can buffer the various read and write operations that is delay them until a time when we are assured that these operations can take place without causing aborts. a read x operation by t must be delayed if there exists a transaction ty that will perform a write e operation but has not yet done so and ts ty ts tj . similarly a wr ite x operation by t must be delayed if there exists a transaction t that will perform either a read x or a write x operation and ts t ts ti . various methods are available for ensuring this property. one such method called the conservative timestamp ordering scheme requires each site to maintain a read queue and a write queue consisting of all the read and write requests that are to be executed at the site and that must be delayed to preserve the above property. we shall not present the scheme here. again we leave the development of the algorithm to you
 the deadlock prevention deadlock avoidance and deadlock detection algorithms presented in chapter can be extended so that they can be used in a distributed system. in this section we describe several of these distributed algorithms. . . deadlock prevention and avoidance the deadlock prevention and deadlock avoidance algorithms presented in chapter can be used in a distributed system provided that appropriate modifications are made. for example we can use the resource ordering deadlock prevention technique by simply defining a global ordering among the system resources. that is all resources in the entire system are assigned unique numbers and a process may request a resource at any processor with . deadlock handling unique number only if it is not holding a resource with a unique number greater than i. similarly we can use the banker's algorithm in a distributed system by designating one of the processes in the system the banker as the process that maintains the information necessary to carry out the banker's algorithm. every resource request must be channelled through the banker. the global resource ordering deadlock prevention scheme is simple to implement in a distributed environment and requires little overhead. the banker's algorithm can also be implemented easily but it may require too much overhead. the banker may become a bottleneck since the number of messages to and from the banker may be large. thus the banker's scheme does not seem to be of practical use in a distributed system. we turn next to a new deadlock prevention scheme based on a timestampordering approach with resource preemption. although this approach can handle any deadlock situation that may arise in a distributed system for simplicity we consider only the case of a single instance of each resource type. to control the preemption we assign a unique priority number to each process. these numbers are used to decide whether a process p should wait for a process pj. for example we can let p wait for pj if p has a priority higher than that of pj otherwise p is rolled back. this scheme prevents deadlocks because for every edge p pj in the wait for graph p has a higher priority than pj. thus a cycle cannot exist. one difficulty with this scheme is the possibility of starvation. some processes with extremely low priorities may always be rolled back. this difficulty can be avoided through the use of timestamps. each process in the system is assigned a unique timestamp when it is created. two complementary deadlock prevention schemes using timestamps have been proposed . the wait die scheme. this approach is based on a nonpreemptive technique. when process p requests a resource currently held by pj pj is allowed to wait only if it has a smaller timestamp than does p that is p is older than p . otherwise p is rolled back dies . for example suppose that processes p p and p have timestamps and respectively. if pi requests a resource held by pi p will wait. if p requests a resource held by p p will be rolled back. . the wound wait scheme. this approach is based on a preemptive technique and is a counterpart to the wait die approach. when process p requests a resource currently held by p r pi is allowed to wait only if it has a larger timestamp than does pj that is p is younger than pj . otherwise pj is rolled back pj is wounded by p . returning to our previous example with processes pi p? and p if pi requests a resource held by pi then the resource will be preempted from pi and p will be rolled back. if p requests a resource held by p? then p will wait. both schemes can avoid starvation provided that when a process is rolled back it is not assigned a new timestamp. since timestamps always increase a process that is rolled back will eventually have the smallest timestamp. thus it will not be rolled back again. there are however significant differences in the way the two schemes operate. chapter distributed coordination in the wait die scheme an older process must wait for a younger one to release its resource. thus the older the process gets the more it tends to wait. by contrast in the wound wait scheme an older process never waits for a younger process. in the wait die scheme if a process p dies and is rolled back because it has requested a resource held by process pj then p may reissue the same sequence of requests when it is restarted. if the resource is still held by pj then pj will die again. thus p may die several times before acquiring the needed resource. contrast this series of events with what happens in the wound wait scheme. process p is wounded and rolled back because pj has requested a resource it holds. when p is restarted and requests the resource now being held by pj pi waits. thus fewer rollbacks occur in the wound wait scheme. the major problem with both schemes is that unnecessary rollbacks may occur. . . deadlock detection the deadlock prevention algorithm may preempt resources even if no deadlock has occurred. to prevent unnecessary preemptions we can use a deadlockdetection algorithm. we construct a wait for graph describing the resourceallocation state. since we are assuming only a single resource of each type a cycle in the wait for graph represents a deadlock. the main problem in a distributed system is deciding how to maintain the wait for graph. we illustrate this problem by describing several common techniques to deal with this issue. these schemes require each site to keep a local wait for graph. the nodes of the graph correspond to all the processes local as well as nonlocal currently holding or requesting any of the resources local to that site. for example in figure . we have a system consisting of two sites each maintaining its local wait for graph. note that processes pj and pj appear in both graphs indicating that the processes have requested resources at both sites. these local wait for graphs are constructed in the usual manner for local processes and resources. when a process p in site si needs a resource held by process p in site sj a request message is sent by p to site si. the edge p pj is then inserted in the local wait for graph of site s . sites site figure . two local wait for graphs. . deadlock handling figure . global wait for graph for figure . . clearly if any local wait for graph has a cycle deadlock has occurred. the fact that we find no cycles in any of the local wait for graphs does not mean that there are no deadlocks however. to illustrate this problem we consider the system depicted in figure . . each wait for graph is acyclic nevertheless a deadlock exists in the system. to prove that a deadlock has not occurred we must show that the union of all local graphs is acyclic. the graph figure . that we obtain by taking the union of the two wait for graphs of figure . does indeed contain a cycle implying that the system is in a deadlocked state. a number of methods are available to organize the wait for graph in a distributed system. we describe several common schemes here. . . . centralized approach in the centralized approach a global wait for graph is constructed as the union of all the local wait for graphs. it is maintained in a single process the deadlock detection coordinator. since there is communication delay in the system we must distinguish between two types of wait for graphs. the real graph describes the real but unknown state of the system at any instance in time as would be seen by an omniscient observer. the constructed graph is an approximation generated by the coordinator during the execution of its algorithm. the constructed graph must be generated so that whenever the detection algorithm is invoked the reported results are correct. by correct we mean the following if a deadlock exists then it is reported properly. if a deadlock is reported then the system is indeed in a deadlocked state. as we shall show it is not easy to construct such correct algorithms. the wait for graph may be constructed at three different points in time . whenever a new edge is inserted in or removed from one of the local wait for graphs . periodically when a number of changes have occurred in a wait for graph . whenever the deadlock detection coordinator needs to invoke the cycledetection algorithm when the deadlock detection algorithm is invoked the coordinator searches its global graph. if a cycle is found a victim is selected to be rolled back. the chapter distributed coordination coordinator must notify all the sites that a particular process has been sejected as victim. the sites in turn roll back the victim process. let us consider option . whenever an edge is either inserted in or removed from a local graph the local site must also send a message to the coordinator to notify it of this modification. on receiving such a message the coordinator updates its global graph. alternatively option a site can send a number of such changes in a single message periodically. returning to our previous example the coordinator process will maintain the global wait for graph as depicted in figure . . when site inserts the edge p p in its local wait for graph it also sends a message to the coordinator. similarly when site si deletes the edge p pi because pi has released a resource that was requested by p an appropriate message is sent to the coordinator. note that no matter which option is used unnecessary rollbacks may occur as a result of two situations . false cycles may exist in the global wait for graph. to illustrate this point we consider a snapshot of the system as depicted in figure . . suppose that p releases the resource it is holding in site si resulting in the deletion of the edge pi p in site si. process p then requests a resource held by p at site s resulting in the addition of the edge p p in site s . if the insert p p message from site s arrives before the delete p p message from site si the coordinator may discover the false cycle pi p p pl after the insert but before the delete . deadlock recovery may be initiated although no deadlock has occurred. . unnecessary rollbacks may also result when a deadlock has indeed occurred and a victim has been picked but at the same time one of the processes has been aborted for reasons unrelated to the deadlock as when a process has exceeded its allocated time . for example suppose that site si in figure . decides to abort p . at the same time the coordinator has discovered a cycle and picked p as a victim. both p? and p are now rolled back although only p needed to be rolled back. let us now consider a centralized deadlock detection algorithm using option that detects all deadlocks that actually occur and does not detect false deadlocks. to avoid the report of false deadlocks we require that requests from different sites be appended with unique identifiers or timestamps . when site si site s coordinator figure . local and global wait for graphs. . deadlock handling process p at site si requests a resource from p. at site s? a request message with timestamp ts is sent. the edge p p with the label ts is inserted'in the local wait for graph of si. this edge is inserted in the local wait for graph of site si only if site s? has received the request message and cannot immediately grant the requested resource. a request from p to p . in the same site is handled in the usual manner no timestamps are associated with the edge p pj. the detection algorithm is as follows . the controller sends an initiating message to each site in the system. . on receiving this message a site sends its local wait for graph to the coordinator. each of these wait for graphs contains all the local information the site has about the state of the real graph. the graph reflects an instantaneous state of the site but it is not synchronized with respect to any other site. . when the controller has received a reply from each site it constructs a graph as follows a. the constructed graph contains a vertex for every process in the system. b. the graph has an edge pj pj if and only if there is an edge p pj in one of the wait for graphs or an edge p pj with some label ts in more than one wait for graph. if the constructed graph contains a cycle then the system is in a deadlocked state. if the constructed graph does not contain a cycle then the system was not in a deadlocked state when the detection algorithm was invoked as result of the initiating messages sent by the coordinator in step . . . . fully distributed approach in the fully distributed deadlock detection algorithm all controllers share equally the responsibility for detecting deadlock. every site constructs a waitfor graph that represents a part of the total graph depending on the dynamic behavior of the system. the idea is that if a deadlock exists a cycle will appear in at least one of the partial graphs. we present one such algorithm which involves construction of partial graphs in every site. each site maintains its own local wait for graph. a local wait for graph in this scheme differs from the one described earlier in that we add one additional node p .v to the graph. an arc p pl x exists in the graph if p is waiting for a data item in another site being held by any process. similarly an arc pex pj exists in the graph if a process at another site is waiting to acquire a resource currently being held by pj in this local site. to illustrate this situation we consider again the two local wait for graphs of figure . . the addition of the node pl x in both graphs results in the local wait for graphs shown in figure . . if a local wait for graph contains a cycle that does not involve node pcx then the system is in a deadlocked state. if however a local graph contains a cycle involving pcxr then this implies the possibility of a deadlock. to ascertain whether a deadlock does exist we must invoke a distributed deadlock detection algorithm. chapter distributed coordination site s figure . augmented local wait for graphs of figure . . suppose that at site s the local wait for graph contains a cycle involving node pcx. this cycle must be of the form pcx pkl pk pkn pex which indicates that process pjt . in site s is waiting to acquire a data item located in some other site say sj. on discovering this cycle site s sends to site sj a deadlock detection message containing information about that cycle. when site sj receives this deadlock detection message it updates its local wait for graph with the new information. then it searches the newly constructed wait for graph for a cycle not involving pex. if one exists a deadlock is found and an appropriate recovery scheme is invoked. if a cycle involving pex is discovered then sj transmits a deadlock detection message to the appropriate site say s . site sk in return repeats the procedure. thus after a finite number of rounds either a deadlock is discovered or the deadlock detection computation halts. to illustrate this procedure we consider the local wait for graphs of figure . . suppose that site si discovers the cycle pcx pi pi pcx. since p is waiting to acquire a data item in site s? a deadlock detection message describing that cycle is transmitted from site si to site sz when site s receives this message it updates its local wait for graph obtaining the wait for graph of figure . . this graph contains the cycle p p p p which does not include node pcx. therefore the system is in a deadlocked state and an appropriate recovery scheme must be invoked. note that the outcome would be the same if site s discovered the cycle first in its local wait for graph and sent the deadlock detection message to site si. in the worst case both sites will discover the cycle at about the same time and two deadlock detection messages will be sent one by si to s and another by s to si. this situation results in unnecessary message transfer and overhead in updating the two local wait for graphs and searching for cycles in both graphs. to reduce message traffic we assign to each process p a unique identifier which we denote id p . when site sk discovers that its local wait for graph contains a cycle involving node pex of the form
 site figure . augmented local wait for graph in site g of figure . . pcx pk pk ... pxu p it sends a deadlock detection message to another site only if id pku otherwise site s continues its normal execution leaving the burden of initiating the deadlock detection algorithm to some other site. to illustrate this scheme we consider again the wait for graphs maintained at sites si and s of figure . . suppose that id p id p let both sites discover these local cycles at about the same time. the cycle in site si is of the form pi p since site si does not send a deadlock detection message to site s . the cycle in site s is of the form since id p id p r site sj does send a deadlock detection message to site si which on receiving the message updates its local wait for graph. site si then searches for a cycle in the graph and discovers that the system is in a deadlocked state. . election algorithms as we pointed out in section . many distributed algorithms employ a coordinator process that performs functions needed by the other processes in the system. these functions include enforcing mutual exclusion maintaining a global wait for graph for deadlock detection replacing a lost token and controlling an input or output device in the system. if the coordinator process fails due to the failure of the site at which it resides the system can continue chapter distributed coordination execution only by restarting a new copy of the coordinator on some other site. the algorithms that determine where a new copy of the coordinator should be restarted are called election algorithms. election algorithms assume that a unique priority number is associated with each active process in the system. for ease of notation we assume that the priority number of process p is . to simplify our discussion we assume a one to one correspondence between processes and sites and thus refer to both as processes. the coordinator is always the process with the largest priority number. hence when a coordinator fails the algorithm must elect that active process with the largest priority number. this number must be sent to each active process in the system. in addition the algorithm must provide a mechanism for a recovered process to identify the current coordinator. in this section we present examples of election algorithms for two different configurations of distributed systems. the first algorithm applies to systems where every process can send a message to every other process in the system. the second algorithm applies to systems organized as a ring logically or physically . both algorithms require n messages for an election where n is the number of processes in the system. we assume that a process that has failed knows on recovery that it has indeed failed and thus takes appropriate actions to rejoin the set of active processes. . . the bully algorithm suppose that process p sends a request that is not answered by the coordinator within a time interval t. in this situation it is assumed that the coordinator has failed and p tries to elect itself as the new coordinator. this task is completed through the following algorithm process p sends an election message to every process with a higher priority number. process p then waits for a time interval t for an answer from any one of these processes. if no response is received within time t p assumes that all processes with numbers greater than have failed and elects itself the new coordinator. process p restarts a new copy of the coordinator and sends a message to inform all active processes with priority numbers less than that p is the new coordinator. however if an answer is received p begins a time interval t waiting to receive a message informing it that a process with a higher priority number has been elected. that is some other process is electing itself coordinator and should report the results within time t. if no message is sent within t then the process with a higher number is assumed to have failed and process p should restart the algorithm. if pi is not the coordinator then at any time during execution p may receive one of the following two messages from process p . pj is the new coordinator j . process p in turn records this information. . pj has started an election j i . process p sends a response to pj and begins its own election algorithm provided that p has not already initiated such an election. the process that completes its algorithm has the highest number and is elected as the coordinator. it has sent its number to all active processes with smaller . election algorithms numbers. after a failed process recovers it immediately begins execution of the same algorithm. if there are no active processes with higher numbers the recovered process forces all processes with lower numbers to let it become the coordinator process even if there is a currently active coordinator with a lower number. for this reason the algorithm is termed the bully algorithm. we can demonstrate the operation of the algorithm with a simple example of a system consisting of processes pi through pj. the operations are as follows . all processes are active p is the coordinator process. . pt and p fail. p determines that p has failed by sending a request that is not answered within time t. p then begins its election algorithm by sending a request to p . . p receives the request responds to p and begins its own algorithm by sending an election request to p . . pi receives pa's response and begins waiting for an interval t'. . pi does not respond within an interval t so p elects itself the new coordinator and sends the number to p and pi. pi does not receive the number since it has failed. . later when p recovers it sends an election request to p? p and p . . p and p respond to pi and begin their own election algorithms. p will again be elected through the same events as before. . finally p recovers and notifies pi pj and p that it is the current coordinator. p sends no election requests since it is the process with the highest number in the system. . . the ring algorithm the ring algorithm assumes that the links are unidirectional and that each process sends its messages to the neighbor on the right. the main data structure used by the algorithm is the active list a list that contains the priority numbers of all active processes in the system when the algorithm ends each process maintains its own active list. the algorithm works as follows . if process p detects a coordinator failure it creates a new active list that is initially empty. it then sends a message elect i to its right neighbor and adds the number to its active list. . if pj receives a message electij from the process on the left it must respond in one of three ways a. if this is the first elect message it has seen or sent p creates a new active list with the numbers i and . it then sends the message ekct i followed by the message elect j . b. if i that is the message received does not contain p.'s number then pj adds to its active list and forwards the message to its right neighbor. chapter distributed coordination c. if that is pi receives the message eled i then the active list for p now contains the numbers of all the active processes in the system. process p can now determine the largest number in the active list to identify the new coordinator process. this algorithm does not specify how a recovering process determines the number of the current coordinator process. one solution requires a recovering process to send an inquiry message. this message is forwarded around the ring to the current coordinator which in turn sends a reply containing its number
 for a system to be reliable we need a mechanism that allows a set of processes to agree on a common value. such an agreement may not take place for several reasons. first the communication medium may be faulty resulting in lost or garbled messages. second the processes themselves may be faulty resulting in unpredictable process behavior. the best we can hope for in this case is that processes fail in a clean way stopping their execution without deviating from their normal execution pattern. in the worst case processes may send garbled or incorrect messages to other processes or even collaborate with other failed processes in an attempt to destroy the integrity of the system. the byzantine generals problem provides an analogy for this situation. several divisions of the byzantine army each commanded by its own general surround an enemy camp. the byzantine generals must reach agreement on whether or not to attack the enemy at dawn. it is crucial that all generals agree since an attack by only some of the divisions would result in defeat. the various divisions are geographically dispersed and the generals can communicate with one another only via messengers who run from camp to camp. the generals may not be able to reach agreement for at least two major reasons . messengers may get caught by the enemy and thus may be unable to deliver their messages. this situation corresponds to unreliable communication in a computer system and is discussed further in section . . . . generals may be traitors trying to prevent the loyal generals from reaching an agreement. this situation corresponds to faulty processes in a computer system and is discussed further in section . . . . . unreliable communications let us first assume that if processes fail they do so in a clean way and that the communication medium is unreliable. suppose that process p at site si which has sent a message to process p at site s needs to know whether pj has received the message so that it can decide how to proceed with its computation. for example p may decide to compute a function foo if pj has received its message or to compute a function boo if pj has not received the message because of some hardware failure . to detect failures we can use a time out scheme similar to the one described in section . . . when p sends out a message it also specifies . reaching agreement a time interval during which it is willing to wait for an acknowledgment message from p . when p receives the message it immediately sends an acknowledgment to p . if p receives the acknowledgment message within the specified time interval it can safely conclude that p has received its message. if however a time out occurs then p needs to retransmit its message and wait for an acknowledgment. this procedure continues until p either gets the acknowledgment message back or is notified by the system that site en is down. in the first case it will compute s in the latter case it will compute f. note that if these are the only two viable alternatives p must wait until it has been notified that one of the situations has occurred. suppose now that p also needs to know that p has received its acknowledgment message so that it can decide how to proceed with its computation. for example pj may want to compute foo only if it is assured that p got its acknowledgment. in other words p and pj will compute foo if and only if both have agreed on it. it turns out that in the presence of failure it is not possible to accomplish this task. more precisely it is not possible in a distributed environment for processes p and pr to agree completely on their respective states. to prove this claim let us suppose that a minimal sequence of message transfers exists such that after the messages have been delivered both processes agree to compute foo. let in' be the last message sent by p to pj. since p does not know whether its message will arrive at pj since the message may be lost due to a failure p will execute foo regardless of the outcome of the message delivery. thus m' could be removed from the sequence without affecting the decision procedure. hence the original sequence was not minimal contradicting our assumption and showing that there is no sequence. the processes can never be sure that both will compute foo. . . faulty processes now let us assume that the communication medium is reliable but that processes can fail in unpredictable ways. consider a system of n processes of which no more than m are faulty. suppose that each process p has some private value of v . we wish to devise an algorithm that allows each nonfaulty process p to construct a vector x a.i a. a n such that the following conditions exist . if pj is a nonfaulty process then aj.j vj. . if p and pj are both nonfaulty processes then x xj. there are many sokitions to this problem and they share the following properties . a correct algorithm can be devised only if n x m . . the worst case delay for reaching agreement is proportionate to in message passing delays. . the number of messages required for reaching agreement is large. no single process is trustworthy so all processes must collect all information and make their own decisions. chapter distributed coordination rather than presenting a general solution which would be complicated we present an algorithm for the simple case where m and n . the algorithm requires two rounds of information exchange . each process sends its private value to the other three processes. . each process sends the information it has obtained in the first round to all other processes. a faulty process obviously may refuse to send messages. in this case a nonfaulty process can choose an arbitrary value and pretend that the value was sent by the faulty process. once these two rounds are completed a nonfaulty process p can construct its vector x a.i a. a. a. as follows . for j i if at least two of the three values reported for process pj in the two rounds of exchange agree then the majority value is used to set the value of a otherwise a default value say nil is used to set the value of a. 
 in a distributed system with no common memory and no common clock it is sometimes impossible to determine the exact order in which two events occur. the happened before relation is only a partial ordering of the events in a distributed system. timestamps can be used to provide a consistent event ordering. mutual exclusion in a distributed environment can be implemented in a variety of ways. in a centralized approach one of the processes in the system is chosen to coordinate the entry to the critical section. in the fully distributed approach the decision making is distributed across the entire system. a distributed algorithm which is applicable to ring structured networks is the token passing approach. for atomicity to be ensured all the sites in which a transaction t has executed must agree on the final outcome of the execution. t either commits at all sites or aborts at all sites. to ensure this property the transaction coordinator of t must execute a commit protocol. the most widely used commit protocol is the pc protocol. the various concurrency control schemes that can be used in a centralized system can be modified for use in a distributed environment. in the case of locking protocols we need only change the way the lock manager is implemented. in the case of timestamping and validation schemes the only change needed is the development of a mechanism for generating unique global timestamps. the mechanism can either concatenate a local timestamp with the site identification or advance local clocks whenever a message arrives that has a larger timestamp. the primary method for dealing with deadlocks in a distributed environment is deadlock detection. the main problem is deciding how to maintain the exercises wait for graph. methods for organizing the wait for graph include a centralized approach and a fully distributed approach. some distributed algorithms require the use of a coordinator. if the coordinator fails because of the failure of the site at which it resides the system can continue execution only by restarting a new copy of the coordinator on some other site. it can do so by maintaining a backup coordinator that is ready to assume responsibility if the coordinator fails. another approach is to choose the new coordinator after the coordinator has failed. the algorithms that determine where a new copy of the coordinator should be restarted are called election algorithms. two algorithms the bully algorithm and the ring algorithm can be used to elect a new coordinator in case of failures. exercises . discuss the advantages and disadvantages of the two methods we presented for generating globally unique timestamps. . the logical clock timestamp scheme presented in this chapter provides the following guarantee if event a happens before event b then the timestamp of a is less than the timestamp of b. note however that one cannot order two events based only on their timestamps. the fact that an event c has a timestamp that is less than the timestamp of event d does not necessarily mean that event c happened before event d c and d could be concurrent events in the system. discuss ways in which the logical clock timestamp scheme could be extended to distinguish concurrent events from events that can be ordered by the happens before relationship. . your company is building a computer network and you are asked to write an algorithm for achieving distributed mutual exclusion. which scheme will you use? explain your choice. . why is deadlock detection much more expensive in a distributed environment than in a centralized environment? . your company is building a computer network and you are asked to develop a scheme for dealing with the deadlock problem. a. would you use a deadlock detection scheme or a deadlockprevention scheme? b. if you were to use a deadlock prevention scheme which one would you use? explain your choice. c. if you were to use a deadlock detection scheme which one would you use? explain your choice. . under what circumstances does the wait die scheme perform betterthan the wound wait scheme for granting resources to concurrently executing transactions? . consider the centralized and the fully distributed approaches to deadlock detection. compare the two algorithms in terms of message complexity. chapter distributed coordination . consider the following hierarchical deadlock detection algorithm in which the global wait for graph is distributed over a number of different controllers which are organized in a tree. each non leaf controller maintains a wait for graph that contains relevant information from the graphs of the controllers in the subtree below it. in particular let sa sg and sc be controllers such that sc is the lowest common ancestor of sa and sb sc must be unique since we are dealing with a tree . suppose that node t appears in the local wait for graph of controllers sa and sg. then t must also appear in the local wait for graph of controller sc every controller in the path from sc to sa every controller in the path from sc to sb in addition if and tj appear in the wait for graph of controller so and there exists a path from to t in the wait for graph of one of the children of so then an edge t tj must be in the wait for graph of sd. show that if a cycle exists in any of the wait for graphs then the system is deadlocked. . derive an election algorithm for bidirectional rings that is more efficient than the one presented in this chapter. how many messages are needed for n processes? . consider a setting where processors are not associated with unique identifiers but the total number of processors is known and the processors are organized along a bidirectional ring. is it possible to derive an election algorithm for such a setting? . consider a failure that occurs during pc for a transaction. for each possible failure explain how pc ensures transaction atomicity despite the failure. . consider the following failure model for faulty processors. processors follow the protocol but might fail at unexpected points in time. when processors fail they simply stop functioning and do not continue to participate in the distributed system. given such a failure model design an algorithm for reaching agreement among a set of processors. discuss the conditions under which agreement could be reached. bibliographical notes the distributed algorithm for extending the happened befbre relation to a consistent total ordering of all the events in the system was developed by lamport b . further discussions of using logical time to characterize the behavior of distributed systems can be found in fidge raynal and singhal babaoglu and marzullo schwarz and mattern and mattern . bibliographical notes the first general algorithm for implementing mutual exclusion in a distributed environment was also developed by lamport b . lamport's scheme requires x n messages per critical section entry. subsequently ricart and agrawala proposed a distributed algorithm that requires only x j messages. their algorithm is presented in section . . . a squareroot algorithm for distributed mutual exclusion was described by maekawa . the token passing algorithm for ring structured systems presented in section . . was developed by lann . carvalho and roucairol discussed mutual exclusion in computer networks and agrawal and abbadi described an efficient and fault tolerant solution of distributed mutual exclusion. a simple taxonomy for distributed mutual exclusion algorithms was presented by raynal the issue of distributed synchronization was discussed by reed and kanodia shared memory environment lamport b lamport a and schneider totally disjoint processes . a distributed solution to the dining philosophers problem was presented by chang . the pc protocol was developed by lampson and sturgis and gray mohan and lindsay discussed two modified versions of pc called presume commit and presume abort that reduce the overhead of pc by defining default assumptions regarding the fate of transactions. papers dealing with the problems of implementing the transaction concept in a distributed database were presented by gray traiger et al. and spector and schwarz . comprehensive discussions of distributed concurrency control were offered by bernstein et al. rosenkrantz et al. reported the timestamp distributed deadlock prevention algorithm. the fully distributed deadlock detection scheme presented in section . . was developed by obermarck . the hierarchical deadlock detection scheme of exercise . appeared in menasce and muntz . knapp and singhal offered surveys of deadlock detection in distributed systems. deadlocks can also be detected by taking global snapshots of a distributed system as discussed in chandy and lamport the byzantine generals problem was discussed by lamport et al. and pease et al. . the bully algorithm was presented by garcia molina and the election algorithm for a ring structured system was written by lann . part seven special purpose systems our coverage of operating system issues thus far has focused mainly on general purpose computing systems. there are however specialpurpose systems with requirements different from those of many of the systems we have described. a real time system is a computer system that requires not only that computed results be correct but also that the results be produced within a specified deadline period. results produced after the deadline has passed even if correct may be of no real value. for such systems many traditional operating system scheduling algorithms must be modified to meet the stringent timing deadlines. a multimedia system must be able to handle not only conventional data such as text files programs and word processing documents but also multimedia data. multimedia data consist of continuous media data audio and video as well as conventional data. continuous media data such as frames of video must be delivered according to certain time restrictions for example frames per second . the demands of handling continuous media data require significant changes in operatingsystem structure most notably in memory disk and network management. apter '
 our coverage of operating system issues thus far has focused mainly on general purpose computing systems for example desktop and server systems . in this chapter we turn our attention to real time computing systems. the requirements of real time systems differ from those of many of the systems we have described largely because real time systems must produce results within certain deadlines. in this chapter we provide an overview of realtime computer systems and describe how real time operating systems must be constructed to meet the stringent timing requirements of these systems. objectives to explain the timing requirements of real time systems. to distinguish between hard and soft real time systems. to discuss the defining characteristics of real time systems to describe scheduling algorithms for hard real time systems
 a real time system is a computer system that requires not only that the computing results be correct but also that the results be produced within a specified deadline period. results produced after the deadline has passed even if correct may be of no real value. to illustrate consider an autonomous robot that delivers mail in an office complex. if its vision control system identifies a wall after the robot has walked into it despite correctly identifying the wall the system has not met its requirement. contrast this timing requirement with the much less strict demands of other systems. in an interactive desktop computer system it is desirable to provide a quick response time to the interactive user but it is not mandatory to do so. some systems such as a batch processing system may have no timing requirements whatsoever. real time systems executing on traditional computer hardware are used in a wide range of applications. in addition many real time systems are chapter real time systems embedded in specialized devices such as ordinary home appliances for example microwave ovens and dishwashers consumer digital devices for example cameras and mp players and communication devices for example cellular telephones and blackberry handheld devices . they are also present in larger entities such as automobiles and airplanes. an embedded system is a computing device that is part of a larger system in which the presence of a computing device is often not obvious to the user. to illustrate consider an embedded system for controlling a home dishwasher. the embedded system may allow various options for scheduling the operation of the dishwasher the water temperature the type of cleaning light or heavy even a timer indicating when the dishwasher is to start. most likely the user of the dishwasher is unaware that there is in fact a computer embedded in the appliance. as another example consider an embedded system controlling antilock brakes in an automobile. each wheel in the automobile has a sensor detecting how much sliding and traction are occurring and each sensor continually sends its data to the system controller. taking the results from these sensors the controller tells the braking mechanism in each wheel how much braking pressure to apply. again to the user in this instance the driver of the automobile the presence of an embedded computer system may not be apparent. it is important to note however that not all embedded systems are real time. for example an embedded system controlling a home furnace may have no real time requirements whatsoever. some real time systems are identified as safety critical systems. in a safety critical system incorrect operation usually due to a missed deadline results in some sort of catastrophe. examples of safety critical systems include weapons systems antilock brake systems flight management systems and health related embedded systems such as pacemakers. in these scenarios the real time system must respond to events by the specified deadlines otherwise serious injury or worse might occur. however a significant majority of embedded systems do not qualify as safety critical including fax machines microwave ovens wristwatches and networking devices such as switches and routers. for these devices missing deadline requirements results in nothing more than perhaps an unhappy user. real time computing is of two types hard and soft. a hard real time system has the most stringent requirements guaranteeing that critical realtime tasks be completed within their deadlines. safety critical systems are typically hard real time systems. a soft real time system is less restrictive simply providing that a critical real time task will receive priority over other tasks and that it will retain that priority until it completes. many commercial operating systems as well as linux provide soft real time support
 in this section we explore the characteristics of real time systems and address issues related to designing both soft and hard real time operating systems. the following characteristics are typical of many real time systems single purpose small size . system characteristics inexpensively mass produced specific timing requirements we next examine each of these characteristics. unlike pcs which are put to many uses a real time system typically serves only a single purpose such as controlling antilock brakes or delivering music on an mp player. it is unlikely that a real time system controlling an airliner's navigation system will also play dvds! the design of a real time operating system reflects its single purpose nature and is often quite simple. many real time systems exist in environments where physical space is constrained. consider the amount of space available in a wristwatch or a microwave oven it is considerably less than what is available in a desktop computer. as a result of space constraints most real time systems lack both the cpu processing power and the amount of memory available in standard desktop pcs. whereas most contemporary desktop and server systems use or bit processors many real time systems run on or bit processors. similarly a desktop pc might have several gigabytes of physical memory whereas a real time system might have less than a megabyte. we refer to the footprint of a system as the amount of memory required to run the operating system and its applications. because the amount of memory is limited most real time operating systems must have small footprints. next consider where many real time systems are implemented they are often found in home appliances and consumer devices. devices such as digital cameras microwave ovens and thermostats are mass produced in very costconscious environments. thus the microprocessors for real time systems must also be inexpensively mass produced. one technique for reducing the cost of an embedded controller is to use an alternative technique for organizing the components of the computer system. rather than organizing the computer around the structure shown in figure . where buses provide the interconnection mechanism to individual components many embedded system controllers use a strategy known as system on chip soc . here the cpu memory including cache memorymouse keyboard printer monitor disks cpu disk usb controller graphics controller adapter memory figure . bus oriented organization. chapter real time systems management unit mmu and any attached peripheral ports such as usb ports are contained in a single integrated circuit. the soc strategy is typically less expensive than the bus oriented organization of figure . . we turn now to the final characteristic identified above for real time systems specific timing requirements. it is in fact the defining characteristic of such systems. accordingly the defining characteristic of both hard and soft realtime operating systems is to support the timing requirements of real time tasks and the remainder of this chapter focuses on this issue. real time operating systems meet timing requirements by using scheduling algorithms that give real time processes the highest scheduling priorities. furthermore schedulers must ensure that the priority of a real time task does not degrade over time. a second somewhat related technique for addressing timing requirements is by minimizing the response time to events such as interrupts
 in this section we discuss the features necessary for designing an operating system that supports real time processes. before we begin though let's consider what is typically not needed for a real time system. we begin by examining several features provided in many of the operating systems discussed so far in this text including linux unix and the various versions of windows. these systems typically provide support for the following a variety of peripheral devices such as graphical displays cd and dvd drives protection and security mechanisms multiple users supporting these features often results in a sophisticated and large kernel. for example windows xp has over forty million lines of source code. in contrast a typical real time operating system usually has a very simple design often written in thousands rather than millions of lines of source code. we would not expect these simple systems to include the features listed above. but why don't real time systems provide these features which are crucial to standard desktop and server systems? there are several reasons but three are most prominent. first because most real time systems serve a single purpose they simply do not require many of the features found in a desktop pc. consider a digital wristwatch it obviously has no need to support a disk drive or dvd let alone virtual memory. furthermore a typical real time system does not include the notion of a user the system simply supports a small number of tasks which often await input from hardware devices sensors vision identification and so forth . second the features supported by standard desktop operating systems are impossible to provide without fast processors and large amounts of memory. both of these are unavailable in real time systems due to space constraints as explained earlier. in addition many real time systems lack sufficient space to support peripheral disk drives or graphical displays although some systems may support file systems using nonvolatile memory nvram . third supporting features common in standard . features of real time kernels physical memory ipagei table figure . address translation in real time systems. desktop computing environments would greatly increase the cost of real time systems which could make such systems economically impractical. additional considerations apply when considering virtual memory in a real time system. providing virtual memory features as described in chapter require the system include a memory management unit mmu for translating logical to physical addresses. however mmus typically increase the cost and power consumption of the system. in addition the time required to translate logical addresses to physical addresses especially in the case of a translation look aside buffer tlb miss may be prohibitive in a hard real time environment. in the following we examine several appraoches for translating addresses in real time systems. figure . illustrates three different strategies for managing address translation available to designers of real time operating systems. in this scenario the cpu generates logical address l that must be mapped to physical address p. the first approach is to bypass logical addresses and have the cpu generate physical addresses directly. this technique known as real addressing mode does not employ virtual memory techniques and is effectively stating that p equals l. one problem with real addressing mode is the absence of memory protection between processes. real addressing mode may also require that programmers specify the physical location where their programs are loaded into memory. however the benefit of this approach is that the system is quite fast as no time is spent on address translation. real addressing mode is quite common in embedded systems with hard real time constraints. in fact some real time operating systems running on microprocessors containing an mmu actually disable the mmu to gain the performance benefit of referencing physical addresses directly. a second strategy for translating addresses is to use an approach similar to the dynamic relocation register shown in figure . . in this scenario a relocation register r is set to the memory location where a program is loaded. the physical address p is generated by adding the contents of the relocation register r to l. some real time systems configure the mmu to perform this way. the obvious benefit of this strategy is that the mmu can easily translate logical addresses to physical addresses using p l r. however this system still suffers from a lack of memory protection between processes. chapter real time systems the last approach is for the real time system to provide full virtual memory functionality as described in chapter . in this instance address translation takes place via page tables and a translation look aside buffer or tlb. in addition to allowing a program to be loaded at any memory location this strategy also provides memory protection between processes. for systems without attached disk drives demand paging and swapping may not be possible. however systems may provide such features using nvram flash memory. the lynxos and oncore systems are examples of real time operating systems providing full support for virtual memory. . implementing real time operating systems keeping in mind the many possible variations we now identify the features necessary for implementing a real time operating system. this list is by no means absolute some systems provide more features than we list below while other systems provide fewer. preemptive priority based scheduling preemptive kernel minimized latency one notable feature we omit from this list is networking support. however deciding whether to support networking protocols such as tcp ip is simple if the real time system must be connected to a network the operating system must provide networking capabilities. for example a system that gathers real time data and transmits it to a server must obviously include networking features. alternatively a self contained embedded system requiring no interaction with other computer systems has no obvious networking requirement. in the remainder of this section we examine the basic requirements listed above and identify how they can be implemented in a real time operating system. . . priority based scheduling the most important feature of a real time operating system is to respond immediately to a real time process as soon as that process requires the cpu. as a result the scheduler for a real time operating system must support a priority based algorithm with preemption. recall that priority based scheduling algorithms assign each process a priority based on its importance more important tasks are assigned higher priorities than those deemed less important. if the scheduler also supports preemption a process currently running on the cpu will be preempted if a higher priority process becomes available to run. preemptive priority based scheduling algorithms are discussed in detail in chapter where we also present examples of the soft real time scheduling features of the solaris windows xp and linux operating systems. each of these systems assigns real time processes the highest scheduling priority. for . implementing real time operating systems example windows xp has different priority levels the highest levels priority values to are reserved for real time processes. solaris and linux have similar prioritization schemes. note however that providing a preemptive priority based scheduler only guarantees soft real time functionality. hard real time systems must further guarantee that real time tasks will be serviced in accord with their deadline requirements and making such guarantees may require additional scheduling features. in section . we cover scheduling algorithms appropriate for hard real time systems. . . preemptive kernels nonpreemptive kernels disallow preemption of a process running in kernel mode a kernel mode process will run until it exits kernel mode blocks or voluntarily yields control of the cpu. in contrast a preemptive kernel allows the preemption of a task running in kernel mode. designing preemptive kernels can be quite difficult and traditional user oriented applications such as spreadsheets word processors and web browsers typically do not require such quick response times. as a result some commercial desktop operating systems such as windows xp are nonpreemptive. however to meet the timing requirements of real time systems in particular hard real time systems preemptive kernels are mandatory. otherwise a real time task might have to wait an arbitrarily long period of time while another task was active in the kernel. there are various strategies for making a kernel preemptible. one approach is to insert preemption points in long duration system calls. a preemption point checks to see whether a high priority process needs to be run. if so a context switch takes place. then when the high priority process terminates the interrupted process continues with the system call. preemption points can be placed only at safe locations in the kernel that is only where kernel data structures are not being modified. a second strategy for making a kernel preemptible is through the use of synchronization mechanisms which we discussed in chapter . with this method the kernel can always be preemptible because any kernel data being updated are protected from modification by the high priority process. event e first occurs event latency to t. t real time system responds to e time figure . event latency. chapter real time systems . . minimizing latency ? consider the event driven nature of a real time system the system is typically waiting for an event in real time to occur. events may arise either in software as when a timer expires or in hardware as when a remote controlled vehicle detects that it is approaching an obstruction. when an event occurs the system must respond to and service it as quickly as possible. we refer to event latency as the amount of time that elapses from when an event occurs to when it is serviced figure . . usually different events have different latency requirements. for example the latency requirement for an antilock brake system might be three to five milliseconds meaning that from the time a wheel first detects that it is sliding the system controlling the antilock brakes has three to five milliseconds to respond to and control the situation. any response that takes longer might result in the automobile's veering out of control. in contrast an embedded system controlling radar in an airliner might tolerate a latency period of several seconds. two types of latencies affect the performance of real time systems . interrupt latency . dispatch latency interrupt latency refers to the period of time from the arrival of an interrupt at the cpu to the start of the routine that services the interrupt. when an interrupt occurs the operating system must first complete the instruction it is executing and determine the type of interrupt that occurred. it must then save the state of the current process before servicing the interrupt using the specific interrupt service routine isr . the total time required to perform these tasks is the interrupt latency figure . . obviously it is crucial for real time interrupt determine task t running interrupt type . context switch isr interrupt latency time figure . interrupt latency. . implementing real time operating systems operating systems to minimize interrupt latency to ensure that real time?tasks receive immediate attention. one important factor contributing to interrupt latency is the amount of time interrupts may be disabled while kernel data structures are being updated. real time operating systems require that interrupts to be disabled for very short periods of time. however for hard real time systems interrupt latency must not only be minimized it must in fact be bounded to guarantee the deterministic behavior required of hard real time kernels. the amount of time required for the scheduling dispatcher to stop one process and start another is known as dispatch latency. providing real time tasks with immediate access to the cpu mandates that real time operating systems minimize this latency. the most effective technique for keeping dispatch latency low is to provide preemptive kernels. in figure . we diagram the makeup of dispatch latency. the conflict phase of dispatch latency has two components . preemption of any process running in the kernel . release by low priority processes of resources needed by a high priority process as an example in solaris the dispatch latency with preemption disabled is over milliseconds. with preemption enabled it is reduced to less than a millisecond. one issue that can affect dispatch latency arises when a higher priority process needs to read or modify kernel data that are currently being accessed by a lower priority process or a chain of lower priority processes. as kernel event response to event response interval process made interrupt available processing dispatch latency real time process execution conflicts dispatch time figure . dispatch latency. chapter real time systems data are typically protected with a lock the higher priority process will have to wait for a lower priority one to finish with the resource. the situation becomes more complicated if the lower priority process is preempted in favor of another process with a higher priority. as an example assume we have three processes l m and h whose priorities follow the order l m h. assume that process h requires resource r which is currently being accessed by process l. ordinarily process h would wait for l to finish using resource r. however now suppose that process m becomes runnable thereby preempting process l. indirectly a process with a lower priority process m has affected how long process h must wait for l to relinquish resource r. this problem known as priority inversion can be solved by use of the priority inheritance protocol. according to this protocol all processes that are accessing resources needed by a higher priority process inherit the higher priority until they are finished with the resources in question. when they are finished their priorities revert to their original values. in the example above a priority inheritance protocol allows process l to temporarily inherit the priority of process h thereby preventing process m from preempting its execution. when process l has finished using resource r it relinquishes its inherited priority from h and assumes its original priority. as resource r is now available process h not m will run next
 our coverage of scheduling so far has focused primarily on soft real time systems. as mentioned though scheduling for such systems provides no guarantee on when a critical process will be scheduled it guarantees only that the process will be given preference over noncritical processes. hard real time systems have stricter requirements. a task must be serviced by its deadline service after the deadline has expired is the same as no service at all. we now consider scheduling for hard real time systems. before we proceed with the details of the individual schedulers however we must define certain characteristics of the processes that are to be scheduled. first the processes are considered periodic. that is they require the cpu at constant intervals periods . each periodic process has a fixed processing time t once it acquires the cpu a deadline d when it must be serviced by the cpu and a period p. the relationship of the processing time the deadline and the period can be expressed as t d p. the rate of a periodic task is p. figure . illustrates the execution of a periodic process over time. schedulers can take advantage of this relationship and assign priorities according to the deadline or rate requirements of a periodic process. what is unusual about this form of scheduling is that a process may have to announce its deadline requirements to the scheduler. then using a technique known as an admission control algorithm the scheduler either admits the process guaranteeing that the process will complete on time or rejects the request as impossible if it cannot guarantee that the task will be serviced by its deadline. in the following sections we explore scheduling algorithms that address the deadline requirements of hard real time systems. . real time cpu scheduling p p j time period i period? period figure . periodic task. . . rate monotonic scheduling the rate monotonic scheduling algorithm schedules periodic tasks using a static priority policy with preemption. if a lower priority process is running and a higher priority process becomes available to run it will preempt the lower priority process. upon entering the system each periodic task is assigned a priority inversely based on its period the shorter the period the higher the priority the longer the period the lower the priority. the rationale behind this policy is to assign a higher priority to tasks that require the cpu more often. furthermore rate monotonic scheduling assumes that the processing time of a periodic process is the same for each cpu burst. that is every time a process acquires the cpu the duration of its cpu burst is the same. let's consider an example. we have two processes pi and p?. the periods for p and pt are and respectively that is f and pz . the processing times are t for pi and tz for pi. the deadline for each process requires that it complete its cpu burst by the start of its next period. we must first ask ourselves whether it is possible to schedule these tasks so that each meets its deadlines. if we measure the cpu utilization of a process pi as the ratio of its burst to its period tj pi the cpu utilization of pi is . and that of p is . for a total cpu utilization of percent. therefore it seems we can schedule these tasks in such a way that both meet their deadlines and still leave the cpu with available cycles. first suppose we assign p a higher priority than p . the execution of pi and p? is shown in figure . . as we can see p starts execution first and completes at time . at this point pi starts it completes its cpu burst at time . however the first deadline for pi was at time so the scheduler has caused pi to miss its deadline. now suppose we use rate monotonic scheduling in which we assign p a higher priority than pi since the period of pi is shorter than that of p?. deadlines pi i figure . scheduling of tasks when p has a higher priority than p . chapter real time systems deadlines p p p p p p i i i i figure . rate monotonic scheduling. the execution of these processes is shown in figure . . pi starts first and completes its cpu burst at time thereby meeting its first deadline. p starts running at this point and runs until time . at this time it is preempted by pi although it still has milliseconds remaining in its cpu burst. pi completes its cpu burst at time at which point the scheduler resumes p . p completes its cpu burst at time also meeting its first deadline. the system is idle until time when pi is scheduled again. rate monotonic scheduling is considered optimal in the sense that if a set of processes cannot be scheduled by this algorithm it cannot be scheduled by any other algorithm that assigns static priorities. let's next examine a set of processes that cannot be scheduled using the rate monotonic algorithm. assume that process pi has a period of p and a cpu burst of fi . for p the corresponding values are p and t . rate monotonic scheduling would assign process pi a higher priority as it has the shorter period. the total cpu utilization of the two processes is . and it therefore seems logical that the two processes could be scheduled and still leave the cpu with percent available time. the gantt chart showing the scheduling of processes pi and p is depicted in figure . . initially pi runs until it completes its cpu burst at time . process p then begins running and runs until time when it is preempted by pi. at this point p still has milliseconds remaining in its cpu burst. process pi runs until time however p misses the deadline for completion of its cpu burst at time . despite being optimal then rate monotonic scheduling has a limitation cpu utilization is bounded and it is not always possible to fully maximize cpu resources. the worst case cpu utilization for scheduling n processes is . with one process in the system cpu utilization is percent but it falls to approximately percent as the number of processes approaches infinity. with two processes cpu utilization is bounded at about percent. combined cpu utilization for the two processes scheduled in figures . and . is percent and therefore the rate monotonic scheduling algorithm is guaranteed deadlines p p p p p i i i figure . missing deadlines with rate monotonic scheduling. . real time cpu scheduling to schedule them so that they can meet their deadlines. for the two processes scheduled in figure . combined cpu utilization is approximately percent therefore rate mono tonic scheduling cannot guarantee that they can be scheduled so that they meet their deadlines. . . earliest deadline first scheduling earliest deadline first edf scheduling dynamically assigns priorities according to deadline. the earlier the deadline the higher the priority the later the deadline the lower the priority. under the edf policy when a process becomes runnable it must announce its deadline requirements to the system. priorities may have to be adjusted to reflect the deadline of the newly runnable process. note how this differs from rate monotonic scheduling where priorities are fixed. to illustrate edf scheduling we again schedule the processes shown in figure . which failed to meet deadline requirements under rate monotonic scheduling. recall that pj has values of p and t and that p has values pi and t . the edf scheduling of these processes is shown in figure . . process pi has the earliest deadline so its initial priority is higher than that of process pi. process pi begins running at the end of the cpu burst for p . however whereas rate monotonic scheduling allows pi to preempt p at the beginning of its next period at time edf scheduling allows process p to continue running. p now has a higher priority than pi because its next deadline at time is earlier than that of p at time . thus both pi and p have met their first deadlines. process pi again begins running at time and completes its second cpu burst at time also meeting its second deadline at time . pi begins running at this point only to be preempted by pi at the start of its next period at time . p? is preempted because pi has an earlier deadline time than p time . at time pi completes its cpu burst and pj resumes execution finishing at time and meeting its deadline as well. the system is idle until time when p is scheduled to run once again. unlike the rate monotonic algorithm edf scheduling does not require that processes be periodic nor must a process require a constant amount of cpu time per burst. the only requirement is that a process announce its deadline to the scheduler when it becomes runnable. the appeal of edf scheduling is that it is theoretically optimal theoretically it can schedule processes so that each process can meet its deadline requirements and cpu utilization will be percent. in practice however it is impossible to achieve this level of cpu utilization due to the cost of context switching between processes and interrupt handling. deadlines p p p p p i figure . earliest deadline first scheduling. chapter real time systems . . proportional share scheduling proportional share schedulers operate by allocating t shares among all applications. an application can receive n shares of time thus ensuring that the application will have n t of the total processor time. as an example assume that there is a total of t shares to be divided among three processes a b and c. a is assigned shares b is assigned shares and c is assigned shares. this scheme ensures that a will have percent of total processor time b will have percent and c will have percent. proportional share schedulers must work in conjunction with an admission control policy to guarantee that an application receives its allocated shares of time. an admission control policy will only admit a client requesting a particular number of shares if there are sufficient shares available. in our current example we have allocated shares of the total of shares. if a new process d requested shares the admission controller would deny d entry into the system. . . pthread scheduling the pos x standard also provides extensions for real time computing posix.lb. in this section we cover some of the posix pthread api related to scheduling real time threads. pthreads defines two scheduling classes for real time threads sched.fifo schedjrr sched fifo schedules threads according to a first come first served policy using a fifo queue as outlined in section . . . however there is no time slicing among threads of equal priority. therefore the highest priority real time thread at the front of the fifo queue will be granted the cpu until it terminates or blocks. sched rr for round robin is similar to sched fifo except that it provides time slicing among threads of equal priority. pthreads provides an additional scheduling class sched.other but its implementation is undefined and system specific it may behave differently on different systems. the pthread api specifies the following two functions for getting and setting the scheduling policy pthread attr getsched policy pthread attr t attr int policy pthread attr getsched policy pthread attr t attr int policy the first parameter to both functions is a pointer to the set of attributes for the thread. the second parameter is either a pointer to an integer that is set to the current scheduling policy for pthread attr getsched policy or an integer value sched.fifo sched rr or schedx ther for the pthread attr getsched policy function. both functions return non zero values if an error occurs. . real time cpu scheduling include pthread.h include stdio.h define num.threads int main int argc char argv int i policy pthread t tid num.threads pthread attr t attr get the default attributes pthread attr init j attr get the current scheduling policy if pthread attr getschedpolicy attr kpolicy ! fprintf stderr unable to get policy. n else if policy sched other printf sched other rl else if policy sched rr printf schedj rvn else if policy sched fifo printf sched fifo n set the scheduling policy fifo rr or other if pthread.attr setschedpolicy attr sched other ! fprintf stderr unable to set policy. n create the threads for i i num threads i pthread create tid i iattr runner hull now join on each thread for i i numjthreads i pthread join tid i null each thread will begin control in this function void runner void param do some work ... pthread exit figure . pthread scheduling api. chapter real time systems in figure . we illustrate a pthread program using this apr this program first determines the current scheduling policy followed by setting the scheduling algorithm to sched.other. . vxworks .x in this section we describe vxworks a popular real time operating system providing hard real time support. vxworks commercially developed by wind river systems is widely used in automobiles consumer and industrial devices and networking equipment such as switches and routers. vxworks is also used to control the two rovers spirit and opportunity that began exploring the planet mars in . the organization of vxworks is shown in figure . . vxworks is centered around the wind microkernel. recall from our discussion in section . . that microkernels are designed so that the operating system kernel provides a bare minimum of features additional utilities such as networking file systems and graphics are provided in libraries outside of the kernel. this approach offers many benefits including minimizing the size of the kernel a desirable feature for an embedded system requiring a small footprint. the wind microkernel supports the following basic features processes. the wind microkernel provides support for individual processes and threads using the pthread api . however similar to linux vxworks does not distinguish between processes and threads instead referring to both as tasks. embedded real time application wind microkernel hardware level pentium power pc mips customized etc. figure . the organization of vxworks. . vxworks .x real time linux the linux operating system is being used increasingly in real time environments. we have already covered its soft real time scheduling features section . . whereby real time tasks are assigned the highest priority in the system . additional features in the . release of the kernel make linux increasingly suitable for embedded systems. these features include a fully preemptive kernel and a more efficient scheduling algorithm which runs in time regardless of the number of tasks active in the system. the . release also makes it easier to port linux to different hardware architectures by dividing the kernel into modular components. another strategy for integrating linux into real time environments involves combining the linux operating system with a small real time kernel thereby providing a system that acts as both a general purpose and a real time system. this is the approach taken by the rtlinux operating system. in rtlinux the standard linux kernel runs as a task in a small real time operating system. the real time kernel handles all interrupts directing each interrupt to a handler in the standard kernel or to an interrupt handler in the real time kernel. furthermore rtlinux prevents the standard linux kernel from ever disabling interrupts thus ensuring that it cannot add latency to the real time system. rtlinux also provides different scheduling policies including rate monotonic scheduling section . . and earliest deadline first scheduling section . . . scheduling. wind provides two separate scheduling models preemptive and nonpreemptive round robin scheduling with different priority levels. the scheduler also supports the posix api for real time threads covered in section . . . interrupts. the wind microkernel also manages interrupts. to support hard real time requirements interrupt and dispatch latency times are bounded. interprocess communication. the wind microkernel provides both shared memory and message passing as mechanisms for communication between separate tasks. wind also allows tasks to communicate using a technique known as pipes a mechanism that behaves in the same way as a fifo queue but allows tasks to communicate by writing to a special file the pipe. to protect data shared by separate tasks vxworks provides semaphores and mutex locks with a priority inheritance protocol to prevent priority inversion. outside the microkernel vxworks includes several component libraries that provide support for posrx java tcp ip networking and the like. all components are optional allowing the designer of an embedded system to customize the system according to its specific needs. for example if networking is not required the tcp ip library can be excluded from the image of the operating system. such a strategy allows the operating system designer to chapter real time systems include only required features thereby minimizing the size or footprint of the operating system. vxworks takes an interesting approach to memory management supporting two levels of virtual memory. the first level which is quite simple allows control of the cache on a per page basis. this policy enables an application to specify certain pages as non cacheable. when data are being shared by separate tasks running on a multiprocessor architecture it is possible that shared data can reside in separate caches local to individual processors. unless an architecture supports a cache coherency policy to ensure that the same data residing in two caches will not be different such shared data should not be cached and should instead reside only in main memory so that all tasks maintain a consistent view of the data. the second level of virtual memory requires the optional virtual memory component vxvmi figure . along with processor support for a memory management unit mmu . by loading this optional component on systems with an mmu vxworks allows a task to mark certain data areas as private. a data area marked as private may only be accessed by the task it belongs to. furthermore vxworks allows pages containing kernel code along with the interrupt vector to be declared as read only. this is useful as vxworks does not distinguish between user and kernel modes all applications run in kernel mode giving an application access to the entire address space of the system
 and decoding may require significant cpu processing. . multimedia tasks must be scheduled with certain priorities to ensure meeting the deadline requirements of continuous media. . similarly file systems must be efficient to meet the rate requirements of continuous media. . network protocols must support bandwidth requirements while minimizing delay and jitter. in later sections we explore these and several other issues related to qos. first however we provide an overview of various techniques for compressing multimedia data. as suggested above compression makes significant demands on the cpu. . compression because of the size and rate requirements of multimedia systems multimedia files are often compressed from their original form to a much smaller form. once a file has been compressed it takes up less space for storage and can be delivered to a client more quickly. compression is particularly important when the content is being streamed across a network connection. in discussing file compression we often refer to the compression ratio which is the ratio of the original file size to the size of the compressed file. for example an kb file that is compressed to kb has a compression ratio of . once a file has been compressed encoded it must be decompressed decoded before it can be accessed. a feature of the algorithm used to compress the file affects the later decompression. compression algorithms are classified as either lossy or lossless. with lossy compression some of the original data are lost when the file is decoded whereas lossless compression ensures that the compressed file can always be restored back to its original form. in general lossy techniques provide much higher compression ratios. obviously though . compression only certain types of data can tolerate lossy compression namely images audio and video. lossy compression algorithms often work by eliminating certain data such as very high or low frequencies that a human ear cannot detect. some lossy compression algorithms used on video operate by storing only the differences between successive frames. lossless algorithms are used for compressing text files such as computer programs for example zipping files because we want to restore these compressed files to their original state. a number of different lossy compression schemes for continuous media data are commercially available. in this section we cover one used by the moving picture experts group better known as mpeg. mpeg refers to a set of file formats and compression standards for digital video. because digital video often contains an audio portion as well each of the standards is divided into three layers. layers and apply to the audio and video portions of the media file. layer is known as the systems layer and contains timing information to allow the mpeg player to multiplex the audio and video portions so that they are synchronized during playback. there are three major mpeg standards mpeg mpeg and mpeg . mpeg is used for digital video and its associated audio stream. the resolution of mpeg is x at frames per second with a bit rate of up to . mbps. this provides a quality slightly lower than that of conventional vcr videos. mp audio files a popular medium for storing music use the audio layer layer of mpeg . for video mpeg can achieve a compression ratio of up to although in practice compression ratios are much lower. because mpeg does not require high data rates it is often used to download short video clips over the internet. mpeg provides better quality than mpeg and is used for compressing dvd movies and digital television including high definition television or hdtv . mpeg identifies a number of levels and profiles of video compression. the level refers to the resolution of the video the profile characterizes the video's quality. in general the higher the level of resolution and the better the quality of the video the higher the required data rate. typical bit rates for mpeg encoded files are . mbps to mbps. because mpeg requires higher rates it is often unsuitable for delivery of video across a network and is generally used for local playback. mpeg is the most recent of the standards and is used to transmit audio video and graphics including two dimensional and three dimensional animation layers. animation makes it possible for end users to interact with the file during playback. for example a potential home buyer can download an mpeg file and take a virtual tour through a home she is considering purchasing moving from room to room as she chooses. another appealing feature of mpeg is that it provides a scalable level of quality allowing delivery over relatively slow network connections such as kbps modems or over high speed local area networks with rates of several megabits per second. furthermore by providing a scalable level of quality mpeg audio and video files can be delivered to wireless devices including handheld computers pdas and cell phones. all three mpeg standards discussed here perform lossy compression to achieve high compression ratios. the fundamental idea behind mpeg compression is to store the differences between successive frames. we do not cover further details of how mpeg performs compression but rather encourage chapter multimedia systems the interested reader to consult the bibliographical notes at the end of this chapter. . requirements of multimedia kernels as a result of the characteristics described in section . . multimedia applications often require levels of service from the operating system that differ from the requirements of traditional applications such as word processors compilers and spreadsheets. timing and rate requirements are perhaps the issues of foremost concern as the playback of audio and video data demands that the data be delivered within a certain deadline and at a continuous fixed rate. traditional applications typically do not have such time and rate constraints. tasks that request data at constant intervals or periods are known as periodic processes. for example an mpeg video might require a rate of frames per second during playback. maintaining this rate requires that a frame be delivered approximately every ' or . hundredths of a second. to put this in the context of deadlines let's assume that frame fj succeeds frame f in the video playback and that frame f was displayed at time to. the deadline for displaying frame fj is . hundredths of a second after time to. if the operating system is unable to display the frame by this deadline the frame will be omitted from the stream. as mentioned earlier rate requirements and deadlines are known as quality of service qos requirements. there are three qos levels . best effort service. the system makes a best effort attempt to satisfy the requirements however no guarantees are made. . soft qos. this level treats different types of traffic in different ways giving certain traffic streams higher priority than other streams. however just as with best effort service no guarantees are made. . hard qos. the quality of service requirements are guaranteed. traditional operating systems the systems we have discussed in this text so far typically provide only best effort service and rely on overprovisioning that is they simply assume that the total amount of resources available will tend to be larger than a worst case workload would demand. if demand exceeds resource capacity manual intervention must take place and a process or several processes must be removed from the system. however next generation multimedia systems cannot make such assumptions. these systems must provide continuous media applications with the guarantees made possible by hard qos. therefore in the remainder of this discussion when we refer to qos we mean hard qos. next we explore various techniques that enable multimedia systems to provide such service level guarantees. there are a number of parameters defining qos for multimedia applications including the following throughput. throughput is the total amount of work done during a certain interval. for multimedia applications throughput is the required data rate. . requirements of multimedia kernels delay. delay refers to the elapsed time from when a request is first submitted to when the desired result is produced. for example the time from when a client requests a media stream to when the stream is delivered is the delay. jitter. jitter is related to delay but whereas delay refers to the time a client must wait to receive a stream jitter refers to delays that occur during playback of the stream. certain multimedia applications such as on demand real time streaming can tolerate this sort of delay. jitter is generally considered unacceptable for continuous media applications however because it may mean long pauses or lost frames during playback. clients can often compensate for jitter by buffering a certain amount of data say seconds' worth before beginning playback. reliability. reliability refers to how errors are handled during transmission and processing of continuous media. errors may occur due to lost packets in the network or processing delays by the cpu. in these and other scenarios errors cannot be corrected since packets typically arrive too late to be useful. the quality of service may be negotiated between the client and the server. for example continuous media data may be compressed at different levels of quality the higher the quality the higher the required data rate. a client may negotiate a specific data rate with a server thus agreeing to a certain level of quality during playback. furthermore many media players allow the client to configure the player according to the speed of the client's connection to the network. this allows a client to receive a streaming service at a data rate specific to a particular connection. thus the client is negotiating quality of service with the content provider. to provide qos guarantees operating systems often use admission control which is simply the practice of admitting a reqtiest for service only if the server has sufficient resources to satisfy the request. we see admission control quite often in our everyday lives. for example a movie theater only admits as many customers as it has seats in the theater. there are also many situations in everyday life where admission control is not practiced but would be desirable! if no admission control policy is used in a multimedia environment the demands on the system might become so great that the system becomes unable to meet its qos guarantees. in chapter we discussed using semaphores as a method of implementing a simple admission control policy. in this scenario there exist a finite number of non shareable resources. when a resource is requested we will only grant the request if there are sufficient resources available otherwise the requesting process is forced to wait until a resource becomes available. semaphores may be used to implement an admission control policy by first initializing a semaphore to the number of resources available. every request for a resource is made through a waito operation on the semaphore a resource is released with an invocation of signal on the semaphore. once all resources are in use subsequent calls to wait block until there is a corresponding s i g n a l . a common technique for implementing admission control is to use resource reservations. for example resources on a file server may include the cpu memory file system devices and network figure . . note that chapter multimedia systems y. j storage j i o bus chh jtahz secondary ct j storage v i o bus butfer space network figure . resources on a file server. resources may be either exclusive or shared and that there may be either single or multiple instances of each resource type. to use a resource a client must make a reservation request for the resource in advance. if the request cannot be granted the reservation is denied. an admission control scheme assigns a resource manager to each type of resource. requests for resources have associated qos requirements for example required data rates. when a request for a resource arrives the resource manager determines if the resource can meet the qos demands of the request. if not the request may be rejected or a lower level of qos may be negotiated between the client and the server. if the request is accepted the resource manager reserves the resources for the requesting client thus assuring the client the desired qos requirements. in section . . we examine the admission control algorithm used to ensure qos guarantees in the cineblitz multimedia storage server
 in chapter which covered real time systems we distinguished between soft real time systems and hard real time systems. soft real time systems simply give scheduling priority to critical processes. a soft real time system ensures that a critical process will be given preference over a noncritical process but provides no guarantee as to when the critical process will be scheduled. a typical requirement of continuous media however is that data must be delivered to a client by a certain deadline data that do not arrive by the deadline are unusable. multimedia systems thus require hard real time scheduling to ensure that a critical task will be serviced within a guaranteed period of time. another scheduling issue concerns whether a scheduling algorithm uses static priority or dynamic priority a distinction we first discussed in chapter . the difference between the two is that the priority of a process will remain unchanged if the scheduler assigns it a static priority. scheduling algorithms
 that assign dynamic priorities allow priorities to change over time. .most operating systems use dynamic priorities when scheduling non real time tasks with the intention of giving higher priority to interactive processes. however when scheduling real time tasks most systems assign static priorities as the design of the scheduler is less complex. several of the real time scheduling strategies discussed in section . can be used to meet the rate and deadline qos requirements of continuous media applications. . disk scheduling we first discussed disk scheduling in chapter . there we focused primarily on systems that handle conventional data for these systems the scheduling goals are fairness and throughput. as a result most traditional disk schedulers employ some form of the scan section . . or c scan section . . algorithm. continuous media files however have two constraints that conventional data files generally do not have timing deadlines and rate requirements. these two constraints must be satisfied to preserve qos guarantees and diskscheduling algorithms must be optimized for the constraints. unfortunately these two constraints are often in conflict. continuous media files typically require very high disk bandwidth rates to satisfy their data rate requirements. because disks have relatively low transfer rates and relatively high latency rates disk schedulers must reduce the latency times to ensure high bandwidth. however reducing latency times may result in a scheduling policy that does not prioritize according to deadlines. in this section we explore two diskscheduling algorithms that meet the qos requirements for continuous media systems. . . earliest deadline first scheduling we first saw the earliest deadline first edf algorithm in section . . as an example of a cpu scheduling algorithm that assigns priorities according to deadlines. edf can also be used as a disk scheduling algorithm in this context edf uses a queue to order requests according to the time each request must be completed its deadline . edf is similar to shortest seek time first sstf which was discussed in . . except that instead of servicing the request closest to the current cylinder we service requests according to deadline the request with the closest deadline is serviced first. a problem with this approach is that servicing requests strictly according to deadline may result in higher seek times since the disk heads may move randomly throughout the disk without any regard to their current position. for example suppose a disk head is currently at cylinder and the queue of cylinders ordered according to deadlines is . under strict edf scheduling the disk head will move from to to and then back to . note that the head passes over cylinder as it travels from to . it is possible that the disk scheduler could have serviced the request for cylinder en route to cylinder and still preserved the deadline requirement for cylinder . chapter multimedia systems . . scan edf scheduling ? the fundamental problem with strict edf scheduling is that it ignores the position of the read write heads of the disk it is possible that the movement of the heads will swing wildly to and fro across the disk leading to unacceptable seek times that negatively affect disk throughput. recall that this is the same issue faced with fcfs scheduling section . . . we ultimately addressed this issue by adopting scan scheduling wherein the disk arm moves in one direction across the disk servicing requests according to their proximity to the current cylinder. once the disk arm reaches the end of the disk it begins moving in the reverse direction. this strategy optimizes seek times. scan edf is a hybrid algorithm that combines edf with scan scheduling. scan edf starts with edf ordering but services requests with the same deadline using scan order. what if several requests have different deadlines that are relatively close together? in this case scan edf may batch requests using scan ordering to service requests in the same batch. there are many techniques for batching requests with similar deadlines the only requirement is that reordering requests within a batch must not prevent a request from being serviced by its deadline. if deadlines are equally distributed batches can be organized in groups of a certain size say requests per batch. another approach is to batch requests whose deadlines fall within a given time threshold say milliseconds. let's consider an example in which we batch requests in this way. assume we have the following requests each with a specified deadline in milliseconds and the cylinder being requested request deadline cylinder a b c d e f g h j suppose we are at ti meo the cylinder currently being serviced is and the disk head is moving toward cylinder . according to our batching scheme requests d and f will be in the first batch a g and h in batch b e and j in batch and c and i in the last batch. requests within each batch will be ordered according to scan order. thus in batch we will first service request f and then request d. note that we are moving downward in cylinder numbers from to . in batch we first service request a then the heads begin moving upward in cylinders servicing requests h and then g. batch is serviced in the order e b j. requests i and c are serviced in the final batch
 linux looks and feels much like any other unix system indeed unix compatibility has been a major design goal of the linux project. however linux is much younger than most unix systems. its development began in when a finnish student linus torvalds wrote and christened linux a small but self contained kernel for the processor the first true bit processor in intel's range of pc compatible cpus. early in its development the linux source code was made available free on the internet. as a result linux's history has been one of collaboration by many users from all around the world corresponding almost exclusively over the internet. from an initial kernel that partially implemented a small subset of chapter the linux system the unix system services the linux system has grown to include much iffnix functionality. in its early days linux development revolved largely around the central operating system kernel the core privileged executive that manages all system resources and that interacts directly with the computer hardware. we need much more than this kernel to produce a full operating system of course. it is useful to make the distinction between the linux kernel and a linux system. the linux kernel is an entirely original piece of software developed from scratch by the linux community. the linux system as we know it today includes a multitude of components some written from scratch others borrowed from other development projects and still others created in collaboration with other teams. the basic linux system is a standard environment for applications and user programming but it does not enforce any standard means of managing the available functionality as a whole. as linux has matured a need has arisen for another layer of functionality on top of the linux system. this need has been met by various linux distributions. a linux distribution includes all the standard components of the linux system plus a set of administrative tools to simplify the initial installation and subsequent upgrading of linux and to manage installation and removal of other packages on the system. a modern distribution also typically includes tools for management of file systems creation and management of user accounts administration of networks web browsers word processors and so on. . . the linux kernel the first linux kernel released to the public was version . dated may . it had no networking ran only on compatible intel processors and pc hardware and had extremely limited device driver support. the virtual memory subsystem was also fairly basic and included no support for memorymapped files however even this early incarnation supported shared pages with copy on write. the only file system supported was the minix file system the first linux kernels were cross developed on a minix platform. however the kernel did implement proper unix processes with protected address spaces. the next milestone version linux . was released on march . this release culminated three years of rapid development of the linux kernel. perhaps the single biggest new feature was networking . included support for unix's standard tcp ip networking protocols as well as a bsd compatible socket interface for networking programming. device driver support was added for running ip over an ethernet or using ppp or slip protocols over serial lines or modems. the . kernel also included a new much enhanced file system without the limitations of the original minix file system and supported a range of scsi controllers for high performance disk access. the developers extended the virtual memory subsystem to support paging to swap files and memory mapping of arbitrary files but only read only memory mapping was implemented in . . a range of extra hardware support was also included in this release. although still restricted to the intel pc platform hardware support had grown to include floppy disk and cd rom devices as well as sound cards a range of mice and international keyboards. floating point emulation was provided . linux history in the kernel for users who had no math coprocessor system v unix style interprocess communication ipc including shared memory semaphores and message queues was implemented. simple support for dynamically loadable and unloadable kernel modules was supplied as well. at this point development started on the . kernel stream but numerous bug fix patches were released subsequently against . . a pattern was adopted as the standard numbering convention for linux kernels. kernels with an odd minor version number such as . . and . are development kernels evennumbered minor version numbers are stable production kernels. updates against the stable kernels are intended only as remedial versions whereas the development kernels may include newer and relatively untested functionality. in march the . kernel was released. this release did not offer nearly the same improvement in functionality as the . release but it did support a much wider variety of hardware including the new pci hardware bus architecture. developers added another pc specific feature support for the cpu's virtual mode to allow emulation of the dos operating system for pc computers. they also updated the networking stack to provide support for the ipx protocol and made the ip implementation more complete by including accounting and firewalling functionality. the . kernel was the final pc only linux kernel. the source distribution for linux . included partially implemented support for sparc alpha and mips cpus but full integration of these other architectures did not begin until after the . stable kernel was released. the linux . release concentrated on wider hardware support and more complete implementations of existing functionality. much new functionality was under development at the time but integration of the new code into the main kernel source code had been deferred until after the stable . kernel had been released. as a result the . development stream saw a great deal of new functionality added to the kernel. this work was finally released as linux . in june . this release was given a major version number increment on account of two major new capabilities support for multiple architectures including a fully bit native alpha port and support for multiprocessor architectures. linux distributions based on . are also available for the motorola series processors and for sun's sparc systems. a derived version of linux running on top of the mach microkernel also runs on pc and powermac systems. the changes in . did not stop there. the memory management code was substantially improved to provide a unified cache for file system data independent of the caching of block devices. as a result of this change the kernel offered greatly increased file system and virtual memory performance. for the first time file system caching was extended to networked file systems and writable memory mapped regions also were supported. the . kernel also included much improved tcp ip performance and a number of new networking protocols were added including appletalk ax. amateur radio networking and isdn support. the ability to mount remote netware and smb microsoft lanmanager network volumes was added. other major improvements in . were support for internal kernel threads for handling dependencies between loadable modules and for automatic loading of modules on demand. dynamic configuration of the kernel at run time was much improved through a new standardized configuration interface. chapter the linux system additional new features included file system quotas and posix compatible real time process scheduling classes. improvements continued with the release of linux . in january . a port for ultrasparc systems was added. networking was enhanced with more flexible firewalling better routing and traffic management and support for tcp large window and selective acks. acorn apple and nt disks could now be read and nfs was enhanced and a kernel mode nfs daemon added. signal handling interrupts and some i o were locked at a finer level than before to improve symmetric multiprocessor smp performance. advances in the . and . releases of the kernel include increased support for smp systems journaling file systems and enhancements to the memorymanagement system. the process scheduler has been modified in version . providing an efficient scheduling algorithm. in addition the linux . kernel is now preemptive allowing a process to be preempted while running in kernel mode. . . the linux system in many ways the linux kernel forms the core of the linux project but other components make up the complete linux operating system. whereas the linux kernel is composed entirely of code written from scratch specifically for the linux project much of the supporting software that makes up the linux system is not exclusive to linux but is common to a number of unix like operating systems. in particular linux uses many tools developed as part of berkeley's bsd operating system mit's x window system and the free software foundation's gnu project. this sharing of tools has worked in both directions. the main system libraries of linux were originated by the gnu project but the linux community greatly improved the libraries by addressing omissions inefficiencies and bugs. other components such as the gnu c compiler gcc were already of sufficiently high quality to be used directly in linux. the networkingadministration tools under linux were derived from code first developed for . bsd but more recent bsd derivatives such as freebsd have borrowed code from linux in return. examples include the intel floating point emulation math library and the pc sound hardware device drivers. the linux system as a whole is maintained by a loose network of developers collaborating over the internet with small groups or individuals having responsibility for maintaining the integrity of specific components. a small number of public internet file transfer protocol ftp archive sites act as de facto standard repositories for these components. the file system hierarchy standard document is also maintained by the linux community as a means of keeping compatibility across the various system components. this standard specifies the overall layout of a standard linux file system it determines under which directory names configuration files libraries system binaries and run time data files should be stored. . . linux distributions in theory anybody can install a linux system by fetching the latest revisions of the necessary system components from the ftp sites and compiling them. in linux's early days this operation was often precisely what a linux user . linux history had to carry out. as linux has matured however various individuals and groups have attempted to make this job less painful by providing a standard precompiled set of packages for easy installation. these collections or distributions include much more than just the basic linux system. they typically include extra system installation and management utilities as well as precompiled and ready to install packages of many of the common unix tools such as news servers web browsers text processing and editing tools and even games. the first distributions managed these packages by simply providing a means of unpacking all the files into the appropriate places. one of the important contributions of modern distributions however is advanced package management. today's linux distributions include a package tracking database that allows packages to be installed upgraded or removed painlessly. the sls distribution dating back to the early days of linux was the first collection of linux packages that was recognizable as a complete distribution. although it could be installed as a single entity sls lacked the packagemanagement tools now expected of linux distributions. the slackware distribution represented a great improvement in overall quality even though it also had poor package management it is still one of the most widely installed distributions in the linux community. since slackware's release many commercial and noncommercial linux distributions have become available. red hat and debian are particularly popular distributions the first comes from a commercial linux support company and the second from the free software linux community. other commercially supported versions of linux include distributions from caldera craftworks and workgroup solutions. a large linux following in germany has resulted in several dedicated german language distributions including versions from suse and unifix. there are too many linux distributions in circulation for us to list all of them here. the variety of distributions does not prohibit compatibility across linux distributions however. the rpm package file format is used or at least understood by the majority of distributions and commercial applications distributed in this format can be installed and run on any distribution that can accept rpm files. . . linux licensing the linux kernel is distributed under the gnu general public license gpl the terms of which are set out by the free software foundation. linux is not public domain software. public domain implies that the authors have waived copyright rights in the software but copyright rights in linux code are still held by the code's various authors. linux is free software however in the sense that people can copy it modify it use it in any manner they want and give away their own copies without any restrictions. the main implications of linux's licensing terms are that nobody using linux or creating her own derivative of linux a legitimate exercise can make the derived product proprietary software released under the gpl cannot be redistributed as a binary only product. if you release software that includes any components covered by the gpl then under the gpl you must make source code available alongside any binary distributions. this restriction does chapter the linux system not prohibit making or even selling binary only software distributions as long as anybody who receives binaries is also given the opportunity to get source code for a reasonable distribution charge. 
 in its overall design linux resembles any other traditional nonmicrokernel unix implementation. it is a multiuser multitasking system with a full set of unix compatible tools. linux's file system adheres to traditional unix semantics and the standard unix networking model is implemented fully. the internal details of linux's design have been influenced heavily by the history of this operating system's development. although linux runs on a wide variety of platforms it was developed exclusively on pc architecture. a great deal of that early development was carried out by individual enthusiasts rather than by well funded development or research facilities so from the start linux attempted to squeeze as much functionality as possible from limited resources. today linux can run happily on a multiprocessor machine with hundreds of megabytes of main memory and many gigabytes of disk space but it is still capable of operating usefully in under mb of ram. as pcs became more powerful and as memory and hard disks became cheaper the original minimalist linux kernels grew to implement more unix functionality. speed and efficiency are still important design goals but much of the recent and current work on linux has concentrated on a third major design goal standardization. one of the prices paid for the diversity of unix implementations currently available is that source code written for one flavor may not necessarily compile or run correctly on another. even when the same system calls are present on two different unix systems they do not necessarily behave in exactly the same way. the posix standards comprise a set of specifications of different aspects of operating system behavior. there are posix documents for common operating system functionality and for extensions such as process threads and real time operations. linux is designed to be compliant with the relevant posix documents at least two linux distributions have achieved official posix certification. because it presents standard interfaces to both the programmer and the user linux presents few surprises to anybody familiar with unix. we do not detail these interfaces here. the sections on the programmer interface section a. and user interface section a. of bsd apply equally well to linux. by default however the linux programming interface adheres to svr unix semantics rather than to bsd behavior. a separate set of libraries is available to implement bsd semantics in places where the two behaviors are significantly different. many other standards exist in the unix world but full certification of linux against them is sometimes slowed because they are often available only for a fee and the expense involved in certifying an operating system's compliance with most standards is substantial. however supporting a wide base of applications is important for any operating system so implementation of standards is a major goal for linux development even if the implementation is not formally certified. in addition to the basic posix standard linux currently . design principles supports the posix threading extensions pthreads and a subset of tl e posix extensions for real time process control. . . components of a linux system the linux system is composed of three main bodies of code in line with most traditional unix implementations . kernel. the kernel is responsible for maintaining all the important abstractions of the operating system including such things as virtual memory and processes. . system libraries. the system libraries define a standard set of functions through which applications can interact with the kernel. these functions implement much of the operating system functionality that does not need the full privileges of kernel code. . system utilities. the system utilities are programs that perform individual specialized management tasks. some system utilities may be invoked just once to initialize and configure some aspect of the system others known as daemons in unix terminology may run permanently handling such tasks as responding to incoming network connections accepting logon requests from terminals and updating log files. figure . illustrates the various components that make up a full linux system. the most important distinction here is between the kernel and everything else. all the kernel code executes in the processor's privileged mode with full access to all the physical resources of the computer. linux refers to this privileged mode as kernel mode. under linux no user mode code is built into the kernel. any operating system support code that does not need to run in kernel mode is placed into the system libraries instead. although various modern operating systems have adopted a messagepassing architecture for their kernel internals linux retains unix's historical model the kernel is created as a single monolithic binary. the main reason is to improve performance because all kernel code and data structures are kept in a single address space no context switches are necessary when a process calls an operating system function or when a hardware interrupt is delivered. not system ! user j manaqement ' utility i compilers programs r i progiarrw j system sharer! libraries linux kernel loadable kernel modules figure . components of the linux system. chapter the linux system only the core scheduling and virtual memory code occupies this address space all kernel code including all device drivers file systems and networking cod e is present in the same single address space. even though all the kernel components share this same melting pot there is still room for modularity. in the same way that user applications can load shared libraries at run time to pull in a needed piece of code so the linux kernel can load and unload modules dynamically at run time. the kernel does not necessarily need to know in advance which modules may be loaded they are truly independent loadable components. the linux kernel forms the core of the linux operating system. it provides all the functionality necessary to run processes and it provides system services to give arbitrated and protected access to hardware resources. the kernel implements all the features required to qualify as an operating system. on its own however the operating system provided by the linux kernel looks nothing like a unix system. it is missing many of the extra features of unix and the features that it does provide are not necessarily in the format in which a unix application expects them to appear. the operating system interface visible to running applications is not maintained directly by the kernel. rather applications make calls to the system libraries which in turn call the operatingsystem services as necessary. the system libraries provide many types of functionality. at the simplest level they allow applications to make kernel system service requests. making a system call involves transferring control from unprivileged user mode to privileged kernel mode the details of this transfer vary from architecture to architecture. the libraries take care of collecting the system call arguments and if necessary arranging those arguments in the special form necessary to make the system call. the libraries may also provide more complex versions of the basic system calls. for example the c language's buffered file handling functions are all implemented in the system libraries providing more advanced control of file i o than the basic kernel system calls. the libraries alsoprovide routines that do not correspond to system calls at all such as sorting algorithms mathematical functions and string manipulation routines. all the functions necessary to support the running of unix or pos x applications are implemented here in the system libraries. the linux system includes a wide variety of user mode programs both system utilities and user utilities. the system utilities include all the programs necessary to initialize the system such as those to configure network devices and to load kernel modules. continually running server programs also count as system utilities svich programs handle user login requests incoming network connections and the printer queues. not all the standard utilities serve key system administration functions. the unix user environment contains a large number of standard utilities to do simple everyday tasks such as listing directories moving and deleting files and displaying the contents of a file. more complex utilities can perform text processing functions such as sorting textual data and performing pattern searches on input text. together these utilities form a standard tool set that users can expect on any unix system although they do not perform any operating system function they are an important part of the basic linux system
 . kernel modules the linux kernel has the ability to load and unload arbitrary sections of kernel code on demand. these loadable kernel modules run in privileged kernel mode and as a consequence have full access to all the hardware capabilities of the machine on which they run. in theory there is no restriction on what a kernel module is allowed to do typically a module might implement a device driver a file system or a networking protocol. kernel modules are convenient for several reasons. linux's source code is free so anybody wanting to write kernel code is able to compile a modified kernel and to reboot to load that new functionality however recompiling relinking and reloading the entire kernel is a cumbersome cycle to undertake when you are developing a new driver. if you use kernel modules you do not have to make a new kernel to test a new driver the driver can be compiled on its own and loaded into the already running kernel. of course once a new driver is written it can be distribttted as a module so that other users can benefit from it without having to rebuild their kernels. this latter point has another implication. because it is covered by the gpl license the linux kernel cannot be released with proprietary components added to it unless those new components are also released under the gpl and the source code for them is made available on demand. the kernel's module interface allows third parties to write and distribute on their own terms device drivers or file systems that could not be distributed under the gpl. kernel modules allow a linux system to be set up with a standard minimal kernel without any extra device drivers built in. any device drivers that the user needs can be either loaded explicitly by the system at startup or loaded automatically by the system on demand and unloaded when not in use. for example a cd rom driver might be loaded when a cd is mounted and unloaded from memory when the cd is dismounted from the file system. the module support under linux has three components . the module management allows modules to be loaded into memory and to talk to the rest of the kernel. . the driver registration allows modules to tell the rest of the kernel that a new driver has become available. . a conflict resolution mechanism allows different device drivers to reserve hardware resources and to protect those resources from accidental use by another driver. . . module management loading a module requires more than just loading its binary contents into kernel memory. the system must also make sure that any references the module makes to kernel symbols or entry points are updated to point to the correct locations in the kernel's address space. linux deals with this reference updating by splitting the job of module loading into two separate sections the management of sections of module code in kernel memory and the handling of symbols that modules are allowed to reference. chapter the linux system linux maintains an internal symbol table in the kernel. this symbol table does not contain the full set of symbols defined in the kernel during the latter's compilation rather a symbol must be exported explicitly by the kernel. the set of exported symbols constitutes a well defined interface by which a module can interact with the kernel. although exporting symbols from a kernel function requires an explicit request by the programmer no special effort is needed to import those symbols into a module. a module writer just uses the standard external linking of the c language any external symbols referenced by the module but not declared by it are simply marked as unresolved in the final module binary produced by the compiler. when a module is to be loaded into the kernel a system utility first scans the module for these unresolved references. all symbols that still need to be resolved are looked up in the kernel's symbol table and the correct addresses of those symbols in the currently running kernel are substituted into the module's code. only then is the module passed to the kernel for loading. if the system utility cannot resolve any references in the module by looking them up in the kernel's symbol table then the module is rejected. the loading of the module is performed in two stages. first the moduleloader utility asks the kernel to reserve a continuous area of virtual kernel memory for the module. the kernel returns the address of the memory allocated and the loader utility can use this address to relocate the module's machine code to the correct loading address. a second system call then passes the module plus any symbol table that the new module wants to export to the kernel. the module itself is now copied verbatim into the previously allocated space and the kernel's symbol table is updated with the new symbols for possible use by other modules not yet loaded. the final module management component is the module requestor. the kernel defines a communication interface to which a module management program can connect. with this connection established the kernel will inform the management process whenever a process requests a device driver file system or network service that is not currently loaded and will give the manager the opportunity to load that service. the original service request will complete once the module is loaded. the manager process regularly queries the kernel to see whether a dynamically loaded module is still in use and unloads that module when it is no longer actively needed. . . driver registration once a module is loaded it remains no more than an isolated region of memory until it lets the rest of the kernel know what new functionality it provides. the kernel maintains dynamic tables of all known drivers and provides a set of routines to allow drivers to be added to or removed from these tables at any time. the kernel makes sure that it calls a module's startup routine when that module is loaded and calls the module's cleanup routine before that module is unloaded these routines are responsible for registering the module's functionality. a module may register many types of drivers and may register more than one driver if it wishes. for example a device driver might want to register two separate mechanisms for accessing the device. registration tables include the following items . kernel modules device drivers. these drivers include character devices such as printers terminals and mice block devices including all disk drives and network . interface devices. file systems. the file system may be anything that implements linux's virrual file system calling routines. it might implement a format for storing files on a disk but it might equally well be a network file system such as nfs or a virtual file system whose contents are generated on demand such as linux's proc file system. network protocols. a module may implement an entire networking protocol such as ipx or simply a new set of packet filtering rules for a network firewrall. binary format. this format specifies a way of recognizing and loading a new type of executable file. in addition a module can register a new set of entries in the sysctl and proc ' tables to allow that module to be configured dynamically section . a . . conflict resolution commercial unix implementations are usually sold to run on a vendor's own hardware. one advantage of a single supplier solution is that the software vendor has a good idea about what hardware configurations are possible. ibm pc hardware however comes in a vast number of configurations with large numbers of possible drivers for devices such as network cards scsi controllers and video display adapters. the problem of managing the hardware configuration becomes more severe when modular device drivers are supported since the currently active set of devices becomes dynamically variable. linux provides a central conflict resolution mechanism to help arbitrate access to certain hardware resources. its aims are as follows to prevent modules from clashing over access to hardware resources to prevent autoprobes device driver probes that auto detect device configuration from interfering with existing device drivers j to resolve conflicts among multiple drivers trying to access the same j hardware for example as when both the parallel printer driver and the i parallel line ip plip network driver try to talk to the parallel printer port . to these ends the kernel maintains lists of allocated hardware resources. e the pc has a limited number of possible i o ports addresses in its hardware i i o address space interrupt lines and dma channels when any device driver i wants to access such a resource it is expected to reserve the resource with i the kernel database first. this requirement incidentally allows the system i administrator to determine exactly which resources have been allocated by which driver at any given point. a module is expected to use this mechanism to reserve in advance any f hardware resources that it expects to use. if the reservation is rejected because i the resource is not present or is already in use then it is up to the module chapter the linux system to decide how to proceed. it may fail its initialization and request thatnt be unloaded if it cannot continue or it may carry on using alternative hardware resources
 a process is the basic context within which all user requested activity is serviced within the operating system. to be compatible with other unix systems linux must use a process model similar to those of other versions of unix. linux operates differently from unix in a few key places however. in this section we review the traditional unix process model from section a. . and introduce linux's own threading model. . . the fork and exec process model the basic principle of unix process management is to separate two operations the creation of a process and the running of a new program. a new process is created by the f ork system call and a new program is run after a call to exec . these are two distinctly separate functions. a new process may be created with forko without a new program being run the new subprocess simply continues to execute exactly the same program that the first parent process was running. equally running a new program does not require that a new process be created first any process may call exec at any time. the currently running program is immediately terminated and the new program starts executing in the context of the existing process. this model has the advantage of great simplicity. rather than having to specify every detail of the environment of a new program in the system call that runs that program new programs simply run in their existing environment. if a parent process wishes to modify the environment in which a new program is to be run it can fork and then still running the original program in a child process make any system calls it requires to modify that child process before finally executing the new program. under unix then a process encompasses all the information that the operating system must maintain to track the context of a single execution of a single program. under linux we can break down this context into a number of specific sections. broadly process properties fall into three groups the process identity environment and context. . . . process identity a process identity consists mainly of the following items process id pid . each process has a unique identifier. pids are used to specify processes to the operating system when an application makes a system call to signal modify or wait for another process. additional identifiers associate the process with a process group typically a tree of processes forked by a single user command and login session. credentials. each process must have an associated user id and one or more group ids user groups are discussed in section . . that determine the rights of a process to access system resources and files. . process management personality. process personalities are not traditionally found on unix systems but under linux each process has an associated personality identifier that can modify slightly the semantics of certain system calls. personalities are primarily used by emulation libraries to request that system calls be compatible with certain flavors of unix. most of these identifiers are under limited control of the process itself. the process group and session identifiers can be changed if the process wants to start a new group or session. its credentials can be changed subject to appropriate security checks. however the primary pid of a process is unchangeable and uniquely identifies that process until termination. . . . process environment a process's environment is inherited from its parent and is composed of two null terminated vectors the argument vector and the environment vector. the argument vector simply lists the command line arguments used to invoke the running program it conventionally starts with the name of the program itself. the environment vector is a list of name value pairs that associates named environment variables with arbitrary textual values. the environment is not held in kernel memory but is stored in the process's own user mode address space as the first datum at the top of the process's stack. the argument and environment vectors are not altered when a new process is created the new child process will inherit the environment that its parent possesses. however a completely new environment is set up when a new program is invoked. on calling exec a process must supply the environment for the new program. the kernel passes these environment variables to the next program replacing the process's current environment. the kernel otherwise leaves the environment and command line vectors alone their interpretation is left entirely to the user mode libraries and applications. the passing of environment variables from one process to the next and the inheriting of these variables by the children of a process provide flexible ways to pass information to components of the user mode system software. various important environment variables have conventional meanings to related parts of the system software. for example the term variable is set up to name the type of terminal connected to a user's login session many programs use this variable to determine how to perform operations on the user's display such as moving the cursor and scrolling a region of text. programs with multilingual support use the lang variable to determine in which language to display system messages for programs that include multilingual support. the environment variable mechanism custom tailors the operating system on a per process basis rather than for the system as a whole. users can choose their own languages or select their own editors independently of one another. . . . process context the process identity and environment properties are usually set up when a process is created and not changed until that process exits. a process may choose to change some aspects of its identity if it needs to do so or it may alter its environment. in contrast process context is the state of the running program at any one time it changes constantly. process context includes the following parts. chapter the linux system 
 thus if clone is passed the flags clone fs cl ne vm clone sig and and clone files the parent and child tasks will share the same file system information such as the current working directory the same memory space the same signal handlers and the same set of open files. using clone in this fashion is equivalent to creating a thread in other systems since the parent task shares most of its resources with its child task. however if none of these flags is set when clone is invoked no sharing takes place resulting in functionality similar to the f ork system call. the lack of distinction between processes and threads is possible because linux does not hold a process's entire context within the main process data structure rather it holds the context within independent subcontexts. thus a process's file system context file descriptor table signal handler table and virtual memory context are held in separate data structures. the process data structure simply contains pointers to these other structures so any number of processes can easily share a subcontext by pointing to the same subcontext as appropriate. the arguments to the clone system call tell it which subcontexts to copy and which to share when it creates a new process. the new process always is given a new identity and a new scheduling context according to the arguments passed however it may either create new subcontext data structures initialized to be copies of the parent's or set up the new process to use the same subcontext data structures being used by the parent. the fork system call is nothing more than a special case of clone o that copies all subcontexts sharing none. . scheduling scheduling is the job of allocating cpu time to different tasks within an operating system. normally we think of scheduling as being the running and interrupting of processes but another aspect of scheduling is also important to linux the running of the various kernel tasks. kernel tasks encompass both tasks that are requested by a running process and tasks that execute internally on behalf of a device driver. . . process scheduling linux has two separate process scheduling algorithms. one is a time sharing algorithm for fair preemptive scheduling among multiple processes the other is designed for real time tasks where absolute priorities are more important than fairness. the scheduling algorithm used for routine time sharing tasks received a major overhaul with version . of the kernel. prior to version . the linux kernel ran a variation of the traditional unix scheduling algorithm. among other issues problems with the traditional unix scheduler are that it does not provide adequate support for smp systems and that it does not scale well as the number of tasks on the system grows. the overhaul of the scheduler with version . of the kernel now provides a scheduling algorithm that runs in constant time known as o l regardless of the number of tasks on the system. the new scheduler also provides increased support for smp including chapter the linux system numeric relative time priority priority quantum highest ms real time tasks other tasks lowest ms figure . the relationship between priorities and time slice length. processor affinity and load balancing as well as maintaining fairness and support for interactive tasks. the linux scheduler is a preemptive priority based algorithm with two separate priority ranges a real time range from to and a nice value ranging from to . these two ranges map into a global priority scheme whereby numerically lower values indicate higher priorities. unlike schedulers for many other systems linux assigns higher priority tasks longer time quanta and vice versa. because of the unique nature of the scheduler this is appropriate for linux as we shall soon see. the relationship between priorities and time slice length is shown in figure . . a runnable task is considered eligible for execution on the cpu so long as it has time remaining in its time slice. when a task has exhausted its time slice it is considered expired and is not eligible for execution again until all other tasks have also exhausted their time quanta. the kernel maintains a list of all runnable tasks in a runqueue data structure. because of its support for smp each processor maintains its own runqueue and schedules itself independently. each runqueue contains two priority arrays active and expired. the active array contains all tasks with time remaining in their time slices and the expired array contains all expired tasks. each of these priority arrays includes a list of tasks indexed according to priority figure . . the scheduler chooses the task with the highest priority from the active array for execution on the cpu. on multiprocessor machines this means that each processor is scheduling the highest priority task from its own runqueue structure. when all tasks have exhausted their time slices that is the active array is empty the two priority arrays are exchanged as the expired array becomes the active array and vice versa. tasks are assigned dynamic priorities that are based on the nice value plus or minus up to the value based upon the interactivity of the task. whether a value is added to or subtracted from a task's nice value depends on the interactivity of the task. a task's interactivity is determined by how long it has been sleeping while waiting for i o. tasks that are more interactive typically have longer sleep times and therefore are more likely to have an adjustment closer to as the scheduler favors such interactive tasks. conversely tasks with shorter sleep times are often more cpu bound and thus will have their priorities lowered. . scheduling active expired array array priority task lists priority task lists o o o o o okx o o o o figure . list of tasks indexed according to priority. the recalculation of a task's dynamic priority occurs when the task has exhausted its time quantum and is to be moved to the expired array. thus when the two arrays are exchanged all tasks in the new active array have been assigned new priorities and corresponding time slices. linux's real time scheduling is simpler still. linux implements the two realtime scheduling classes required by posix.lb first come first served fcfs and round robin sections . . and . . respectively . in both cases each process has a priority in addition to its scheduling class. processes of different priorities can compete with one another to some extent in time sharing scheduling in real time scheduling however the scheduler always runs the process with the highest priority. among processes of equal priority it runs the process that has been waiting longest. the only difference between fcfs and round robin scheduling is that fcfs processes continue to run until they either exit or block whereas a round robin process will be preempted after a while and will be moved to the end of the scheduling queue so round robin processes of equal priority will automatically time share among themselves. unlike routine time sharing tasks real time tasks are assigned static priorities. linux's real time scheduling is soft rather than hard real time. the scheduler offers strict guarantees about the relative priorities of real time processes but the kernel does not offer any guarantees about how quickly a real time process will be scheduled once that process becomes runnable. . . kernel synchronization the way the kernel schedules its own operations is fundamentally different from the way it schedules processes. a request for kernel mode execution can occur in two ways. a running program may request an operating system service either explicitly via a system call or implicitly for example when a page fault occurs. alternatively a device driver may deliver a hardware interrupt that causes the cpu to start executing a kernel defined handler for that interrupt. the problem posed to the kernel is that all these tasks may try to access the same internal data structures. if one kernel task is in the middle of accessing some data structure when an interrupt service routine executes then that service routine cannot access or modify the same data without risking data corruption. this fact relates to the idea of critical sections portions of code that access shared data and that must not be allowed to execute concurrently. as a result kernel synchronization involves much more than just process chapter the linux system scheduling. a framework is required that allows kernel tasks to run wfthout violating the integrity of shared data. prior to version . linux was a nonpreemptive kernel meaning that a process running in kernel mode could not be preempted even if a higherpriority process became available to run. with version . the linux kernel became fully preemptive so a task can now be preempted when it is running in the kernel. the linux kernel provides spinlocks and semaphores as well as readerwriter versions of these two locks for locking in the kernel. on smp machines the fundamental locking mechanism is a spinlock the kernel is designed so that the spinlock is held only for short durations. on single processor machines spinlocks are inappropriate for use and are replaced by enabling and disabling kernel preemption. that is on single processor machines rather than holding a spinlock the task disables kernel preemption. when the task would otherwise release the spinlock it enables kernel preemption. this pattern is summarized below single processor multiple processors disable kernel preemption. acquire spin lock. enable kernel preemption. release spin lock. linux uses an interesting approach to disable and enable kernel preemption. it provides two simple system calls preempt.disable and preempt .enable for disabling and enabling kernel preemption. however in addition the kernel is not preemptible if a kernel mode task is holding a lock. to enforce this rule each task in the system has a thread info structure that includes the field preempt count which is a counter indicating the number of locks being held by the task. when a lock is acquired preempt count is incremented. likewise it is decremented when a lock is released. if the value of preempt .count for the task currently running is greater than zero it is not safe to preempt the kernel as this task currently holds a lock. if the count is zero the kernel can safely be interrupted assuming there are no outstanding calls to preempt disable . spinlocks along with enabling and disabling kernel preemption are used in the kernel only when the lock is held for short durations. when a lock must be held for longer periods semaphores are used. the second protection technique that linux uses applies to critical sections that occur in interrupt service routines. the basic tool is the processor's interrupt control hardware. by disabling interrupts or using spinlocks during a critical section the kernel guarantees that it can proceed without the risk of concurrent access of shared data structures. however there is a penalty for disabling interrupts. on most hardware architectures interrupt enable and disable instructions are expensive. furthermore as long as interrupts remain disabled all i o is suspended and any device waiting for servicing will have to wait until interrupts are reenabled so performance degrades. the linux kernel uses a synchronization architecture that allows long critical sections to run for their entire duration without having interrupts disabled. this ability is especially useful in the networking code an . scheduling top half interrupt handlers bottom half interrupt handlers kernel system service routines preemptible user mode programs preemptible figure . interrupt protection levels. interrupt in a network device driver can signal the arrival of an entire network packet which may result in a great deal of code being executed to disassemble route and forward that packet within the interrupt service routine. linux implements this architecture by separating interrupt service routines into two sections the top half and the bottom half. the top half is a normal interrupt service routine and runs with recursive interrupts disabled interrupts of a higher priority may interrupt the routine but interrupts of the same or lower priority are disabled. the bottom half of a service routine is run with all interrupts enabled by a miniature scheduler that ensures that bottom halves never interrupt themselves. the bottom half scheduler is invoked automatically whenever an interrupt service routine exits. this separation means that the kernel can complete any complex processing that has to be done in response to an interrupt without worrying about being interrupted itself. if another interrupt occurs while a bottom half is executing then that interrupt can request that the same bottom half execute but the execution will be deferred until the one currently running completes. each execution of the bottom half can be interrupted by a top half but can never be interrupted by a similar bottom half. the top half bottom half architecture is completed by a mechanism for disabling selected bottom halves while executing normal foreground kernel code. the kernel can code critical sections easily using this system. interrupt handlers can code their critical sections as bottom halves and when the foreground kernel wants to enter a critical section it can disable any relevant bottom halves to prevent any other critical sections from interrupting it. at the end of the critical section the kernel can reenable the bottom halves and run any bottom half tasks that have been queued by top half interrupt service routines during the critical section. figure . summarizes the various levels of interrupt protection within the kernel. each level may be interrupted by code running at a higher level but will never be interrupted by code running at the same or a lower level except for user mode code user processes can always be preempted by another process when a time sharing scheduling interrupt occurs. . . symmetric multiprocessing the linux . kernel was the first stable linux kernel to support symmetric multiprocessor smp hardware allowing separate processes to execute in parallel on separate processors. originally the implementation of smp imposed chapter the linux system the restriction that only one processor at a time could be executing kernel anode code. in version . of the kernel a single kernel spinlock sometimes termed bkl for big kernel lock was created to allow multiple processes running on different processors to be active in the kernel concurrently. however the bkl provided a very coarse level of locking granularity. later releases of the kernel made the smp implementation more scalable by splitting this single kernel spinlock into multiple locks each of which protects only a small subset of the kernel's data structures. such spinlocks are described in section . . . the . kernel provided additional smp enhancements including processor affinity and load balancing algorithms
 to the user the i o system in linux looks much like that in any unix system. that is to the extent possible all device drivers appear as normal files. a user can open an access channel to a device in the same way she opens any . input and output user application i file system j . b!ock.. character network device file device file socket i o scheduler . . .. i i . ij protocol ji. .. . . i j driver l block scsi manager device s c s device character network dnver device device driver driver driver figure . device driver block structure. other file devices can appear as objects within the file system. the system administrator can create special files within a file system that contain references to a specific device driver and a user opening such a file will be able to read from and write to the device referenced. by using the normal file protection system which determines who can access which file the administrator can set access permissions for each device. linux splits all devices into three classes block devices character devices and network devices. figure . illustrates the overall structure of the device driver system. block devices include all devices that allow random access to completely independent fixed sized blocks of data including hard disks and floppy disks cd roms and flash memory. block devices are typically used to store file systems but direct access to a block device is also allowed so that programs can create and repair the file system that the device contains. applications can also access these block devices directly if they wish for example a database application may prefer to perform its own fine tuned laying out of data onto the disk rather than using the general purpose file system. character devices include most other devices such as mice and keyboards. the fundamental difference between block and character devices is random access block devices may be accessed randomly while character devices are only accessed serially. for example seeking to a certain position in a file might be supported for a dvd but makes no sense to a pointing device such as a mouse. network devices are dealt with differently from block and character devices. users cannot directly transfer data to network devices instead they must communicate indirectly by opening a connection to the kernel's networking subsystem. we discuss the interface to network devices separately in section . . . . block devices block devices provide the main interface to all disk devices in a system. performance is particularly important for disks and the block device system must provide functionality to ensure that disk access is as fast as possible. this functionality is achieved through the scheduling of i o operations. chapter the linux system in the context of block devices a block represents the unit with which the kernel performs i o. when a block is read into memory it is stored in a buffer. the request manager is the layer of software that manages the reading and writing of buffer contents to and from a block device driver. a separate list of requests is kept for each block device driver. traditionally these requests have been scheduled according to a unidirectional elevator c scan algorithm that exploits the order in which requests are inserted in and removed from the per device lists. the request lists are maintained in sorted order of increasing starting sector number. when a request is accepted for processing by a block device driver it is not removed from the list. it is removed only after the i o is complete at which point the driver continues with the next request in the list even if new requests have been inserted into the list before the active request. as new i o requests are made the request manager attempts to merge requests in the per device lists. the scheduling of i o operations changed somewhat with version . of the kernel. the fundamental problem with the elevator algorithm is that i o operations concentrated in a specific region of the disk can result in starvation of requests that need to occur in other regions of the disk. the deadline i o scheduler used in version . works similarly to the elevator algorithm except that it also associates a deadline with each request thus addressing the starvation issue. by default the deadline for read requests is . second and that for write requests is seconds. the deadline scheduler maintains a sorted queue of pending i o operations sorted by sector number. however it also maintains two other queues a read queue for read operations and a write queue for write operations. these two queues are ordered according to deadline. every i o request is placed in both the sorted queue and either the read or the write queue as appropriate. ordinarily i o operations occur from the sorted queue. however if a deadline expires for a request in either the read or the write queue i o operations are scheduled from the queue containing the expired request. this policy ensures that an i o operation will wait no longer than its expiration time. . . character devices a character device driver can be almost any device driver that does not offer random access to fixed blocks of data. any character device drivers registered to the linux kernel must also register a set of functions that implement the file i o operations that the driver can handle. the kernel performs almost no preprocessing of a file read or write request to a character device it simply passes the request to the device in question and lets the device deal with the request. the main exception to this rule is the special subset of character device drivers that implement terminal devices. the kernel maintains a standard interface to these drivers by means of a set of t t y s t r u c t structures. each of these structures provides buffering and flow control on the data stream from the terminal device and feeds those data to a line discipline. a line discipline is an interpreter for the information from the terminal device. the most common line discipline is the t t y discipline which glues the terminal's data stream onto the standard input and output streams of a user's running processes allowing those processes to communicate directly with the
 user's terminal. this job is complicated by the fact that several such processes may be running simultaneously and the t t y line discipline is responsible for attaching and detaching the terminal's input and output from the various processes connected to it as those processes are suspended or awakened by the user. other line disciplines also are implemented that have nothing to do with i o to a user process. the ppp and slip networking protocols are ways of encoding a networking connection over a terminal device such as a serial line. these protocols are implemented under linux as drivers that at one end appear to the terminal system as line disciplines and at the other end appear to the networking system as network device drivers. after one of these line disciplines has been enabled on a terminal device any data appearing on that terminal will be routed directly to the appropriate network device driver. . interprocess communication unix provides a rich environment for processes to communicate with each other. communication may be just a matter of letting another process know that some event has occurred or it may involve transferring data from one process to another. . . synchronization and signals the standard unix mechanism for informing a process that an event has occurred is the signal. signals canbe sent from any process to any other process with restrictions on signals sent to processes owned by another user. however a limited number of signals are available and they cannot carry information only the fact that a signal occurred is available to a process. signals are not generated only by processes. the kernel also generates signals internally for example it can send a signal to a server process when data arrive on a network channel to a parent process when a child terminates or to a waiting process when a timer expires. internally the linux kernel does not use signals to communicate with processes running in kernel mode. if a kernel mode process is expecting an event to occur it will not normally use signals to receive notification of that event. rather communication about incoming asynchronous events within the kernel is performed through the use of scheduling states and wait queue structures. these mechanisms allow kernel mode processes to inform one another about relevant events and they also allow events to be generated by device drivers or by the networking system. whenever a process wants to wait for some event to complete it places itself on a wait queue associated with that event and tells the scheduler that it is no longer eligible for execution. once the event has completed it will wake up every process on the wait queue. this procedure allows multiple processes to wait for a single event. for example if several processes are trying to read a file from a disk then they will all be awakened once the data have been read into memory successfully. although signals have always been the main mechanism for communicating asynchronous events among processes linux also implements the semaphore mechanism of system v unix. a process can wait on a semaphore chapter the linux system as easily as it can wait for a signal but semaphores have two advantages large numbers of semaphores can be shared among multiple independent processes and operations on multiple semaphores can be performed atomically. internally the standard linux wait queue mechanism synchronizes processes that are communicating with semaphores. . . passing of data among processes linux offers several mechanisms for passing data among processes. the standard unix pipe mechanism allows a child process to inherit a communication channel from its parent data written to one end of the pipe can be read at the other. under linux pipes appear as just another type of inode to virtual filesystem software and each pipe has a pair of wait queues to synchronize the reader and writer. unix also defines a set of networking facilities that can send streams of data to both local and remote processes. networking is covered in section . . two other methods of sharing data among processes are available. first shared memory offers an extremely fast way to communicate large or small amounts of data any data written by one process to a shared memory region can be read immediately by any other process that has mapped that region into its address space. the main disadvantage of shared memory is that on its own it offers no synchronization a process can neither ask the operating system whether a piece of shared memory has been written to nor suspend execution until such a write occurs. shared memory becomes particularly powerful when used in conjunction with another interprocess communication mechanism that provides the missing synchronization. a shared memory region in linux is a persistent object that can be created or deleted by processes. such an object is treated as though it were a small independent address space. the linux paging algorithms can elect to page out to disk shared memory pages just as they can page out a process's data pages. the shared memory object acts as a backing store for shared memory regions just as a file can act as a backing store for a memory mapped memory region. when a file is mapped into a virtual address space region then any page faults that occur cause the appropriate page of the file to be mapped into virtual memory. similarly shared memory mappings direct page faults to map in pages from a persistent shared memory object. also just as for files sharedmemory objects remember their contents even if no processes are currently mapping them into virtual memory
 networking is a key area of functionality for linux. not only does linux support the standard internet protocols used for most unix to unix communications but it also implements a number of protocols native to other non unix operating systems. in particular since linux was originally implemented primarily on pcs rather than on large workstations or on server class systems it supports many of the protocols typically used on pc networks such as appletalk and ipx. . network structure internally networking in the linux kernel is implemented by three layers of software . the socket interface . protocol drivers . network device drivers user applications perform all networking requests through the socket interface. this interface is designed to look like the . bsd socket layer so that any programs designed to make use of berkeley sockets will run on linux without any source code changes. this interface is described in section a. . . the bsd socket interface is sufficiently general to represent network addresses for a wide range of networking protocols. this single interface is used in linux to access not just those protocols implemented on standard bsd systems but all the protocols supported by the system. the next layer of software is the protocol stack which is similar in organization to bsd's own framework. whenever any networking data arrive at this layer either from an application's socket or from a network device driver the data are expected to have been tagged with an identifier specifying which network protocol they contain. protocols can communicate with one another if they desire for example within the internet protocol set separate protocols manage routing error reporting and reliable retransmission of lost data. the protocol layer may rewrite packets create new packets split or reassemble packets into fragments or simply discard incoming data. ultimately once it has finished processing a set of packets it passes them on up to the socket interface if the data are destined for a local connection or downward to a device driver if the packet needs to be transmitted remotely. the protocol layer decides to which socket or device to send the packet. all communication between the layers of the networking stack is performed by passing single skbuff structures. an skbuff contains a set of pointers into a single continuous area of memory representing a buffer inside which network packets can be constructed. the valid data in an skbuff do not need to start at the beginning of the skbuf f's buffer and they do not need to run to the end. the networking code can add data to or trim data from either end of the packet as long as the result still fits into the skbuff. this capacity is especially important on modern microprocessors where improvements in cpu speed have far outstripped the performance of main memory. the skbuff architecture allows flexibility in manipulating packet headers and checksums while avoiding any unnecessary data copying. the most important set of protocols in the linux networking system is the tcp ip protocol suite. this suite comprises a number of separate protocols. the ip protocol implements routing between different hosts anywhere on the network. on top of the routing protocol are built the udp tcp and icmp protocols. the udp protocol carries arbitrary individual datagrams between hosts. the tcp protocol implements reliable connections between hosts with guaranteed in order delivery of packets and automatic retransmission of lost data. the icmp protocol is used to carry various error and status messages between hosts. chapter the linux system packets skbuf fs arriving at the networking stack's protocol software are expected to be already tagged with an internal identifier indicating to which protocol the packet is relevant. different networking device drivers encode the protocol type in different ways over their communications media thus the protocol for incoming data must be identified in the device driver. the device driver uses a hash table of known networking protocol identifiers to look up the appropriate protocol and passes the packet to that protocol. new protocols can be added to the hash table as kernel loadable modules. incoming ip packets are delivered to the ip driver. the job of this layer is to perform routing. after deciding where the packet is destined it forwards the packet to the appropriate internal protocol driver to be delivered locally or injects it back into a selected network device driver queue to be forwarded to another host. it performs the routing decision using two tables the persistent forwarding information base fib and a cache of recent routing decisions. the fib holds routing configuration information and can specify routes based either on a specific destination address or on a wildcard representing multiple destinations. the fib is organized as a set of hash tables indexed by destination address the tables representing the most specific routes are always searched first. successful lookups from this table are added to the route caching table which caches routes only by specific destination no wildcards are stored in the cache so lookups can be made quickly. an entry in the route cache expires after a fixed period with no hits. at various stages the ip software passes packets to a separate section of code for firewall management selective filtering of packets according to arbitrary criteria usually for security purposes. the firewall manager maintains a number of separate firewall chains and allows an skbuf f to be matched against any chain. chains are reserved for separate purposes one is used for forwarded packets one for packets being input to this host and one for data generated at this host. each chain is held as an ordered list of rules where a rule specifies one of a number of possible firewall decision functions plus some arbitrary data to match against. two other functions performed by the ip driver are disassembly and reassembly of large packets. if an outgoing packet is too large to be queued to a device it is simply split up into smaller fragments which are all queued to the driver. at the receiving host these fragments must be reassembled. the ip driver maintains an ipf rag object for each fragment awaiting reassembly and an ipq for each datagram being assembled. incoming fragments are matched against each known ipq. if a match is found the fragment is added to it otherwise a new ipq is created. once the final fragment has arrived for a ipq a completely new skbuf f is constructed to hold the new packet and this packet is passed back into the ip driver. packets identified by the ip as destined for this host are passed on to one of the other protocol drivers. the udp and tcp protocols share a means of associating packets with source and destination sockets each connected pair of sockets is uniquely identified by its source and destination addresses and by the source and destination port numbers. the socket lists are linked onto hash tables keyed on these four address port values for socket lookup on incoming packets. the tcp protocol has to deal with unreliable connections so it maintains ordered lists of unacknowledged outgoing packets to retransmit
 after a timeout and of incoming out of order packets to be presented to the socket when the missing data have arrived. . security linux's security model is closely related to typical unix security mechanisms. the security concerns can be classified in two groups . authentication. making sure that nobody can access the system without first proving that she has entry rights . access control. providing a mechanism for checking whether a user has the right to access a certain object and preventing access to objects as required . . authentication authentication in unix has typically been performed through the use of a publicly readable password file. a user's password is combined with a random salt value and the result is encoded with a one way transformation function and stored in the password file. the use of the one way function means that the original password cannot be deduced from the password file except by trial and error. when a user presents a password to the system the password is recombined with the salt value stored in the password file and passed through the same one way transformation. if the result matches the contents of the password file then the password is accepted. historically unix implementations of this mechanism have had several problems. passwords were often limited to eight characters and the number of possible salt values was so low that an attacker could easily combine a dictionary of commonly used passwords with every possible salt value and have a good chance of matching one or more passwords in the password file gaining unauthorized access to any accounts compromised as a result. extensions to the password mechanism have been introduced that keep the encrypted password secret in a file that is not publicly readable that allow longer passwords or that use more secure methods of encoding the password. other authentication mechanisms have been introduced that limit the times during which a user is permitted to connect to the system or to distribute authentication information to all the related systems in a network. a new security mechanism has been developed by unix vendors to address authentication problems. the pluggable authentication modules pam system is based on a shared library that can be used by any system component that needs to authenticate users. an implementation of this system is available under linux. pam allows authentication modules to be loaded on demand as specified in a system wide configuration file. if a new authentication mechanism is added at a later date it can be added to the configuration file and all system components will immediately be able to take advantage of it. pam modules can specify authentication methods account restrictions sessionsetup functions and password changing functions so that when users change their passwords all the necessary authentication mechanisms can be updated at once . chapter the linux system . . access control access control under unix systems including linux is performed through the use of unique numeric identifiers. a user identifier uid identifies a single user or a single set of access rights. a group identifier gid is an extra identifier that can be used to identify rights belonging to more than one user. access control is applied to various objects in the system. every file available in the system is protected by the standard access control mechanism. in addition other shared objects such as shared memory sections and semaphores employ the same access system. every object in a unix system under user and group access control has a single uid and a single gid associated with it. user processes also have a single uid but they may have more than one gid. if a process's uid matches the uid of an object then the process has user rights or owner rights to that object. if the uids do not match but any of the process's gids match the object's gid then group rights are conferred otherwise the process has world rights to the object. linux performs access control by assigning objects a protection mask that specifies which access modes read write or execute are to be granted to processes with owner group or world access. thus the owner of an object might have full read write and execute access to a file other users in a certain group might be given read access but denied write access and everybody else might be given no access at all. the only exception is the privileged root uid. a process with this special uid is granted automatic access to any object in the system bypassing normal access checks. such processes are also granted permission to perform privileged operations such as reading any physical memory or opening reserved network sockets. this mechanism allows the kernel to prevent normal users from accessing these resources most of the kernel's key internal resources are implicitly owned by the root uid. linux implements the standard unix setuid mechanism described in section a. . . this mechanism allows a program to run with privileges different from those of the user running the program. for example the l p r program which submits a job onto a print queue has access to the system's print queues even if the user running that program does not. the unix implementation of s e t u i d distinguishes between a process's real and effective uid the real uid is that of the user running the program the effective uid is that of the file's owner. under linux this mechanism is augmented in two ways. first linux implements the posix specification's saved user id mechanism which allows a process to drop and reacquire its effective uid repeatedly. for security reasons a program may want to perform most of its operations in a safe mode waiving the privileges granted by its setuid status but may wish to perform selected operations with all its privileges. standard unix implementations achieve this capacity only by swapping the real and effective uids the previous effective uid is remembered but the program's real uid does not always correspond to the uid of the user running the program. saved uids allow a process to set its effective uid to its real uid and then back to the previous value of its effective uid without having to modify the real uid at any time. the second enhancement provided by linux is the addition of a process characteristic that grants just a subset of the rights of the effective uid. the
 fsuid and fsgid process properties are used when access rights are granted to files. the appropriate property is set every time the effective uid or gid is set. however the fsuid and fsgid can be set independently of the effective ids allowing a process to access files on behalf of another user without taking on the identity of that other user in any other way. specifically server processes can use this mechanism to serve files to a certain user without the process becoming vulnerable to being killed or suspended by that user. finally linux provides a mechanism for flexible passing of rights from one program to another a mechanism that has become common in modern versions of unix. when a local network socket has been set up between any two processes on the system either of those processes may send to the other process a file descriptor for one of its open files the other process receives a duplicate file descriptor for the same file. this mechanism allows a client to pass access to a single file selectively to some server process without granting that process any other privileges. for example it is no longer necessary for a print server to be able to read all the files of a user who submits a new print job the print client could simply pass the server file descriptors for any files to be printed denying the server access to any of the user's other files. . summary linux is a modern free operating system based on unix standards. it has been designed to run efficiently and reliably on common pc hardware it also runs on a variety of other platforms. it provides a programming interface and user interface compatible with standard unix systems and can run a large number of unix applications including an increasing number of commercially supported applications. linux has not evolved in a vacuum. a complete linux system includes many components that were developed independently of linux. the core linux operating system kernel is entirely original but it allows much existing free unix software to run resulting in an entire unix compatible operating system free from proprietary code. the linux kernel is implemented as a traditional monolithic kernel for performance reasons but it is modular enough in design to allow most drivers to be dynamically loaded and unloaded at run time. linux is a multiuser system providing protection between processes and running multiple processes according to a time sharing scheduler. newly created processes can share selective parts of their execution environment with their parent processes allowing multithreaded programming. interprocess communication is supported by both system v mechanisms message queues semaphores and shared memory and bsd's socket interface. multiple networking protocols can be accessed simultaneously through the socket interface. to the user the file system appears as a hierarchical directory tree that obeys unix semantics. internally linux uses an abstraction layer to manage multiple different file systems. device oriented networked and virtual file systems are supported. device oriented file systems access disk storage through a page cache that is unified with the virtual memory system. chapter the linux system the memory management system uses page sharing and copy on write to minimize the duplication of data shared by different processes. pages are loaded on demand when they are first referenced and are paged back out to backing store according to an lfu algorithm if physical memory needs to be reclaimed. exercises . what are the advantages and disadvantages of writing an operating system in a high level language such as c? . in what circumstances is the system call sequence f ork exec most appropriate? when is vforko preferable? . what socket type should be used to implement an intercomputer file transfer program? what type should be used for a program that periodically tests to see whether another computer is up on the netwrork? explain your answer. . linux runs on a variety of hardware platforms. what steps must the linux developers take to ensure that the system is portable to different processors and memory management architectures and to minimize the amount of architecture specific kernel code? . what are the advantages and disadvantages of making only some of the symbols defined inside a kernel accessible to a loadable kernel module? . what are the primary goals of the conflict resolution mechanism used by the linux kernel for loading kernel modules? . discuss how the clone operation supported by linux is used to support both processes and threads. . would one classify linux threads as user level threads or as kernel level threads? support your answer with the appropriate arguments. . what extra costs are incurred by the creation and scheduling of a process compared with the cost of a cloned thread? . the linux scheduler implements soft real time scheduling. what features necessary for certain real time programming tasks are missing? how might they be added to the kernel? . under what circumstances would an user process request an operation that results in the allocation of a demand zero memory region? . what scenarios would cause a page of memory to be mapped into an user program's address space with the copy on write attribute enabled? . in linux shared libraries perform many operations central to the operating system. what is the advantage of keeping this functionality out of the kernel? are there any drawbacks? explain your answer. . the directory structure of a linux operating system could comprise of files corresponding to different file systems including the linux proc bibliographical notes file system. what are the implications of having to support different file system types on the structure of the limix kernel? . in what ways does the linux setuid feature differ from the setuid feature in standard unix? . the linux source code is freely and widely available over the internet or from cd rom vendors. what are three implications of this availability for the security of the linux system? bibliographical notes the linux system is a product of the internet as a result much of the available documentation on linux is available in some form on the internet. the following key sites reference most of the useful information available the linux cross reference pages at http lxr.linux.no maintain current listings of the linux kernel browsable via the web and fully crossreferenced. linux hq at http www.linuxhq.com hosts a large amount of information relating to the linux .x kernels. this site also includes links to the home pages of most linux distributions as well as archives of the major mailing lists. the linux documentation project at http sunsite.unc.edu linux lists manybooks on linux that are available in source format as part of the linux documentation project. the project also hosts the linux how to guides which contain a series of hints and tips relating to aspects of linux. the kernel hackers' guide is an internet based guide to kernel internals in general. this constantly expanding site is located at http www.redhat.com hypernews get khg.html. the kernel newbies website http www.kernelnewbies.org provides a resource for introducing the linux kernel to newcomers. many mailing lists devoted to linux are also available. the most important are maintained by a mailing list manager that can be reached at the e mail address maj ordomoovger. rutgers . edu. send e mail to this address with the single line help in the mail's body for information on how to access the list server and to subscribe to any lists. finally the linux system itself can be obtained over the internet. complete linux distributions can be obtained from the home sites of the companies concerned and the linux community also maintains archives of current system components at several places on the internet. the most important are these ftp tsx ll.mit.edu pub linux ftp sunsite.unc.edu pub linux ftp linux .kernel. org pub linux in addition to investigating internet resources you can read about the internals of the linux kernel in bovet and cesati and love . mnc owsxp the microsoft
 operating system is a bit preemptive multitasking operating system for amd k k intel ia ia and later microprocessors. the successor to windows nt and windows windows xp is also intended to replace the windows operating system. key goals for the system are security reliability ease of use windows and posix application compatibility high performance extensibility portability and international support. in this chapter we discuss the key goals of windows xp the layered architecture of the system that makes it so easy to use the file system the networking features and the programming interface. objectives to explore the principles upon which windows xp is designed and the specific components involved in the system. to understand how windows xp can run programs designed for other operating systems. to provide a detailed explanation of the windows xp file system. to illustrate the networking protocols supported in windows xp. to cover the interface available to system and application programmers
 in the mid s microsoft and ibm cooperated to develop the os operating system which was written in assembly language for single processor intel systems. in microsoft decided to make a fresh start and to develop a new technology or nt portable operating system that supported both the os and posix application programming interfaces apis . in october dave cutler the architect of the dec vax vms operating system was hired and given the charter of building this new operating system. originally the team planned for nt to use the os api as its native environment but during development nt was changed to use the bit chapter windows xp windows api or win api reflecting the popularity of windows . . the first versions of nt were windows nt . and windows nt . advanced server. at that time bit windows was at version . . windows nt version . adopted the windows user interface and incorporated internet web server and web browser software. in addition user interface routines and all graphics code were moved into the kernel to improve performance with the side effect of decreased system reliability. although previous versions of nt had been ported to other microprocessor architectures the windows version released in february discontinued support for other than intel and compatible processors due to marketplace factors. windows incorporated significant changes over windows nt. it added active directory an x. based directory service better networking and laptop support support for plug and play devices a distributed file system and support for more processors and more memory. in october windows xp was released as both an update to the windows desktop operating system and a replacement for windows . in the server versions of windows xp became available called windows .net server . windows xp updates the graphical user interface gui with a visual design that takes advantage of more recent hardware advances and many new ease of use features. numerous features have been added to automatically repair problems in applications and the operating system itself. windows xp provides better networking and device experience including zero configuration wireless instant messaging streaming media and digital photography video dramatic performance improvements both for the desktop and large multiprocessors and better reliability and security than even windows . windows xp uses a client server architecture like mach to implement multiple operating system personalities such as win api and posix with user level processes called subsystems. the subsystem architecture allows enhancements to be made to one operating system personality without affecting the application compatibility of any others. windows xp is a multiuser operating system supporting simultaneous access through distributed services or through multiple instances of the graphical user interface via the windows terminal server. the server versions of windows xp support simultaneous terminal server sessions from windows desktop systems. the desktop versions of terminal server multiplex the keyboard mouse and monitor between virtual terminal sessions for each logged on user. this feature called fast user switching allows users to preempt each other at the console of a pc without having to log off and onto the system. windows xp is the first version of windows to ship a bit version. the native nt file system ntps and many of the win apis have always used bit integers where appropriate so the major extension to bit in windows xp is support for large addresses. there are two desktop versions of windows xp. windows xp professional is the premium desktop system for power users at work and at home. for home users migrating from windows window's xp personal provides the reliability and ease of use of windows xp but lacks the more advanced features needed to work seamlessly with active directory or rim posix applications. the members of the windows .net server family use the same core components as the desktop versions but add a range of features needed for
 uses such as webserver farms print file servers clustered systems and large datacenter machines. the large datacenter machines can have up to gb of memory and processors on ia systems and gb and processors on ia systems. . design principles microsoft's design goals for windows xp include security reliability windows and posix application compatibility high performance extensibility portability and international support. . . security windows xp security goals required more than just adherence to the design standards that enabled windows nt . to receive a c security classification from the u.s. government which signifies a moderate level of protection from defective software and malicious attacks . extensive code review and testing were combined with sophisticated automatic analysis tools to identify and investigate potential defects that might represent security vulnerabilities. . . reliability windows was the most reliable stable operating system microsoft had ever shipped to that point. much of this reliability came from maturity in the source code extensive stress testing of the system and automatic detection of many serious errors in drivers. the reliability requirements for windows xp were even more stringent. microsoft used extensive manual and automatic code review to identify over lines in the source files that might contain issues not detected by testing and then set about reviewing each area to verify that the code was indeed correct. windows xp extends driver verification to catch more subtle bugs improves the facilities for catching programming errors in user level code and subjects third party applications drivers and devices to a rigorous certification process. furthermore windows xp adds new facilities for monitoring the health of the pc including downloading fixes for problems before they are encountered by users. the perceived reliability of windows xp was also improved by making the graphical user interface easier to use through better visual design simpler menus and measured improvements in the ease with which users can discover how to perform common tasks. . . windows and posix application compatibility windows xp is not only an update of windows it is a replacement for windows . windows focused primarily on compatibility for business applications. the requirements for windows xp include a much higher compatibility with consumer applications that run on windows . application compatibility is difficult to achieve because each application checks for a particular version of windows may have some dependence on the chapter windows xp quirks of the implementation of apis may have latent application bugs that were masked in the previous system and so forth. windows xp introduces a compatibility layer that falls between applications and the win apis. this layer makes windows xp look almost bug for bug compatible with previous versions of windows. windows xp like earlier nt releases maintains support for running many bit applications using a thunking or conversion layer that translates bit api calls into equivalent bit calls. similarly the bit version of windows xp provides a thunking layer that translates bit api calls into native bit calls. posix support in windows xp is much improved. a new posix subsystem called interix is now available. most available unix compatible software compiles and runs under interix without modification. . . high performance windows xp is designed to provide high performance on desktop systems which are largely constrained by i o performance server systems where the cpu is often the bottleneck and large multithreaded and multiprocessor environments where locking and cache line management are key to scalability . high performance has been an increasingly important goal for windows xp. windows with sql on compaq hardware achieved top tpc c numbers at the time it shipped. to satisfy performance requirements nt uses a variety of techniques such as asynchronous i o optimized protocols for networks for example optimistic locking of distributed data batching of requests kernel based graphics and sophisticated caching of file system data. the memory management and synchronization algorithms are designed with an awareness of the performance considerations related to cache lines and multiprocessors. windows xp has further improved performance by reducing the code path length in critical functions using better algorithms and per processor data structures using memory coloring for numa non uniform memory access machines and implementing more scalable locking protocols such as queued spinlocks. the new locking protocols help reduce system bus cycles and include lock free lists and queues use of atomic read modify write operations like interlocked increment and other advanced locking techniques. the subsystems that constitute windows xp communicate with one another efficiently by a local procedure call lpc facility that provides highperformance message passing. except while executing in the kernel dispatcher threads in the subsystems of windows xp can be preempted by higher priority threads. thus the system responds quickly to external events. in addition windows xp is designed for symmetrical multiprocessing on a multiprocessor computer several threads can run at the same time. . . extensibility extensibility refers to the capacity of an operating system to keep up with advances in computing technology. so that changes over time are facilitated the developers implemented windows xp using a layered architecture. the windows xp executive runs in kernel or protected mode and provides the basic system services. on top of the executive several server subsystems operate in user mode. among them are environmental subsystems that emulate
 different operating systems. thus programs written for ms dos microsoft windows and posix all run on windows xp in the appropriate environment. see section . for more information on environmental subsystems. because of the modular structure additional environmental subsystems can be added without affecting the executive. in addition windows xp uses loadable drivers in the i o system so new file systems new kinds of i o devices and new kinds of networking can be added while the system is running. windows xp uses a client server model like the mach operating system and supports distributed processing by remote procedure calls rpcs as defined by the open software foundation. . . portability an operating system is portable if it can be moved from one hardware architecture to another with relatively few changes. windows xp is designed to be portable. as is true of the unix operating system the majority of the system is written in c and c . most processor dependent code is isolated in a dynamic link library dll called the hardware abstraction layer hal . a dll is a file that is mapped into a process's address space such that any functions in the dll appear to be part of the process. the upper layers of the windows xp kernel depend on the hal interfaces rather than on the underlying hardware bolstering windows xp portability. the hal manipulates hardware directly isolating the rest of windows xp from hardware differences among the platforms on which it runs. although for market reasons windows shipped only on intel ia compatible platforms it was also tested on ia and dec alpha platforms until just prior to release to ensure portability. windows xp runs on ia compatible and ia processors. microsoft recognizes the importance of multiplatform development and testing since as a practical matter maintaining portability is a matter of use it or lose it. . . international support windows xp is also designed for international and multinational use. it provides support for different locales via the national language support nls api. the nls api provides specialized routines to format dates time and money in accordance with various national customs. string comparisons are specialized to account for varying character sets. unicode is windows xp's native character code. windows xp supports ansi characters by converting them to unicode characters before manipulating them bit to bit conversion . system text strings are kept in resource files that can be replaced to localize the system for different languages. multiple locales can be used concurrently which is important to multilingual individuals and businesses. . system components the architecture of windows xp is a layered system of modules as shown in figure . . the main layers are the hal the kernel and the executive all of which run in protected mode and a collection of subsystems and services that run in user mode. the user mode subsystems fall into two categories chapter windows xp logon wini ms dos process applications applications applications i applications appticamons security. winw ms dos bqsu subsystem subsystem vom o vfdm security account manager database executive i o manager local object security ! process plug and virtual procedure file system manager reference manager play memory call window cache monitor manager manager facility manager device drivers kernel graphic n networ device drivers drivers hardware abstraction layer hardware figure . windows xp block diagram. the environmental subsystems which emulate different operating systems and the protection subsystems which provide security functions. one of the chief advantages of this type of architecture is that interactions between modules are kept simple. the remainder of this section describes these layers and subsystems. . . hardware abstraction layer the hal is the layer of software that hides hardware differences from upper levels of the operating system to help make windows xp portable. the hal exports a virtual machine interface that is used by the kernel dispatcher the executive and the device drivers. one advantage of this approach is that only a single version of each device driver is required it runs on all hardware platforms without porting the driver code. the hal also provides support for symmetric multiprocessing. device drivers map devices and access them directly but the administrative details of mapping memory configuring i o buses setting up dma and coping with motherboard specific facilities are all provided by the hal interfaces. . . kernel the kernel of windows xp provides the foundation for the executive and the subsystems. the kernel remains in memory and its execution is never . system components preempted. it has four main responsibilities thread scheduling interrupt and exception handling low level processor synchronization and recovery after a power failure. the kernel is object oriented. an object type in windows is a systemdefined data type that has a set of attributes data values and a set of methods for example functions or operations . an object is an instance of an object type. the kernel performs its job by using a set of kernel objects whose attributes store the kernel data and whose methods perform the kernel activities. . . . kernel dispatcher the kernel dispatcher provides the foundation for the executive and the subsystems. most of the dispatcher is never paged out of memory and its execution is never preempted. its main responsibilities are thread scheduling implementation of synchronization primitives timer management software interrupts asynchronous and deferred procedure calls and exception dispatching. . . . threads and scheduling like many other modern operating systems windows xp uses processes and threads for executable code. the process has a virtual memory address space and information used to initialize each thread such as a base priority and an affinity for either one or more processors. each process has one or more threads each of which is an executable unit dispatched by the kernel. each thread has its own scheduling state including actual priority processor affinity and cpu usage information. the six possible thread states are ready standby running waiting transition and terminated. ready indicates that the thread is waiting to run. the highest priority ready thread is moved to the standby state which means it is the next thread to run. in a multiprocessor system each process keeps one thread in a standby state. a thread is running when it is executing on a processor. it runs until it is preempted by a higher priority thread until it terminates until its allotted exectition time quantum ends or until it blocks on a dispatcher object such as an event signaling i o completion. a thread is in the waiting state when it is waiting for a dispatcher object to be signaled. a new thread is in the transition state while it waits for resources necessary for execution. a thread enters the terminated state when it finishes execution. the dispatcher uses a level priority scheme to determine the order of thread execution. priorities are divided into two classes variable class and real time class. the variable class contains threads having priorities from to and the real time class contains threads with priorities ranging from to . the dispatcher uses a queue for each scheduling priority and traverses the set of queues from highest to lowest until it finds a thread that is ready to run. if a thread has a particular processor affinity but that processor is not available the dispatcher skips past it and continues looking for a ready thread that is willing to run on the available processor. if no ready thread is found the dispatcher executes a special thread called the idle thread. when a thread's time quantum runs out the clock interrupt queues a quantum end deferred procedure call dpc to the processor in order to reschedule the processor. if the preempted thread is in the variable priority class its priority is lowered. the priority is never lowered below the base chapter windows xp priority. lowering the thread's priority tends to limit the cpu consumption of compute bound threads. when a variable priority thread is released from a wait operation the dispatcher boosts the priority. the amount of the boost depends on the device for which the thread was waiting for example a thread waiting for keyboard i o would get a large priority increase whereas a thread waiting for a disk operation would get a moderate one. this strategy tends to give good response times to interactive threads using a mouse and windows. it also enables i o bound threads to keep the i o devices busy while permitting compute bound threads to use spare cpu cycles in the background. this strategy is used by several time sharing operating systems including unix. in addition the thread associated with the user's active gui window receives a priority boost to enhance its response time. scheduling occurs when a thread enters the ready or wait state when a thread terminates or when an application changes a thread's priority or processor affinity if a higher priority real time thread becomes ready while a lower priority thread is running the lower priority thread is preempted. this preemption gives a real time thread preferential access to the cpu when the thread needs such access. windows xp is not a hard real time operating system however because it does not guarantee that a real time thread will start to execute within a particular time limit. . . . implementation of synchronization primitives key operating system data structures are managed as objects using common facilities for allocation reference counting and security. dispatcher objects control dispatching and synchronization in the system. examples of these objects are events mutants mutexes semaphores processes threads and timers. the event object is used to record an event occurrence and to synchronize the latter with some action. notification events signal all waiting threads and synchronization events signal a single waiting thread. the mutant provides kernel mode or user mode mutual exclusion with the notion of ownership. the mutex available only in kernel mode provides deadlock free mutual exclusion. a semaphore object acts as a counter or gate to control the number of threads that access a resource. the thread object is the entity that is scheduled by the kernel dispatcher and is associated with a process object which encapsulates a virtual address space. timer objects are used to keep track of time and to signal timeouts when operations take too long and need to be interrupted or when a periodic activity needs to be scheduled. many of the dispatcher objects are accessed from user mode via an open operation that returns a handle. the user mode code polls and or waits on handles to synchronize with other threads as well as the operating system see section . . . . . . software interrupts asynchronous and deferred procedure calls the dispatcher implements two types of software interrupts asynchronous procedure calls and deferred procedure calls. asynchronous procedure calls apcs break into an executing thread and call a procedure. apcs are used to begin execution of a new thread terminate processes and deliver notification that an asynchronous i o has completed. apcs are queued to specific threads . system components and allow the system to execute both system and user code within a process's context. deferred procedure calls dpcs are used to postpone interrupt processing. after handling all blocked device interrupt processes the interrupt service routine isr schedules the remaining processing by queuing a dpc. the dispatcher schedules software interrupts at a lower priority than the device interrupts so that dpcs do not block other isrs. in addition to deferring deviceinterrupt processing the dispatcher uses dpcs to process timer expirations and to preempt thread execution at the end of the scheduling quantum. execution of dpcs prevents threads from being scheduled on the current processor and also keeps apcs from signaling the completion of i o. this is done so that dpc routines do not take an extended amount of time to complete. as an alternative the dispatcher maintains a pool of worker threads. isrs and dpcs queue work items to the worker threads. dpc routines are restricted so that they cannot take page faults call system services or take any other action that might possibly result in an attempt to block execution on a dispatcher object. unlike apcs dpc routines make no assumptions about what process context the processor is executing. . . . exceptions and interrupts the kernel dispatcher also provides trap handling for exceptions and interrupts generated by hardware or software. windows xp defines several architectureindependent exceptions including memory access violation integer overflow floating point overflow or underflow integer divide by zero floating point divide by zero illegal instruction data misalignment privileged instruction page read error access violation paging file quota exceeded debugger breakpoint debugger single step the trap handlers deal with simple exceptions. elaborate exception handling is performed by the kernel's exception dispatcher. the exception dispatcher creates an exception record containing the reason for the exception and finds an exception handler to deal with it. when an exception occurs in kernel mode the exception dispatcher simply calls a routine to locate the exception handler. if no handler is found a fatal chapter windows xp system error occurs and the user is left with the infamous blue screen of death that signifies system failure. exception handling is more complex for user mode processes because an environmental subsystem such as the posix system sets up a debugger port and an exception port for every process it creates. if a debugger port is registered the exception handler sends the exception to the port. if the debugger port is not found or does not handle that exception the dispatcher attempts to find an appropriate exception handler. if no handler is found the debugger is called again to catch the error for debugging. if no debugger is running a message is sent to the process's exception port to give the environmental subsystem a chance to translate the exception. for example the posix environment translates windows xp exception messages into posix signals before sending them to the thread that caused the exception. finally if nothing else works the kernel simply terminates the process containing the thread that caused the exception. the interrupt dispatcher in the kernel handles interrupts by calling either an interrupt service routine isr supplied by a device driver or a kernel trap handler routine. the interrupt is represented by an interrupt object that contains all the information needed to handle the interrupt. using an interrupt object makes it easy to associate interrupt service routines with an interrupt without having to access the interrupt hardware directly. different processor architectures such as intel and dec alpha have different types and numbers of interrupts. for portability the interrupt dispatcher maps the hardware interrupts into a standard set. the interrupts are prioritized and are serviced in priority order. there are interrupt request levels irqls in windows xp. eight are reserved for use by the kernel the remaining represent hardware interrupts via the hal although most ia systems use only . the windows xp interrupts are defined in figure . . the kernel uses an interrupt dispatch table to bind each interrupt level to a service routine. in a multiprocessor computer windows xp keeps a separate interrupt dispatch table for each processor and each processor's irql can be set independently to mask out interrupts. all interrupts that occur at a level equal to or less than the irql of a processor are blocked until the irql is lowered by a interrupt levels types of interrupts machine check or bus error power fail interprocessor notification request another processor to act e.g. dispatch a process or update the tlb clock used to keep track of time profile traditional pc irq hardware interrupts dispatch and deferred procedure call dpc kernel asynchronous procedure call apc passive figure . windows xp interrupt request levels. . system components kernel level thread or by an sr returning from interrupt processing. windows xp takes advantage of this property and uses software interrupts to deliver apcs and dpcs to perform system functions such as synchronizing threads with i o completion to start thread dispatches and to handle timers. . . executive the windows xp executive provides a set of services that all environmental subsystems use. the services are grouped as follows object manager virtual memory manager process manager local procedure call facility i o manager cache manager security reference monitor plug and play and security managers registry and booting. . . . object manager for managing kernel mode entities windows xp uses a generic set of interfaces that are manipulated by user mode programs. windows xp calls these entities objects and the executive component that manipulates them is the object manager. each process has an object table containing entries that track the objects used by the process. user mode code accesses these objects using an opaque value called a handle that is returned by many apis. object handles can also be created by duplicating an existing handle either from the same process or a different process. examples of objects are semaphores mutexes events processes and threads. these are all dispatcher objects. threads can block in the kernel dispatcher waiting for any of these objects to be signaled. the process thread and virtual memory apis use process and thread handles to identify the process or thread to be operated on. other examples of objects include files sections ports and various internal i o objects. file objects are vised to maintain the open state of files and devices. sections are used to map files. open files are described in terms of file objects. local communication endpoints are implemented as port objects. the object manager maintains the windows xp internal name space. in contrast to unix which roots the system name space in the file system windows xp uses an abstract name space and connects the file systems as devices. the object manager provides interfaces for defining both object types and object instances translating names to objects maintaining the abstract name space through internal directories and symbolic links and managing object creation and deletion. objects are typically managed using reference counts in protected mode code and handles in user mode code. however some kernelmode components use the same apis as user mode code and thus use handles to manipulate objects. if a handle needs to exist beyond the lifetime of the current process it is marked as a kernel handle and stored in the object table for the system process. the abstract name space does not persist across reboots but is built up from configuration information stored in the system registry plug and play device discovery and creation of objects by system components. the windows xp executive allows any object to be given a name. one process may create a named object while a second process opens a handle to the object and shares it with the first process. processes can also share objects by duplicating handles between processes in which case the objects need not be named. chapter windows xp a name can be either permanent or temporary. a permanent 'name represents an entity such as a disk drive that remains even if no process is accessing it. a temporary name exists only while a process holds a handle to the object. object names are structured like file path names in ms dos and unix. name space directories are represented by a directory object that contains the names of all the objects in the directory. the object name space is extended by the addition of device objects representing volumes containing file systems. objects are manipulated by a set of virtual functions with implementations provided for each object type create open close delete qiieryjname parse and s e c u r i t y . the latter three objects need explanation query name is called when a thread has a reference to an object but wants to know the object's name. parse is used by the object manager to search for an object given the object's name. s e c u r i t y is called to make security checks on all object operations such as when a process opens or closes an object makes changes to the security descriptor or duplicates a handle for an object. the parse procedure is used to extend the abstract name space to include files. the translation of a path name to a file object begins at the root of the abstract name space. path name components are separated by whack characters ' ' rather than the slashes ' ' used in unix. each component is looked up in the current parse directory of the name space. internal nodes within the name space are either directories or symbolic links. if a leaf object is found and there are no path name components remaining the leaf object is returned. otherwise the leaf object's parse procedure is invoked with the remaining path name. parse procedures are only used with a small number of objects belonging to the windows gui the configuration manager registry and most notably device objects representing file systems. the parse procedure for the device object type allocates a file object and initiates an open or create i o operation on the file system. if successful the file object fields are filled in to describe the file. in summary the path name to a file is used to traverse the object manager namespace translating the original absolute path name into a device object relative path name pair. this pair is then passed to the file system via the i o manager which fills in the file object. the file object itself has no name but is referred to by a handle. unix file systems have symbolic links that permit multiple nicknames or aliases for the same file. the symbolic link object implemented by the windows xp object manager is used within the abstract name space not to provide files aliases on a file system. even so symbolic links are very useful. they are used to organize the name space similar to the organization of the devices directory in unix. they are also used to map standard ms dos drive letters to drive names. drive letters are symbolic links that can be remapped to suit the convenience of the user or administrator. . system components drive letters are one place where the abstract name space in windows xp is not global. each logged on user has his or her own set of drive letters so that users can avoid interfering with one another. in contrast terminal server sessions share all processes within a session. basenamedobjects contain the named objects created by most applications. although the name space is not directly visible across a network the object manager's parse method is used to help access a named object on another system. when a process attempts to open an object that resides on a remote computer the object manager calls the parse method for the device object corresponding to a network redirector. this results in an i o operation that accesses the file across the network. objects are instances of an object type. the object type specifies how instances are to be allocated the definitions of the data fields and the implementation of the standard set of virtual functions used for all objects. these functions implement operations such as mapping names to objects closing and deleting and applying security. the object manager keeps track of two counts for each object. the pointer count is the number of distinct references made to an object. protected mode code that refers to objects must keep a reference on the object to ensure that the object is not deleted while in use. the handle count is the number of handle table entries referring to an object. each handle is also reflected in the reference count. when a handle for an object is closed the object's close routine is called. in the case of file objects this call causes the i o manager to do a cleanup operation at the close of the last handle. the cleanup operation tells the file system that the file is no longer accessed by user mode so that sharing restrictions range locks and other states specific to the corresponding open routine can be removed. each handle close removes a reference from the pointer count but internal system components may retain additional references. when the final reference is removed the object's delete procedure is called. again using file objects as an example the delete procedure causes the i o manager to send the file system a close operation on the file object. this causes the file system to deallocate any internal data structures that were allocated for the file object. after the delete procedure for a temporary object completes the object is deleted from memory. objects can be made permanent at least with respect to the current boot of the system by asking the object manager to take an extra reference against the object. thus permanent objects are not deleted even when the last reference outside the object manager is removed. when a permanent object is made temporary again the object manager removes the extra reference. if this was the last reference the object is deleted. permanent objects are rare used mostly for devices drive letter mappings and the directory and symbolic link objects. the job of the object manager is to supervise the use of all managed objects. when a thread wants to use an object it calls the object manager's open method to get a reference to the object. if the object is being opened from a user mode api the reference is inserted into the process's object table and a handle is returned. a process gets a handle by creating an object by opening an existing object by receiving a duplicated handle from another process or by inheriting a handle from a parent process similar to the way a unix process gets a file chapter windows xp descriptor. these handles are all stored in the process's object table. an entry in the object table contains the object's access rights and states whether the handle should be inherited by child processes. when a process terminates windows xp automatically closes all the process's open handles. handles are a standardized interface to all kinds of objects. like a file descriptor in unix an object handle is an identifier unique to a process that confers the ability to access and manipulate a system resource. handles can be duplicated within a process or between processes. the latter case is used when child processes are created and when out of process execution contexts are implemented. since the object manager is the only entity that generates object handles it is the natural place to check security. the object manager checks whether a process has the right to access an object when the process tries to open the object. the object manager also enforces quotas such as the maximum amount of memory a process may use by charging a process for the memory occupied by all its referenced objects and refusing to allocate more memory when the accumulated charges exceed the process's quota. when the login process authenticates a user an access token is attached to the user's process. the access token contains information such as the security id group ids privileges primary group and default access control list. the services and objects a user can access are determined by these attributes. the token that controls access is associated with the thread making the access. normally the thread token is missing and defaults to the process token but services often need to execute code on behalf of their client. windows xp allows threads to impersonate temporarily by using a client's token. thus the thread token is not necessarily the same as the process token. in windows xp each object is protected by an access control list that contains the security ids and access rights granted. when a thread attempts to access an object the system compares the security id in the thread's access token with the object's access control list to determine whether access should be permitted. the check is performed only when an object is opened so it is not possible to deny access after the open occurs. operating system components executing in kernel mode bypass the access check since kernel mode code is assumed to be trusted. therefore kernel mode code must avoid security vulnerabilities such as leaving checks disabled while creating a user modeaccessible handle in an untrusted process. generally the creator of the object determines the access control list for the object. if none is explicitly supplied one may be set to a default by the object type's open routine or a default list may be obtained from the user's access token object. the access token has a field that controls auditing of object accesses. operations that are being audited are logged to the system's security log with an identification of the user. an administrator monitors this log to discover attempts to break into the system or to access protected objects. . . . virtual memory manager the executive component that manages the virtual address space physical memory allocation and paging is the virtual memory vm manager. the design of the vm manager assumes that the underlying hardware supports . system components virtual to physical mapping a paging mechanism and transparent cache coherence on multiprocessor systems as well as allowing multiple page table entries to map to the same physical page frame. the vm manager in windows xp uses a page based management scheme with a page size of kb on ia compatible processors and kb on the ia . pages of data allocated to a process that are not in physical memory are either stored in the paging files on disk or mapped directly to a regular file on a local or remote file system. pages can also be marked zero fill on demand which fills the page with zeros before being allocated thus erasing the previous contents. on ia processors each process has a gb virtual address space. the upper gb are mostly identical for all processes and are used by windows xp in kernel mode to access the operating system code and data structures. key areas of the kernel mode region that are not identical for all processes are the page table self map hyperspace and session space. the hardware references a process's page tables using physical page frame numbers. the vm manager maps the page tables into a single mb region in the process's address space so they are accessed through virtual addresses. hyperspace maps the current process's working set information into the kernel mode address space. session space is used to share the win and other session specific drivers among all the processes in the same terminal server session rather than all the processes in the system. the lower gb are specific to each process and are accessible by both user and kernel mode threads. certain configurations of windows xp reserve only gb for operating system use allowing a process to use gb of address space. running the system in gb mode drastically reduces the amount of data caching in the kernel. however for large applications that manage their own i o such as sql databases the advantage of a larger user mode address space may be worth the loss of caching. the windows xp vm manager uses a two step process to allocate user memory. the first step reserves a portion of the process's virtual address space. the second step commits the allocation by assigning virtual memory space physical memory or space in the paging files . windows xp limits the amount of virtual memory space a process consumes by enforcing a quota on committed memory. a process decommits memory that it is no longer using to free up virtual memory for use by other processes. the apis used to reserve virtual addresses and commit virtual memory take a handle on a process object as a parameter. this allows one process to control the virtual memory of another. environmental subsystems manage the memory of their client processes in this way. for performance the vm manager allows a privileged process to lock selected pages in physical memory thus ensuring that the pages are not paged out to the paging file. processes also allocate raw physical memory and then map regions into its virtual address space. ia processors with the physical address extension pae feature can have up to gb of physical memory on a system. this memory cannot all be mapped in a process's address space at once but windows xp makes it available using the address windowing extension awe apis which allocate physical memory and then map regions of virtual addresses in the process's address space onto part of the physical memory. the awe facility is used primarily by very large applications such as the sql database. chapter windows xp windows xp implements shared memory by defining a section dbject. after getting a handle to a section object a process maps the memory portion it needs into its address space. this portion is called a view. a process redefines its view of an object to gain access to the entire object one region at a time. a process can control the use of a shared memory section object in many ways. the maximum size of a section can be bounded. the section can be backed by disk space either in the system paging file or in a regular file a memory mapped file . a section can be based meaning the section appears at the same virtual address for all processes attempting to access it. finally the memory protection of pages in the section can be set to read only read write read write execute execute only no access or copy on write. the last two of these protection settings need some explanation a no access page raises an exception if accessed the exception is used for example to check whether a faulty program iterates beyond the end of an array. both the user mode memory allocator and the special kernel allocator used by the device verifier can be configured to map each allocation onto the end of a page followed by a no access page in order to detect buffer overruns. the copy on write mechanism increases the efficient use of physical memory by the vm manager. when two processes want independent copies of an object the vm manager places a single shared copy into virtual memory and activates the copy on write property for that region of memory. if one of the processes tries to modify data in a copy on write page the vm manager makes a private copy of the page for the process. the virtual address translation in windows xp uses a multilevel page table. for ia processors without the physical address extensions enabled page p gedirectory diregibiiy directory entry ..y .. . . f. entry page page page page page pagetabte tabled table table table table entry entry entry entry k k k k page page page page figure . page table layout. . system components each process has a page directory that contains page directory entries pdes of size bytes. each pde points to a page table that contains page table entries ptes of size bytes. each pte points to a kb page frame in physical memory. the total size of all page tables for a process is mb so the vm manager pages out individual tables to disk when necessary. see figure . for a diagram of this structure. the page directory and page tables are referenced by the hardware via physical addresses. to improve performance the vm manager self maps the page directory and page tables into a mb region of virtual addresses. the self map allows the vm manager to translate a virtual address into the corresponding pde or pte without additional memory accesses. when a process context is changed a single page directory entry needs to be changed to map the new process's page tables. for a variety of reasons the hardware requires that each page directory or page table occupy a single page. thus the number of pdes or ptes that fit in a page determine how virtual addresses are translated. the following describes how virtual addresses are translated into physical addresses on ia compatible processors without pae enabled . a bit value can represent all the values from to . thus a bit value can select any entry in the page directory or in a page table. this property is used when a virtual address pointer is translated to a byte address in physical memory. a bit virtual memory address is split into three values as shown in figure . . the first bits of the virtual address are used as an index into the page directory. this address selects one page directory entry pde which contains the physical page frame of a page table. the memory management unit mmu uses the next bits of the virtual address to select a pte from the page table. the pte specifies a page frame in physical memory. the remaining bits of the virtual address are the offset of a specific byte in the page frame. the mmu creates a pointer to the specific byte in physical memory by concatenating the bits from the pte with the lower bits from the virtual address. thus the bit pte has bits to describe the state of the physical page. the ia hardware reserves bits for use by the operating system. the rest of the bits specify whether the page has been accessed or written the caching attributes the access mode whether the page is global and whether the pte is valid. a processors running with pae enabled use bit pdes and ptes in order to represent the larger bit page frame number field. thus the secondlevel page directories and the page tables contain only pdes and ptes respectively. to provide gb of virtual address space requires an extra level of page directory containing four pdes. translation of a bit virtual address uses bits for the top level directory index and bits for each of the second level page directories and the page tables. pde pte page offset figure . virtual to physical address translation on ia . chapter windows xp to avoid the overhead of translating every virtual address by looking up the pde and pte processors use a translation lookaside buffer tlb which contains an associative memory cache for mapping virtual pages to ptes. unlike the ia architecture in which the tlb is maintained by the hardware mmu the ia invokes a software trap routine to supply translations missing from the tlb. this gives the vm manager flexibility in choosing the data structures to use. in windows xp a three level tree structure is chosen for mapping user mode virtual addresses on the ia . on ia processors the page size is kb but the ptes occupy bits so a page still contains only bits' worth of pdes or ptes. therefore with bits of top level pdes bits of second level bits of page table and bits of page offset the user portion of the process's virtual address space for windows xp on the ia is tb bits' worth . the tb limitation in the current version of windows xp is less than the capabilities of the ia processor but represents a tradeoff between the number of memory references required to handle tlb misses and the size of the user mode address space supported. a physical page can be in one of six states valid free zeroed modified standby bad or in transition. a valid page is in use by an active process. a free page is a page that is not referenced in a pte. a zeroed page is a free page that has been zeroed out and is ready for immediate use to satisfy zero on demand faults. a modified page is one that has been written by a process and must be sent to the disk before it is allocated for another process. a standby page is a copy of information already stored on disk. standby pages can be pages that were not modified modified pages that have already been written to the disk or pages that were prefetched to exploit locality. a bad page is unusable because a hardware error has been detected. finally a transition page is one that is on its way in from disk to a page frame allocated in physical memory. when the valid bit in a pte is zero the vm manager defines the format of the other bits. invalid pages can have a number of states represented by bits in the pte. page file pages that have never been faulted in are marked zero ondemand. files mapped through section objects encode a pointer to that section object. pages that have been written to the page file contain enough information to find the page on disk and so forth. the actual structure of the page file pte is shown in figure . . the pte contains bits for page protection bits for page file offset bits to select the paging file and bits that describe the page state. a page file pte is marked to be an invalid virtual address to the mmu. since executable code and memorymapped files already have a copy on disk they do not need space in a paging file. if one of these pages is not in physical memory the pte structure is as follows the most significant bit is used to specify the page protection the next . system components ! piagie address j p protection page v file i i ! figure . page file page table entry. the valid bit is zero. bits are used to index into a system data structure that indicates a file and offset within the file for the page and the lower bits specify the page state. invalid virtual addresses can also be in a number of temporary states that are part of the paging algorithms. when a page is removed from a process working set it is moved either to the modified list to be written to disk or directly to the standby list. if written to the standby list the page is reclaimed without being read from disk if it is needed again before it is moved to the free list. when possible the vm manager uses idle cpu cycles to zero pages on the free list and move them to the zeroed list. transition pages have been allocated a physical page and are awaiting the completion of the paging i o before the pte is marked as valid. windows xp uses section objects to describe pages that are sharable between processes. each process has its own set of virtual page tables but the section object also includes a set of page tables containing the master or prototype ptes. when a pte in a process page table is marked valid it points to the physical page frame containing the page as it must on ia processors where the hardware mmu reads the page tables directly from memory. but when a shared page is made invalid the pte is edited to point to the prototype pte associated with the section object. the page tables associated with a section object are virtual insofar as they are created and trimmed as needed. the only prototype ptes needed are those that describe pages for which there is a currently mapped view. this greatly improves performance and allows more efficient use of kernel virtual addresses. the prototype pte contains the page frame address and the protection and state bits. thus the first access by a process to a shared page generates a page fault. after the first access further accesses are performed in the normal manner. if a process writes to a copy on write page marked read only in the pte the vm manager makes a copy of the page and marks the pte writable and the process effectively does not have a shared page any longer. shared pages never appear in the page file but are instead found in the file system. the vm manager keeps track of all pages of physical memory in a pageframe database. there is one entry for every page of physical memory in the system. the entry points to the pte which in turn points to the page frame so the vm manager can maintain the state of the page. page frames not referenced by a valid pte are linked to lists according to page type such as zeroed modified or free. if a shared physical page is marked as valid for any process the page cannot be removed from memory. the vm manager keeps a count of valid ptes for each page in the page frame database. when the count goes to zero the chapter windows xp physical page can be reused once its contents have been written back tb disk if it was marked dirty . when a page fault occurs the vm manager finds a physical page to hold the data. for zero on demand pages the first choice is to find a page that has already been zeroed. if none is available a page from the free list or standby list is chosen and the page is zeroed before proceeding. if the faulted page has been marked as in transition it is either already being read in from disk or has been unmapped or trimmed and is still available on the standby or modified list. the thread either waits for the i o to complete or in the latter cases reclaims the page from the appropriate list. otherwise an i o must be issued to read the page in from the paging file or file system. the vm manager tries to allocate an available page from either the free list or the standby list. pages in the modified list cannot be used until they have been written back to disk and transferred to the standby list. if no pages are available the thread blocks until the working set manager trims pages from memory or a page in physical memory is unmapped by a process. windows xp uses a per process first in first out fifo replacement policy to take pages from processes that are using more than their minimum workingset size. windows xp monitors the page faulting of each process that is at its minimum working set size and adjusts the working set size accordingly. when a process is started it is assigned a default minimum working set size of pages. the vm manager replaces and trims pages in the working set of a process according to their age. the age of a page is determined by how many trimming cycles have occurred without the pte. trimmed pages are moved to the standby or modified list depending on whether the modified bit is set in the page's pte. the vm manager does not fault in only the page immediately needed. research shows that the memory referencing of a thread tends to have a locality property when a page is used it is likely that adjacent pages will be referenced in the near future. think of iterating over an array or fetching sequential instructions that form the executable code for a thread. because of locality when the vm manager faults in a page it also faults in a few adjacent pages. this prefetching tends to reduce the total number of page faults. writes are also clustered to reduce the number of independent i o operations. in addition to managing committed memory the vm manager manages each process's reserved memory or virtual address space. each process has an associated splay tree that describes the ranges of virtual addresses in use and what the use is. this allows the vm manager to fault in page tables as needed. if the pte for a faulting address does not exist the vm manager searches for the address in the process's tree of virtual address descriptors vads and uses this information to fill in the missing pte and retrieve the page. in some cases a page table page itself may not exist such a page must be transparently allocated and initialized by the vm manager. . . . process manager the windows xp process manager provides services for creating deleting and using processes threads and jobs. it has no knowledge about parent child relationships or process hierarchies those refinements are left to the particular environmental subsystem that owns the process. the process manager is also . system components not involved in the scheduling of processes other than setting the priorities and affinities in processes and threads when they are created. thread scheduling takes place in the kernel dispatcher. each process contains one or more threads. processes themselves can be collected together into large units called job objects the use of job objects allows limits on cpu usage working set size and processor affinities that control multiple processes at once. job objects are used to manage large datacenter machines. an example of process creation in the win api environment is as follows. when a win api application calls createprocess . a message is sent to the win api subsystem to notify it that the process is being created. . createprocess in the original process then calls an api in the process manager of the nt executive to actually create the process. . the process manager calls the object manager to create a process object and returns the object handle to win api. . win api calls the process manager again to create a thread for the process and returns handles to the new process and thread. the windows xp apis for manipulating virtual memory and threads and for duplicating handles take a process handle so subsystems can perform operations on behalf of a new process without having to execute directly in the new process's context. once a new process is created the initial thread is created and an asynchronous procedure call is delivered to the thread to prompt the start of execution at the user mode image loader. the loader is an ntdll.dll which is a link library automatically mapped into every newly created process. windows xp also supports a unix fork style of process creation in order to support the posix environmental subsystem. although the win api environment calls the process manager from the client process posix uses the cross process nature of the windows xp apis to create the new process from within the subsystem process. the process manager also implements the queuing and delivery of asynchronous procedure calls apcs to threads. apcs are used by the system to initiate thread execution complete i o terminate threads and processes and attach debuggers. user mode code can also queue an apc to a thread for delivery of signal like notifications. to support posix the process manager provides apis that send alerts to threads to unblock them from system calls. the debugger support in the process manager includes the capability to suspend and resume threads and to create threads that begin in a suspended mode. there are also process manager apis that get and set a thread's register context and access another process's virtual memory. threads can be created in the current process they can also be injected into another process. within the executive existing threads can temporarily attach to another process. this method is used by worker threads that need to execute in the context of the process originating a work request. the process manager also supports impersonation. a thread running in a process with a security token belonging to one user can set a thread specific chapter windows xp token belonging to another user. this facility is fundamental to the clientserver computing model where services need to act on behalf of a variety of clients with different security ids. . . . local procedure call facility the implementation of windows xp uses a client server model. the environmental subsystems are servers that implement particular operating system personalities. the client server model is used for implementing a variety of operating system services besides the environmental subsystems. security management printer spooling web services network file systems plug andplay and many other features are implemented using this model. to reduce the memory footprint multiple services are often collected together into a few processes which then rely on the user mode thread pool facilities to share threads and wait for messages see section . . . . the operating system uses the local procedure call lpc facility to pass requests and results between client and server processes within a single machine. in particular lpc is used to request services from the various windows xp subsystems. lpc is similar in many respects to the rpc mechanisms used by many operating systems for distributed processing across networks but lpc is optimized for use within a single system. the windows xp implementation of open software foundation osf rpc often uses lpc as a transport on the local machine. lpc is a message passing mechanism. the server process publishes a globally visible connection port object. when a client wants services from a subsystem it opens a handle to the subsystem's connection port object and sends a connection request to the port. the server creates a channel and returns a handle to the client. the channel consists of a pair of private communication ports one for client to server messages and the other for server to client messages. communication channels support a callback mechanism so the client and server can accept requests when they would normally be expecting a reply. when an lpc channel is created one of three message passing techniques must be specified. . the first technique is suitable for small messages up to a couple of hundred bytes . in this case the port's message queue is used as intermediate storage and the messages are copied from one process to the other. . the second technique is for larger messages. in this case a sharedmemory section object is created for the channel. messages sent through the port's message queue contain a pointer and size information referring to the section object. this avoids the need to copy large messages. the sender places data into the shared section and the receiver views them directly. . the third technique uses the apis that read and write directly into a process's address space. the lpc provides functions and synchronization so a server can access the data in a client. . system components the win api window manager uses its own form of message passing that is independent of the executive lpc facilities. when a client asks for a connection that uses window manager messaging the server sets up three objects a dedicated server thread to handle requests a kb section object and an event pair object. an event pair object is a synchronization object that is used by the win api subsystem to provide notification when the client thread has copied a message to the win api server or vice versa. the section object passes the messages and the event pair object performs synchronization. window manager messaging has several advantages the section object eliminates message copying since it represents a region of shared memory. the event pair object eliminates the overhead of using the port object to pass messages containing pointers and lengths. the dedicated server thread eliminates the overhead of determining which client thread is calling the server since there is one server thread per client thread. the kernel gives scheduling preference to these dedicated server threads to improve performance. . . . i o manager the i o manager is responsible for file systems device drivers and network drivers. it keeps track of which device drivers filter drivers and file systems are loaded and it also manages buffers for i o requests. it works with the vm manager to provide memory mapped file i o and controls the windows xp cache manager which handles caching for the entire i o system. the i o manager is fundamentally asynchronous. synchronous i o is provided by explicitly waiting for an i o operation to complete. the i o manager provides several models of asynchronous i o completion including setting of events delivery of apcs to the initiating thread and use of i o completion ports which allow a single thread to process i o completions from many other threads. device drivers are arranged as a list for each device called a driver or i o stack because of how device drivers are added . the i o manager converts the requests it receives into a standard form called an i o request packet irp . it then forwards the irp to the first driver in the stack for processing. after each driver processes the irp it calls the i o manager either to forward it to the next driver in the stack or if all processing is finished to complete the operation on theirp. completions may occur in a different context from the original i o request. for example if a driver is performing its part of an i o operation and is forced to block for an extended time it may queue the irp to a worker thread to continue processing in the system context. in the original thread the driver returns a status indicating that the i o request is pending so that the thread can continue executing in parallel with the i o operation. irps may also be processed in interrupt service routines and completed in an arbitrary context. because some final processing may need to happen in the context that initiated chapter windows xp the i o the i o manager uses an apc to do final i o completion processing in the context of the originating thread. the stack model is very flexible. as a driver stack is built various drivers have the opportunity to insert themselves into the stack as filter drivers. filter drivers can examine and potentially modify each i o operation. mount management partition management and disk striping and mirroring are all examples of functionality implemented using filter drivers that execute beneath the file system in the stack. file system filter drivers execute above the file system and have been used to implement functionality such as hierarchical storage management single instancing of files for remote boot and dynamic format conversion. third parties also use file system filter drivers to implement virus detection. device drivers for windows xp are written to the windows driver model wdm specification. this model lays out all the requirements for device drivers including how to layer filter drivers share common code for handling power and plug and play requests build correct cancellation logic and so forth. because of the richness of the wdm writing a full wdm device driver for each new hardware device can involve an excessive amount of work. fortunately the port miniport model makes it unnecessary to do this. within a class of similar devices such as audio drivers scsi devices or ethernet controllers each instance of a device shares a common driver for that class called a port driver. the port driver implements the standard operations for the class and then calls device specific routines in the device's miniport driver to implement device specific functionality. . . . cache manager in many operating systems caching is done by the file system. instead windows xp provides a centralized caching facility. the cache manager works closely with the vm manager to provide cache services for all components under the control of the i o manager. caching in windows xp is based on files rather than raw blocks. the size of the cache changes dynamically according to how much free memory is available in the system. recall that the upper gb of a process's address space comprise the system area it is available in the context of all processes. the vm manager allocates up to one half of this space to the system cache. the cache manager maps files into this address space and uses the capabilities of the vm manager to handle file i o. the cache is divided into blocks of kb. each cache block can hold a view that is a memory mapped region of a file. each cache block is described by a virtual address control block vacb that stores the virtual address and file offset for the view as well as the number of processes using the view. the vacbs reside in a single array maintained by the cache manager. for each open file the cache manager maintains a separate vacb index array that describes the caching for the entire file. this array has an entry for each kb chunk of the file so for instance a mb file would have an entry vacb index array an entry in the vacb index array points to the vacb if that portion of the file is in the cache it is null otherwise. when the i o manager receives a file's user level read request the i o manager sends an irp to the device driver stack on which the file resides. the file system attempts to look . system components es s i o i o manager cached i o . . t . . eacwiraartager . . . data copy isip page fault vm itianagep figure . file i o. up the requested data in the cache manager unless the request specifically asks for a noncached read . the cache manager calculates which entry of that file's vacb index array corresponds to the byte offset of the request. the entry either points to the view in the cache or is invalid. if it is invalid the cache manager allocates a cache block and the corresponding entry in the vacb array and maps the view into the cache block. the cache manager then attempts to copy data from the mapped file to the caller's buffer. if the copy succeeds the operation is completed. if the copy fails it does so because of a page fault which causes the vm manager to send a noncached read request to the i o manager. the i o manager sends another request down the driver stack this time requesting a paging operation which bypasses the cache manager and reads the data from the file directly into the page allocated for the cache manager. upon completion the vacb is set to point at the page. the data now in the cache are copied to the caller's buffer and the original i o request is completed. figure . shows an overview of these operations. when possible for synchronous operations on cached files i o is handled by the fast i o mechanism. this mechanism parallels the normal irp based i o but calls into the driver stack directly rather than passing down an irp. because no irp is involved the operation should not block for an extended period of time and cannot be queued to a worker thread. therefore when the operation reaches the file system and calls the cache manager the operation fails if the information is not already in cache. the i o manager then attempts the operation using the normal irp path. a kernel level read operation is similar except that the data can be accessed directly from the cache rather than being copied to a buffer in user space. to use file system metadata data structures that describe the file system the kernel uses the cache manager's mapping interface to read the metadata. to modify the metadata the file system uses the cache manager's pinning interface. pinning a page locks the page into a physical memory page frame so that the vm manager cannot move or page out the page. after updating chapter windows xp the metadata the file system asks the cache manager to unpin the page. a modified page is marked dirty and so the vm manager flushes the page to disk. the metadata is stored in a regular file. to improve performance the cache manager keeps a small history of read requests and from this history attempts to predict future requests. if the cache manager finds a pattern in the previous three requests such as sequential access forward or backward it prefetches data into the cache before the next request is submitted by the application. in this way the application finds its data already cached and does not need to wait for disk i o. the win api dpenfile and c r e a t e f i l e o functions can be passed the file flag sequential scan flag which is a hint to the cache manager to try to prefetch kb ahead of the thread's requests. typically windows xp performs i o operations in chunks of kb or pages thus this read ahead is three times the normal amount. the cache manager is also responsible for telling the vm manager to flush the contents of the cache. the cache manager's default behavior is write back caching it accumulates writes for to seconds and then wakes up the cachewriter thread. when write through caching is needed a process can set a flag when opening the file or the process can call an explicit cache flush function. a fast writing process could potentially fill all the free cache pages before the cache writer thread had a chance to wake up and flush the pages to disk. the cache writer prevents a process from flooding the system in the following way. when the amount of free cache memory becomes low the cache manager temporarily blocks processes attempting to write data and wakes the cachewriter thread to flush pages to disk. if the fast writing process is actually a network redirector for a network file system blocking it for too long could cause network transfers to time out and be retransmitted. this retransmission would waste network bandwidth. to prevent such waste network redirectors can instruct the cache manager to limit the backlog of writes in the cache. because a network file system needs to move data between a disk and the network interface the cache manager also provides a dma interface to move the data directly. moving data directly avoids the need to copy data through an intermediate buffer. . . . security reference monitor centralizing management of system entities in the object manager enables windows xp to use a uniform mechanism to perform run time access validation and audit checks for every user accessible entity in the system. whenever a process opens a handle to an object the security reference monitor srm checks the process's security token and the object's access control list to see whether the process has the necessary rights. the srm is also responsible for manipulating the privileges in security tokens. special privileges are required for users to perform backup or restore operations on file systems overcome certain checks as an administrator debug processes and so forth. tokens can also be marked as being restricted in their privileges so that they cannot access objects that are available to most users. restricted tokens are primarily used to restrict the damage that can be done by execution of untrusted code. another responsibility of the srm is logging security audit events. a c security rating requires that the system have the ability to detect and log all . system components attempts to access system resources so that it is easier to trace attempts at unauthorized access. because the srm is responsible for making access checks it generates most of the audit records in the security event log. . . . plug and play and power managers the operating system uses the plug and play pnp manager to recognize and adapt to changes in the hardware configuration. for pnp to work both the device and the driver must support the pnp standard. the pnp manager automatically recognizes installed devices and detects changes in devices as the system operates. the manager also keeps track of resources used by a device as well as potential resources that could be used and takes care of loading the appropriate drivers. this management of hardware resources primarily interrupts and i o memory ranges has the goal of determining a hardware configuration in which all devices are able to operate. for example if device b can use interrupt and device a can use or then the pnp manager will assign to b and to a. in previous versions the user might have had to remove device a and reconfigure it to use interrupt before installing device b. the user thus had to study system resources before installing new hardware and had to determine which devices were using which hardware resources. the proliferation of pcmcia cards laptop docks and usb ieee infiniband and other hot pluggable devices also dictates the support of dynamically configurable resources. the pnp manager handles dynamic reconfiguration as follows. first it gets a list of devices from each bus driver for example pci usb . it loads the installed driver or installs one if necessary and sends an add device request to the appropriate driver for each device. the pnp manager figures out the optimal resource assignments and sends a s t a r t d e v i c e request to each driver along with the resource assignment for the device. if a device needs to be reconfigured the pnp manager sends a query stop request which asks the driver whether the device can be temporarily disabled. if the driver can disable the device then all pending operations are completed and new operations are prevented from starting. next the pnp manager sends a stop request it can then reconfigure the device with another s t a r t d e v i c e request. the pnp manager also supports other requests such as query remove. this request which is used when the user is getting ready to eject a pccard device operates in a fashion similar to query stop. the surprise remove request is used when a device fails or more likely when a user removes a pccard device without stopping it first. the remove request tells the driver to stop using the device and release all resources allocated to it. windows xp supports sophisticated power management. although these facilities are useful for home systems to reduce power consumption their primary application is for ease of use quicker access and extending the battery life of laptops. the system and individual devices can be moved to low power mode called standby or sleep mode when not in use so the battery is primarily directed at physical memory ram data retention. the system can turn itself back on when packets are received from the network a phone line to a modem rings or a user opens a laptop or pushes a soft power button. windows xp can also hibernate a system by storing physical memory contents to disk and chapter windows xp completely shutting down the machine then restoring the system at a later point before execution continues. further strategies for reducing power consumption are supported as well. rather than allowing it to spin in a processor loop when the cpu is idle windows xp moves the system to a state requiring lower power consumption. if the cpu is underutilized windows xp reduces the cpu clock speed which can save significant power. . . . registry windows xp keeps much of its configuration information in an internal database called the registry. a registry database is called a hive. there are separate hives for system information default user preferences software installation and security. because the information in the system hive is required in order to boot the system the registry manager is implemented as a component of the executive. every time the system successfully boots it saves the system hive as last known good. if the user installs software such as a device driver that produces a system hive configuration that will not boot the user can usually boot using the last known good configuration. damage to the system hive from installing third party applications and drivers is so common that windows xp has a component called system restore that periodically saves the hives as well as other software states like driver executables and configuration files so that the system can be restored to a previously working state in cases where the system boots but no longer operates as expected. . . . booting the booting of a windows xp pc begins when the hardware powers on and the bios begins executing from rom. the bios identifies the system device to be booted and loads and executes the bootstrap loader from the front of the disk. this loader knows enough about the file system format to load the ntldr program from the root directory of the system device. ntldr is used to determine which boot device contains the operating system. next the ntldr loads in the hal library the kernel and the system hive from the boot device. from the system hive it determines what device drivers are needed to boot the system the boot drivers and loads them. finally ntldr begins kernel execution. the kernel initializes the system and creates two processes. the system process contains all the internal worker threads and never executes in user mode. the first user mode process created is smss which is similar to the nit initialization process in unix. smss does further initialization of the system including establishing the paging files and loading device drivers and creates the vvinlogon and csrss processes. csrss is the win api subsystem. winlogon brings up the rest of the system including the lsass security subsystem and the remaining services needed to run the system. the system optimizes the boot process by pre loading files from disk based on previous boots of the system. disk access patterns at boot are also used to lay out system files on disk to reduce the number of i o operations required. the processes required to start the system are reduced by grouping services
 into one process. all of these approaches contribute to a dramatic reduction in system boot time. of course system boot time is less important than it once was because of the sleep and hibernation capabilities of windows xp which allow users to power down their computers and then quickly resume where they left off. . environmental subsystems environmental subsystems are user mode processes layered over the native windows xp executive services to enable windows xp to run programs developed for other operating systems including bit windows ms dos and posix. each environmental subsystem provides a single application environment. windows xp uses the win api subsystem as the main operating environment and thus this subsystem starts all processes. when an application is executed the win api subsystem calls the vm manager to load the application's executable code. the memory manager returns a status to win indicating the type of executable. if it is not a native win api executable the win api environment checks whether the appropriate environmental subsystem is running if the subsystem is not running it is started as a user mode process. the subsystem then takes control over the application startup. the environmental subsystems use the lpc facility to provide operatingsystem services to client processes. the windows xp subsystem architecture keeps applications from mixing api routines from different environments. for instance a win api application cannot make a posix system call because only one environmental subsystem can be associated with each process. since each subsystem is run as a separate user mode process a crash in one has no effect on other processes. the exception is win api which provides all keyboard mouse and graphical display capabilities. if it fails the system is effectively disabled and requires a reboot. the win api environment categorizes applications as either graphical or character based where a character based application is one that thinks interactive output goes to a character based command window. win api transforms the output of a character based application to a graphical representation in the command window. this transformation is easy whenever an output routine is called the environmental subsystem calls a win routine to display the text. since the win api environment performs this function for all characterbased windows it can transfer screen text between windows via the clipboard. this transformation works for ms dos applications as well as for posix command line applications. . . ms dos environment the ms dos environment does not have the complexity of the other windows xp environmental subsystems. it is provided by a win api application called the virtual dos machine vdm . since the vdm is a user mode process it is paged and dispatched like any other windows xp application. the vdm has an instruction execution unit to execute or emulate intel instructions. the vdm also provides routines to emulate the ms dos rom bios and chapter windows xp int software interrupt services and has virtual device drivers for the screen keyboard and communication ports. the vdm is based on ms dos . source code it allocates at least kb of memory to the application. the windows xp command shell is a program that creates a window that looks like an ms dos environment. it can run both bit and bit executables. when an ms dos application is run the command shell starts a vdm process to execute the program. if windows xp is running on a ia compatible processor ms dos graphical applications run in full screen mode and character applications can run full screen or in a window. not all ms dos applications run under the vdm. for example some ms dos applications access the disk hardware directly so they fail to run on windows xp because disk access is restricted to protect the file system. in general ms dos applications that directly access hardware will fail to operate under windows xp. since ms dos is not a multitasking environment some applications have been written in such a way as to hog the cpu. for instance the use of busy loops can cause time delays or pauses in execution. the scheduler in the kernel dispatcher detects such delays and automatically throttles the cpu usage but this may cause the offending application to operate incorrectly. . . bit windows environment the winl execution environment is provided by a vdm that incorporates additional software called windows on windows wow for bit applications this software provides the windows . kernel routines and stub routines for window manager and graphical device interface gdi functions. the stub routines call the appropriate win api subroutines converting or thunking bit addresses into bit addresses. applications that rely on the internal structure of the bit window manager or gdi may not work because the underlying win api implementation is of course different from true bit windows. wow can multitask with other processes on windows xp but it resembles windows . in many ways. only one winl application can run at a time all applications are single threaded and reside in the same address space and all share the same input queue. these features imply that an application that stops receiving input will block all the other winl applications just as in windows .x and one winl application can crash other winl applications by corrupting the address space. multiple winl environments can coexist however by using the command start separate wml application from the command line. there are relatively few bit applications that users need to continue to run on windows xp but some of them include common installation setup programs. thus the wow environment continues to exist primarily because a number of bit applications cannot be installed on windows xp without it. . . bit windows environment on ia the native environment for windows on ia uses bit addresses and the native ia instruction set. to execute ia programs in this environment requires a thunking layer to translate bit win api calls into the corresponding bit calls just as bit applications require translation on ia systems. . environmental subsystems thus bit windows supports the wow environment. the implementations of bit and bit windows are essentially identical and the ia processor provides direct execution of ia instructions so wow achieves a higher level of compatibility than vvow . . . win environment the main subsystem in windows xp is the win api. it runs win api applications and manages all keyboard mouse and screen i o. since it is the controlling environment it is designed to be extremely robust. several features of the win api contribute to this robustness. unlike processes in the winl environment each win process has its own input queue. the window manager dispatches all input on the system to the appropriate process's input queue so a failed process does not block input to other processes. the windows xp kernel also provides preemptive multitasking which enables the user to terminate applications that have failed or are no longer needed. the win api also validates all objects before using them to prevent crashes that could otherwise occur if an application tried to use an invalid or wrong handle. the win api subsystem verifies the type of the object to which a handle points before using the object. the reference counts kept by the object manager prevent objects from being deleted while they are still being vised and prevent their use after they have been deleted. to achieve a high level of compatibility with windows systems windows xp allows users to specify that individual applications be run using a shim layer which modifies the win api to better approximate the behavior expected by old applications. for example some applications expect to see a particular version of the system and fail on new versions. frequently applications have latent bugs that become exposed due to changes in the implementation. for example using memory after freeing it may cause corruption only if the order of memory reuse by the heap changes or an application may make assumptions about which errors can be returned by a routine or about the number of valid bits in an address. running an application with the windows shims enabled causes the system to provide behavior much closer to windows though with reduced performance and limited interoperability with other applications. . . posix subsystem the posix subsystem is designed to run posix applications written to follow the posix standard which is based on the unix model. posix applications can be started by the win api subsystem or by another posix application. posix applications use the posix subsystem server psxss.exe the posix dynamic link library psxdll .dll and the posix console session manager posix .exe. although the posix standard does not specify printing posix applications can use printers transparently via the windows xp redirection mechanism. posix applications have access to any file system on the windows xp system the posix environment enforces unix like permissions on directory trees. due to scheduling issues the posix system in windows xp does not ship with the system but is available separately for professional desktop systems and servers. it provides a much higher level of compatibility with unix applications than previous versions of nt. of the commonly available unix chapter windows xp applications most compile and run without change with the latest version of interix. . . logon and security subsystems before a user can access objects on windows xp that user must be authenticated by the logon sendee winlogon. winlogon is responsible for responding to the secure attention sequence control alt delete . the secure attention sequence is a required mechanism for keeping an application from acting as a trojan horse. only winlogon can intercept this sequence in order to put up a logon screen change passwords and lock the workstation. to be authenticated a user must have an account and provide the password for that account. alternatively a user logs on by using a smart card and personal identification number subject to the security policies in effect for the domain. the local security authority subsystem lsass is the process that generates access tokens to represent users on the system. it calls an authentication package to perform authentication using information from the logon subsystem or network server. typically the authentication package simply looks up the account information in a local database and checks to see that the password is correct. the security subsystem then generates the access token for the user id containing the appropriate privileges quota limits and group ids. whenever the user attempts to access an object in the system such as by opening a handle to the object the access token is passed to the security reference monitor which checks privileges and quotas. the default authentication package for windows xp domains is kerberos. lsass also has the responsibility for implementing security policy such as strong passwords for authenticating users and for performing encryption of data and keys
 historically ms dos systems have used the file allocation table fat file system. the bit fat file system has several shortcomings including internal fragmentation a size limitation of gb and a lack of access protection for files. the bit fat file system has solved the size and fragmentation problems but its performance and features are still weak by comparison with modern file systems. the ntfs file system is much better. it was designed to include many features including data recovery security fault tolerance large files and file systems multiple data streams unicode names sparse files encryption journaling volume shadow copies and file compression. windows xp uses ntfs as its basic file system and we focus on it here. windows xp continues to use fat however to read floppies and other removable media. and despite the advantages of ntfs fat continues to be important for interoperability of media with windows systems. windows xp supports additional file system types for the common formats used for cd and dvd media. . . ntfs internal layout the fundamental entity in ntfs is a volume. a volume is created by the windows xp logical disk management utility and is based on a logical disk . file system partition. a volume may occupy a portion of a disk may occupy an entire disk or may span several disks. ntfs does not deal with individual sectors of a disk but instead uses clusters as the units of disk allocation. a cluster is a number of disk sectors that is a power of . the cluster size is configured when an ntfs file system is formatted. the default cluster size is the sector size for volumes up to mb kb for volumes up to gb kb for volumes up to gb and kb for larger volumes. this cluster size is much smaller than that for the bit fat file system and the small size reduces the amount of internal fragmentation. as an example consider a . gb disk with files. if you use a fat file system mb may be lost to internal fragmentation because the cluster size is kb. under ntfs only mb would be lost when storing the same files. ntfs uses logical cluster numbers lcns as disk addresses. it assigns them by numbering clusters from the beginning of the disk to the end. using this scheme the system can calculate a physical disk offset in bytes by multiplying the lcn by the cluster size. a file in ntfs is not a simple byte stream as it is m ms dos or unix rather it is a structured object consisting of typed attributes. each attribute of a file is an independent byte stream that can be created deleted read and written. some attribute types are standard for all files including the file name or names if the file has aliases such as an ms dos shortname the creation time and the security descriptor that specifies access control. user data is stored in data attributes. most traditional data files have an unnamed data attribute that contains all the file's data. however additional data streams can be created with explicit names. for instance in macintosh files stored on a windows xp server the resource fork is a named data stream. the iprop interfaces of the component object model com use a named data stream to store properties on ordinary files including thumbnails of images. in general attributes may be added as necessary and are accessed using afile name attributesyntax. ntfs returns the size of the unnamed attribute only in response to file query operations such as when running the d i r command. every file in ntfs is described by one or more records in an array stored in a special file called the master file table mft . the size of a record is determined when the file system is created it ranges from to kb. small attributes are stored in the mft record itself and are called resident attributes. large attributes such as the unnamed bulk data are called nonresident attributes and are stored in one or more contiguous extents on the disk a pointer to each extent is stored in the mft record. for a small file even the data attribute may fit inside the mft record. if a file has many attributes or if it is highly fragmented so that many pointers are needed to point to all the fragments one record in the mft might not be large enough. in this case the file is described by a record called the base file record which contains pointers to overflow records that hold the additional pointers and attributes. each file in an ntfs volume has a unique id called a file reference. the file reference is a bit quantity that consists of a bit file number and a bit sequence number. the file number is the record number that is the array slot in the mft that describes the file. the sequence number is incremented every time an mft entry is reused. the sequence number enables ntfs to perform chapter windows xp internal consistency checks such as catching a stale reference to a deleted file after the mft entry has been reused for a new file. . . . ntfs b tree as in ms dos and unfix the ntfs namespace is organized as a hierarchy of directories. each directory uses a data structure called a b tree to store an index of the file names in that directory. a b tree is used because it eliminates the cost of reorganizing the tree and has the property that the length of every path from the root of the tree to a leaf is the same. the index root of a directory contains the top level of the b tree. for a large directory this top level contains pointers to disk extents that hold the remainder of the tree. each entry in the directory contains the name and file reference of the file as well as a copy of the update timestamp and file size taken from the file's resident attributes in the mft. copies of this information are stored in the directory so a directory listing can be efficiently generated. because all the file names sizes and update times are available from the directory itself there is no need to gather these attributes from the mft entries for each of the files. . . . ntfs metadata the ntfs volume's metadata are all stored in files. the first file is the mft. the second file which is used during recovery if the mft is damaged contains a copy of the first entries of the mft. the next few files are also special in purpose. they include the log file volume file attribute definition table root directory bitmap file boot file and bad cluster file. we describe the role of each of these files below. the log file records all metadata updates to the file system. the volume file contains the name of the volume the version of ntfs that formatted the volume and a bit that tells whether the volume may have been corrupted and needs to be checked for consistency. the attribute definition table indicates which attribute types are used in the volume and what operations can be performed on each of them. the root directory is the top level directory in the file system hierarchy. the bitmap file indicates which clusters on a volume are allocated to files and which are free. the boot file contains the startup code for windows xp and must be located at a particular disk address so that it can be found easily by a simple rom bootstrap loader. the boot file also contains the physical address of the mft. the bad cluster file keeps track of any bad areas on the volume ntfs uses this record for error recovery. . . recovery in many simple file systems a power failure at the wrong time can damage the file system data structures so severely that the entire volume is scrambled. . file system many versions of unix store redundant metadata on the disk and they recover from crashes using the f sck program to check all the file system data structures and restore them forcibly to a consistent state. restoring them often involves deleting damaged files and freeing data clusters that had been written with user data but not properly recorded in the file system's metadata structures. this checking can be a slow process and can cause the loss of significant amounts of data. ntfs takes a different approach to file system robustness. in ntfs all filesystem data structure updates are performed inside transactions. before a data structure is altered the transaction writes a log record that contains redo and undo information after the data structure has been changed the transaction writes a commit record to the log to signify that the transaction succeeded. after a crash the system can restore the file system data structures to a consistent state by processing the log records first redoing the operations for committed transactions and then undoing the operations for transactions that did not commit successfully before the crash. periodically usually every seconds a checkpoint record is written to the log. the system does not need log records prior to the checkpoint to recover from a crash. they can be discarded so the log file does not grow without bounds. the first time after system startup that an ntfs volume is accessed ntfs automatically performs file system recovery. this scheme does not guarantee that all the user file contents are correct after a crash it ensures only that the file system data structures the metadata files are undamaged and reflect some consistent state that existed prior to the crash. it would be possible to extend the transaction scheme to cover user files and microsoft may do so in the future. the log is stored in the third metadata file at the beginning of the volume. it is created with a fixed maximum size when the file system is formatted. it has two sections the logging area which is a circular queue of log records and the restart area which holds context information such as the position in the logging area where ntfs should start reading during a recovery. in fact the restart area holds two copies of its information so recovery is still possible if one copy is damaged during the crash. the logging functionality is provided by the windows xp log file service. in addition to writing the log records and performing recovery actions the log file service keeps track of the free space in the log file. if the free space gets too low the log file service queues pending transactions and ntfs halts all new i o operations. after the in progress operations complete ntfs calls the cache manager to flush all data then resets the log file and performs the queued transactions. . . security the security of an ntfs volume is derived from the windows xp object model. each ntfs file references a security descriptor which contains the access token of the owner of the file and an access control list which states the access privileges granted to each user having access to the file. in normal operation ntfs does not enforce permissions on traversal of directories in file path names. however for compatibility with posix these checks can be enabled. traversal checks are inherently more expensive chapter windows xp disk . gb disk . gb ' ' ' ' ' . . . . disk c fat gb ' . . ' . ' . ' . . ' . . ' ' . ' ' ' ' logical drive d ntfs gb ! lcns o i ! . . . . '' ' ' ' ' ' ' ' '' '. figure . volume set on two drives. since modern parsing of file path names uses prefix matching rather than component by component opening of directory names. . . volume management and fault tolerance ftdisk is the fault tolerant disk driver for windows xp. when installed it provides several ways to combine multiple disk drives into one logical volume so as to improve performance capacity or reliability. . . . volume set one way to combine multiple disks is to concatenate them logically to form a large logical volume as shown in figure . . in windows xp this logical volume called a volume set can consist of up to physical partitions. a volume set that contains an ntfs volume can be extended without disturbance of the data already stored in the file system. the bitmap metadata on the ntfs volume are simply extended to cover the newly added space. ntfs continues to use the same lcn mechanism that it uses for a single physical disk and the ftdisk driver supplies the mapping from a logical volume offset to the offset on one particular disk. . . . stripe set another way to combine multiple physical partitions is to interleave their blocks in round robin fashion to form what is called a stripe set as shown in figure . . this scheme is also called raid level or disk striping. ftdisk uses a stripe size of kb the first kb of the logical volume are stored in the first physical partition the second kb in the second physical partition and so on until each partition has contributed kb of space. then the allocation wraps around to the first disk allocating the second kb block. a stripe set forms one large logical volume but the physical layout can improve the i o bandwidth because for a large i o all the disks can transfer data in parallel. . file system disk gb disk gb lcns i logical drive c gb figure . stripe set on two drives. . . . stripe set with parity a variation of this idea is the stripe set with parity which is shown in figure . . this scheme is also called raid level . suppose that a stripe set has eight disks. seven of the disks will store data stripes with one data stripe on each disk and the eighth disk will store a parity stripe for each data stripe. the parity stripe contains the byte wise exclusive or of the data stripes. if any one of the eight stripes is destroyed the system can reconstrvict the data by calculating the exclusive or of the remaining seven. this ability to reconstruct data makes the disk array much less likely to lose data in case of a disk failure. notice that an update to one data stripe also requires recalculation of the parity stripe. seven concurrent writes to seven different data stripes thus would also require updates to seven parity stripes. if the parity stripes were all on the same disk that disk could have seven times the i o load of the data disks. to disk gb disk gb disk gb parity lcns lcns lcns parity lcns lcns lcns parity parity lgns lcns . . d logical drive c gb figure . stripe set with parity on three drives. chapter windows xp disk gb disk gb drive c gb copy of drive c gb figure . mirror set on two drives. avoid creating this bottleneck we spread the parity stripes over all the disks by assigning them in round robin style. to build a stripe set with parity we need a minimum of three equal sized partitions located on three separate disks. . . . disk mirroring an even more robust scheme is called disk mirroring or raid level it is depicted in figure . . a mirror set comprises two equal sized partitions on two disks. when an application writes data to a mirror set ftdisk writes the data to both partitions so that the data contents of the two partitions are identical. if one partition fails ftdisk has another copy safely stored on the mirror. mirror sets can also improve performance because read requests can be split between the two mirrors giving each mirror half of the workload. to protect against the failure of a disk controller we can attach the two disks of a mirror set to two separate disk controllers. this arrangement is called a duplex set. . . . sector sparing and cluster remapping to deal with disk sectors that go bad ftdisk uses a hardware technique called sector sparing and ntfs uses a software technique called cluster remapping. sector sparing is a hardware capability provided by many disk drives. when a disk drive is formatted it creates a map from logical block numbers to good sectors on the disk. it also leaves extra sectors unmapped as spares. if a sector fails ftdisk instructs the disk drive to substitute a spare. cluster remapping is a software technique performed by the file system. if a disk block goes bad ntfs substitutes a different unallocated block by changing any affected pointers in the mft. ntfs also makes a note that the bad block should never be allocated to any file. . file system when a disk block goes bad the usual outcome is a data loss. but sector sparing or cluster remapping can be combined with fault tolerant volumes to mask the failure of a disk block. if a read fails the system reconstructs the missing data by reading the mirror or by calculating the exclusive or parity in a stripe set with parity. the reconstructed data are stored into a new location that is obtained by sector sparing or cluster remapping. . . compression and encryption ntfs can perform data compression on individual files or on all data files in a directory. to compress a file ntfs divides the file's data into compression units which are blocks of contiguous clusters. when each compression unit is written a data compression algorithm is applied. if the result fits into fewer than clusters the compressed version is stored. when reading ntfs can determine whether data have been compressed if they have been the length of the stored compression unit is less than clusters. to improve performance when reading contiguous compression units ntfs prefetches and decompresses ahead of the application requests. for sparse files or files that contain mostly zeros ntfs uses another technique to save space. clusters that contain only zeros because they have never been written are not actually allocated or stored on disk. instead gaps are left in the sequence of virtual cluster numbers stored in the mft entry for the file. when reading a file if it finds a gap in the virtual cluster numbers ntfs just zero fills that portion of the caller's buffer. this technique is also used by unix. ntfs supports encryption of files. individual files or entire directories can be specified for encryption. the security system manages the keys used and a key recovery service is available to retrieve lost keys. . . mount points mount points are a form of symbolic link specific to directories on ntfs. they provide a mechanism for administrators to organize disk volumes that is more flexible than the use of global names like drive letters . mount points are implemented as a symbolic link with associated data that contain the true volume name. ultimately mount points will supplant drive letters completely but there will be a long transition due to the dependence of many applications on the drive letter scheme. . . change journal ntfs keeps a journal describing all changes that have been made to the file system. user mode services can receive notifications of changes to the journal and then identify what files have changed. the content indexing service uses the change journal to identify files that need to be re indexed. the filereplication service uses it to identify files that need to be replicated across the network. . . volume shadow copies windows xp implements the capability of bringing a volume to a known state and then creating a shadow copy that can be used to back up a consistent view chapter windows xp of the volume. making a shadow copy of a volume is a form of copy on a'rite where blocks modified after the shadow copy is created have their original contents stashed in the copy. to achieve a consistent state for the volume requires the cooperation of applications since the system cannot know when the data used by the application are in a stable state from which the application could be safely restarted. the server version of windows xp uses shadow copies to efficiently maintain old versions of files stored on file servers. this allows users to see documents stored on file servers as they existed at earlier points in time. the user can use this feature to recover files that were accidentally deleted or simply to look at a previous version of the file all without pulling out a backup tape
 windows xp supports both peer to peer and client server networking. it also has facilities for network management. the networking components in windows xp provide data transport interprocess communication file sharing across a network and the ability to send print jobs to remote printers. . . network interfaces to describe networking in windows xp we must first mention two of the internal networking interfaces the network device interface specification ndis and the transport driver interface tdi . the ndis interface was developed in by microsoft and com to separate network adapters from transport protocols so that either could be changed without affecting the other. ndis resides at the interface between the data link control and media accesscontrol layers in the osi model and enables many protocols to operate over many different network adapters. in terms of the osi model the tdi is the interface between the transport layer layer and the session layer layer . this interface enables any session layer component to use any available transport mechanism. similar reasoning led to the streams mechanism in unix. the tdi supports both connection based and connectionless transport and has functions to send any type of data. . . protocols windows xp implements transport protocols as drivers. these drivers can be loaded and unloaded from the system dynamically although in practice the system typically has to be rebooted after a change. windows xp comes with several networking protocols. next we discuss a number of the protocols supported in windows xp to provide a variety of network functionality. . . . server message block the server message block smb protocol was first introduced in ms dos . . the system uses the protocol to send i o requests over the network. the smb protocol has four message types. the session control messages are commands that start and end a redirector connection to a shared resource at the server. a redirector uses f i l e messages to access files at the server. the system . networking uses p r i n t e r messages to send data to a remote print queue and to receive back status information and the message message is used to communicate with another workstation. the smb protocol was published as the common internet file system cif and is supported on a number of operating systems. . . . network basic input output system the network basic input output system netbios is a hardware abstraction interface for networks analogous to the bios hardware abstraction interface devised for pcs running ms dos. netbios developed in the early s has become a standard network programming interface. netbios is used to establish logical names on the network to establish logical connections or sessions between two logical names on the network and to support reliable data transfer for a session via either netbios or smb requests. . . . netbios extended user interface the netbiosextended user interface netbeui was introduced by ibm in as a simple efficient networking protocol for up to machines. it is the default protocol for windows peer networking and for windows for workgroups. windows xp uses netbeui when it wants to share resources with these networks among the limitations of netbeui are that it uses the actual name of a computer as the address and that it does not support routing. . . . transmission control protocol internet protocol the transmission control protocol internet protocol tcp ip suite that is used on the internet has become the de facto standard networking infrastructure. windows xp uses tcp ip to connect to a wide variety of operating systems and hardware platforms. the windows xp tcp ip package includes the simple network management protocol snm dynamic host configuration protocol dhcp windows internet name service wins and netbios support. . . . point to point tunneling protocol the point to point tunneling protocol pptp is a protocol provided by windows xp to communicate between remote access server modules running on windows xp server machines and other client systems that are connected over the internet. the remote access servers can encrypt data sent over the connection and they support multi protocol virtual private networks vpns over the internet. . . . novell netware protocols the novell netware protocols ipx datagram service on the spx transport layer are widely used for pc lans. the windows xp nwlink protocol connects the netbios to netware networks. in combination with a redirector such as microsoft's client service for netware or novell's netware client for windows this protocol enables a windows xp client to connect to a netware server. chapter windows xp . . . web distributed authoring and versioning protocol web distributed authoring and versioning vvebdav is an http based protocol for collaborative authoring across the network. windows xp builds a webdav redirector into the file system. by building webdav support directly into the file system it can work with other features such as encryption. personal files can now be stored securely in a public place. . . . appletalk protocol the appletalk protocol was designed as a low cost connection by apple to allow macintosh computers to share files. windows xp systems can share files and printers with macintosh computers via appletalk if a windows xp server on the network is running the windows services for macintosh package. . . distributed processing mechanisms although windows xp is not a distributed operating system it does support distributed applications. mechanisms that support distributed processing on windows xp include netbios named pipes and mailslots windows sockets rpcs the microsoft interface definition language and finally com. . . . netbios in windows xp netbios applications can communicate over the network using netbeui nwlink or tcp ip. . . . named pipes named pipes are a connection oriented messaging mechanism. named pipes were originally developed as a high level interface to netbios connections over the network. a process can also use named pipes to communicate with other processes on the same machine. since named pipes are accessed through the file system interface the security mechanisms used for file objects also apply to named pipes. the name of a named pipe has a format called the uniform naming convention unc . a unc name looks like a typical remote file name. the format of a unc name is serverjiame sharejna me x y z where the server name identifies a server on the network a sharejname identifies any resource that is made available to network users such as directories files named pipes and printers and the x y z part is a normal file path name. . . . mailslots mailslots are a connectionless messaging mechanism. they are unreliable when accessed across the network in that a message sent to a mailslot may be lost before the intended recipient receives it. mailslots are used for broadcast applications such as finding components on the network they are also used by the windows computer browser service. . networking . . . winsock winsock is the windows xp sockets api. winsock is a session layer interface that is largely compatible with unix sockets but has some added windows xp extensions. it provides a standardized interface to many transport protocols that may have different addressing schemes so that any winsock application can run on any winsock compliant protocol stack. . . . remote procedure calls a remote procedure call rpc is a client server mechanism that enables an application on one machine to make a procedure call to code on another machine. the client calls a local procedure a stub routine that packs its arguments into a message and sends them across the network to a particular server process. the client side stub routine then blocks. meanwhile the server unpacks the message calls the procedure packs the return results into a message and sends them back to the client stub. the client stub unblocks receives the message unpacks the results of the rpc and returns them to the caller. this packing of arguments is sometimes called marshalling. the windows xp rpc mechanism follows the widely used distributed computingenvironment standard for rpc messages so programs written to use windows xp rpcs are highly portable. the rpc standard is detailed. it hides many of the architectural differences among computers such as the sizes of binary numbers and the order of bytes and bits in computer words by specifying standard data formats for rpc messages. windows xp can send rpc messages using netbios or winsock on tcp ip networks or named pipes on lan manager networks. the lpc facility discussed earlier is similar to rpc except that in the case of lpc the messages are passed between two processes running on the same computer. . . . microsoft interface definition language it is tedious and error prone to write the code to marshal and transmit arguments in the standard format to unmarshal and execute the remote procedure to marshal and send the return results and to unmarshal and return them to the caller. fortunately however much of this code can be generated automatically from a simple description of the arguments and return results. windows xp provides the microsoft interface definition language to describe the remote procedure names arguments and results. the compiler for this language generates header files that declare the stubs for the remote procedures as well as the data types for the argument and return value messages. it also generates source code for the stub routines used at the client side and for an unmarshaller and dispatcher at the server side. when the application is linked the stub routines are included. when the application executes the rpc stub the generated code handles the rest. . . . component object model the component object model com is a mechanism for interprocess communication that was developed for windows. com objects provide a well defined interface to manipulate the data in the object. for instance com is the infrastructure used by microsoft's object linking and embedding ole technology chapter windows xp for inserting spreadsheets into microsoft word documents. windows xp has a distributed extension called dcom that can be used over a network utilizing rfc to provide a transparent method of developing distributed applications. . . redirectors and servers in windows xp an application can use the windows xp i o api to access files from a remote computer as though they were local provided that the remote computer is running a cifs server such as is provided by windows xp or earlier windows systems. a redirector is the client side object that forwards i o requests to remote files where they are satisfied by a server. for performance and security the redirectors and servers run in kernel mode. in more detail access to a remote file occurs as follows . the application calls the i o manager to request that a file be opened with a file name in the standard unc format. . the i o manager builds an i o request packet as described in section . . . . . the i o manager recognizes that the access is for a remote file and calls a driver called a multiple universal naming convention provider mup . . the mup sends the i o request packet asynchronously to all registered redirectors. . a redirector that can satisfy the request responds to the mup. to avoid asking all the redirectors the same question in the future the mup uses a cache to remember which redirector can handle this file. . the redirector sends the network request to the remote system. . the remote system network drivers receive the request and pass it to the server driver. . the server driver hands the request to the proper local file system driver. . the proper device driver is called to access the data. . the results are returned to the server driver which sends the data back to the requesting redirector. the redirector then returns the data to the calling application via the i o manager. a similar process occurs for applications that use the win api network api rather than the unc services except that a module called a multi provider router is used instead of a mup. for portability redirectors and servers use the tdi api for network transport. the requests themselves are expressed in a higher level protocol which by default is the smb protocol mentioned in section . . . the list of redirectors is maintained in the system registry database. . . . distributed file system the unc names are not always convenient because multiple file servers may be available to serve the same content and unc names explicitly include the . networking name of the server. windows xp supports a distributed file systenf dfs protocol that allows a network administrator to serve up files from multiple servers using a single distributed name space. . . . folder redirection and client side caching to improve the pc experience for business users who frequently switch among computers windows xp allows administrators to give users roaming profiles which keep users preferences and other settings on servers. folder redirection is then used to automatically store a user's documents and other files on a server. this works well until one of the computers is no longer attached to the network such as a laptop on an airplane. to give users off line access to their redirected files windows xp uses client side caching csc . csc is used when the computer is online to keep copies of the server files on the local machine for better performance. the files are pushed up to the server as they are changed. if the computer becomes disconnected the files are still available and the update of the server is deferred until the next time the computer is online with a suitably performing network link. . . domains many networked environments have natural groups of users such as students in a computer laboratory at school or employees in one department in a business. frequently we want all the members of the group to be able to access shared resources on their various computers in the group. to manage the global access rights within such groups windows xp uses the concept of a domain. previously these domains had no relationship whatsoever to the domain name system dns that maps internet host names to ip addresses. now however they are closely related. specifically a windows xp domain is a group of windows xp workstations and servers that share a common security policy and user database. since windows xp now uses the kerberos protocol for trust and authentication a windows xp domain is the same thing as a kerberos realm. previous versions of nt used the idea of primary and backup domain controllers now all servers in a domain are domain controllers. in addition previous versions required the setup of one way trusts between domains. windows xp uses a hierarchical approach based on dns and allows transitive trusts that can flow up and down the hierarchy. this approach reduces the number of trusts required for n domains from n n to o . the workstations in the domain trust the domain controller to give correct information about the access rights of each user via the user's access token . all users retain the ability to restrict access to their own workstations no matter what any domain controller may say. . . . domain trees and forests because a business may have many departments and a school may have many classes it is often necessary to manage multiple domains within a single organization. a domain tree is a contiguous dns naming hierarchy for managing multiple domains. for example bell labs.com might be the root of the tree with research.bell labs.com and pez.bell labs.com as children domains research and pez. a forest is a set of noncontiguous names. an example would chapter windows xp be the trees bell lahs.com and or lucent.com. a forest may be made up of onlyone domain tree however. . . . trust relationships trust relationships may be set up between domains in three ways one way transitive and cross link. versions of nt through . allowed only one way trusts. a one way trust is exactly what its name implies domain a is told it can trust domain b. however b will not trust a tinless another relationship is configured. under a transitive trust if a trusts b and b trusts c then a b and c all trust one another since transitive trusts are two way by default. transitive trusts are enabled by default for new domains in a tree and can be configured only among domains within a forest. the third type a cross link trust is useful to cut down on authentication traffic. suppose that domains a and b are leaf nodes and that users in a often use resources in b. if a standard transitive trust is used authentication requests must traverse up to the common ancestor of the two leaf nodes but if a and b have a cross linking trust established the authentications are sent directly to the other node. . . active directory active directory is the windows xp implementation of lightweight directoryaccess protocol ldap services. active directory stores the topology information about the domain keeps the domain based user and group accounts and passwords and provides a domain based store for technologies like group policies and intellimirror. administrators use group policies to establish standards for desktop preferences and software. for many corporate information technology groups uniformity drastically reduces the cost of computing. intellimirror is used in conjunction with group policies to specify what software should be available to each class of user even automatically installing it on demand from a corporate server. . . name resolution in tcp ip networks on an ip network name resolution is the process of converting a computer name to an ip address such as resolving zuivzv.bell iabs.com to . . . . windows xp provides several methods of name resolution including windows internet name service wins broadcast name resolution domain name system dns a hosts file and an lmhosts file. most of these methods are used by many operating systems so we describe only wins here. under wins two or more wins servers maintain a dynamic database of name to ip address bindings along with client software to query the servers. at least two servers are used so that the wins service can survive a server failure and so that the name resolution workload can be spread over multiple machines. wins uses the dynamic host configuration protocol dhcp . dhcp updates address configurations automatically in the wins database without user or administrator intervention as follows. when a dhcp client starts up it broadcasts a discover message. each dhcp server that receives the message replies with an offer message that contains an ip address and configuration
 information for the client. the client chooses one of the configurations and sends a request message to the selected dhcp server. the dhcp server responds with the ip address and configuration information it gave previously and with a lease for that address. the lease gives the client the right to use the ip address for a specified period of time. when the lease time is half expired the client attempts to renew the lease for the address. if the lease is not renewed the client must obtain a new one. . programmer interface the win api is the fundamental interface to the capabilities of windows xp. this section describes five main aspects of the win api access to kernel objects sharing of objects between processes process management interprocess communication and memory management. . . access to kernel objects the windows xp kernel provides many services that application programs can use. application programs obtain these services by manipulating kernel objects. a process gains access to a kernel object named xxx by calling the createxxx function to open a handle to xxx. this handle is unique to the process. depending on which object is being opened if the create function fails it may return or it may return a special constant named invalid handle value. a process can close any handle by calling the closehandle function and the system may delete the object if the count of processes using the object drops to . . . sharing objects between processes windows xp provides three ways to share objects between processes. the first way is for a child process to inherit a handle to the object. when the parent calls the createxxx function the parent supplies a securitiesjvttributes structure with the blnherithandle field set to true. this field creates an inheritable handle. next the child process is created passing a value of true to the createprocesso function's blnherithandle argument. figure . shows a code sample that creates a semaphore handle inherited by a child process. assuming the child process knows which handles are shared the parent and child can achieve interprocess communication through the shared objects. in the example in figure . the child process gets the value of the handle from the first command line argument and then shares the semaphore with the parent process. the second way to share objects is for one process to give the object a name when the object is created and for the second process to open the name. this method has two drawbacks windows xp does not provide a way to check whether an object with the chosen name already exists and the object name space is global without regard to the object type. for instance two applications may create an object named pipe when two distinct and possibly different objects are desired. chapter windows xp security attributes sa sa.nlength sizeof sa sa.lpsecuritydescriptor null sa.blnherithandle true handle a semaphore createsemaphore sa null char comand line ostrstream ostring comraandjine sizeof command. ine ostring a semaphore ends createprocess another process . exe command line null null true . . . figure . code enabling a child to share an object by inheriting a handle. named objects have the advantage that unrelated processes can readily share them. the first process calls one of the createxxx functions and supplies a name in the lpszname parameter. the second process gets a handle to share the object by calling openxxx or createxxx with the same name as shown in the example of figure . . the third way to share objects is via the duplicatehandleo function. this method requires some other method of interprocess communication to pass the duplicated handle. given a handle to a process and the value of a handle within that process a second process can get a handle to the same object and thus share it. an example of this method is shown in figure . . . . process management in windows xp a process is an executing instance of an application and a thread is a unit of code that can be scheduled by the operating system. thus a process contains one or more threads. a process is started when some other process calls the createprocess routine. this routine loads any dynamic link libraries used by the process and creates a primary thread. additional threads can be created by the createthreado function. each thread is created with its own stack which defaults to mb unless specified otherwise in an argument to createthreado. because some c run time functions maintain state in static variables such as errno a multithread application needs to guard against unsynchronized access. the wrapper function beginthreadexo provides appropriate synchronization. process a handle a semaphore createsemaphore null myseml process b handle b semaphore opensemaphore semaphorej lljiccess false myseml figure . code for sharing an object by name lookup. . programmer interface process a wants to give process b access to a semaphore process a handle a.semaphore createsemaphore null null send the value of the semaphore to process b using a message or shared memory object process b handle process a openprocess process j lljiccess false process id of a handle b.semaphore duplicatehandle process a a semaphore getcurrentprocess b semaphore false duplicate same access use b.semaphore to access the semaphore figure . code for sharing an object by passing a handle. . . . instance handles every dynamic link library or executable file loaded into the address space of a process is identified by an instance handle. the value of the instance handle is actually the virtual address where the file is loaded. an application can get the handle to a module in its address space by passing the name of the module to getmodulehandleo. if null is passed as the name the base address of the process is returned. the lowest kb of the address space are not used so a faulty program that tries to de reference a null pointer gets an access violation. priorities in the win api environment are based on the windows xp scheduling model but not all priority values may be chosen. win api uses four priority classes . idle priority class priority level . normal priority class priority level . high priqrity class priority level . realtime priority class priority level processes are typically members of the normaljpriority class unless the parent of the process was of the idle priority class or another class was specified when createprocess was called. the priority class of a process can be changed with the setpriorityclasso function or by passing of an argument to the start command. for example the command start realtime cbserver.exe would run the cbserver program in the realtimejpriority class. only users with the increase scheduling priority privilege can move a process into the realtime priority xlass. administrators and power users have this privilege by default. chapter windows xp . . . scheduling rule f when a user is running an interactive program the system needs to provide especially good performance for the process. for this reason windows xp has a special scheduling rule for processes in the normal.priority class. windows xp distinguishes between the foreground process that is currently selected on the screen and the background processes that are not currently selected. when a process moves into the foreground windows xp increases the scheduling quantum by some factor typically by . this factor can be changed via the performance option in the system section of the control panel. this increase gives the foreground process three times longer to run before a time sharing preemption occurs. . . . thread priorities a thread starts with an initial priority determined by its class. the priority can be altered by the setthreadpriorityo function. this function takes an argument that specifies a priority relative to the base priority of its class thread priority ldwest base thread priority jelow jjormal base thread priorityjjormal base thread priority above normal base thread priority highest base two other designations are also used to adjust the priority. recall from section . . . that the kernel has two priority classes for the realtime class and for the variable priority class. threadjpriority idle sets the priority to for real time threads and to for variable priority threads. threadjpriority time critical sets the priority to for real time threads and to for variable priority threads. as we discussed in section . . . the kernel adjusts the priority of a thread dynamically depending on whether the thread is i o bound or cpu bound. the win api provides a method to disable this adjustment via setprocesspriorityboost and setthreadpriorityboostq functions. . . . thread synchronization a thread can be created in a suspended state the thread does not execute until another thread makes it eligible via the resumethreado function. the suspendthreado function does the opposite. these functions set a counter so if a thread is suspended twice it must be resumed twice before it can run. to synchronize the concurrent access to shared objects by threads the kernel provides synchronization objects such as semaphores and mutexes. in addition synchronization of threads can be achieved by use of the waitforsingleobjectq and waitformultipleobjectsq functions. another method of synchronization in the win api is the critical section. a critical section is a synchronized region of code that can be executed by only one thread at a time. a thread establishes a critical section by calling i n i t i a l i z e c r i t . programmer interface i c a l s e c t i o n . the application must call e n t e r c r i t i c a l s e c t i o n q hefore entering the critical section and leavecriticalsectiono after exiting the critical section. these two routines guarantee that if multiple threads attempt to enter the critical section concurrently only one thread at a time will be permitted to proceed the others will wait in the e n t e r c r i t i c a l s e c t i o n o routine. the critical section mechanism is faster than using kernel synchronization objects because it does not allocate kernel objects until it first encounters contention for the critical section. . . . fibers a fiber is user mode code that is scheduled according to a user defined scheduling algorithm. a process may have multiple fibers in it just as it may have multiple threads. a major difference between threads and fibers is that whereas threads can execute concurrently only one fiber at a time is permitted to execute even on multiprocessor hardware. this mechanism is included in windows xp to facilitate the porting of those legacy unix applications that were written for a fiber execution model. the system creates a fiber by calling either convertthreadtofiberq or createfiber . the primary difference between these functions is that createfiber does not begin executing the fiber that was created. to begin execution the application must call switchtofibero. the application can terminate a fiber by calling deletefiber . . . . thread pool repeated creation and deletion of threads can be expensive for applications and services that perform small amounts of work in each. the thread pool provides user mode programs with three services a queue to which work requests may be submitted via the queueuserworkltemq api an api that can be used to bind callbacks to waitable handles registerwaitforsingleobject and apis to bind callbacks to timeouts createtimerqueueo and createtimerqueuetimero . the thread pool's goal is to increase performance. threads are relatively expensive and a processor can only be executing one thing at a time no matter how many threads are used. the thread pool attempts to reduce the number of outstanding threads by slightly delaying work requests reusing each thread for many requests while providing enough threads to effectively utilize the machine's cpus. the wait and timer callback apis allow the thread pool to further reduce the number of threads in a process using far fewer threads than would be necessary if a process were to devote one thread to servicing each waitable handle or timeout. . . interprocess communication win api applications handle interprocess communication in several ways. one way is by sharing kernel objects. another way is by passing messages an approach that is particularly popular for windows gui applications. one thread can send a message to another thread or to a window by calling postmessageo postthreadmessageo sendmessageq sendthreadmessageo or sendmessagecallbackq. the difference between posting a mes chapter windows xp sage and sending a message is that the post routines are asynchronous? they return immediately and the calling thread does not know when the message is actually delivered. the send routines are synchronous they block the caller until the message has been delivered and processed. in addition to sending a message a thread can send data with the message. since processes have separate address spaces the data must be copied. the system copies data by calling sendmessageo to send a message of type wm copydata with a copydatastruct data structure that contains the length and address of the data to be transferred. when the message is sent windows xp copies the data to a new block of memory and gives the virtual address of the new block to the receiving process. unlike threads in the bit windows environment every win api thread has its own input queue from which it receives messages. all input is received via messages. this structure is more reliable than the shared input queue of bit windows because with separate queues it is no longer possible for one stuck application to block input to the other applications. if a win api application does not call getmessage to handle events on its input queue the queue fills up and after about five seconds the system marks the application as not responding . . . memory management the win api provides several ways for an application to use memory virtual memory memory mapped files heaps and thread local storage. . . . virtual memory an application calls virtualalloc to reserve or commit virtual memory and virtualfreeo to decommit or release the memory. these functions enable the application to specify the virtual address at which the memory is allocated. they operate on multiples of the memory page size and the starting address of an allocated region must be greater than x . examples of these functions appear in figure . . a process may lock some of its committed pages into physical memory by calling virtuallocko. the maximum number of pages a process can lock allocate mb at the top of our address space void buf virtualalloc oxlqoqcoc memjieserve mem top down pagejreadwrite commit the upper mb of the allocated space virtualalloc buf x x mem commit page readwrite do something with the memory now decommit the memory virtualfree buf x x memj ecommit release all of the allocated address space virtualfree buf mem release figure . code fragments for allocating virtual memory. . programmer interface is unless the process first calls setprocessworkingsetsizeo to increase the maximum working set size. . . . memory mapping files another way for an application to use memory is by memory mapping a file into its address space. memory mapping is also a convenient way for two processes to share memory both processes map the same file into their virtual memory memory mapping is a multistage process as you can see in the example in figure . . if a process wants to map some address space just to share a memory region with another process no file is needed. the process calls createfilemappingo with a file handle of oxffffffff and a particular size. the resulting file mapping object can be shared by inheritance by name lookup or by duplication. . . . heaps heaps provide a third way for applications to use memory. a heap in the win environment is a region of reserved address space. when a win api process is initialized it is created with a mb default heap. since many win api functions use the default heap access to the heap is synchronized to protect the heap's space allocation data structures from being damaged by concurrent updates by multiple threads. win api provides several heap management functions so that a process can allocate and manage a private heap. these functions are heapcreateq heapalloco heaprealloco heapsizeo heapfreeq and heapdestroyc . the win api also provides the heaplocko and heapunlocko functions to enable a thread to gain exclusive access to a heap. unlike virtuallocko these functions perform only synchronization they do not lock pages into physical memory. open the file or create it if it does not exist handle hfile createfile somef ile genericjiead generic.write file sharejread file.share.write null openjvlways file attribute normal null create the file mapping mb in size handle hmap createfilemapping hfile page readwritb sec commit x shm new get a view of the space mapped void buf mapviewoffile hmap filej apj ll.access c x do something with the mapped file now unmap the file unmapviewoffile buf closehandle hmap closehandle hfile figure . code fragments for memory mapping of a file. chapter windows xp reserve a slot for a variable dword var index tlsalloco set it to the value tlssetvalue var.index get the value int var tlsgetvalue var.index release the index tlsfree var.index figure . code for dynamic thread local storage. . . . thread local storage the fourth way for applications to use memory is through a thread local storage mechanism. functions that rely on global or static data typically fail to work properly in a multithreaded environment. for instance the c runtime function strtoko uses a static variable to keep track of its current position while parsing a string. for two concurrent threads to execute s t r t o k correctly they need separate current position variables. the thread local storage mechanism allocates global storage on a per thread basis. it provides both dynamic and static methods of creating thread local storage. the dynamic method is illustrated in figure . . to use a thread local static variable the application declares the variable as follows to ensure that every thread has its own private copy ..declspec thread dword cur pos 
 early computers were physically enormous machines run from a console. the programmer who was also the operator of the computer system would write a program and then would operate the program directly from the operator's console. first the program would be loaded manually into memory from the front panel switches one instruction at a time from paper tape or from punched cards. then the appropriate buttons would be pushed to set the starting address and to start the execution of the program. as the program ran the programmer operator could monitor its execution by the display lights on the console. if errors were discovered the programmer could halt the program examine the contents of memory and registers and debug the program directly from the console. output was printed or was punched onto paper tape or cards for later printing. . . dedicated computer systems as time went on additional software and hardware were developed. card readers line printers and magnetic tape became commonplace. assemblers loaders and linkers were designed to ease the programming task. libraries of common functions were created. common functions could then be copied chapter influential operating systems into a new program without having to be written again providing software reusability. the routines that performed i o were especially important. each new i o device had its own characteristics requiring careful programming. a special subroutine called a device driver was written for each i o device. a device driver knows how the buffers flags registers control bits and status bits for a particular device should be used. each type of device has its own driver. a simple task such as reading a character from a paper tape reader might involve complex sequences of device specific operations. rather than writing the necessary code every time the device driver was simply used from the library. later compilers for fortran cobol and other languages appeared making the programming task much easier but the operation of the computer more complex. to prepare a fortran program for execution for example the programmer would first need to load the fortran compiler into the computer. the compiler was normally kept on magnetic tape so the proper tape would need to be mounted on a tape drive. the program would be read through the card reader and written onto another tape. the fortran compiler produced assembly language output which then needed to be assembled. this procedure required mounting another tape with the assembler. the output of the assembler would need to be linked to supporting library routines. finally the binary object form of the program would be ready to execute. it could be loaded into memory and debugged from the console as before. a significant amount of set up time could be involved in the running of a job. each job consisted of many separate steps . loading the fortran compiler tape . running the compiler . unloading the compiler tape . loading the assembler tape . running the assembler . unloading the assembler tape . loading the object program . running the object program if an error occurred during any step the programmer operator might have to start over at the beginning. each job step might involve the loading and unloading of magnetic tapes paper tapes and punch cards. the job set up time was a real problem. while tapes were being mounted or the programmer was operating the console the cpu sat idle. remember that in the early days few computers were available and they were expensive. a computer might have cost millions of dollars not including the operational costs of power cooling programmers and so on. thus computer time was extremely valuable and owners wanted their computers to be used as much as possible. they needed high utilization to get as much as they could from their investments. . early systems . . shared computer systems ? the solution was two fold. first a professional computer operator was hired. the programmer no longer operated the machine. as soon as one job was finished the operator could start the next. since the operator had more experience with mounting tapes than a programmer set up time was reduced. the programmer provided whatever cards or tapes were needed as well as a short description of how the job was to be run. of course the operator could not debug an incorrect program at the console since the operator would not understand the program. therefore in the case of program error a dump of memory and registers was taken and the programmer had to debug from the dump. dumping the memory and registers allowed the operator to continue immediately with the next job but left the programmer with the more difficult debugging problem. second jobs with similar needs were batched together and run through the computer as a group to reduce set up time. for instance suppose the operator received one fortran job one cobol job and another fortran job. if she ran them in that order she would have to set up for fortran load the compiler tapes and so on then set up for cobol and then set up for fortran again. if she ran the two fortran programs as a batch however she could set up only once for fortran saving operator time. but there were still problems. for example when a job stopped the operator would have to notice that it had stopped by observing the console determine why it stopped normal or abnormal termination dump memory and register if necessary load the appropriate device with the next job and restart the computer. during this transition from one job to the next the cpu sat idle. to overcome this idle time people developed automatic job sequencing with this technique the first rudimentary operating systems were created. a small program called a resident monitor was created to transfer control automatically from one job to the next figure . . the resident monitor is always in memory or resident . loader monitor job sequencing control card interpreter user program area figure . memory layout for a resident monitor. chapter influential operating systems when the computer was turned on the resident monitor was invoked and it would transfer control to a program. when the program terminated it would return control to the resident monitor which would then go on to the next program. thus the resident monitor would automatically sequence from one program to another and from one job to another. but how would the resident monitor know which program to execute? previously the operator had been given a short description of what programs were to be run on what data. control cards were introduced to provide this information directly to the monitor. the idea is simple in addition to the program or data for a job the programmer included the control cards which contained directives to the resident monitor indicating what program to run. for example a normal user program might reqtiire one of three programs to run the fortran compiler ftn the assembler asm or the user's program run . we could use a separate control card for each of these ftn execute the fortran compiler. asm execute the assembler. run execute the user program. these cards tell the resident monitor which programs to run. we can use two additional control cards to define the boundaries of each job job first card of a job end final card of a job these two cards might be useful in accounting for the machine resources used by the programmer. parameters can be used to define the job name account number to be charged and so on. other control cards can be defined for other functions such as asking the operator to load or unload a tape. one problem with control cards is how to distinguish them from data or program cards. the usual solution is to identify them by a special character or pattern on the card. several systems used the dollar sign character in the first column to identify a control card. others used a different code. ibm's job control language jcl used slash marks in the first two columns. figure . shows a sample card deck setup for a simple batch system. a resident monitor thus has several identifiable parts the control card interpreter is responsible for reading and carrying out the instructions on the cards at the point of execution. the loader is invoked by the control card interpreter to load system programs and application programs into memory at intervals. the device drivers are used by both the control card interpreter and the loader for the system's i o devices to perform i o. often the system and application programs are linked to these same device drivers providing continuity in their operation as well as saving memory space and programming time. . early systems figure . card deck for a simple batch system. these batch systems work fairly well. the resident monitor provides automatic job sequencing as indicated by the control cards. when a control card indicates that a program is to be run the monitor loads the program into memory and transfers control to it. when the program completes it transfers control back to the monitor which reads the next control card loads the appropriate program and so on. this cycle is repeated until all control cards are interpreted for the job. then the monitor automatically continues with the next job. the switch to batch systems with automatic job sequencing was made to improve performance. the problem quite simply is that humans are considerably slower than the computer. consequently it is desirable to replace human operation with operating system software. automatic job sequencing eliminates the need for human set up time and job sequencing. as was pointed out above however even with this arrangement the cpu is often idle. the problem is the speed of the mechanical i o devices which are intrinsically slower than electronic devices. even a slow cpu works in the microsecond range with thousands of instructions executed per second. a fast card reader in contrast might read cards per minute or cards per second . thus the difference in speed between the cpu and its i o devices may be three orders of magnitude or more. over time of course improvements in technology resulted in faster i o devices. unfortunately cpu speeds increased even faster so that the problem was not only unresolved but also exacerbated. . . overlapped i o one common solution to the i o problem was to replace slow card readers input devices and line printers output devices with magnetic tape units. the majority of computer systems in the late s and early s were batch systems reading from card readers and writing to line printers or card punches. rather than have the cpu read directly from cards however the cards were first copied onto a magnetic tape via a separate device. when the tape was sufficiently full it was taken down and carried over to the computer. when a card was needed for input to a program the equivalent record was read from chapter influential operating systems cpu card reader line printer a cpu j card reader tape drives tape drives line printer b figure . operation of i o devices a online and b off line. the tape. similarly output was written to the tape and the contents of the tape were printed later. the card readers and line printers were operated off line rather than by the main computer figure . . an obvious advantage of off line operation was that the main computer was no longer constrained by the speed of the card readers and line printers but was limited only by the speed of the much faster magnetic tape units. the technique of using magnetic tape for all i o could be applied with any similar equipment such as card readers card punches plotters paper tape and printers . the real gain in off line operation comes from the possibility of using multiple reader to tape and tape to printer systems for one cpu. if the cpu can process input twice as fast as the reader can read cards then two readers working simultaneously can produce enough tape to keep the cpu busy. there is a disadvantage too however a longer delay in getting a particular job run. the job must first be read onto tape. then it must wait until enough other jobs are read onto the tape to fill it. the tape must then be rewound unloaded hand carried to the cpu and mounted on a free tape drive. this process is not unreasonable for batch systems of course. many similar jobs can be batched onto a tape before it is taken to the computer. although off line preparation of jobs continued for some time it was quickly replaced in most systems. disk systems became widely available and greatly improved on off line operation. the problem with tape systems was that the card reader could not write onto one end of the tape while the cpu read from the other. the entire tape had to be written before it was rewound and read because tapes are by nature sequential access devices. disk systems eliminated this problem by being random access devices. because the head is moved from one area of the disk to another a disk can switch rapidly from the area on the disk being used by the card reader to store new cards to the position needed by the cpu to read the next card. in a disk system cards are read directly from the card reader onto the disk. the location of card images is recorded in a table kept by the operating system. when a job is executed the operating system satisfies its requests for card reader input by reading from the disk. similarly when the job requests the printer to output a line that line is copied into a system buffer and is written to the disk. when the job is completed the output is actually printed. this form of processing is called spooling figure . the name is an acronym for
 disk card reader line printer figure . spooling. simultaneous peripheral operation on line. spooling in essence uses the disk as a huge buffer for reading as far ahead as possible on input devices and for storing output files until the output devices are able to accept them. spooling is also used for processing data at remote sites. the cpu sends the data via communication paths to a remote printer or accepts an entire input job from a remote card reader . the remote processing is done at its own speed with no cpu intervention. the cpu just needs to be notified when the processing is completed so that it can spool the next batch of data. spooling overlaps the i o of one job with the computation of other jobs. even in a simple system the spooler may be reading the input of one job while printing the output of a different job. during this time still another job or other jobs may be executed reading its cards from disk and printing its output lines onto the disk. spooling has a direct beneficial effect on the performance of the system. for the cost of some disk space and a few tables the computation of one job can overlap with the i o of other jobs. thus spooling can keep both the cpu and the i o devices working at much higher rates. spooling leads naturally to multiprogramming which is the foundation of all modern operating systems. . atlas the atlas operating system kilburn et al. howarth et al. was designed at the university of manchester in england in the late s and early s. many of its basic features that were novel at the time have become standard parts of modern operating systems. device drivers were a major part of the system. in addition system calls were added by a set of special instructions called extra codes. atlas was a batch operating system with spooling. spooling allowed the system to schedule jobs according to the availability of peripheral devices such as magnetic tape units paper tape readers paper tape punches line printers card readers and card punches. chapter influential operating systems the most remarkable feature of atlas however was its memory management. core memory was new and expensive at the time. many computers like the ibm used a drum for primary memory. the atlas system used a drum for its main memory but it had a small amount of core memory that was used as a cache for the drum. demand paging was used to transfer information between core memory and the drum automatically. the atlas system used a british computer with bit words. addresses were bits but were encoded in decimal which allowed only million words to be addressed. at that time this was an extremely large address space. the physical memory for atlas was a kb word drum and kb words of core. memory was divided into word pages providing frames in physical memory. an associative memory of registers implemented the mapping from a virtual address to a physical address. if a page fault occurred a page replacement algorithm was invoked. one memory frame was always kept empty so that a drum transfer could start immediately. the page replacement algorithm attempted to predict future memory accessing behavior based on past behavior. a reference bit for each frame was set whenever the frame was accessed. the reference bits were read into memory every instructions and the last values of these bits were retained. this history was used to define the time since the most recent reference h and the interval between the last two references t . pages were chosen for replacement in the following order . any page with t t . such a page is considered to be no longer in use. . if fi h for all pages then replace the page with the largest f fi. the page replacement algorithm assumes that programs access memory in loops. if the time between the last two references is t then another reference is expected fc time units later. if a reference does not occur t t it is assumed that the page is no longer being used and the page is replaced. if all pages are still in use then the page that will not be needed for the longest time is replaced. the time to the next reference is expected to be to h. . xds the xds operating system lichtenberger and pirtle was designed at the university of california at berkeley. like the atlas system it used paging for memory management. unlike the atlas system it was a time shared system. the paging was used only for relocation it was not used for demand paging. the virtual memory of any user process was made up of kb words whereas the physical memory was made up of kb words. each page was made up of kb words. the page table was kept in registers. since physical memory was larger than virtual memory several user processes could be in memory at the same time. the number of users could be increased by sharing of pages when the pages contained read only reentrant code. processes were kept on a drum and were swapped in and out of memory as necessary
 the xds system was constructed from a modified xds q. the modifications were typical of the changes made to a basic computer to allow an operating system to be written properly. a user monitor mode was added. certain instructions such as i o and halt were defined to be privileged. an attempt to execute a privileged instruction in user mode would trap to the operating system. a system call instruction was added to the user mode instruction set. this instruction was used to create new resources such as files allowing the operating system to manage the physical resources. files for example were allocated in word blocks on the drum. a bit map was used to manage free drum blocks. each file had an index block with pointers to the actual data blocks. index blocks were chained together. the xds system also provided system calls to allow processes to create start suspend and destroy subprocesses. a programmer could construct a system of processes. separate processes could share memory for communication and synchronization. process creation defined a tree structure where a process is the root and its subprocesses are nodes below it in the tree. each of the subprocesses could in turn create more subprocesses. . the the the operating system dijkstra mckeag and wilson was designed at the technische hogeschool at eindhoven in the netherlands. it was a batch system running on a dutch computer the el x with kb of bit words. the system was mainly noted for its clean design particularly its layer structure and its use of a set of concurrent processes employing semaphores for synchronization. unlike the xds system however the set of processes in the the system was static. the operating system itself was designed as a set of cooperating processes. in addition five user processes were created that served as the active agents to compile execute and print user programs. when one job was finished the process would return to the input queue to select another job. a priority cpu scheduling algorithm was used. the priorities were recomputed every seconds and were inversely proportional to the amount of cpu time used recently in the last to seconds . this scheme gave higher priority to o bound processes and to new processes. memory management was limited by the lack of hardware support. however since the system was limited and user programs could be written only in algol a software paging scheme was used. the algol compiler automatically generated calls to system routines wrhich made sure the requested information was in memory swapping if necessary. the backing store was a kb word drum. a word page was used with an l.ru page replacement strategy. another major concern of the the system was deadlock control. the banker's algorithm was used to provide deadlock avoidance. closely related to the the system is the venus system liskov . the venus system was also a layer structured design using semaphores to synchronize processes. the lower levels of the design were implemented in microcode however providing a much faster system. the memory management was chapter influential operating systems changed to a paged segmented memory. the system was also designed as a time sharing system rather than a batch system. . rc the rc system like the the system was notable primarily for its design concepts. it was designed for the danish computer by regnecentralen particularly by brinch hansen brinch hansen brindvhansen . the objective was not to design a batch system or a time sharing system or any other specific system. rather the goal was to create an operating system nucleus or kernel on which a complete operating system could be built. thus the system structure was layered and only the lower levels comprising the kernel were provided. the kernel supported a collection of concurrent processes. a round robin cpu scheduler was used. although processes could share memory the primary communication and synchronization mechanism was the message system provided by the kernel. processes could communicate with each other by exchanging fixed sized messages of eight words in length. all messages were stored in buffers from a common buffer pool. when a message buffer was no longer required it was returned to the common pool. a message queue was associated with each process. it contained all the messages that had been sent to that process but had not yet been received. messages were removed from the queue in fifo order. the system supported four primitive operations which were executed atomically send message in receiver in message out buffer wait message out sender out message out buffer send answer out result in message in buffer wait answer out result out message in buffer the last two operations allowed processes to exchange several messages at a time. these primitives required that a process service its message queue in fifo order and that it block itself while other processes were handling its messages. to remove these restrictions the developers provided two additional communication primitives that allowed a process to wait for the arrival of the next message or to answer and service its queue in any order wait event in previous buffer out next buffer out result get event out buffer i o devices were also treated as processes. the device drivers were code that converted the device interrupts and registers into messages. thus a process would write to a terminal by sending that terminal a message. the device driver would receive the message and output the character to the terminal. an input character would interrupt the system and transfer to
 a device driver. the device driver would create a message from the input character and send it to a waiting process
 the compatible time sharing system ctss corbato et al. was designed at mit as an experimental time sharing system. it was implemented on an ibm and eventually supported up to interactive users. the users were provided with a set of interactive commands that allowed them to manipulate files and to compile and run programs through a terminal. the had a kb memory made up of bit words. the monitor used kb words leaving kb for the users. user memory images were swapped between memory and a fast drum. cpu scheduling employed a multilevelfeedback queue algorithm. the time quantum for level i was i time units. if a program did not finish its cpu burst in one time quantum it was moved down to the next level of the queue giving it twice as much time. the program at the highest level with the shortest quantum was run first. the initial level of a program was determined by its size so that the time quantum was at least as long as the swap time. ctss was extremely successful and was in use as late as . although it was limited it succeeded in demonstrating that time sharing was a convenient and practical mode of computing. one result of ctss was increased development of time sharing systems. another result was the development of multics. . multics the multics operating system corbato and vyssotsky organick was designed at mit as a natural extension of ctss. ctss and other early time sharing systems were so successful that they created an immediate desire to proceed quickly to bigger and better systems. as larger computers became available the designers of ctss set out to create a time sharing utility. computing service would be provided like electrical power. large computer systems would be connected by telephone wires to terminals in offices and homes throughout a city. the operating system would be a time shared system running continuously with a vast file system of shared programs and data. multics was designed by a team from mit ge which later sold its computer department to honeywell and bell laboratories which dropped out of the project in . the basic ge computer was modified to a new computer system called the ge mainly by the addition of pagedsegmentation memory hardware. a virtual address was composed of an bit segment number and a bit word offset. the segments were then paged in kb word pages. the second chance page replacement algorithm was used. the segmented virtual address space was merged into the file system each segment was a file. segments were addressed by the name of the file. the file system itself was a multilevel tree structure allowing users to create their own subdirectory structures. chapter influential operating systems like ctss multics used a multilevel feedback queue for cpu scheduling. protection was accomplished through an access list associated with each file and a set of protection rings for executing processes. the system which was written almost entirely in pl comprised about lines of code. it was extended to a multiprocessor system allowing a cpu to be taken out of service for maintenance while the system continued running. . ibm os the longest line of operating system development is undoubtedly that of ibm computers. the early ibm computers such as the ibm and the ibm are prime examples of the development of common i o subroutines followed by development of a resident monitor privileged instructions memory protection and simple batch processing. these systems were developed separately often by each site independently. as a result ibm was faced with many different computers with different languages and different system software. the ibm was designed to alter this situation. the ibm was designed as a family of computers spanning the complete range from small business machines to large scientific machines. only one set of software would be needed for these systems which all used the same operating system os mealy et al. . this arrangement was intended to reduce maintenance problems for ibm and to allow users to move programs and applications freely from one ibm system to another. unfortunately os tried to be all things for all people. as a result it did none of its tasks especially well. the file system included a type field that defined the type of each file and different file types were defined for fixed length and variable length records and for blocked and unblocked files. contiguous allocation was used so the user had to guess the size of each output file. the job control language jcl added parameters for every possible option making it incomprehensible to the average user. the memory management routines were hampered by the architecture. although a base register addressing mode was used the program could access and modify the base register so that absolute addresses were generated by the cpu. this arrangement prevented dynamic relocation the program was bound to physical memory at load time. two separate versions of the operating system were produced os mpt used fixed regions and os mvt used variable regions. the system was written in assembly language by thousands of programmers resulting in millions of lines of code. the operating system itself required large amounts of memory for its code and tables. operating system overhead often consumed one half of the total cpu cycles. over the years new versions were released to add new features and to fix errors. however fixing one error often caused another in some remote part of the system so that the number of known errors in the system remained fairly constant. virtual memory was added to os with the change to the ibm architecture. the underlying hardware provided a segmented paged virtual memory. new versions of os used this hardware in different ways. os vs created one large virtual address space and ran os mft in that virtual memory. thus the operating system itself was paged as well as user programs. os vs
 release ran os mvt in virtual memory. finally os vs release w hich is now called mvs pro rided each user with his own virtual memory. mvs is still basically a batch operating system. the ctss system was run on an ibm but mit decided that the address space of the ibm's successor to the was too small for multics so they switched vendors. ibm then decided to create its own time sharing system tss lett and konigsford . like multics tss was supposed to be a large time shared utility. the basic architecture was modified in the model to provide virtual memory. several sites purchased the in anticipation of tss . tss was delayed however so other time sharing systems were developed as temporary systems until tss was available. a time sharing option tso was added to os . ibm's cambridge scientific center developed cms as a single user system and cp to provide a virtual machine to run it on meyer and seawright parmelee et al. . when tss was eventually delivered it was a failure. it was too large and too slow. as a result no site would switch from its temporary system to tss . today time sharing on ibm systems is largely provided either by tso under mvs or by cms under cp renamed vm . both tss and multics did not achieve commercial success. what went wrong with these systems? part of the problem was that these advanced systems were too large and too complex to be understood. another problem was the assumption that computing power would be available from a large remote computer. it now appears that most computing will be done by small individual machines personal computers not by large remote time shared systems that try to be all things to all users. . mach the mach operating system traces its ancestry to the accent operating system developed at carnegie mellon university cmu rashid and robertson . mach's communication system and philosophy are derived from accent but many other significant portions of the system for example the virtual memory system task and thread management were developed from scratch rashid tevanian et al. and accetta et al. . the mach scheduler was described in detail by tevanian et al. a and black . an early version of the mach shared memory and memory mapping system was presented by tevanian et al. b . the mach operating system was designed with the following three critical goals in mind . emulate . bsd unix so that the executable files from a unix system can run correctly under mach. . be a modern operating system that supports many memory models as well as parallel and distributed computing. . have a kernel that is simpler and easier to modify than is . bsd. mach's development followed an evolutionary path from bsd unix systems. mach code was initially developed inside the . bsd kernel with bsd chapter influential operating systems kernel components replaced by mach components as the mach components were completed. the bsd components were updated to . bsd when that became available. by the virtual memory and communication subsystems were running on the dec vax computer family including multiprocessor versions of the vax. versions for the ibm rt pc and for sun workstations followed shortly. then saw the completion of the encore multimax and sequent balance multiprocessor versions including task and thread support as well as the first official releases of the system release and release . through release mach provided compatibility with the corresponding bsd systems by including much of bsd's code in the kernel. the new features and capabilities of mach made the kernels in these releases larger than the corresponding bsd kernels. mach moved the bsd code outside of the kernel leaving a much smaller microkernel. this system implements only basic mach features in the kernel all unix specific code has been evicted to run in user mode servers. excluding unix specific code from the kernel allows the replacement of bsd with another operating system or the simultaneous execution of multiple operating system interfaces on top of the microkernel. in addition to bsd user mode implementations have been developed for dos the macintosh operating system and osf . this approach has similarities to the virtual machine concept but here the virtual machine is defined by software the mach kernel interface rather than by hardware. with release . mach became available on a wide variety of systems including single processor sun intel ibm and dec machines and multiprocessor dec sequent and encore systems. mach was propelled into the forefront of industry attention when the open software foundation osf announced in that it would use mach . as the basis for its new operating system osf . the initial release of osf occurred a year later and this system competed with unix system v release the operating system of choice at that time among unix international ui members. osf members included key technological companies such as ibm dec and hp. osf has since changed its direction and only dec unix is based on the mach kernel. mach . is also the basis for the operating system on the next workstation the brainchild of steve jobs of apple computer fame. unlike unix which was developed without regard for multiprocessing mach incorporates multiprocessing support throughout. its multiprocessing support is also exceedingly flexible ranging from shared memory systems to systems with no memory shared between processors. mach tises lightweight processes in the form of multiple threads of execution within one task or address space to support multiprocessing and parallel computation. its extensive use of messages as the only communication method ensures that protection mechanisms are complete and efficient. by integrating messages with the virtual memory system mach also ensures that messages can be handled efficiently. finally by having the virtual memory system use messages to communicate with the daemons managing the backing store mach provides great flexibility in the design and implementation of these memory objectmanaging tasks. by providing low level or primitive system calls from which more complex functions can be built mach reduces the size of the kernel while permitting operating system emulation at the user level much like ibm's virtual machine systems. exercises previous editions of operating system concepts included an entire chapter on mach. this chapter as it appeared in the fourth edition is available on the web http www.os book.com 
 there are of course other operating systems and most of them have interesting properties. the mcp operating system for the burroughs computer family mckeag and wilson was the first to be written in a systemprogramming language. it supported segmentation and multiple cpus. the scope operating system for the cdc mckeag and wilson was also a multi cpu system. the coordination and synchronization of the multiple processes were surprisingly well designed. tenex bobrow et al. was an early demand paging system for the pdp that has had a great influence on subsequent time sharing systems such as tops for the dec . the vms operating system for the vax is based on the rsx operating system for the pdp . cp m was the most common operating system for bit microcomputer systems few of which exist today ms dos is the most common system for bit microcomputers. graphical user interfaces guis have become popular to make computers easier to use the macintosh operating system and microsoft windows are the two leaders in this area