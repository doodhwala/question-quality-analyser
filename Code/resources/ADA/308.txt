Floyd's Algorithm for the All-Pairs Shortest-Paths Problem
Given a weighted connected graph (undirected or directed), the all-pairs shortest-
         paths problem asks to find the distances--i.e., the lengths of the shortest paths--
         from each vertex to all other vertices. This is one of several variations of the
         problem involving shortest paths in graphs. Because of its important applications
         to communications, transportation networks, and operations research, it has been
         thoroughly studied over the years. Among recent applications of the all-pairs
         shortest-path problem is precomputing distances for motion planning in computer
         games.
         It is convenient to record the lengths of shortest paths in an n × n matrix D
         called the distance matrix: the element dij in the ith row and the j th column of
         this matrix indicates the length of the shortest path from the ith vertex to the j th
         vertex. For an example, see Figure 8.14.
         We can generate the distance matrix with an algorithm that is very similar to
         Warshall's algorithm. It is called Floyd's algorithm after its co-inventor Robert W.
         Floyd.1 It is applicable to both undirected and directed weighted graphs provided
     1.  Floyd explicitly referenced Warshall's paper in presenting his algorithm [Flo62]. Three years earlier,
         Bernard Roy published essentially the same algorithm in the proceedings of the French Academy of
         Sciences [Roy59].
that they do not contain a cycle of a negative length. (The distance between any two
vertices in such a cycle can be made arbitrarily small by repeating the cycle enough
times.) The algorithm can be enhanced to find not only the lengths of the shortest
paths for all vertex pairs but also the shortest paths themselves (Problem 10 in this
section's exercises).
Floyd's algorithm computes the distance matrix of a weighted graph with n
vertices through a series of n × n matrices:
                       D(0), . . . , D(k-1), D(k), . . . , D(n).           (8.12)
Each of these matrices contains the lengths of shortest paths with certain con-
straints on the paths considered for the matrix in question. Specifically, the el-
ement di(jk) in the ith row and the j th column of matrix D(k) (i, j = 1, 2, . . . , n,
k = 0, 1, . . . , n) is equal to the length of the shortest path among all paths from
the ith vertex to the j th vertex with each intermediate vertex, if any, numbered
not higher than k. In particular, the series starts with D(0), which does not allow
any intermediate vertices in its paths; hence, D(0) is simply the weight matrix of the
graph. The last matrix in the series, D(n), contains the lengths of the shortest paths
among all paths that can use all n vertices as intermediate and hence is nothing
other than the distance matrix being sought.
As in Warshall's algorithm, we can compute all the elements of each matrix
D(k) from its immediate predecessor D(k-1) in series (8.12). Let di(jk) be the element
in the ith row and the j th column of matrix D(k). This means that di(jk) is equal to
the length of the shortest path among all paths from the ith vertex vi to the j th
vertex vj with their intermediate vertices numbered not higher than k:
vi, a list of intermediate vertices each numbered not higher than k, vj .  (8.13)
We can partition all such paths into two disjoint subsets: those that do not use the
kth vertex vk as intermediate and those that do. Since the paths of the first subset
have their intermediate vertices numbered not higher than k - 1, the shortest of
them is, by definition of our matrices, of length di(jk-1).
What is the length of the shortest path in the second subset? If the graph does
not contain a cycle of a negative length, we can limit our attention only to the
paths in the second subset that use vertex vk as their intermediate vertex exactly
once (because visiting vk more than once can only increase the path's length). All
such paths have the following form:
vi, vertices numbered  k - 1, vk, vertices numbered  k - 1, vj .
In other words, each of the paths is made up of a path from vi to vk with each
intermediate vertex numbered not higher than k - 1 and a path from vk to vj
with each intermediate vertex numbered not higher than k - 1. The situation is
depicted symbolically in Figure 8.15.
Since the length of the shortest path from vi to vk among the paths that use
intermediate vertices numbered not higher than k - 1 is equal to di(kk-1) and the
length of the shortest path from vk to vj among the paths that use intermediate
                                              d   (k  ­1)
                                                  ij
                             vi                                 vj
                             di(kk ­1)                          dk(kj ­1)
                                              vk
     FIGURE 8.15 Underlying  idea of Floyd's  algorithm.
     vertices numbered not higher than k - 1 is equal to dk(jk-1), the length of the shortest
     path among the paths that use the kth vertex is equal to di(kk-1) + dk(jk-1). Taking into
     account the lengths of the shortest paths in both subsets leads to the following
     recurrence:
                  di(jk) = min{di(jk-1),  di(kk-1) + dk(jk-1)}  for k  1,  di(j0) = wij .  (8.14)
     To put it another way, the element in row i and column j of the current distance
     matrix D(k-1) is replaced by the sum of the elements in the same row i and the
     column k and in the same column j and the row k if and only if the latter sum is
     smaller than its current value.
     The application of Floyd's algorithm to the graph in Figure 8.14 is illustrated
     in Figure 8.16.
     Here is pseudocode of Floyd's algorithm. It takes advantage of the fact that
     the next matrix in sequence (8.12) can be written over its predecessor.
     ALGORITHM        Floyd(W [1..n, 1..n])
     //Implements Floyd's algorithm for the all-pairs shortest-paths problem
     //Input: The weight matrix W of a graph with no negative-length cycle
     //Output: The distance matrix of the shortest paths' lengths
     DW           //is not necessary if W can be overwritten
     for k  1 to n do
     for i  1 to n do
                  for j  1 to n do
                      D[i, j ]  min{D[i, j ], D[i, k] + D[k, j ]}
     return D
     Obviously, the time efficiency of Floyd's algorithm is cubic--as is the time
     efficiency of Warshall's algorithm. In the next chapter, we examine Dijkstra's
     algorithm--another method for finding shortest paths.
a       2     b              a       b   c  d
                          a  0           3          Lengths of the shortest paths
3   6      7     D (0) =  b  2       0              with no intermediate vertices
                          c          7   0  1       (D (0) is simply the weight matrix).
c       1     d           d  6              0
                             a       b   c  d
                          a  0           3          Lengths of the shortest paths
                          b  2       0   5          with intermediate vertices numbered
                 D (1) =  c          7   0  1       not higher than 1, i.e., just a
                          d  6           9  0       (note two new shortest paths from
                                                    b to c and from d to c ).
                             a       b   c  d
                          a  0           3          Lengths of the shortest paths
                 D (2) =  b  2       0   5          with intermediate vertices numbered
                          c  9       7   0  1       not higher than 2, i.e., a and b
                          d  6           9  0       (note a new shortest path from c to a).
                             a       b   c  d
                          a  0       10  3  4       Lengths of the shortest paths
                          b  2       0   5  6       with intermediate vertices numbered
                 D (3) =  c  9       7   0  1       not higher than 3, i.e., a, b, and c
                          d  6    16     9  0       (note four new shortest paths from a to b,
                                                    from a to d, from b to d, and from d to b).
                             a       b   c  d
                          a  0       10  3  4       Lengths of the shortest paths
                          b  2       0   5  6       with intermediate vertices numbered
                 D (4) =  c  7       7   0  1       not higher than 4, i.e., a, b, c, and d
                          d  6       16  9  0       (note a new shortest path from c to a).
FIGURE 8.16      Application of Floyd's  algorithm  to the digraph shown. Updated elements
                 are shown in bold.
Exercises 8.4
1.  Apply Warshall's algorithm to find the transitive closure of the                  digraph  de-
    fined by the following adjacency matrix:
                                            0  1    0  0  
                                            0  0    1  0  
                                            0  0    0  1
                                            0  0    0  0
2.  a.  Prove that the time efficiency of Warshall's algorithm is cubic.
    b.  Explain why the time efficiency class of Warshall's algorithm is inferior to
        that of the traversal-based algorithm for sparse graphs represented by their
        adjacency lists.
     3.   Explain how to implement Warshall's algorithm without using extra memory
          for storing elements of the algorithm's intermediate matrices.
     4.   Explain how to restructure the innermost loop of the algorithm Warshall to
          make it run faster at least on some inputs.
     5.   Rewrite pseudocode of Warshall's algorithm assuming that the matrix rows
          are represented by bit strings on which the bitwise or operation can be per-
          formed.
     6.   a.  Explain how Warshall's algorithm can be used to determine whether a
              given digraph is a dag (directed acyclic graph). Is it a good algorithm for
              this problem?
          b. Is it a good idea to apply Warshall's algorithm to find the transitive closure
              of an undirected graph?
     7.   Solve the all-pairs shortest-path problem for the digraph with the following
          weight matrix:
                                         0  2          1  8     
                                         6  0  3       2        
                                               0       4  
                                               2       0  3
                                         3                0
     8.   Prove that the next matrix in sequence (8.12) of Floyd's algorithm can be
          written over its predecessor.
     9.   Give an example of a graph or a digraph with negative weights for which
          Floyd's algorithm does not yield the correct result.
     10.  Enhance Floyd's algorithm so that shortest paths themselves, not just their
          lengths, can be found.
     11.  Jack Straws     In the game of Jack Straws, a number of plastic or wooden
          "straws" are dumped on the table and players try to remove them one by
          one without disturbing the other straws. Here, we are only concerned with
          whether various pairs of straws are connected by a path of touching straws.
          Given a list of the endpoints for n > 1 straws (as if they were dumped on a large
          piece of graph paper), determine all the pairs of straws that are connected.
          Note that touching is connecting, but also that two straws can be connected
          indirectly via other connected straws. [1994 East-Central Regionals of the
          ACM International Collegiate Programming Contest]
     SUMMARY
          Dynamic programming is a technique for solving problems with overlapping
          subproblems. Typically, these subproblems arise from a recurrence relating a
          solution to a given problem with solutions to its smaller subproblems of the
same type. Dynamic programming suggests solving each smaller subproblem
once and recording the results in a table from which a solution to the original
problem can be then obtained.
Applicability of dynamic programming to an optimization problem requires
the problem to satisfy the principle of optimality: an optimal solution to any
of its instances must be made up of optimal solutions to its subinstances.
Among many other problems, the change-making problem with arbitrary coin
denominations can be solved by dynamic programming.
Solving a knapsack problem by a dynamic programming algorithm exempli-
fies an application of this technique to difficult problems of combinatorial
optimization.
The memory function technique seeks to combine the strengths of the top-
down and bottom-up approaches to solving problems with overlapping
subproblems. It does this by solving, in the top-down fashion but only
once, just the necessary subproblems of a given problem and recording their
solutions in a table.
Dynamic programming can be used for constructing an optimal binary search
tree for a given set of keys and known probabilities of searching for them.
Warshall's algorithm for finding the transitive closure and Floyd's algorithm
for the all-pairs shortest-paths problem are based on the idea that can be
interpreted as an application of the dynamic programming technique.

