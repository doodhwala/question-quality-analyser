In open hashing, keys are stored in linked lists attached to cells of a hash table.
     Each list contains all the keys hashed to its cell. Consider, as an example, the
     following list of words:
                   A, FOOL, AND, HIS, MONEY, ARE, SOON, PARTED.
     As a hash function, we will use the simple function for strings mentioned above,
     i.e., we will add the positions of a word's letters in the alphabet and compute the
     sum's remainder after division by 13.
     We start with the empty table. The first key is the word A; its hash value is
     h(A) = 1 mod 13 = 1. The second key--the word FOOL--is installed in the ninth
     cell since (6 + 15 + 15 + 12) mod 13 = 9, and so on. The final result of this process
     is given in Figure 7.5; note a collision of the keys ARE and SOON because h(ARE) =
     (1 + 18 + 5) mod 13 = 11 and h(SOON) = (19 + 15 + 15 + 14) mod 13 = 11.
     How do we search in a dictionary implemented as such a table of linked lists?
     We do this by simply applying to a search key the same procedure that was used
     for creating the table. To illustrate, if we want to search for the key KID in the hash
     table of Figure 7.5, we first compute the value of the same hash function for the
     key: h(KID) = 11. Since the list attached to cell 11 is not empty, its linked list may
     contain the search key. But because of possible collisions, we cannot tell whether
     this is the case until we traverse this linked list. After comparing the string KID first
     with the string ARE and then with the string SOON, we end up with an unsuccessful
     search.
     In general, the efficiency of searching depends on the lengths of the linked
     lists, which, in turn, depend on the dictionary and table sizes, as well as the quality
keys                A     FOOL     AND      HIS    MONEY         ARE  SOON  PARTED
hash addresses      1        9     6        10     7             11    11   12
0     1  2    3  4     5        6        7      8  9             10   11    12
                                                                            
      A                      AND   MONEY           FOOL          HIS  ARE   PARTED
                                                                       
                                                                      SOON
FIGURE 7.5 Example  of a  hash table construction  with separate chaining.
of the hash function. If the hash function distributes n keys among m cells of the
hash table about evenly, each list will be about n/m keys long. The ratio  = n/m,
called the load factor of the hash table, plays a crucial role in the efficiency of
hashing. In particular, the average number of pointers (chain links) inspected in
successful searches, S, and unsuccessful searches, U, turns out to be
                             S 1+           and    U = ,                        (7.4)
                                         2
respectively, under the standard assumptions of searching for a randomly selected
element and a hash function distributing keys uniformly among the table's cells.
These results are quite natural. Indeed, they are almost identical to searching
sequentially in a linked list; what we have gained by hashing is a reduction in
average list size by a factor of m, the size of the hash table.
   Normally, we want the load factor to be not far from 1. Having it too small
would imply a lot of empty lists and hence inefficient use of space; having it too
large would mean longer linked lists and hence longer search times. But if we
do have the load factor around 1, we have an amazingly efficient scheme that
makes it possible to search for a given key for, on average, the price of one or
two comparisons! True, in addition to comparisons, we need to spend time on
computing the value of the hash function for a search key, but it is a constant-time
operation, independent from n and m. Note that we are getting this remarkable
efficiency not only as a result of the method's ingenuity but also at the expense of
extra space.
   The two other dictionary operations--insertion and deletion--are almost
identical to searching. Insertions are normally done at the end of a list (but see
Problem 6 in this section's exercises for a possible modification of this rule).
Deletion is performed by searching for a key to be deleted and then removing
it from its list. Hence, the efficiency of these operations is identical to that of
searching, and they are all        (1) in the average case if the number of keys n is
about equal to the hash table's size m.
