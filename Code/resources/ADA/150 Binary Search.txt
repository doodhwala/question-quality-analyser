Binary search is a remarkably efficient algorithm for searching in a sorted array. It
          works by comparing a search key K with the array's middle element A[m]. If they
          match, the algorithm stops; otherwise, the same operation is repeated recursively
          for the first half of the array if K < A[m], and for the second half if K > A[m]:
                                                            K
                            A[0] . . . A[m - 1]          A[m]      A[m + 1] . . . A[n - 1] .
                                search here if                               search here if
                                   K <A[m]                                    K >A[m]
          As an example, let us apply binary search to searching for K = 70 in the array
          3                 14     27     31     39     42     55     70     74     81     85     93  98
          The iterations of the algorithm are given in the following table:
          index                 0      1      2      3      4      5      6      7      8      9      10  11  12
          value                 3      14     27     31     39     42     55     70     74     81     85  93  98
          iteration 1           l                                         m                                   r
          iteration 2                                                            l             m              r
          iteration 3                                                         l,m       r
          Though binary search is clearly based on a recursive idea, it can be easily
          implemented as a nonrecursive algorithm, too. Here is pseudocode of this nonre-
          cursive version.
ALGORITHM  BinarySearch(A[0..n - 1], K)
//Implements nonrecursive binary search
//Input: An array A[0..n - 1] sorted in ascending order and
//     a search key K
//Output: An index of the array's element that is equal to K
//     or -1 if there is no such element
l  0;  r n-1
while l  r do
    m      (l + r)/2
    if K = A[m] return m
    else if K < A[m] r  m - 1
    else l  m + 1
return -1
The standard way to analyze the efficiency of binary search is to count the number
of times the search key is compared with an element of the array. Moreover, for
the sake of simplicity, we will count the so-called three-way comparisons. This
assumes that after one comparison of K with A[m], the algorithm can determine
whether K is smaller, equal to, or larger than A[m].
How many such comparisons does the algorithm make on an array of n
elements? The answer obviously depends not only on n but also on the specifics of
a particular instance of the problem. Let us find the number of key comparisons
in the worst case Cworst(n). The worst-case inputs include all arrays that do not
contain a given search key, as well as some successful searches. Since after one
comparison the algorithm faces the same situation but for an array half the size,
we get the following recurrence relation for Cworst(n):
       Cworst (n) = Cworst ( n/2 ) + 1            for n > 1,  Cworst (1) = 1.  (4.3)
(Stop and convince yourself that n/2 must be, indeed, rounded down and that the
initial condition must be written as specified.)
We already encountered recurrence (4.3), with a different initial condition, in
Section 2.4 (see recurrence (2.4) and its solution there for n = 2k). For the initial
condition Cworst(1) = 1, we obtain
                      Cworst (2k) = k + 1 = log2 n + 1.                        (4.4)
Further, similarly to the case of recurrence (2.4) (Problem 7 in Exercises 2.4), the
solution given by formula (4.4) for n = 2k can be tweaked to get a solution valid
for an arbitrary positive integer n:
                Cworst (n) =          log2 n  +1=  log2(n + 1) .               (4.5)
Formula (4.5) deserves attention. First, it implies that the worst-case time
efficiency of binary search is in     (log n). Second, it is the answer we should have
         fully expected: since the algorithm simply reduces the size of the remaining array
         by about half on each iteration, the number of such iterations needed to reduce the
         initial size n to the final size 1 has to be about log2 n. Third, to reiterate the point
         made in Section 2.1, the logarithmic function grows so slowly that its values remain
         small even for very large values of n. In particular, according to formula (4.5),
         it will take no more than  log2(103 + 1)              = 10 three-way comparisons to find an
         element of a given value (or establish that there is no such element) in any sorted
         array of one thousand elements, and it will take no more than        log2(106 + 1)  = 20
         comparisons to do it for any sorted array of size one million!
         What can we say about the average-case efficiency of binary search? A so-
         phisticated analysis shows that the average number of key comparisons made by
         binary search is only slightly smaller than that in the worst case:
                                    Cavg(n)  log2 n.
         (More accurate formulas for the average number of comparisons in a successful
         and an unsuccessful search are Cayvegs (n)  log2 n - 1 and Canvog(n)  log2(n + 1),
         respectively.)
         Though binary search is an optimal searching algorithm if we restrict our op-
         erations only to comparisons between keys (see Section 11.2), there are searching
         algorithms (see interpolation search in Section 4.5 and hashing in Section 7.3) with
         a better average-case time efficiency, and one of them (hashing) does not even re-
         quire the array to be sorted! These algorithms do require some special calculations
         in addition to key comparisons, however. Finally, the idea behind binary search
         has several applications beyond searching (see, e.g., [Ben00]). In addition, it can be
         applied to solving nonlinear equations in one unknown; we discuss this continuous
         analogue of binary search, called the method of bisection, in Section 12.4.
