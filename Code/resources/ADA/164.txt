The Game of Nim
There are several well-known games that share the following features. There are
     two players, who move in turn. No randomness or hidden information is permitted:
     all players know all information about gameplay. A game is impartial: each player
     has the same moves available from the same game position. Each of a finite
     number of available moves leads to a smaller instance of the same game. The
     game ends with a win by one of the players (there are no ties). The winner is the
     last player who is able to move.
     A prototypical example of such games is Nim. Generally, the game is played
     with several piles of chips, but we consider the one-pile version first. Thus, there is
     a single pile of n chips. Two players take turns by removing from the pile at least
     one and at most m chips; the number of chips taken may vary from one move to
     another, but both the lower and upper limits stay the same. Who wins the game
     by taking the last chip, the player moving first or second, if both players make the
     best moves possible?
     Let us call an instance of the game a winning position for the player to
     move next if that player has a winning strategy, i.e., a sequence of moves that
     results in a victory no matter what moves the opponent makes. Let us call an
     instance of the game a losing position for the player to move next if every move
     available for that player leads to a winning position for the opponent. The standard
     approach to determining which positions are winning and which are losing is to
     investigate small values of n first. It is logical to consider the instance of n = 0 as
     a losing one for the player to move next because this player is the first one who
     cannot make a move. Any instance with 1  n  m chips is obviously a winning
     position for the player to move next (why?). The instance with n = m + 1 chips
     is a losing one because taking any allowed number of chips puts the opponent in
     a winning position. (See an illustration for m = 4 in Figure 4.16.) Any instance
     with m + 2  n  2m + 1 chips is a winning position for the player to move next
     because there is a move that leaves the opponent with m + 1 chips, which is a losing
                                1     6
                                2     7
             0                     5                               10
                                3     8
                                4     9
FIGURE 4.16  Illustration of one-pile Nim with the maximum number of chips that may
             be taken on each move m = 4. The numbers indicate n, the number of
             chips in the pile. The losing positions for the player to move are circled.
             Only winning moves from the winning positions are shown (in bold).
position. 2m + 2 = 2(m + 1) chips is the next losing position, and so on. It is not
difficult to see the pattern that can be formally proved by mathematical induction:
an instance with n chips is a winning position for the player to move next if and only
if n is not a multiple of m + 1. The winning strategy is to take n mod(m + 1) chips
on every move; any deviation from this strategy puts the opponent in a winning
position.
One-pile Nim has been known for a very long time. It appeared, in particular,
as the summation game in the first published book on recreational mathematics,
authored by Claude-Gaspar Bachet, a French aristocrat and mathematician, in
1612: a player picks a positive integer less than, say, 10, and then his opponent and
he take turns adding any integer less than 10; the first player to reach 100 exactly
is the winner [Dud70].
In general, Nim is played with I > 1 piles of chips of sizes n1, n2, . . . , nI . On
each move, a player can take any available number of chips, including all of them,
from any single pile. The goal is the same--to be the last player able to make a
move. Note that for I = 2, it is easy to figure out who wins this game and how.
Here is a hint: the answer for the game's instances with n1 = n2 differs from the
answer for those with n1 = n2.
A solution to the general case of Nim is quite unexpected because it is based
on the binary representation of the pile sizes. Let b1, b2, . . . , bI be the pile sizes
in binary. Compute their binary digital sum, also known as the nim sum, defined
as the sum of binary digits discarding any carry. (In other words, a binary digit
si in the sum is 0 if the number of 1's in the ith position in the addends is even,
and it is 1 if the number of 1's is odd.) It turns out that an instance of Nim is a
winning one for the player to move next if and only if its nim sum contains at least
one 1; consequently, Nim's instance is a losing instance if and only if its nim sum
contains only zeros. For example, for the commonly played instance with n1 = 3,
n2 = 4, n3 = 5, the nim sum is
                                     011
                                     100
                                     101
                                     010
     Since this sum contains a 1, the instance is a winning one for the player moving
     first. To find a winning move from this position, the player needs to change one of
     the three bit strings so that the new nim sum contains only 0's. It is not difficult to
     see that the only way to accomplish this is to remove two chips from the first pile.
         This ingenious solution to the game of Nim was discovered by Harvard math-
     ematics professor C. L. Bouton more than 100 years ago. Since then, mathemati-
     cians have developed a much more general theory of such games. An excellent
     account of this theory, with applications to many specific games, is given in the
     monograph by E. R. Berlekamp, J. H. Conway, and R. K. Guy [Ber03].
     Exercises 4.5
     1.  a.  If we measure an instance size of computing the greatest common divisor
             of m and n by the size of the second number n, by how much can the size
             decrease after one iteration of Euclid's algorithm?
         b. Prove that an instance size will always decrease at least by a factor of two
             after two successive iterations of Euclid's algorithm.
     2.  Apply quickselect to find the median of the list of numbers 9, 12, 5, 17, 20,
         30, 8.
     3.  Write pseudocode for a nonrecursive implementation of quickselect.
     4.  Derive the formula underlying interpolation search.
     5.  Give an example of the worst-case input for interpolation search and show
         that the algorithm is linear in the worst case.
     6.  a.  Find the smallest value of n for which log2 log2 n + 1 is greater than 6.
         b.  Determine which, if any, of the following assertions are true:
             i. log log n  o(log n)  ii. log log n        (log n)  iii. log log n   (log n)
     7.  a.  Outline an algorithm for finding the largest key in a binary search tree.
             Would you classify your algorithm as a variable-size-decrease algorithm?
         b. What is the time efficiency class of your algorithm in the worst case?
     8.  a.  Outline an algorithm for deleting a key from a binary search tree. Would
             you classify this algorithm as a variable-size-decrease algorithm?
         b. What is the time efficiency class of your algorithm in the worst case?
     9.  Outline a variable-size-decrease algorithm for constructing an Eulerian circuit
         in a connected graph with all vertices of even degrees.
10.  Mise`re one-pile Nim  Consider the so-called mise`re version of the one-pile
     Nim, in which the player taking the last chip loses the game. All the other
     conditions of the game remain the same, i.e., the pile contains n chips and on
     each move a player takes at least one but no more than m chips. Identify the
     winning and losing positions (for the player to move next) in this game.
11.  a.  Moldy chocolate   Two players take turns by breaking an m × n chocolate
         bar, which has one spoiled 1 × 1 square. Each break must be a single
         straight line cutting all the way across the bar along the boundaries between
         the squares. After each break, the player who broke the bar last eats the
         piece that does not contain the spoiled square.    The player left with the
         spoiled square loses the game. Is it better to go first or second in this game?
     b.  Write an interactive program to play this game with the computer. Your
         program should make a winning move in a winning position and a random
         legitimate move in a losing position.
12.  Flipping pancakes     There are n pancakes all of different sizes that are stacked
     on top of each other. You are allowed to slip a flipper under one of the
     pancakes and flip over the whole stack above the flipper. The purpose is to
     arrange pancakes according to their size with the biggest at the bottom. (You
     can see a visualization of this puzzle on the Interactive Mathematics Miscellany
     and Puzzles site [Bog].) Design an algorithm for solving this puzzle.
13.  You need to search for a given number in an n × n matrix in which every
     row and every column is sorted in increasing order. Can you design a O(n)
     algorithm for this problem? [Laa10]
SUMMARY
     Decrease-and-conquer is a general algorithm design technique, based on
     exploiting a relationship between a solution to a given instance of a problem
     and a solution to a smaller instance of the same problem. Once such a
     relationship is established, it can be exploited either top down (usually
     recursively) or bottom up.
     There are three major variations of decrease-and-conquer:
     .   decrease-by-a-constant, most often by one (e.g., insertion sort)
     .   decrease-by-a-constant-factor, most often by the factor of two (e.g., binary
         search)
     .   variable-size-decrease (e.g., Euclid's algorithm)
     Insertion sort is a direct application of the decrease-(by one)-and-conquer
     technique to the sorting problem. It is a  (n2) algorithm both in the worst
     and average cases, but it is about twice as fast on average than in the worst case.
     The algorithm's notable advantage is a good performance on almost-sorted
     arrays.
     A digraph is a graph with directions on its edges. The topological sorting
     problem asks to list vertices of a digraph in an order such that for every edge
     of the digraph, the vertex it starts at is listed before the vertex it points to.
     This problem has a solution if and only if a digraph is a dag (directed acyclic
     graph), i.e., it has no directed cycles.
     There are two algorithms for solving the topological sorting problem. The first
     one is based on depth-first search; the second is based on a direct application
     of the decrease-by-one technique.
     The decrease-by-one technique is a natural approach to developing algo-
     rithms for generating elementary combinatorial objects. The most efficient
     class of such algorithms are minimal-change algorithms. However, the num-
     ber of combinatorial objects grows so fast that even the best algorithms are
     of practical interest only for very small instances of such problems.
     Binary search is a very efficient algorithm for searching in a sorted array. It
     is a principal example of a decrease-by-a-constant-factor algorithm. Other
     examples include exponentiation by squaring, identifying a fake coin with a
     balance scale, Russian peasant multiplication, and the Josephus problem.
     For some decrease-and-conquer algorithms, the size reduction varies from
     one iteration of the algorithm to another. Examples of such variable-size-
     decrease algorithms include Euclid's algorithm, the partition-based algorithm
     for the selection problem, interpolation search, and searching and insertion in
     a binary search tree. Nim exemplifies games that proceed through a series of
     diminishing instances of the same game.
